{"cells":[{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"TXOLlhisilDx","executionInfo":{"status":"ok","timestamp":1766933299916,"user_tz":-330,"elapsed":27,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":224,"outputs":[]},{"cell_type":"code","source":["# !pip install -q torch_geometric\n","# !pip install -q class_resolver\n","# !pip3 install pymatting\n"],"metadata":{"id":"tAONEptfind3","executionInfo":{"status":"ok","timestamp":1766933299919,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":225,"outputs":[]},{"cell_type":"code","execution_count":226,"metadata":{"id":"VSYEATM8HJ2u","executionInfo":{"status":"ok","timestamp":1766933299923,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import random\n","import copy\n","import scipy.sparse as sp\n","\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","from torchvision import models\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","\n","# torch-geometric imports\n","from torch_geometric.nn import GATConv\n","from torch_geometric.data import Data"]},{"cell_type":"code","execution_count":227,"metadata":{"id":"vVdNNNJreeQ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766933299983,"user_tz":-330,"elapsed":58,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"f95570a8-11f0-40bf-a995-1f38d6841a42"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available: True\n","GPU Name: NVIDIA RTX A4000\n"]}],"source":["import torch\n","print(\"CUDA available:\", torch.cuda.is_available())\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"]},{"cell_type":"code","execution_count":228,"metadata":{"id":"JinL9v8LHM8o","executionInfo":{"status":"ok","timestamp":1766933299985,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["data = np.load('/home/snu/Downloads/breastmnist_224.npz', allow_pickle=True)"]},{"cell_type":"code","execution_count":229,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":371,"status":"ok","timestamp":1766933300357,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"xrNOqnjlHUXo","outputId":"fbf187d6-1b69-4b92-9836-985bd9657e7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Images, labels shapes: torch.Size([780, 3, 224, 224]) torch.Size([780])\n"]}],"source":["all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","images = all_images.astype(np.float32) / 255.0\n","images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N,3,224,224)\n","\n","X = torch.tensor(images)\n","y = torch.tensor(all_labels).long()\n","print(\"Images, labels shapes:\", X.shape, y.shape)\n","\n","dataset = TensorDataset(X, y)\n","class0_indices = [i for i in range(len(y)) if y[i] == 0]\n","class1_indices = [i for i in range(len(y)) if y[i] == 1]\n","\n","random.seed(42)\n","sampled_class0 = random.sample(class0_indices, min(1000, len(class0_indices)))\n","sampled_class1 = random.sample(class1_indices, min(1000, len(class1_indices)))\n","\n","combined_indices = sampled_class0 + sampled_class1\n","random.shuffle(combined_indices)\n","\n","final_dataset = Subset(dataset, combined_indices)\n","final_loader = DataLoader(final_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":230,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8886,"status":"ok","timestamp":1766933309244,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"egLJ3D9jHmdP","outputId":"20c5744a-1ed2-4585-a50d-22e6fcce4627","scrolled":true},"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /home/snu/.cache/torch/hub/facebookresearch_dino_main\n"]},{"output_type":"stream","name":"stdout","text":["Feature shape: (780, 768)\n","Label shape: (780,)\n"]}],"source":["import torch\n","import timm\n","import numpy as np\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","vit = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n","vit.eval().to(device)\n","\n","vit_feats = []\n","y_list = []\n","\n","with torch.no_grad():\n","    for imgs, lbls in final_loader:\n","        imgs = imgs.to(device)\n","        feats = vit(imgs)\n","        vit_feats.append(feats.cpu())\n","        y_list.extend(lbls.cpu().tolist())\n","\n","F = torch.cat(vit_feats, dim=0).numpy().astype(np.float32)\n","y_labels = np.array(y_list).astype(np.int64)\n","\n","print(\"Feature shape:\", F.shape)\n","print(\"Label shape:\", y_labels.shape)\n","features = F"]},{"cell_type":"code","execution_count":231,"metadata":{"id":"UHJ387UneeQ2","executionInfo":{"status":"ok","timestamp":1766933309246,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def sim(h1, h2, tau=0.2):\n","    z1 = nnFn.normalize(h1, dim=-1, p=2)\n","    z2 = nnFn.normalize(h2, dim=-1, p=2)\n","    return torch.mm(z1, z2.t()) / tau\n","\n","def contrastive_loss_wo_cross_network(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    intra_sim = f(sim(h1, h1))\n","    inter_sim = f(sim(h1, h2))\n","    return -torch.log(inter_sim.diag() /\n","                     (intra_sim.sum(dim=-1) + inter_sim.sum(dim=-1) - intra_sim.diag()))\n","\n","def contrastive_loss_wo_cross_view(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    cross_sim = f(sim(h1, z))\n","    return -torch.log(cross_sim.diag() / cross_sim.sum(dim=-1))"]},{"cell_type":"code","execution_count":232,"metadata":{"id":"AEcGcMk8eeQ2","executionInfo":{"status":"ok","timestamp":1766933309309,"user_tz":-330,"elapsed":62,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.PReLU(), # nn.ELU()\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n"]},{"cell_type":"code","execution_count":253,"metadata":{"id":"ZH7dcLiNeeQ3","executionInfo":{"status":"ok","timestamp":1766945949345,"user_tz":-330,"elapsed":9,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch_geometric.nn import GATConv\n","\n","class GATEncoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ, cut=0, heads=1):\n","        super(GATEncoder, self).__init__()\n","        self.device = device\n","        self.activ = activ\n","        self.cut = cut\n","        self.heads = heads\n","        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True)\n","        self.bn1 = nn.BatchNorm1d(hidden_dim * heads)\n","        self.dropout1 = nn.Dropout(0.3)\n","        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=heads, concat=True)\n","        self.bn2 = nn.BatchNorm1d(hidden_dim * heads)\n","        self.dropout2 = nn.Dropout(0.3)\n","        self.gat3 = GATConv(hidden_dim * heads, hidden_dim, heads=1, concat=False)\n","        self.bn3 = nn.BatchNorm1d(hidden_dim)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","\n","        x = self.gat1(x, edge_index)\n","        x = self.dropout1(x)\n","        x = self.bn1(x)\n","\n","        x = self.gat2(x, edge_index)\n","        x = self.dropout2(x)\n","        x = self.bn2(x)\n","\n","        x = self.gat3(x, edge_index)\n","        x = self.dropout3(x)\n","        x = self.bn3(x)\n","\n","        logits = self.mlp(x)\n","        return logits\n"]},{"cell_type":"code","execution_count":254,"metadata":{"id":"DqH_j0szeeQ3","executionInfo":{"status":"ok","timestamp":1766945950604,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class EMA():  # Moving Average update\n","    def __init__(self, beta):\n","        super().__init__()\n","        self.beta = beta\n","\n","    def update_average(self, old, new):\n","        if old is None:\n","            return new\n","        return old * self.beta + (1 - self.beta) * new\n","\n","def update_moving_average(ema_updater, ma_model, current_model):\n","    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n","        old_weight, up_weight = ma_params.data, current_params.data\n","        ma_params.data = ema_updater.update_average(old_weight, up_weight)"]},{"cell_type":"code","execution_count":255,"metadata":{"id":"fLr3BCPkeeQ3","executionInfo":{"status":"ok","timestamp":1766945952373,"user_tz":-330,"elapsed":13,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","from torch_geometric.nn import GATConv\n","import copy\n","\n","class GAT(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ, cut=0,\n","                 heads=1, moving_average_decay=0.5):\n","        super(GAT, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","        self.cut = cut\n","        self.beta = 0.6\n","\n","\n","        self.online_encoder = GATEncoder(input_dim, hidden_dim, device, activ, cut, heads)\n","        self.target_encoder = copy.deepcopy(self.online_encoder)\n","\n","\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_dim)\n","\n","        self.loss = self.cut_loss if cut else self.modularity_loss\n","        self.target_ema_updater = EMA(moving_average_decay)\n","\n","    def reset_moving_average(self):\n","        del self.target_encoder\n","        self.target_encoder = None\n","\n","    def update_ma(self):\n","        assert self.target_encoder is not None, 'target encoder has not been created yet'\n","        update_moving_average(self.target_ema_updater, self.target_encoder, self.online_encoder)\n","\n","    def forward(self, data1, data2):\n","\n","        x1 = self.online_encoder(data1)\n","        logits1 = self.online_predictor(x1)\n","        S1 = nnFn.softmax(logits1, dim=1)\n","\n","\n","        x2 = self.online_encoder(data2)\n","        logits2 = self.online_predictor(x2)\n","        S2 = nnFn.softmax(logits2, dim=1)\n","\n","        with torch.no_grad():\n","            target_proj_one = self.target_encoder(data1).detach()\n","            target_proj_two = self.target_encoder(data2).detach()\n","\n","\n","        l1 = self.beta * contrastive_loss_wo_cross_network(x1, x2, target_proj_two) + \\\n","          (1.0 - self.beta) * contrastive_loss_wo_cross_view(x1, x2, target_proj_two)\n","\n","        l2 = self.beta * contrastive_loss_wo_cross_network(x2, x1, target_proj_one) + \\\n","          (1.0 - self.beta) * contrastive_loss_wo_cross_view(x2, x1, target_proj_one)\n","\n","        return S1, S2, logits1, logits2, l1, l2\n","\n","    def modularity_loss(self, A, S):\n","        C = nnFn.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A)\n","        B = A - torch.ger(d, d) / (2 * m)\n","\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        k = torch.norm(I_S)\n","        n = S.shape[0]\n","\n","        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n","\n","        return modularity_term + collapse_reg_term\n","\n","    def cut_loss(self, A, S):\n","        S = nnFn.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / den)\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n","\n","        return mincut_loss + ortho_loss"]},{"cell_type":"code","execution_count":236,"metadata":{"id":"X4_3_cvSeeQ4","executionInfo":{"status":"ok","timestamp":1766933309364,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def create_adj(features, cut, alpha=1.0):\n","    \"\"\"Return a dense W0 matrix (only once), as you originally used for A1 / unsup loss.\n","       We still create the dense matrix once, but all augmentations below work with edge_index.\n","    \"\"\"\n","    F_norm = features / np.linalg.norm(features, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = (W * (W >= alpha)).astype(np.float32)\n","    return W"]},{"cell_type":"code","execution_count":237,"metadata":{"id":"PfC51cQDeeQ4","executionInfo":{"status":"ok","timestamp":1766933309409,"user_tz":-330,"elapsed":44,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def edge_index_from_dense(W):\n","    \"\"\"Return edge_index as numpy array shape (2, E) and edge_weight vector.\"\"\"\n","    rows, cols = np.nonzero(W > 0)\n","    edge_index = np.vstack([rows, cols]).astype(np.int64)\n","    edge_weight = W[rows, cols].astype(np.float32)\n","    return edge_index, edge_weight"]},{"cell_type":"code","execution_count":238,"metadata":{"id":"JsXN7D23eeQ4","executionInfo":{"status":"ok","timestamp":1766933309411,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def build_adj_list(edge_index_np, num_nodes):\n","    \"\"\"Build adjacency list: list of neighbor arrays for each node (numpy).\"\"\"\n","    adj = [[] for _ in range(num_nodes)]\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    for s, d in zip(src, dst):\n","        adj[s].append(d)\n","    # convert to numpy arrays for speed\n","    adj = [np.array(neis, dtype=np.int64) if len(neis) > 0 else np.array([], dtype=np.int64) for neis in adj]\n","    return adj"]},{"cell_type":"code","execution_count":239,"metadata":{"id":"qR_yaOfWeeQ4","executionInfo":{"status":"ok","timestamp":1766933309413,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=None):\n","    \"\"\"Randomly drop edges from edge_index. Returns new edge_index (2 x E') and edge_weight placeholder.\"\"\"\n","    rng = np.random.default_rng(seed)\n","    E = edge_index_np.shape[1]\n","    keep_mask = rng.random(E) >= drop_percent\n","    new_edge_index = edge_index_np[:, keep_mask]\n","    return new_edge_index"]},{"cell_type":"code","execution_count":240,"metadata":{"id":"o5dCZStEeeQ4","executionInfo":{"status":"ok","timestamp":1766933309469,"user_tz":-330,"elapsed":55,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def aug_subgraph_edge_index(features_np, edge_index_np, adj_list, drop_percent=0.2, seed=None):\n","    \"\"\"\n","    Sample a subgraph by selecting s_node_num nodes via neighbor expansion (BFS-like),\n","    then return (sub_features, sub_edge_index) with node ids remapped to [0..s-1].\n","    \"\"\"\n","    rng = np.random.default_rng(seed)\n","    num_nodes = features_np.shape[0]\n","    s_node_num = int(num_nodes * (1 - drop_percent))\n","    if s_node_num < 1:\n","        s_node_num = 1\n","\n","    # choose a random center node\n","    center_node = int(rng.integers(0, num_nodes))\n","    sub_nodes = [center_node]\n","    front_idx = 0\n","\n","    # BFS-like expansion using adjacency list until we reach s_node_num\n","    while len(sub_nodes) < s_node_num and front_idx < len(sub_nodes):\n","        cur = sub_nodes[front_idx]\n","        neighbors = adj_list[cur]\n","        if neighbors.size > 0:\n","            # shuffle neighbors and try to add new ones\n","            nbrs_shuffled = neighbors.copy()\n","            rng.shuffle(nbrs_shuffled)\n","            for nb in nbrs_shuffled:\n","                if nb not in sub_nodes:\n","                    sub_nodes.append(int(nb))\n","                    if len(sub_nodes) >= s_node_num:\n","                        break\n","        front_idx += 1\n","        # if BFS stalls (no new neighbors), add random nodes\n","        if front_idx >= len(sub_nodes) and len(sub_nodes) < s_node_num:\n","            remaining = [n for n in range(num_nodes) if n not in sub_nodes]\n","            if not remaining:\n","                break\n","            add = int(rng.choice(remaining))\n","            sub_nodes.append(add)\n","\n","    sub_nodes = sorted(set(sub_nodes))\n","    node_map = {old: new for new, old in enumerate(sub_nodes)}\n","\n","    # induce edges that have both ends in sub_nodes\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    mask_src_in = np.isin(src, sub_nodes)\n","    mask_dst_in = np.isin(dst, sub_nodes)\n","    mask = mask_src_in & mask_dst_in\n","    sel_src = src[mask]\n","    sel_dst = dst[mask]\n","    # remap\n","    remapped_src = np.array([node_map[int(s)] for s in sel_src], dtype=np.int64)\n","    remapped_dst = np.array([node_map[int(d)] for d in sel_dst], dtype=np.int64)\n","    new_edge_index = np.vstack([remapped_src, remapped_dst])\n","    # sub features\n","    sub_features = features_np[sub_nodes, :].astype(np.float32)\n","    return sub_features, new_edge_index"]},{"cell_type":"code","execution_count":241,"metadata":{"id":"WjxU6EEKeeQ4","executionInfo":{"status":"ok","timestamp":1766933309477,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def load_data_from_edge_index(node_feats_np, edge_index_np, device):\n","    \"\"\"Return PyG Data with torch tensors. edge_index_np is (2, E) numpy.\"\"\"\n","    node_feats = torch.from_numpy(node_feats_np).float()\n","    edge_index = torch.from_numpy(edge_index_np.astype(np.int64)).long()\n","    return node_feats, edge_index"]},{"cell_type":"code","execution_count":242,"metadata":{"id":"_hBfbNCzDXtq","executionInfo":{"status":"ok","timestamp":1766933309479,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["# Required Parameters\n","cut = 0 # Consider n-cut loss OR Modularity loss (by default cut = 0)\n","alpha = 0.73 # Edge creation Threshold\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","K = 2  # Number of clusters\n","np.random.seed(42)\n","# Define all activation functions to test\n","define_activations = [\"SELU\", \"SiLU\", \"GELU\", \"ELU\", \"RELU\"]\n","activ = \"ELU\"\n","num_epochs = 5000\n","base_seed = 42\n","lambda_contrastive = 0.005\n","feats_dim = features.shape[1]"]},{"cell_type":"code","execution_count":243,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":105,"status":"ok","timestamp":1766933309585,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"XEKC0_x4Da-3","outputId":"f3ab71ca-a586-4f56-b4c9-f52f3df4343b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data0: Data(x=[780, 768], edge_index=[2, 266936])\n"]}],"source":["W0 = create_adj(features, cut, alpha)  # shape (N, N) dense\n","A1 = torch.from_numpy(W0).float().to(device)\n","\n","edge_index_np, edge_weight_np = edge_index_from_dense(W0)  # numpy edge_index (2, E)\n","num_nodes = features.shape[0]\n","adj_list = build_adj_list(edge_index_np, num_nodes)  # adjacency list for fast subgraph sampling\n","\n","# convert features to numpy (we'll slice them in augmentations)\n","features_np = features.copy()\n","\n","# Build initial Data object (full graph)\n","node_feats_full, edge_index_full = load_data_from_edge_index(features_np, edge_index_np, device)\n","data0 = Data(x=node_feats_full.to(device), edge_index=edge_index_full.to(device))\n","print(\"Data0:\", data0)"]},{"cell_type":"code","execution_count":244,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sGbMVrM5Dcbk","outputId":"f9e49075-9916-4c07-8811-a86d1bef80fd","executionInfo":{"status":"ok","timestamp":1766933752877,"user_tz":-330,"elapsed":443290,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Total: -0.2773 | Unsup: -0.2840 | Cont: 6.7667\n","Epoch 100 | Total: -0.3288 | Unsup: -0.3352 | Cont: 6.3746\n","Epoch 200 | Total: -0.3303 | Unsup: -0.3365 | Cont: 6.2271\n","Epoch 300 | Total: -0.3312 | Unsup: -0.3374 | Cont: 6.1583\n","Epoch 400 | Total: -0.3309 | Unsup: -0.3370 | Cont: 6.0879\n","Epoch 500 | Total: -0.3316 | Unsup: -0.3376 | Cont: 5.9594\n","Epoch 600 | Total: -0.3320 | Unsup: -0.3379 | Cont: 5.9301\n","Epoch 700 | Total: -0.3317 | Unsup: -0.3377 | Cont: 5.9540\n","Epoch 800 | Total: -0.3318 | Unsup: -0.3377 | Cont: 5.8747\n","Epoch 900 | Total: -0.3322 | Unsup: -0.3381 | Cont: 5.8754\n","Epoch 1000 | Total: -0.3319 | Unsup: -0.3378 | Cont: 5.8979\n","Epoch 1100 | Total: -0.3320 | Unsup: -0.3379 | Cont: 5.8516\n","Epoch 1200 | Total: -0.3317 | Unsup: -0.3375 | Cont: 5.8857\n","Epoch 1300 | Total: -0.3321 | Unsup: -0.3380 | Cont: 5.8782\n","Epoch 1400 | Total: -0.3322 | Unsup: -0.3381 | Cont: 5.8473\n","Epoch 1500 | Total: -0.3319 | Unsup: -0.3378 | Cont: 5.8525\n","Epoch 1600 | Total: -0.3321 | Unsup: -0.3379 | Cont: 5.8581\n","Epoch 1700 | Total: -0.3322 | Unsup: -0.3380 | Cont: 5.8277\n","Epoch 1800 | Total: -0.3321 | Unsup: -0.3379 | Cont: 5.8275\n","Epoch 1900 | Total: -0.3321 | Unsup: -0.3380 | Cont: 5.8832\n","Epoch 2000 | Total: -0.3322 | Unsup: -0.3380 | Cont: 5.8468\n","Epoch 2100 | Total: -0.3323 | Unsup: -0.3381 | Cont: 5.8269\n","Epoch 2200 | Total: -0.3322 | Unsup: -0.3381 | Cont: 5.8713\n","Epoch 2300 | Total: -0.3318 | Unsup: -0.3376 | Cont: 5.8607\n","Epoch 2400 | Total: -0.3318 | Unsup: -0.3377 | Cont: 5.8563\n"]}],"source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","feats_dim = features.shape[1]\n","model = GAT(feats_dim, 256, K, device, activ, cut).to(device)\n","optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","# Seeds\n","np.random.seed(42)\n","random.seed(42)\n","torch.manual_seed(42)\n","\n","# Training hyperparams (you can reduce num_epochs for debugging)\n","num_epochs = 2500\n","lambda_contrastive = 0.001\n","\n","for epoch in range(num_epochs):\n","    # --- Augmentations using edge_index or adjacency list (fast, sparse) ---\n","    # 1) Random edge drop on edge_index\n","    W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","\n","    # 2) Subgraph via adjacency list (returns sub_features and sub_edge_index)\n","    W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","    features_aug2 = features_np.copy()\n","\n","    # 3) Feature augmentations (keep these as numpy operations)\n","    # Feature dropout (column-wise)\n","    rng = np.random.default_rng(epoch)\n","    mask = rng.random(features_np.shape) >= 0.2\n","    features_aug1 = (features_np * mask.astype(np.float32))\n","\n","    # Feature cell dropout (random cell zeroing)\n","    aug_feat2 = features_np.copy()\n","    num_nodes_local, feat_dim = aug_feat2.shape\n","    drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","    # random positions to zero\n","    flat_idx = rng.choice(num_nodes_local * feat_dim, size=drop_feat_num, replace=False)\n","    rows = (flat_idx // feat_dim)\n","    cols = (flat_idx % feat_dim)\n","    aug_feat2[rows, cols] = 0.0\n","    features_aug2_feat = aug_feat2.astype(np.float32)\n","\n","    # --- Build PyG Data objects for the two views ---\n","    # view1: features_aug1 with W_aug1_edge_index\n","    node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","    data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","\n","    # view2: features_aug2 (from subgraph) and its edge_index\n","    node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, W_aug2_edge_index, device)\n","    data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","    # --- Training step ---\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","    unsup_loss = model.loss(A1, logits1)\n","    cont_loss = ((l1 + l2) / 2).mean()\n","    total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","    total_loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","    model.update_ma()\n","\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} | Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")"]},{"cell_type":"code","execution_count":245,"metadata":{"id":"jpYmDT0aDeG3","executionInfo":{"status":"ok","timestamp":1766933753041,"user_tz":-330,"elapsed":157,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["model.eval()\n","with torch.no_grad():\n","    S1, _, logits1, _, _, _ = model(data0, data0)\n","    y_pred_proba = nnFn.softmax(logits1, dim=1).cpu().numpy()\n","    y_pred = np.argmax(y_pred_proba, axis=1)"]},{"cell_type":"code","execution_count":246,"metadata":{"id":"NbofKb5oDhyj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766933753051,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"6110f152-7562-481b-8aa4-677cb9969c63"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 1]\n","[0.99999607 0.99999976 0.9999974  0.999637   0.99909294 0.9999367\n"," 0.9999887  0.99294287 0.99983037 0.9937949  0.97240496 1.\n"," 0.9998271  0.99999964 0.9976131  0.9897048  0.99975306 0.9392869\n"," 0.99840087 0.997712  ]\n"]}],"source":["print(y_pred[:20])\n","print(y_pred_proba.max(axis=-1)[:20])"]},{"cell_type":"code","execution_count":247,"metadata":{"id":"n1HmfThBDifY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766933753055,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"e26319cd-e318-4ddb-b340-e1e69afb97f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Score: 0.5846153846153846\n","Precision Score: 0.8170103092783505\n","Recall Score: 0.5561403508771929\n","F1 Score: 0.6617954070981211\n","Log Loss: 4.927305145455055\n"]}],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","acc_score = accuracy_score(y_labels, y_pred)\n","acc_score_inverted = accuracy_score(y_labels, 1 - y_pred)\n","if acc_score_inverted > acc_score:\n","    acc_score = acc_score_inverted\n","    y_pred = 1 - y_pred\n","\n","prec_score = precision_score(y_labels, y_pred)\n","rec_score = recall_score(y_labels, y_pred)\n","f1 = f1_score(y_labels, y_pred)\n","log_loss_value = log_loss(y_labels, y_pred_proba)\n","\n","print(\"Accuracy Score:\", acc_score)\n","print(\"Precision Score:\", prec_score)\n","print(\"Recall Score:\", rec_score)\n","print(\"F1 Score:\", f1)\n","print(\"Log Loss:\", log_loss_value)"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","\n","NUM_RUNS = 10\n","\n","acc_list = []\n","prec_list = []\n","rec_list = []\n","f1_list = []\n","logloss_list = []\n","\n","for run in range(NUM_RUNS):\n","    print(f\"\\n===== RUN {run+1}/{NUM_RUNS} =====\")\n","\n","    from torch.optim.lr_scheduler import StepLR\n","    from torch.optim import AdamW\n","\n","    feats_dim = features.shape[1]\n","    model = GAT(feats_dim, 256, K, device, activ, cut).to(device)\n","    optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","    scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","    # Seeds\n","    np.random.seed(42 + run)\n","    random.seed(42 + run)\n","    torch.manual_seed(42 + run)\n","\n","    num_epochs = 2500\n","    lambda_contrastive = 0.5\n","\n","    for epoch in range(num_epochs):\n","        # -------- augmentations --------\n","        W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","        W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","\n","        rng = np.random.default_rng(epoch)\n","        mask = rng.random(features_np.shape) >= 0.2\n","        features_aug1 = (features_np * mask.astype(np.float32))\n","\n","        aug_feat2 = features_np.copy()\n","        n_nodes, feat_dim = aug_feat2.shape\n","        drop_feat_num = int(n_nodes * feat_dim * 0.2)\n","        flat_idx = rng.choice(n_nodes * feat_dim, size=drop_feat_num, replace=False)\n","        rows = flat_idx // feat_dim\n","        cols = flat_idx % feat_dim\n","        aug_feat2[rows, cols] = 0.0\n","        features_aug2 = aug_feat2.astype(np.float32)\n","\n","        node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","        data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","\n","        node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, W_aug2_edge_index, device)\n","        data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","        # -------- training --------\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","        unsup_loss = model.loss(A1, logits1)\n","        cont_loss = ((l1 + l2) / 2).mean()\n","        total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","        total_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        model.update_ma()\n","\n","        if epoch % 100 == 0:\n","            print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} \"\n","                  f\"| Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")\n","\n","    # -------- evaluation --------\n","    model.eval()\n","    with torch.no_grad():\n","        S1, _, logits1, _, _, _ = model(data0, data0)\n","        y_pred_proba = nnFn.softmax(logits1, dim=1).cpu().numpy()\n","        y_pred = np.argmax(y_pred_proba, axis=1)\n","\n","    acc = accuracy_score(y_labels, y_pred)\n","    acc_inv = accuracy_score(y_labels, 1 - y_pred)\n","    if acc_inv > acc:   # flip if class labels reversed\n","        acc = acc_inv\n","        y_pred = 1 - y_pred\n","\n","    prec = precision_score(y_labels, y_pred)\n","    rec = recall_score(y_labels, y_pred)\n","    f1 = f1_score(y_labels, y_pred)\n","    ll = log_loss(y_labels, y_pred_proba)\n","\n","    acc_list.append(acc)\n","    prec_list.append(prec)\n","    rec_list.append(rec)\n","    f1_list.append(f1)\n","    logloss_list.append(ll)\n","\n","# -------- mean ± std printing --------\n","def mean_std(a):\n","    return np.mean(a), np.std(a)\n","\n","print(\"\\n===== FINAL RESULTS OVER 10 RUNS =====\")\n","m, s = mean_std(acc_list);     print(f\"Accuracy: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(prec_list);    print(f\"Precision: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(rec_list);     print(f\"Recall: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(f1_list);      print(f\"F1: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(logloss_list); print(f\"Log Loss: {m:.4f} ± {s:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UpzMqignfgoW","executionInfo":{"status":"ok","timestamp":1766950405691,"user_tz":-330,"elapsed":1961293,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"c2d66625-790f-44a0-d29c-44c4cd5e37ad"},"execution_count":257,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== RUN 1/10 =====\n","Epoch 0 | Total: 2.9449 | Unsup: -0.2838 | Cont: 6.4572\n","Epoch 100 | Total: 2.2610 | Unsup: -0.3285 | Cont: 5.1790\n","Epoch 200 | Total: 2.1487 | Unsup: -0.3333 | Cont: 4.9640\n","Epoch 300 | Total: 2.1233 | Unsup: -0.3339 | Cont: 4.9145\n","Epoch 400 | Total: 2.1079 | Unsup: -0.3351 | Cont: 4.8859\n","Epoch 500 | Total: 2.0778 | Unsup: -0.3349 | Cont: 4.8254\n","Epoch 600 | Total: 2.0555 | Unsup: -0.3340 | Cont: 4.7791\n","Epoch 700 | Total: 2.0450 | Unsup: -0.3349 | Cont: 4.7596\n","Epoch 800 | Total: 2.0188 | Unsup: -0.3346 | Cont: 4.7068\n","Epoch 900 | Total: 2.0174 | Unsup: -0.3344 | Cont: 4.7037\n","Epoch 1000 | Total: 1.9964 | Unsup: -0.3348 | Cont: 4.6625\n","Epoch 1100 | Total: 2.0281 | Unsup: -0.3342 | Cont: 4.7247\n","Epoch 1200 | Total: 2.0108 | Unsup: -0.3343 | Cont: 4.6903\n","Epoch 1300 | Total: 2.0021 | Unsup: -0.3347 | Cont: 4.6735\n","Epoch 1400 | Total: 1.9940 | Unsup: -0.3350 | Cont: 4.6580\n","Epoch 1500 | Total: 2.0198 | Unsup: -0.3351 | Cont: 4.7098\n","Epoch 1600 | Total: 1.9968 | Unsup: -0.3349 | Cont: 4.6634\n","Epoch 1700 | Total: 1.9899 | Unsup: -0.3352 | Cont: 4.6502\n","Epoch 1800 | Total: 2.0030 | Unsup: -0.3350 | Cont: 4.6760\n","Epoch 1900 | Total: 2.0215 | Unsup: -0.3341 | Cont: 4.7112\n","Epoch 2000 | Total: 2.0124 | Unsup: -0.3350 | Cont: 4.6948\n","Epoch 2100 | Total: 2.0114 | Unsup: -0.3345 | Cont: 4.6919\n","Epoch 2200 | Total: 2.0159 | Unsup: -0.3344 | Cont: 4.7008\n","Epoch 2300 | Total: 1.9914 | Unsup: -0.3350 | Cont: 4.6528\n","Epoch 2400 | Total: 2.0110 | Unsup: -0.3353 | Cont: 4.6926\n","\n","===== RUN 2/10 =====\n","Epoch 0 | Total: 3.0041 | Unsup: -0.2846 | Cont: 6.5774\n","Epoch 100 | Total: 2.3771 | Unsup: -0.3292 | Cont: 5.4127\n","Epoch 200 | Total: 2.2752 | Unsup: -0.3335 | Cont: 5.2174\n","Epoch 300 | Total: 2.1860 | Unsup: -0.3336 | Cont: 5.0391\n","Epoch 400 | Total: 2.1250 | Unsup: -0.3344 | Cont: 4.9188\n","Epoch 500 | Total: 2.1218 | Unsup: -0.3343 | Cont: 4.9122\n","Epoch 600 | Total: 2.1017 | Unsup: -0.3353 | Cont: 4.8740\n","Epoch 700 | Total: 2.0981 | Unsup: -0.3350 | Cont: 4.8662\n","Epoch 800 | Total: 2.0905 | Unsup: -0.3355 | Cont: 4.8521\n","Epoch 900 | Total: 2.0882 | Unsup: -0.3354 | Cont: 4.8472\n","Epoch 1000 | Total: 2.0807 | Unsup: -0.3349 | Cont: 4.8312\n","Epoch 1100 | Total: 2.0838 | Unsup: -0.3351 | Cont: 4.8378\n","Epoch 1200 | Total: 2.0816 | Unsup: -0.3349 | Cont: 4.8330\n","Epoch 1300 | Total: 2.0961 | Unsup: -0.3352 | Cont: 4.8627\n","Epoch 1400 | Total: 2.0830 | Unsup: -0.3356 | Cont: 4.8373\n","Epoch 1500 | Total: 2.0994 | Unsup: -0.3355 | Cont: 4.8698\n","Epoch 1600 | Total: 2.0795 | Unsup: -0.3355 | Cont: 4.8300\n","Epoch 1700 | Total: 2.0780 | Unsup: -0.3354 | Cont: 4.8268\n","Epoch 1800 | Total: 2.0852 | Unsup: -0.3348 | Cont: 4.8400\n","Epoch 1900 | Total: 2.0736 | Unsup: -0.3349 | Cont: 4.8172\n","Epoch 2000 | Total: 2.0815 | Unsup: -0.3354 | Cont: 4.8338\n","Epoch 2100 | Total: 2.0772 | Unsup: -0.3354 | Cont: 4.8253\n","Epoch 2200 | Total: 2.0842 | Unsup: -0.3355 | Cont: 4.8394\n","Epoch 2300 | Total: 2.0715 | Unsup: -0.3350 | Cont: 4.8129\n","Epoch 2400 | Total: 2.0810 | Unsup: -0.3350 | Cont: 4.8321\n","\n","===== RUN 3/10 =====\n","Epoch 0 | Total: 3.1853 | Unsup: -0.2791 | Cont: 6.9289\n","Epoch 100 | Total: 2.3370 | Unsup: -0.3264 | Cont: 5.3269\n","Epoch 200 | Total: 2.1499 | Unsup: -0.3320 | Cont: 4.9638\n","Epoch 300 | Total: 2.1402 | Unsup: -0.3334 | Cont: 4.9472\n","Epoch 400 | Total: 2.1284 | Unsup: -0.3336 | Cont: 4.9239\n","Epoch 500 | Total: 2.1021 | Unsup: -0.3335 | Cont: 4.8713\n","Epoch 600 | Total: 2.0757 | Unsup: -0.3344 | Cont: 4.8201\n","Epoch 700 | Total: 2.0783 | Unsup: -0.3347 | Cont: 4.8259\n","Epoch 800 | Total: 2.0640 | Unsup: -0.3349 | Cont: 4.7978\n","Epoch 900 | Total: 2.0696 | Unsup: -0.3351 | Cont: 4.8094\n","Epoch 1000 | Total: 2.0675 | Unsup: -0.3349 | Cont: 4.8048\n","Epoch 1100 | Total: 2.0677 | Unsup: -0.3348 | Cont: 4.8049\n","Epoch 1200 | Total: 2.0619 | Unsup: -0.3351 | Cont: 4.7940\n","Epoch 1300 | Total: 2.0629 | Unsup: -0.3348 | Cont: 4.7955\n","Epoch 1400 | Total: 2.0649 | Unsup: -0.3352 | Cont: 4.8002\n","Epoch 1500 | Total: 2.0635 | Unsup: -0.3353 | Cont: 4.7978\n","Epoch 1600 | Total: 2.0676 | Unsup: -0.3348 | Cont: 4.8049\n","Epoch 1700 | Total: 2.0543 | Unsup: -0.3347 | Cont: 4.7780\n","Epoch 1800 | Total: 2.0639 | Unsup: -0.3348 | Cont: 4.7975\n","Epoch 1900 | Total: 2.0675 | Unsup: -0.3346 | Cont: 4.8041\n","Epoch 2000 | Total: 2.0609 | Unsup: -0.3351 | Cont: 4.7920\n","Epoch 2100 | Total: 2.0799 | Unsup: -0.3347 | Cont: 4.8292\n","Epoch 2200 | Total: 2.0685 | Unsup: -0.3344 | Cont: 4.8057\n","Epoch 2300 | Total: 2.0519 | Unsup: -0.3350 | Cont: 4.7738\n","Epoch 2400 | Total: 2.0611 | Unsup: -0.3349 | Cont: 4.7919\n","\n","===== RUN 4/10 =====\n","Epoch 0 | Total: 3.1951 | Unsup: -0.2827 | Cont: 6.9556\n","Epoch 100 | Total: 2.3767 | Unsup: -0.3257 | Cont: 5.4048\n","Epoch 200 | Total: 2.1899 | Unsup: -0.3325 | Cont: 5.0450\n","Epoch 300 | Total: 2.1714 | Unsup: -0.3334 | Cont: 5.0097\n","Epoch 400 | Total: 2.1339 | Unsup: -0.3343 | Cont: 4.9363\n","Epoch 500 | Total: 2.1195 | Unsup: -0.3337 | Cont: 4.9066\n","Epoch 600 | Total: 2.0942 | Unsup: -0.3346 | Cont: 4.8576\n","Epoch 700 | Total: 2.1012 | Unsup: -0.3345 | Cont: 4.8712\n","Epoch 800 | Total: 2.0973 | Unsup: -0.3348 | Cont: 4.8641\n","Epoch 900 | Total: 2.1065 | Unsup: -0.3347 | Cont: 4.8824\n","Epoch 1000 | Total: 2.0792 | Unsup: -0.3347 | Cont: 4.8278\n","Epoch 1100 | Total: 2.0727 | Unsup: -0.3347 | Cont: 4.8148\n","Epoch 1200 | Total: 2.1078 | Unsup: -0.3343 | Cont: 4.8842\n","Epoch 1300 | Total: 2.0864 | Unsup: -0.3348 | Cont: 4.8423\n","Epoch 1400 | Total: 2.0746 | Unsup: -0.3352 | Cont: 4.8195\n","Epoch 1500 | Total: 2.0843 | Unsup: -0.3349 | Cont: 4.8384\n","Epoch 1600 | Total: 2.0899 | Unsup: -0.3353 | Cont: 4.8505\n","Epoch 1700 | Total: 2.0756 | Unsup: -0.3347 | Cont: 4.8207\n","Epoch 1800 | Total: 2.0904 | Unsup: -0.3344 | Cont: 4.8498\n","Epoch 1900 | Total: 2.0822 | Unsup: -0.3345 | Cont: 4.8335\n","Epoch 2000 | Total: 2.0752 | Unsup: -0.3351 | Cont: 4.8206\n","Epoch 2100 | Total: 2.0824 | Unsup: -0.3353 | Cont: 4.8353\n","Epoch 2200 | Total: 2.1047 | Unsup: -0.3343 | Cont: 4.8781\n","Epoch 2300 | Total: 2.0744 | Unsup: -0.3349 | Cont: 4.8186\n","Epoch 2400 | Total: 2.0820 | Unsup: -0.3346 | Cont: 4.8332\n","\n","===== RUN 5/10 =====\n","Epoch 0 | Total: 3.3546 | Unsup: -0.2848 | Cont: 7.2788\n","Epoch 100 | Total: 2.4043 | Unsup: -0.3271 | Cont: 5.4628\n","Epoch 200 | Total: 2.2036 | Unsup: -0.3323 | Cont: 5.0718\n","Epoch 300 | Total: 2.1805 | Unsup: -0.3333 | Cont: 5.0275\n","Epoch 400 | Total: 2.1663 | Unsup: -0.3342 | Cont: 5.0009\n","Epoch 500 | Total: 2.1393 | Unsup: -0.3346 | Cont: 4.9478\n","Epoch 600 | Total: 2.1162 | Unsup: -0.3348 | Cont: 4.9021\n","Epoch 700 | Total: 2.1273 | Unsup: -0.3346 | Cont: 4.9239\n","Epoch 800 | Total: 2.1039 | Unsup: -0.3342 | Cont: 4.8763\n","Epoch 900 | Total: 2.1146 | Unsup: -0.3353 | Cont: 4.8998\n","Epoch 1000 | Total: 2.0962 | Unsup: -0.3346 | Cont: 4.8615\n","Epoch 1100 | Total: 2.0926 | Unsup: -0.3351 | Cont: 4.8554\n","Epoch 1200 | Total: 2.1035 | Unsup: -0.3348 | Cont: 4.8767\n","Epoch 1300 | Total: 2.0994 | Unsup: -0.3351 | Cont: 4.8691\n","Epoch 1400 | Total: 2.0993 | Unsup: -0.3350 | Cont: 4.8686\n","Epoch 1500 | Total: 2.1015 | Unsup: -0.3352 | Cont: 4.8735\n","Epoch 1600 | Total: 2.1179 | Unsup: -0.3344 | Cont: 4.9044\n","Epoch 1700 | Total: 2.0927 | Unsup: -0.3347 | Cont: 4.8548\n","Epoch 1800 | Total: 2.0968 | Unsup: -0.3350 | Cont: 4.8635\n","Epoch 1900 | Total: 2.1223 | Unsup: -0.3348 | Cont: 4.9142\n","Epoch 2000 | Total: 2.0986 | Unsup: -0.3351 | Cont: 4.8673\n","Epoch 2100 | Total: 2.0981 | Unsup: -0.3345 | Cont: 4.8651\n","Epoch 2200 | Total: 2.0972 | Unsup: -0.3344 | Cont: 4.8633\n","Epoch 2300 | Total: 2.0894 | Unsup: -0.3349 | Cont: 4.8486\n","Epoch 2400 | Total: 2.0990 | Unsup: -0.3349 | Cont: 4.8677\n","\n","===== RUN 6/10 =====\n","Epoch 0 | Total: 3.2658 | Unsup: -0.2733 | Cont: 7.0782\n","Epoch 100 | Total: 2.3756 | Unsup: -0.3232 | Cont: 5.3976\n","Epoch 200 | Total: 2.1835 | Unsup: -0.3292 | Cont: 5.0253\n","Epoch 300 | Total: 2.1594 | Unsup: -0.3325 | Cont: 4.9838\n","Epoch 400 | Total: 2.1411 | Unsup: -0.3317 | Cont: 4.9457\n","Epoch 500 | Total: 2.1343 | Unsup: -0.3328 | Cont: 4.9342\n","Epoch 600 | Total: 2.1074 | Unsup: -0.3334 | Cont: 4.8816\n","Epoch 700 | Total: 2.1227 | Unsup: -0.3336 | Cont: 4.9124\n","Epoch 800 | Total: 2.1002 | Unsup: -0.3338 | Cont: 4.8680\n","Epoch 900 | Total: 2.1089 | Unsup: -0.3337 | Cont: 4.8851\n","Epoch 1000 | Total: 2.1020 | Unsup: -0.3340 | Cont: 4.8721\n","Epoch 1100 | Total: 2.1011 | Unsup: -0.3340 | Cont: 4.8703\n","Epoch 1200 | Total: 2.1294 | Unsup: -0.3344 | Cont: 4.9276\n","Epoch 1300 | Total: 2.0932 | Unsup: -0.3339 | Cont: 4.8542\n","Epoch 1400 | Total: 2.0892 | Unsup: -0.3338 | Cont: 4.8459\n","Epoch 1500 | Total: 2.1097 | Unsup: -0.3338 | Cont: 4.8870\n","Epoch 1600 | Total: 2.1015 | Unsup: -0.3343 | Cont: 4.8716\n","Epoch 1700 | Total: 2.0844 | Unsup: -0.3341 | Cont: 4.8371\n","Epoch 1800 | Total: 2.0852 | Unsup: -0.3341 | Cont: 4.8386\n","Epoch 1900 | Total: 2.1124 | Unsup: -0.3331 | Cont: 4.8910\n","Epoch 2000 | Total: 2.0860 | Unsup: -0.3343 | Cont: 4.8405\n","Epoch 2100 | Total: 2.1076 | Unsup: -0.3336 | Cont: 4.8823\n","Epoch 2200 | Total: 2.1025 | Unsup: -0.3337 | Cont: 4.8724\n","Epoch 2300 | Total: 2.0958 | Unsup: -0.3343 | Cont: 4.8601\n","Epoch 2400 | Total: 2.0869 | Unsup: -0.3342 | Cont: 4.8422\n","\n","===== RUN 7/10 =====\n","Epoch 0 | Total: 3.2095 | Unsup: -0.2850 | Cont: 6.9890\n","Epoch 100 | Total: 2.3431 | Unsup: -0.3257 | Cont: 5.3376\n","Epoch 200 | Total: 2.1846 | Unsup: -0.3314 | Cont: 5.0320\n","Epoch 300 | Total: 2.1505 | Unsup: -0.3332 | Cont: 4.9674\n","Epoch 400 | Total: 2.1362 | Unsup: -0.3341 | Cont: 4.9405\n","Epoch 500 | Total: 2.1183 | Unsup: -0.3344 | Cont: 4.9053\n","Epoch 600 | Total: 2.1120 | Unsup: -0.3353 | Cont: 4.8946\n","Epoch 700 | Total: 2.1135 | Unsup: -0.3347 | Cont: 4.8963\n","Epoch 800 | Total: 2.0965 | Unsup: -0.3351 | Cont: 4.8632\n","Epoch 900 | Total: 2.1057 | Unsup: -0.3350 | Cont: 4.8815\n","Epoch 1000 | Total: 2.1044 | Unsup: -0.3351 | Cont: 4.8790\n","Epoch 1100 | Total: 2.0879 | Unsup: -0.3357 | Cont: 4.8472\n","Epoch 1200 | Total: 2.0871 | Unsup: -0.3356 | Cont: 4.8455\n","Epoch 1300 | Total: 2.0859 | Unsup: -0.3353 | Cont: 4.8425\n","Epoch 1400 | Total: 2.0864 | Unsup: -0.3354 | Cont: 4.8435\n","Epoch 1500 | Total: 2.0968 | Unsup: -0.3358 | Cont: 4.8651\n","Epoch 1600 | Total: 2.1030 | Unsup: -0.3356 | Cont: 4.8773\n","Epoch 1700 | Total: 2.0820 | Unsup: -0.3357 | Cont: 4.8355\n","Epoch 1800 | Total: 2.0782 | Unsup: -0.3355 | Cont: 4.8275\n","Epoch 1900 | Total: 2.0969 | Unsup: -0.3350 | Cont: 4.8637\n","Epoch 2000 | Total: 2.0971 | Unsup: -0.3355 | Cont: 4.8653\n","Epoch 2100 | Total: 2.0918 | Unsup: -0.3351 | Cont: 4.8540\n","Epoch 2200 | Total: 2.1032 | Unsup: -0.3352 | Cont: 4.8768\n","Epoch 2300 | Total: 2.0972 | Unsup: -0.3355 | Cont: 4.8655\n","Epoch 2400 | Total: 2.0908 | Unsup: -0.3357 | Cont: 4.8528\n","\n","===== RUN 8/10 =====\n","Epoch 0 | Total: 3.0069 | Unsup: -0.2835 | Cont: 6.5807\n","Epoch 100 | Total: 2.2931 | Unsup: -0.3298 | Cont: 5.2456\n","Epoch 200 | Total: 2.1282 | Unsup: -0.3333 | Cont: 4.9229\n","Epoch 300 | Total: 2.1062 | Unsup: -0.3340 | Cont: 4.8804\n","Epoch 400 | Total: 2.1031 | Unsup: -0.3346 | Cont: 4.8756\n","Epoch 500 | Total: 2.0794 | Unsup: -0.3337 | Cont: 4.8261\n","Epoch 600 | Total: 2.0635 | Unsup: -0.3347 | Cont: 4.7964\n","Epoch 700 | Total: 2.0617 | Unsup: -0.3341 | Cont: 4.7916\n","Epoch 800 | Total: 2.0337 | Unsup: -0.3349 | Cont: 4.7373\n","Epoch 900 | Total: 2.0334 | Unsup: -0.3338 | Cont: 4.7343\n","Epoch 1000 | Total: 2.0214 | Unsup: -0.3344 | Cont: 4.7116\n","Epoch 1100 | Total: 2.0019 | Unsup: -0.3346 | Cont: 4.6731\n","Epoch 1200 | Total: 2.0080 | Unsup: -0.3343 | Cont: 4.6847\n","Epoch 1300 | Total: 1.9951 | Unsup: -0.3343 | Cont: 4.6587\n","Epoch 1400 | Total: 1.9984 | Unsup: -0.3349 | Cont: 4.6667\n","Epoch 1500 | Total: 2.0090 | Unsup: -0.3345 | Cont: 4.6869\n","Epoch 1600 | Total: 2.0099 | Unsup: -0.3344 | Cont: 4.6885\n","Epoch 1700 | Total: 1.9916 | Unsup: -0.3349 | Cont: 4.6530\n","Epoch 1800 | Total: 2.0038 | Unsup: -0.3342 | Cont: 4.6759\n","Epoch 1900 | Total: 2.0030 | Unsup: -0.3346 | Cont: 4.6752\n","Epoch 2000 | Total: 1.9989 | Unsup: -0.3352 | Cont: 4.6683\n","Epoch 2100 | Total: 1.9833 | Unsup: -0.3344 | Cont: 4.6352\n","Epoch 2200 | Total: 2.0083 | Unsup: -0.3340 | Cont: 4.6847\n","Epoch 2300 | Total: 2.0148 | Unsup: -0.3345 | Cont: 4.6987\n","Epoch 2400 | Total: 1.9986 | Unsup: -0.3345 | Cont: 4.6663\n","\n","===== RUN 9/10 =====\n","Epoch 0 | Total: 3.2868 | Unsup: -0.2809 | Cont: 7.1355\n","Epoch 100 | Total: 2.3501 | Unsup: -0.3277 | Cont: 5.3556\n","Epoch 200 | Total: 2.1568 | Unsup: -0.3326 | Cont: 4.9787\n","Epoch 300 | Total: 2.1527 | Unsup: -0.3327 | Cont: 4.9707\n","Epoch 400 | Total: 2.1193 | Unsup: -0.3340 | Cont: 4.9065\n","Epoch 500 | Total: 2.1128 | Unsup: -0.3347 | Cont: 4.8951\n","Epoch 600 | Total: 2.0821 | Unsup: -0.3346 | Cont: 4.8333\n","Epoch 700 | Total: 2.0857 | Unsup: -0.3350 | Cont: 4.8413\n","Epoch 800 | Total: 2.0855 | Unsup: -0.3345 | Cont: 4.8400\n","Epoch 900 | Total: 2.0919 | Unsup: -0.3351 | Cont: 4.8539\n","Epoch 1000 | Total: 2.0718 | Unsup: -0.3353 | Cont: 4.8142\n","Epoch 1100 | Total: 2.0783 | Unsup: -0.3350 | Cont: 4.8266\n","Epoch 1200 | Total: 2.0825 | Unsup: -0.3348 | Cont: 4.8346\n","Epoch 1300 | Total: 2.0717 | Unsup: -0.3350 | Cont: 4.8134\n","Epoch 1400 | Total: 2.0669 | Unsup: -0.3353 | Cont: 4.8043\n","Epoch 1500 | Total: 2.0726 | Unsup: -0.3350 | Cont: 4.8152\n","Epoch 1600 | Total: 2.0777 | Unsup: -0.3356 | Cont: 4.8266\n","Epoch 1700 | Total: 2.0666 | Unsup: -0.3354 | Cont: 4.8041\n","Epoch 1800 | Total: 2.0708 | Unsup: -0.3352 | Cont: 4.8120\n","Epoch 1900 | Total: 2.0719 | Unsup: -0.3354 | Cont: 4.8145\n","Epoch 2000 | Total: 2.0668 | Unsup: -0.3355 | Cont: 4.8045\n","Epoch 2100 | Total: 2.0671 | Unsup: -0.3351 | Cont: 4.8043\n","Epoch 2200 | Total: 2.0726 | Unsup: -0.3345 | Cont: 4.8141\n","Epoch 2300 | Total: 2.0667 | Unsup: -0.3353 | Cont: 4.8040\n","Epoch 2400 | Total: 2.0705 | Unsup: -0.3351 | Cont: 4.8112\n","\n","===== RUN 10/10 =====\n","Epoch 0 | Total: 2.9736 | Unsup: -0.2815 | Cont: 6.5101\n","Epoch 100 | Total: 2.2999 | Unsup: -0.3295 | Cont: 5.2588\n","Epoch 200 | Total: 2.1444 | Unsup: -0.3325 | Cont: 4.9538\n","Epoch 300 | Total: 2.1155 | Unsup: -0.3337 | Cont: 4.8984\n","Epoch 400 | Total: 2.1113 | Unsup: -0.3343 | Cont: 4.8911\n","Epoch 500 | Total: 2.1025 | Unsup: -0.3344 | Cont: 4.8737\n","Epoch 600 | Total: 2.0486 | Unsup: -0.3343 | Cont: 4.7659\n","Epoch 700 | Total: 2.0196 | Unsup: -0.3345 | Cont: 4.7081\n","Epoch 800 | Total: 1.9958 | Unsup: -0.3347 | Cont: 4.6612\n","Epoch 900 | Total: 2.0017 | Unsup: -0.3348 | Cont: 4.6731\n","Epoch 1000 | Total: 2.0018 | Unsup: -0.3349 | Cont: 4.6735\n","Epoch 1100 | Total: 1.9935 | Unsup: -0.3349 | Cont: 4.6567\n","Epoch 1200 | Total: 1.9721 | Unsup: -0.3346 | Cont: 4.6134\n","Epoch 1300 | Total: 1.9883 | Unsup: -0.3349 | Cont: 4.6465\n","Epoch 1400 | Total: 2.0012 | Unsup: -0.3349 | Cont: 4.6722\n","Epoch 1500 | Total: 1.9864 | Unsup: -0.3350 | Cont: 4.6427\n","Epoch 1600 | Total: 1.9789 | Unsup: -0.3350 | Cont: 4.6278\n","Epoch 1700 | Total: 1.9769 | Unsup: -0.3351 | Cont: 4.6240\n","Epoch 1800 | Total: 1.9909 | Unsup: -0.3350 | Cont: 4.6518\n","Epoch 1900 | Total: 2.0033 | Unsup: -0.3348 | Cont: 4.6761\n","Epoch 2000 | Total: 1.9814 | Unsup: -0.3348 | Cont: 4.6325\n","Epoch 2100 | Total: 1.9817 | Unsup: -0.3351 | Cont: 4.6335\n","Epoch 2200 | Total: 1.9965 | Unsup: -0.3341 | Cont: 4.6613\n","Epoch 2300 | Total: 1.9767 | Unsup: -0.3352 | Cont: 4.6238\n","Epoch 2400 | Total: 1.9734 | Unsup: -0.3350 | Cont: 4.6168\n","\n","===== FINAL RESULTS OVER 10 RUNS =====\n","Accuracy: 0.6101 ± 0.0498\n","Precision: 0.7880 ± 0.0460\n","Recall: 0.6468 ± 0.0974\n","F1: 0.7046 ± 0.0521\n","Log Loss: 4.4007 ± 1.4209\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","\n","NUM_RUNS = 10\n","\n","acc_list = []\n","prec_list = []\n","rec_list = []\n","f1_list = []\n","logloss_list = []\n","\n","for run in range(NUM_RUNS):\n","    print(f\"\\n===== RUN {run+1}/{NUM_RUNS} =====\")\n","\n","    from torch.optim.lr_scheduler import StepLR\n","    from torch.optim import AdamW\n","\n","    feats_dim = features.shape[1]\n","    model = ARMA(feats_dim, 256, K, device, activ, cut).to(device)\n","    optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","    scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","    # Seeds\n","    np.random.seed(42 + run)\n","    random.seed(42 + run)\n","    torch.manual_seed(42 + run)\n","\n","    num_epochs = 2500\n","    lambda_contrastive = 0.001\n","\n","    for epoch in range(num_epochs):\n","        # -------- augmentations --------\n","        W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","        W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","\n","        rng = np.random.default_rng(epoch)\n","        mask = rng.random(features_np.shape) >= 0.2\n","        features_aug1 = (features_np * mask.astype(np.float32))\n","\n","        aug_feat2 = features_np.copy()\n","        n_nodes, feat_dim = aug_feat2.shape\n","        drop_feat_num = int(n_nodes * feat_dim * 0.2)\n","        flat_idx = rng.choice(n_nodes * feat_dim, size=drop_feat_num, replace=False)\n","        rows = flat_idx // feat_dim\n","        cols = flat_idx % feat_dim\n","        aug_feat2[rows, cols] = 0.0\n","        features_aug2 = aug_feat2.astype(np.float32)\n","\n","        node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","        data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","\n","        node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, W_aug2_edge_index, device)\n","        data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","        # -------- training --------\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","        unsup_loss = model.loss(A1, logits1)\n","        cont_loss = ((l1 + l2) / 2).mean()\n","        total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","        total_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        model.update_ma()\n","\n","        if epoch % 100 == 0:\n","            print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} \"\n","                  f\"| Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")\n","\n","    # -------- evaluation --------\n","    model.eval()\n","    with torch.no_grad():\n","        S1, _, logits1, _, _, _ = model(data0, data0)\n","        y_pred_proba = nnFn.softmax(logits1, dim=1).cpu().numpy()\n","        y_pred = np.argmax(y_pred_proba, axis=1)\n","\n","    acc = accuracy_score(y_labels, y_pred)\n","    acc_inv = accuracy_score(y_labels, 1 - y_pred)\n","    if acc_inv > acc:   # flip if class labels reversed\n","        acc = acc_inv\n","        y_pred = 1 - y_pred\n","\n","    prec = precision_score(y_labels, y_pred)\n","    rec = recall_score(y_labels, y_pred)\n","    f1 = f1_score(y_labels, y_pred)\n","    ll = log_loss(y_labels, y_pred_proba)\n","\n","    acc_list.append(acc)\n","    prec_list.append(prec)\n","    rec_list.append(rec)\n","    f1_list.append(f1)\n","    logloss_list.append(ll)\n","\n","# -------- mean ± std printing --------\n","def mean_std(a):\n","    return np.mean(a), np.std(a)\n","\n","print(\"\\n===== FINAL RESULTS OVER 10 RUNS =====\")\n","m, s = mean_std(acc_list);     print(f\"Accuracy: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(prec_list);    print(f\"Precision: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(rec_list);     print(f\"Recall: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(f1_list);      print(f\"F1: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(logloss_list); print(f\"Log Loss: {m:.4f} ± {s:.4f}\")\n"],"metadata":{"id":"0xhXm8SXVUX4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":248,"metadata":{"id":"j5M6xJcWeeQ5","executionInfo":{"status":"ok","timestamp":1766933753058,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["# num_runs = 10\n","# num_epochs = 5000\n","# lr = 1e-4\n","# weight_decay = 1e-4\n","# lambda_list = [0.001, 0.005, 0.009, 0.01, 0.05, 0.09, 0.1, 0.3, 0.5, 0.9, 1, 2, 5, 8]\n","# base_seed = 42\n","\n","# all_results = []\n","\n","# for lam in lambda_list:\n","#     print(f\"\\n================ LAMBDA = {lam} ================\\n\")\n","\n","#     acc_scores, prec_scores, rec_scores, f1_scores, log_losses = [], [], [], [], []\n","\n","#     for run in range(num_runs):\n","#         print(f\"\\n--- Run {run + 1}/{num_runs} ---\")\n","#         torch.manual_seed(base_seed + run)\n","#         np.random.seed(base_seed + run)\n","#         random.seed(base_seed + run)\n","\n","#         # --- Model Setup ---\n","#         model = GAT(feats_dim, 256, K, device, activ, cut).to(device)\n","#         optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","#         scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","#         for epoch in range(num_epochs):\n","#             # 1) Two random edge augmentations\n","#             W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","#             W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","\n","#             # 2) Feature augmentations\n","#             rng = np.random.default_rng(epoch)\n","#             mask = rng.random(features_np.shape) >= 0.2\n","#             features_aug1 = (features_np * mask.astype(np.float32))\n","#             features_aug2 = features_np.copy()\n","#             num_nodes_local, feat_dim = features_aug2.shape\n","#             drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","#             flat_idx = rng.choice(num_nodes_local * feat_dim, size=drop_feat_num, replace=False)\n","#             rows = (flat_idx // feat_dim)\n","#             cols = (flat_idx % feat_dim)\n","#             features_aug2[rows, cols] = 0.0\n","#             features_aug2_feat = features_aug2.astype(np.float32)\n","\n","#             # 3) Build Data views\n","#             node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","#             data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","#             node_feats2, edge_index2 = load_data_from_edge_index(features_aug2_feat, W_aug2_edge_index, device)\n","#             data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","#             # --- Training step ---\n","#             model.train()\n","#             optimizer.zero_grad()\n","\n","#             S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","#             unsup_loss = model.loss(A1, logits1)\n","#             cont_loss = ((l1 + l2) / 2).mean()\n","#             total_loss = unsup_loss + lam * cont_loss\n","\n","#             total_loss.backward()\n","#             optimizer.step()\n","#             scheduler.step()\n","#             model.update_ma()\n","\n","#             if epoch % 500 == 0:\n","#                 print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} | Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")\n","\n","#         # --- Evaluation ---\n","#         model.eval()\n","#         with torch.no_grad():\n","#             S1, _, logits1, _, _, _ = model(data0, data0)\n","#             y_pred_proba = nnFn.softmax(logits1, dim=1).cpu().numpy()\n","#             y_pred = np.argmax(y_pred_proba, axis=1)\n","\n","#         acc = accuracy_score(y_labels, y_pred)\n","#         acc_inv = accuracy_score(y_labels, 1 - y_pred)\n","#         if acc_inv > acc:\n","#             acc = acc_inv\n","#             y_pred = 1 - y_pred\n","\n","#         prec = precision_score(y_labels, y_pred)\n","#         rec = recall_score(y_labels, y_pred)\n","#         f1 = f1_score(y_labels, y_pred)\n","#         ll = log_loss(y_labels, y_pred_proba)\n","\n","#         acc_scores.append(acc)\n","#         prec_scores.append(prec)\n","#         rec_scores.append(rec)\n","#         f1_scores.append(f1)\n","#         log_losses.append(ll)\n","\n","#         print(f\"Run {run + 1} Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n","\n","#     # --- Aggregate Results ---\n","#     lambda_results = {\n","#         \"lambda\": lam,\n","#         \"accuracy\": (np.mean(acc_scores), np.std(acc_scores)),\n","#         \"precision\": (np.mean(prec_scores), np.std(prec_scores)),\n","#         \"recall\": (np.mean(rec_scores), np.std(rec_scores)),\n","#         \"f1\": (np.mean(f1_scores), np.std(f1_scores)),\n","#         \"log_loss\": (np.mean(log_losses), np.std(log_losses))\n","#     }\n","#     all_results.append(lambda_results)\n","\n","#     print(f\"\\n--- RESULTS FOR LAMBDA = {lam} ---\")\n","#     print(f\"Accuracy: {lambda_results['accuracy'][0]:.4f} ± {lambda_results['accuracy'][1]:.4f}\")\n","#     print(f\"Precision: {lambda_results['precision'][0]:.4f} ± {lambda_results['precision'][1]:.4f}\")\n","#     print(f\"Recall: {lambda_results['recall'][0]:.4f} ± {lambda_results['recall'][1]:.4f}\")\n","#     print(f\"F1 Score: {lambda_results['f1'][0]:.4f} ± {lambda_results['f1'][1]:.4f}\")\n","#     print(f\"Log Loss: {lambda_results['log_loss'][0]:.4f} ± {lambda_results['log_loss'][1]:.4f}\")\n","\n","# # ==========================================================\n","# # === Final Summary ===\n","# # ==========================================================\n","# print(\"\\n================ FINAL SUMMARY FOR ALL LAMBDAS ================\\n\")\n","# print(f\"{'Lambda':>8} | {'Accuracy':>18} | {'Precision':>18} | {'Recall':>18} | {'F1 Score':>18} | {'Log Loss':>18}\")\n","# print(\"-\" * 108)\n","# for res in all_results:\n","#     print(f\"{res['lambda']:>8} | \"\n","#           f\"{res['accuracy'][0]:.4f} ± {res['accuracy'][1]:.4f} | \"\n","#           f\"{res['precision'][0]:.4f} ± {res['precision'][1]:.4f} | \"\n","#           f\"{res['recall'][0]:.4f} ± {res['recall'][1]:.4f} | \"\n","#           f\"{res['f1'][0]:.4f} ± {res['f1'][1]:.4f} | \"\n","#           f\"{res['log_loss'][0]:.4f} ± {res['log_loss'][1]:.4f}\")"]},{"cell_type":"code","execution_count":248,"metadata":{"id":"ApTGKLsMeeQ5","executionInfo":{"status":"ok","timestamp":1766933753067,"user_tz":-330,"elapsed":8,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
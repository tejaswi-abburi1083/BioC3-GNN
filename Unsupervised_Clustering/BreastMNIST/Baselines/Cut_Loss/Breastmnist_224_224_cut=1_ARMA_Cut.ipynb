{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_w2ZeMZk4S9M","executionInfo":{"status":"ok","timestamp":1766896844185,"user_tz":-330,"elapsed":1879,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"76d083b4-e74a-45d0-8b02-763e3777df2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install -q torch_geometric\n","!pip install -q class_resolver\n","!pip3 install pymatting\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GyQ15pG-4QQM","executionInfo":{"status":"ok","timestamp":1766896857444,"user_tz":-330,"elapsed":13260,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"1e8f5937-8737-406d-c95f-cd68822ba674"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pymatting in /usr/local/lib/python3.12/dist-packages (1.1.14)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pymatting) (2.0.2)\n","Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from pymatting) (11.3.0)\n","Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.12/dist-packages (from pymatting) (0.60.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from pymatting) (1.16.3)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba!=0.49.0->pymatting) (0.43.0)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"VSYEATM8HJ2u","executionInfo":{"status":"ok","timestamp":1766982388045,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import random\n","import copy\n","import scipy.sparse as sp\n","\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","from torchvision import models\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","\n","# torch-geometric imports\n","from torch_geometric.nn import ARMAConv\n","from torch_geometric.data import Data\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","from sklearn.manifold import TSNE"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_8KVtdM42f3W","outputId":"16f195ac-02a7-4aa4-894f-5b2a38308652","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766982391181,"user_tz":-330,"elapsed":17,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available: True\n","GPU Name: NVIDIA RTX A4000\n"]}],"source":["import torch\n","print(\"CUDA available:\", torch.cuda.is_available())\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"JinL9v8LHM8o","executionInfo":{"status":"ok","timestamp":1766982412386,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["data = np.load('/home/snu/Downloads/breastmnist_224.npz', allow_pickle=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1766982415368,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"xrNOqnjlHUXo","outputId":"5b8860c5-be02-40d2-e490-bd7ce7f5e3fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Images, labels shapes: torch.Size([780, 3, 224, 224]) torch.Size([780])\n"]}],"source":["all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","images = all_images.astype(np.float32) / 255.0\n","images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N,3,224,224)\n","\n","X = torch.tensor(images)\n","y = torch.tensor(all_labels).long()\n","print(\"Images, labels shapes:\", X.shape, y.shape)\n","\n","dataset = TensorDataset(X, y)\n","class0_indices = [i for i in range(len(y)) if y[i] == 0]\n","class1_indices = [i for i in range(len(y)) if y[i] == 1]\n","\n","random.seed(42)\n","sampled_class0 = random.sample(class0_indices, min(1000, len(class0_indices)))\n","sampled_class1 = random.sample(class1_indices, min(1000, len(class1_indices)))\n","\n","combined_indices = sampled_class0 + sampled_class1\n","random.shuffle(combined_indices)\n","\n","final_dataset = Subset(dataset, combined_indices)\n","final_loader = DataLoader(final_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12035,"status":"ok","timestamp":1766982450855,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"egLJ3D9jHmdP","outputId":"026f0983-2d4c-481f-f5c0-7219c118b47f","scrolled":true},"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /home/snu/.cache/torch/hub/facebookresearch_dino_main\n"]},{"output_type":"stream","name":"stdout","text":["Feature shape: (780, 768)\n","Label shape: (780,)\n"]}],"source":["import torch\n","import timm\n","import numpy as np\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","vit = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n","vit.eval().to(device)\n","\n","vit_feats = []\n","y_list = []\n","\n","with torch.no_grad():\n","    for imgs, lbls in final_loader:\n","        imgs = imgs.to(device)\n","        feats = vit(imgs)\n","        vit_feats.append(feats.cpu())\n","        y_list.extend(lbls.cpu().tolist())\n","\n","F = torch.cat(vit_feats, dim=0).numpy().astype(np.float32)\n","y_labels = np.array(y_list).astype(np.int64)\n","\n","print(\"Feature shape:\", F.shape)\n","print(\"Label shape:\", y_labels.shape)\n","features = F"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"OYv_5-bl2f3X","executionInfo":{"status":"ok","timestamp":1766982450906,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.PReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VJS7CLP2f3Y"},"outputs":[],"source":["# class ARMAEncoder(torch.nn.Module):\n","#     def __init__(self, input_dim, hidden_dim, device, activ, stacks=3, layers=3):\n","#         super(ARMAEncoder, self).__init__()\n","#         self.device = device\n","#         self.arma = ARMAConv(input_dim, hidden_dim, num_stacks=stacks, num_layers=layers)\n","#         self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","#         self.dropout = nn.Dropout(0.3)\n","#         self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","#     def forward(self, data):\n","#         x, edge_index = data.x, data.edge_index\n","#         x = self.arma(x, edge_index)\n","#         x = self.dropout(x)\n","#         x = self.batchnorm(x)\n","#         logits = self.mlp(x)\n","#         return logits"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","from torch_geometric.nn import ARMAConv\n","\n","class ARMAEncoder(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ=\"ELU\",\n","                 num_stacks=1, num_layers=3):\n","        super(ARMAEncoder, self).__init__()\n","        self.device = device\n","\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"ELU\": nnFn.elu,\n","            \"RELU\": nnFn.relu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","        # Layer 1\n","        self.arma1 = ARMAConv(\n","            in_channels=input_dim,\n","            out_channels=hidden_dim,\n","            num_stacks=num_stacks,\n","            num_layers=num_layers,\n","            act=self.act,\n","            shared_weights=True,\n","            dropout=0.25\n","        )\n","        self.bn1 = nn.BatchNorm1d(hidden_dim)\n","\n","        # Layer 2\n","        self.arma2 = ARMAConv(\n","            in_channels=hidden_dim,\n","            out_channels=hidden_dim,\n","            num_stacks=num_stacks,\n","            num_layers=num_layers,\n","            act=self.act,\n","            shared_weights=True,\n","            dropout=0.25\n","        )\n","        self.bn2 = nn.BatchNorm1d(hidden_dim)\n","\n","        # Layer 3\n","        self.arma3 = ARMAConv(\n","            in_channels=hidden_dim,\n","            out_channels=hidden_dim,\n","            num_stacks=num_stacks,\n","            num_layers=num_layers,\n","            act=self.act,\n","            shared_weights=True,\n","            dropout=0.25\n","        )\n","        self.bn3 = nn.BatchNorm1d(hidden_dim)\n","\n","        self.dropout = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","\n","        x = self.arma1(x, edge_index)\n","        x = self.bn1(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","\n","        x = self.arma2(x, edge_index)\n","        x = self.bn2(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","\n","        x = self.arma3(x, edge_index)\n","        x = self.bn3(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","\n","        logits = self.mlp(x)\n","        return logits\n"],"metadata":{"id":"OgHipx6sQiVo","executionInfo":{"status":"ok","timestamp":1766982697909,"user_tz":-330,"elapsed":42,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"0RW3bRMz2f3Y","executionInfo":{"status":"ok","timestamp":1766982702619,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class ARMA(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ):\n","        super(ARMA, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","\n","        self.online_encoder = ARMAEncoder(input_dim, hidden_dim, device, activ)\n","\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_dim)\n","\n","        # use cut loss instead of modularity\n","        self.loss = self.cut_loss\n","\n","    def forward(self, data):\n","        x = self.online_encoder(data)\n","        logits = self.online_predictor(x)\n","        S = nnFn.softmax(logits, dim=1)\n","        return S, logits\n","\n","    def cut_loss(self, A, S):\n","        S = nnFn.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / den)\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n","\n","        return mincut_loss + ortho_loss"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"vt08W8CG2f3Y","executionInfo":{"status":"ok","timestamp":1766982705518,"user_tz":-330,"elapsed":40,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def create_adj(F, cut, alpha=1):\n","    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = W - (W.max() / alpha)\n","    return W"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"wL0FEHgY2f3Y","executionInfo":{"status":"ok","timestamp":1766982706667,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def load_data(adj, node_feats):\n","    node_feats = torch.from_numpy(node_feats)\n","    edge_index = torch.from_numpy(np.array(np.nonzero((adj > 0))))\n","    row, col = edge_index\n","    edge_weight = torch.from_numpy(adj[row, col])\n","    return node_feats, edge_index, edge_weight"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"_hBfbNCzDXtq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766982708856,"user_tz":-330,"elapsed":8,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"9d5c2b3b-eff0-415b-d095-f60626f140eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["(780, 768) float32\n","Data(x=[780, 768], edge_index=[2, 266936])\n"]}],"source":["print(features.shape, features.dtype)\n","cut = 0 # Consider n-cut loss OR Modularity loss (by default cut = 0)\n","alpha = 0.73 # Edge creation Threshold\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","K = 2  # Number of clusters\n","np.random.seed(42)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","feats_dim = 768\n","K = 2\n","W0 = create_adj(features, 0, alpha)\n","node_feats, edge_index, _ = load_data(W0, features)\n","data0 = Data(x=node_feats, edge_index=edge_index).to(device)\n","A1 = torch.from_numpy(W0).float().to(device)\n","print(data0)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1002127,"status":"ok","timestamp":1766983713209,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"sGbMVrM5Dcbk","outputId":"7de510ed-3aad-46cf-f1f7-fe2fe0119454"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Loss: -0.2412\n","Epoch 100 | Loss: -0.6002\n","Epoch 200 | Loss: -0.6141\n","Epoch 300 | Loss: -0.6142\n","Epoch 400 | Loss: -0.6185\n","Epoch 500 | Loss: -0.6180\n","Epoch 600 | Loss: -0.6200\n","Epoch 700 | Loss: -0.6207\n","Epoch 800 | Loss: -0.6199\n","Epoch 900 | Loss: -0.6203\n","Epoch 1000 | Loss: -0.6213\n","Epoch 1100 | Loss: -0.6210\n","Epoch 1200 | Loss: -0.6203\n","Epoch 1300 | Loss: -0.6213\n","Epoch 1400 | Loss: -0.6211\n","Epoch 1500 | Loss: -0.6210\n","Epoch 1600 | Loss: -0.6211\n","Epoch 1700 | Loss: -0.6200\n","Epoch 1800 | Loss: -0.6211\n","Epoch 1900 | Loss: -0.6208\n","Epoch 2000 | Loss: -0.6211\n","Epoch 2100 | Loss: -0.6210\n","Epoch 2200 | Loss: -0.6203\n","Epoch 2300 | Loss: -0.6214\n","Epoch 2400 | Loss: -0.6214\n","Epoch 2500 | Loss: -0.6208\n","Epoch 2600 | Loss: -0.6206\n","Epoch 2700 | Loss: -0.6199\n","Epoch 2800 | Loss: -0.6211\n","Epoch 2900 | Loss: -0.6211\n","Epoch 3000 | Loss: -0.6214\n","Epoch 3100 | Loss: -0.6217\n","Epoch 3200 | Loss: -0.6206\n","Epoch 3300 | Loss: -0.6213\n","Epoch 3400 | Loss: -0.6206\n","Epoch 3500 | Loss: -0.6213\n","Epoch 3600 | Loss: -0.6207\n","Epoch 3700 | Loss: -0.6204\n","Epoch 3800 | Loss: -0.6204\n","Epoch 3900 | Loss: -0.6214\n","Epoch 4000 | Loss: -0.6210\n","Epoch 4100 | Loss: -0.6210\n","Epoch 4200 | Loss: -0.6215\n","Epoch 4300 | Loss: -0.6209\n","Epoch 4400 | Loss: -0.6210\n","Epoch 4500 | Loss: -0.6199\n","Epoch 4600 | Loss: -0.6207\n","Epoch 4700 | Loss: -0.6216\n","Epoch 4800 | Loss: -0.6210\n","Epoch 4900 | Loss: -0.6215\n"]}],"source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","model = ARMA(feats_dim, 256, K, device, \"ELU\").to(device)\n","optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","num_epochs = 5000\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    S, logits = model(data0)\n","    unsup_loss = model.loss(A1, logits)\n","\n","    total_loss = unsup_loss\n","    total_loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch} | Loss: {total_loss:.4f}\")\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"jpYmDT0aDeG3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766983713376,"user_tz":-330,"elapsed":154,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"cc1714d8-e9a1-4242-c47b-86d00a7a744a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.5576923076923077\n","Precision: 0.7494456762749445\n","Recall: 0.5929824561403508\n","F1: 0.6620959843290891\n","Log Loss: 6.528569908284446\n"]}],"source":["model.eval()\n","with torch.no_grad():\n","    S, logits = model(data0)\n","    y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","    y_pred_proba = nnFn.softmax(logits, dim=1).cpu().numpy()\n","\n","\n","acc_score = accuracy_score(y_labels, y_pred)\n","acc_score_inverted = accuracy_score(y_labels, 1 - y_pred)\n","\n","if acc_score_inverted > acc_score:\n","    acc_score = acc_score_inverted\n","    y_pred = 1 - y_pred\n","\n","prec_score = precision_score(y_labels, y_pred)\n","rec_score = recall_score(y_labels, y_pred)\n","f1 = f1_score(y_labels, y_pred)\n","log_loss_value = log_loss(y_labels, y_pred_proba)\n","\n","print(\"Accuracy:\", acc_score)\n","print(\"Precision:\", prec_score)\n","print(\"Recall:\", rec_score)\n","print(\"F1:\", f1)\n","print(\"Log Loss:\", log_loss_value)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"TX7tKQK-2f3b","outputId":"f68abeda-72ab-4a76-bc71-e9c4e455da61","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766989309606,"user_tz":-330,"elapsed":5596228,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================ Run 0 ================\n","Epoch 0 | Loss: -0.2393\n","Epoch 1000 | Loss: -0.6193\n","Epoch 2000 | Loss: -0.6201\n","Epoch 3000 | Loss: -0.6200\n","Epoch 4000 | Loss: -0.6199\n","Accuracy: 0.5884615384615385 Precision: 0.7588357588357588 Recall: 0.6403508771929824 F1: 0.6945765937202664\n","\n","================ Run 1 ================\n","Epoch 0 | Loss: -0.2431\n","Epoch 1000 | Loss: -0.6203\n","Epoch 2000 | Loss: -0.6216\n","Epoch 3000 | Loss: -0.6212\n","Epoch 4000 | Loss: -0.6208\n","Accuracy: 0.5897435897435898 Precision: 0.757201646090535 Recall: 0.6456140350877193 F1: 0.696969696969697\n","\n","================ Run 2 ================\n","Epoch 0 | Loss: -0.2407\n","Epoch 1000 | Loss: -0.6214\n","Epoch 2000 | Loss: -0.6209\n","Epoch 3000 | Loss: -0.6208\n","Epoch 4000 | Loss: -0.6211\n","Accuracy: 0.5615384615384615 Precision: 0.7556053811659192 Recall: 0.5912280701754385 F1: 0.6633858267716536\n","\n","================ Run 3 ================\n","Epoch 0 | Loss: -0.2454\n","Epoch 1000 | Loss: -0.6063\n","Epoch 2000 | Loss: -0.6076\n","Epoch 3000 | Loss: -0.6066\n","Epoch 4000 | Loss: -0.6075\n","Accuracy: 0.5858974358974359 Precision: 0.7990314769975787 Recall: 0.5789473684210527 F1: 0.671414038657172\n","\n","================ Run 4 ================\n","Epoch 0 | Loss: -0.2466\n","Epoch 1000 | Loss: -0.6198\n","Epoch 2000 | Loss: -0.6192\n","Epoch 3000 | Loss: -0.6205\n","Epoch 4000 | Loss: -0.6211\n","Accuracy: 0.5705128205128205 Precision: 0.7494692144373672 Recall: 0.6192982456140351 F1: 0.6781940441882806\n","\n","================ Run 5 ================\n","Epoch 0 | Loss: -0.2443\n","Epoch 1000 | Loss: -0.6206\n","Epoch 2000 | Loss: -0.6207\n","Epoch 3000 | Loss: -0.6209\n","Epoch 4000 | Loss: -0.6210\n","Accuracy: 0.5782051282051283 Precision: 0.7558386411889597 Recall: 0.624561403508772 F1: 0.6839577329490875\n","\n","================ Run 6 ================\n","Epoch 0 | Loss: -0.2391\n","Epoch 1000 | Loss: -0.6206\n","Epoch 2000 | Loss: -0.6216\n","Epoch 3000 | Loss: -0.6217\n","Epoch 4000 | Loss: -0.6217\n","Accuracy: 0.5923076923076923 Precision: 0.7581967213114754 Recall: 0.6491228070175439 F1: 0.6994328922495274\n","\n","================ Run 7 ================\n","Epoch 0 | Loss: -0.2450\n","Epoch 1000 | Loss: -0.6198\n","Epoch 2000 | Loss: -0.6213\n","Epoch 3000 | Loss: -0.6199\n","Epoch 4000 | Loss: -0.6206\n","Accuracy: 0.5717948717948718 Precision: 0.7532188841201717 Recall: 0.6157894736842106 F1: 0.6776061776061776\n","\n","================ Run 8 ================\n","Epoch 0 | Loss: -0.2419\n","Epoch 1000 | Loss: -0.6208\n","Epoch 2000 | Loss: -0.6212\n","Epoch 3000 | Loss: -0.6206\n","Epoch 4000 | Loss: -0.6217\n","Accuracy: 0.5615384615384615 Precision: 0.7533333333333333 Recall: 0.5947368421052631 F1: 0.6647058823529411\n","\n","================ Run 9 ================\n","Epoch 0 | Loss: -0.2436\n","Epoch 1000 | Loss: -0.6199\n","Epoch 2000 | Loss: -0.6191\n","Epoch 3000 | Loss: -0.6198\n","Epoch 4000 | Loss: -0.6198\n","Accuracy: 0.6 Precision: 0.7611336032388664 Recall: 0.6596491228070176 F1: 0.706766917293233\n","\n","===== Final Results across 10 runs ===telek\n","Accuracy: mean= 0.5799999999999998 std= 0.012629343954897183\n","Precision: mean= 0.7601864660719964 std= 0.01332211175644681\n","Recall: mean= 0.6219298245614036 std= 0.025775148187377247\n","F1: mean= 0.6837009802758037 std= 0.014373222823229864\n"]}],"source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","results = []\n","\n","# Store the initial extracted features and labels (from the sampled dataset)\n","initial_extracted_features = features\n","initial_sampled_labels = y_labels\n","\n","for run_seed in range(10):\n","    print(\"\\n================ Run\", run_seed, \"================\")\n","\n","    # Set seeds for reproducibility\n","    np.random.seed(run_seed)\n","    torch.manual_seed(run_seed)\n","    random.seed(run_seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(run_seed)\n","\n","    # Shuffle features and labels for the current run\n","    perm = np.random.permutation(initial_extracted_features.shape[0])\n","    current_run_features = initial_extracted_features[perm]\n","    current_run_labels = initial_sampled_labels[perm]\n","\n","    cut = 0\n","    alpha = 0.73\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    feats_dim = 768\n","    K = 2\n","\n","    W0 = create_adj(current_run_features, cut, alpha)\n","    node_feats, edge_index, _ = load_data(W0, current_run_features)\n","    data0 = Data(x=node_feats, edge_index=edge_index).to(device)\n","    A1 = torch.from_numpy(W0).float().to(device)\n","\n","    model = ARMA(feats_dim, 256, K, device, \"ELU\").to(device)\n","    optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","    scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","    num_epochs = 5000\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","\n","        S, logits = model(data0)\n","        unsup_loss = model.loss(A1, logits)\n","\n","        unsup_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        if epoch % 1000 == 0:\n","            print(f\"Epoch {epoch} | Loss: {unsup_loss:.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        S, logits = model(data0)\n","        y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","        y_pred_proba = nnFn.softmax(logits, dim=1).cpu().numpy()\n","\n","    acc_score = accuracy_score(current_run_labels, y_pred)\n","    acc_score_inverted = accuracy_score(current_run_labels, 1 - y_pred)\n","\n","    if acc_score_inverted > acc_score:\n","        acc_score = acc_score_inverted\n","        y_pred = 1 - y_pred\n","\n","    prec_score = precision_score(current_run_labels, y_pred)\n","    rec_score = recall_score(current_run_labels, y_pred)\n","    f1 = f1_score(current_run_labels, y_pred)\n","    log_loss_value = log_loss(current_run_labels, y_pred_proba)\n","\n","    print(\"Accuracy:\", acc_score, \"Precision:\", prec_score, \"Recall:\", rec_score, \"F1:\", f1)\n","\n","    results.append({\n","        \"seed\": run_seed,\n","        \"accuracy\": acc_score,\n","        \"precision\": prec_score,\n","        \"recall\": rec_score,\n","        \"f1\": f1,\n","        \"log_loss\": log_loss_value\n","    })\n","\n","accs = [r[\"accuracy\"] for r in results]\n","precisions = [r[\"precision\"] for r in results]\n","recalls = [r[\"recall\"] for r in results]\n","f1s = [r[\"f1\"] for r in results]\n","\n","print(\"\\n===== Final Results across 10 runs ===telek\")\n","print(\"Accuracy: mean=\", np.mean(accs), \"std=\", np.std(accs))\n","print(\"Precision: mean=\", np.mean(precisions), \"std=\", np.std(precisions))\n","print(\"Recall: mean=\", np.mean(recalls), \"std=\", np.std(recalls))\n","print(\"F1: mean=\", np.mean(f1s), \"std=\", np.std(f1s))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1eXNqblL2f3b"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
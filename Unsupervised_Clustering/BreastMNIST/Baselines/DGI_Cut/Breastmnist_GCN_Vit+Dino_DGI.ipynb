{"cells":[{"cell_type":"code","execution_count":153,"metadata":{"id":"YXFd7Zsz-3XQ","executionInfo":{"status":"ok","timestamp":1767031717760,"user_tz":-330,"elapsed":10,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GCNConv\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","import random\n","from torchvision import models"]},{"cell_type":"code","execution_count":154,"metadata":{"id":"JQ6KiAvW-5rn","executionInfo":{"status":"ok","timestamp":1767031717965,"user_tz":-330,"elapsed":202,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["data = np.load('/home/snu/Downloads/breastmnist_224.npz', allow_pickle=True)\n","\n","# Combine train, val, and test sets\n","all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()"]},{"cell_type":"code","execution_count":155,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UCLc0VbWkE0t","executionInfo":{"status":"ok","timestamp":1767031718109,"user_tz":-330,"elapsed":133,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"85aa48f6-233c-4ed1-8164-d7a48f267f37"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([780, 3, 224, 224]) torch.Size([780])\n"]}],"source":["images = all_images.astype(np.float32) / 255.0\n","images = np.repeat(images[:, None, :, :], 3, axis=1)  # Convert to 3 channels (N, 3, 224, 224)\n","\n","# Convert to torch tensors\n","X = torch.tensor(images)\n","y = torch.tensor(all_labels).long()\n","print(X.shape, y.shape)"]},{"cell_type":"code","execution_count":156,"metadata":{"id":"YfByS-qykE0u","executionInfo":{"status":"ok","timestamp":1767031718112,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["dataset = TensorDataset(X, y)\n","class0_indices = [i for i in range(len(y)) if y[i] == 0]\n","class1_indices = [i for i in range(len(y)) if y[i] == 1]\n","\n","random.seed(42)\n","sampled_class0 = random.sample(class0_indices, min(1000, len(class0_indices)))\n","sampled_class1 = random.sample(class1_indices, min(1000, len(class1_indices)))\n","\n","combined_indices = sampled_class0 + sampled_class1\n","random.shuffle(combined_indices)\n","\n","# Final subset\n","final_dataset = Subset(dataset, combined_indices)\n","final_loader = DataLoader(final_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":157,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5OEXUmebkE0u","executionInfo":{"status":"ok","timestamp":1767031722686,"user_tz":-330,"elapsed":4573,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"53d02c84-2fc7-4c90-a54f-a966755d51e9"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /home/snu/.cache/torch/hub/facebookresearch_dino_main\n"]},{"output_type":"stream","name":"stdout","text":["Feature shape: (780, 768)\n","Label shape: (780,)\n"]}],"source":["import torch\n","import timm\n","import numpy as np\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","vit = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n","vit.eval().to(device)\n","\n","vit_feats = []\n","y_list = []\n","\n","with torch.no_grad():\n","    for imgs, lbls in final_loader:\n","        imgs = imgs.to(device)\n","        feats = vit(imgs)\n","        vit_feats.append(feats.cpu())\n","        y_list.extend(lbls.cpu().tolist())\n","\n","F = torch.cat(vit_feats, dim=0).numpy().astype(np.float32)\n","y_labels = np.array(y_list).astype(np.int64)\n","\n","print(\"Feature shape:\", F.shape)\n","print(\"Label shape:\", y_labels.shape)\n"]},{"cell_type":"code","execution_count":158,"metadata":{"id":"MkKdnnzI-7zI","executionInfo":{"status":"ok","timestamp":1767031722730,"user_tz":-330,"elapsed":42,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def create_adj(F, alpha=1):\n","    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","    W = (W >= alpha).astype(np.float32)\n","    return W"]},{"cell_type":"code","execution_count":159,"metadata":{"id":"Qk8neEfFl7kX","executionInfo":{"status":"ok","timestamp":1767031722732,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def asymmetrize_random(adj_matrix, seed=None):\n","    \"\"\"\n","    Randomly orient each undirected edge from a symmetric adjacency matrix.\n","    \"\"\"\n","    adj = np.array(adj_matrix, dtype=np.float32)\n","    n = adj.shape[0]\n","    asym = np.zeros((n, n), dtype=np.float32)\n","    rng = np.random.default_rng(seed)\n","\n","    for i in range(n):\n","        for j in range(i + 1, n):\n","            if adj[i, j]:\n","                if rng.random() < 0.5:\n","                    asym[i, j] = adj[i, j]\n","                else:\n","                    asym[j, i] = adj[i, j]\n","\n","    return asym"]},{"cell_type":"code","execution_count":160,"metadata":{"id":"klhn9g9sl-SV","executionInfo":{"status":"ok","timestamp":1767031722781,"user_tz":-330,"elapsed":48,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def load_data(adj, node_feats):\n","    node_feats = torch.from_numpy(node_feats).float()\n","    edge_index = torch.from_numpy(np.array(np.nonzero(adj))).long()\n","    return node_feats, edge_index"]},{"cell_type":"code","execution_count":161,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zz160NfE--Tg","outputId":"9ea0ab7f-168d-4171-a118-2d3a4d771894","executionInfo":{"status":"ok","timestamp":1767031722795,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Data(x=[780, 768], edge_index=[2, 266936])\n"]}],"source":["features = F # Use ResNet embeddings\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","W0 = create_adj(features, alpha=0.73)\n","# W_asym = asymmetrize_random(W0, seed=42)\n","node_feats, edge_index = load_data(W0, features)\n","data = Data(x=node_feats, edge_index=edge_index).to(device)\n","A = torch.from_numpy(W0).to(device)\n","print(data)"]},{"cell_type":"code","execution_count":162,"metadata":{"id":"nhh413xH_Awp","executionInfo":{"status":"ok","timestamp":1767031722802,"user_tz":-330,"elapsed":6,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch_geometric.nn import GCNConv\n","\n","class GCNEncoder(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ=nn.ELU()):\n","        super(GCNEncoder, self).__init__()\n","        self.device = device\n","\n","        # 3 GCN layers\n","        self.gcn1 = GCNConv(input_dim, hidden_dim)\n","        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n","        self.gcn3 = GCNConv(hidden_dim, hidden_dim)\n","\n","        # BatchNorm for each layer\n","        self.bn1 = nn.BatchNorm1d(hidden_dim)\n","        self.bn2 = nn.BatchNorm1d(hidden_dim)\n","        self.bn3 = nn.BatchNorm1d(hidden_dim)\n","\n","        self.dropout = nn.Dropout(0.3)\n","        self.act = activ\n","\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","\n","        x = self.gcn1(x, edge_index)\n","        x = self.bn1(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","\n","        x = self.gcn2(x, edge_index)\n","        x = self.bn2(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","\n","        x = self.gcn3(x, edge_index)\n","        x = self.bn3(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","\n","        logits = self.mlp(x)\n","        return logits\n"]},{"cell_type":"code","execution_count":163,"metadata":{"id":"t1CWUjjG48t_","executionInfo":{"status":"ok","timestamp":1767031722845,"user_tz":-330,"elapsed":48,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class AvgReadout(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, seq, msk=None):\n","        if msk is None:\n","            return torch.mean(seq, 0)\n","        else:\n","            msk = torch.unsqueeze(msk, -1)\n","            return torch.sum(seq * msk, 0) / torch.sum(msk)"]},{"cell_type":"code","execution_count":164,"metadata":{"id":"IbNOUPjg42s9","executionInfo":{"status":"ok","timestamp":1767031722847,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, n_h):\n","        super().__init__()\n","        self.f_k = nn.Bilinear(n_h, n_h, 1)\n","        nn.init.xavier_uniform_(self.f_k.weight.data)\n","        if self.f_k.bias is not None:\n","            self.f_k.bias.data.fill_(0.0)\n","\n","    def forward(self, c, h_pl, h_mi):\n","        c_x = torch.unsqueeze(c, 0).expand_as(h_pl)\n","        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 1)\n","        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 1)\n","        logits = torch.cat((sc_1, sc_2), 0)\n","        return logits"]},{"cell_type":"code","execution_count":165,"metadata":{"id":"7X7cwk2N8Al2","executionInfo":{"status":"ok","timestamp":1767031722849,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class DGI(nn.Module):\n","    def __init__(self, n_in, n_h, dropout=0.25):\n","        super().__init__()\n","        self.gcn1 = GCNEncoder(n_in, n_h, device='cuda' if torch.cuda.is_available() else 'cpu', activ=nn.ELU())\n","        self.read = AvgReadout()\n","        self.sigm = nn.Sigmoid()\n","        self.disc = Discriminator(n_h)\n","\n","    def forward(self, seq1, seq2, edge_index):\n","        # Create Data objects for the GCNEncoder\n","        data1 = Data(x=seq1, edge_index=edge_index)\n","        data2 = Data(x=seq2, edge_index=edge_index)\n","\n","        h_1 = self.gcn1(data1)\n","        c = self.read(h_1)\n","        c = self.sigm(c)\n","        h_2 = self.gcn1(data2)\n","        logits = self.disc(c, h_1, h_2)\n","        return logits, h_1"]},{"cell_type":"code","execution_count":166,"metadata":{"id":"yVuaMXM1C9T3","executionInfo":{"status":"ok","timestamp":1767031722905,"user_tz":-330,"elapsed":55,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","class DGI_with_classifier(DGI):\n","    def __init__(self, n_in, n_h, n_classes=2, cut=0, dropout=0.25):\n","        super().__init__(n_in, n_h, dropout=dropout)\n","        self.classifier = nn.Linear(n_h, n_classes)\n","        self.cut = cut\n","\n","    def get_embeddings(self, node_feats, edge_index):\n","        _, embeddings = self.forward(node_feats, node_feats, edge_index)\n","        return embeddings\n","\n","    def cut_loss(self, A, S):\n","        # ensure tensor\n","        if isinstance(A, np.ndarray):\n","            A = torch.from_numpy(A).float().to(S.device)\n","\n","        S = F.softmax(S, dim=1)   # cluster assignment\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","\n","        mincut_loss = -(num / den)\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(S.shape[1], device=A.device)\n","        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n","\n","        return mincut_loss + ortho_loss\n","\n","    def modularity_loss(self, A, S):\n","        # ensure tensor\n","        if isinstance(A, np.ndarray):\n","            A = torch.from_numpy(A).float().to(S.device)\n","\n","        C = F.softmax(S, dim=1)   # cluster assignment\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A)\n","\n","        B = A - torch.outer(d, d) / (2 * m)\n","\n","        I_S = torch.eye(C.shape[1], device=A.device)\n","        k = torch.norm(I_S)\n","        n = S.shape[0]\n","\n","        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n","\n","        return modularity_term + collapse_reg_term\n","\n","    def Reg_loss(self, A, embeddings):\n","        # classifier output used as soft cluster assignment\n","        logits = self.classifier(embeddings)\n","\n","        if self.cut == 1:\n","            return self.cut_loss(A, logits)\n","        else:\n","            return self.modularity_loss(A, logits)"]},{"cell_type":"code","execution_count":167,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ClSGTZaA_xt","outputId":"1a820381-663a-440e-d529-04f9d899bf54","executionInfo":{"status":"ok","timestamp":1767031859013,"user_tz":-330,"elapsed":136104,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | DGI Loss: 0.7014 | Reg Loss: -0.2489 | Total: 0.7011\n","Epoch 500 | DGI Loss: 0.3455 | Reg Loss: -0.4683 | Total: 0.3451\n","Epoch 1000 | DGI Loss: 0.2044 | Reg Loss: -0.5160 | Total: 0.2039\n","Epoch 1500 | DGI Loss: 0.1812 | Reg Loss: -0.5271 | Total: 0.1807\n","Epoch 2000 | DGI Loss: 0.1281 | Reg Loss: -0.5268 | Total: 0.1276\n","Epoch 2500 | DGI Loss: 0.1311 | Reg Loss: -0.5318 | Total: 0.1305\n"]}],"source":["hidden_dim = 256\n","cut = 1\n","dropout = 0.25\n","\n","# make sure adjacency is a tensor on GPU\n","if isinstance(A, np.ndarray):\n","    A = torch.from_numpy(A).float().to(device)\n","else:\n","    A = A.float().to(device)\n","\n","model = DGI_with_classifier(features.shape[1], hidden_dim, n_classes=2, cut=cut, dropout=dropout).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n","bce_loss = nn.BCEWithLogitsLoss()\n","\n","num_epochs = 2500\n","for epoch in range(num_epochs + 1):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    perm = torch.randperm(node_feats.size(0))\n","    corrupt_features = node_feats[perm]\n","\n","    logits, embeddings = model(node_feats.to(device), corrupt_features.to(device), edge_index.to(device))\n","\n","    lbl = torch.cat([\n","        torch.ones(node_feats.size(0)),\n","        torch.zeros(node_feats.size(0))\n","    ]).to(device)\n","\n","    dgi_loss = bce_loss(logits.squeeze(), lbl)\n","    reg_loss = model.Reg_loss(A, embeddings)\n","    loss = dgi_loss + 0.001 * reg_loss\n","\n","    if epoch % 500 == 0:\n","        print(f\"Epoch {epoch} | DGI Loss: {dgi_loss.item():.4f} | Reg Loss: {reg_loss.item():.4f} | Total: {loss.item():.4f}\")\n","\n","    loss.backward()\n","    optimizer.step()\n"]},{"cell_type":"code","execution_count":168,"metadata":{"id":"giN_kiZckBqV","executionInfo":{"status":"ok","timestamp":1767031859024,"user_tz":-330,"elapsed":10,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["model.eval()\n","with torch.no_grad():\n","    embeddings = model.get_embeddings(node_feats.to(device), edge_index.to(device))\n","    class_probabilities = F.softmax(model.classifier(embeddings), dim=1).cpu().numpy()\n","\n","y_pred = np.argmax(class_probabilities, axis=1)"]},{"cell_type":"code","execution_count":169,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVJYp9cnauDO","outputId":"aa0171f1-71ac-4cf7-ef92-8540cc67dfee","executionInfo":{"status":"ok","timestamp":1767031859035,"user_tz":-330,"elapsed":9,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.573076923076923\n","Accuracy (inverted): 0.4269230769230769\n","Precision: 0.6978297161936561\n","Recall: 0.7333333333333333\n","F1: 0.7151411462788708\n","Log Loss: 1.8759441116266722\n"]}],"source":["# Extract the true labels for the subset used for prediction\n","y_subset = y[combined_indices].cpu().numpy()\n","\n","acc_score = accuracy_score(y_subset, y_pred)\n","acc_score_inverted = accuracy_score(y_subset, 1 - y_pred)\n","prec_score = precision_score(y_subset, y_pred)\n","rec_score = recall_score(y_subset, y_pred)\n","f1 = f1_score(y_subset, y_pred)\n","log_loss_value = log_loss(y_subset, class_probabilities)\n","\n","print(\"Accuracy:\", acc_score)\n","print(\"Accuracy (inverted):\", acc_score_inverted)\n","print(\"Precision:\", prec_score)\n","print(\"Recall:\", rec_score)\n","print(\"F1:\", f1)\n","print(\"Log Loss:\", log_loss_value)"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","import torch.nn.functional as F\n","import torch\n","\n","NUM_RUNS = 10\n","\n","acc_list = []\n","acc_inv_list = []\n","prec_list = []\n","rec_list = []\n","f1_list = []\n","logloss_list = []\n","\n","for run in range(NUM_RUNS):\n","    print(f\"\\n===== RUN {run+1}/{NUM_RUNS} =====\")\n","\n","    hidden_dim = 256\n","    cut = 1\n","    dropout = 0.25\n","\n","    # make sure adjacency is tensor on GPU\n","    if isinstance(A, np.ndarray):\n","        A_gpu = torch.from_numpy(A).float().to(device)\n","    else:\n","        A_gpu = A.float().to(device)\n","\n","    model = DGI_with_classifier(\n","        features.shape[1],\n","        hidden_dim,\n","        n_classes=2,\n","        cut=cut,\n","        dropout=dropout\n","    ).to(device)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","    bce_loss = nn.BCEWithLogitsLoss()\n","\n","    num_epochs = 2500\n","    for epoch in range(num_epochs + 1):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        perm = torch.randperm(node_feats.size(0))\n","        corrupt_features = node_feats[perm]\n","\n","        logits, embeddings = model(\n","            node_feats.to(device),\n","            corrupt_features.to(device),\n","            edge_index.to(device)\n","        )\n","\n","        lbl = torch.cat([\n","            torch.ones(node_feats.size(0)),\n","            torch.zeros(node_feats.size(0))\n","        ]).to(device)\n","\n","        dgi_loss = bce_loss(logits.squeeze(), lbl)\n","        reg_loss = model.Reg_loss(A_gpu, embeddings)\n","        loss = dgi_loss + 0.1 * reg_loss\n","\n","        if epoch % 500 == 0:\n","            print(f\"Epoch {epoch} | DGI Loss: {dgi_loss.item():.4f} | Reg Loss: {reg_loss.item():.4f} | Total: {loss.item():.4f}\")\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    # ---------- Evaluation ----------\n","    model.eval()\n","    with torch.no_grad():\n","        embeddings = model.get_embeddings(node_feats.to(device), edge_index.to(device))\n","        class_probabilities = F.softmax(model.classifier(embeddings), dim=1).cpu().numpy()\n","\n","    y_pred = np.argmax(class_probabilities, axis=1)\n","    y_subset = y[combined_indices].cpu().numpy()\n","\n","    acc = accuracy_score(y_subset, y_pred)\n","    acc_inv = accuracy_score(y_subset, 1 - y_pred)\n","    prec = precision_score(y_subset, y_pred)\n","    rec = recall_score(y_subset, y_pred)\n","    f1 = f1_score(y_subset, y_pred)\n","    ll = log_loss(y_subset, class_probabilities)\n","\n","    acc_list.append(acc)\n","    acc_inv_list.append(acc_inv)\n","    prec_list.append(prec)\n","    rec_list.append(rec)\n","    f1_list.append(f1)\n","    logloss_list.append(ll)\n","\n","# -------- Print mean ± std ----------\n","def mean_std(arr):\n","    return np.mean(arr), np.std(arr)\n","\n","metrics = {\n","    \"Accuracy\": acc_list,\n","    \"Accuracy (Inverted)\": acc_inv_list,\n","    \"Precision\": prec_list,\n","    \"Recall\": rec_list,\n","    \"F1\": f1_list,\n","    \"Log Loss\": logloss_list\n","}\n","\n","print(\"\\n===== FINAL RESULTS OVER 10 RUNS =====\")\n","for name, values in metrics.items():\n","    m, s = mean_std(values)\n","    print(f\"{name}: {m:.4f} ± {s:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_TB3mTg6CQvj","executionInfo":{"status":"ok","timestamp":1767033195497,"user_tz":-330,"elapsed":1336461,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"866f7d93-86be-446f-ed54-250e8d6b91b0"},"execution_count":170,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== RUN 1/10 =====\n","Epoch 0 | DGI Loss: 0.7029 | Reg Loss: -0.2493 | Total: 0.6780\n","Epoch 500 | DGI Loss: 0.1437 | Reg Loss: -0.5932 | Total: 0.0843\n","Epoch 1000 | DGI Loss: 0.0551 | Reg Loss: -0.5998 | Total: -0.0049\n","Epoch 1500 | DGI Loss: 0.0349 | Reg Loss: -0.6017 | Total: -0.0252\n","Epoch 2000 | DGI Loss: 0.0218 | Reg Loss: -0.6033 | Total: -0.0386\n","Epoch 2500 | DGI Loss: 0.0149 | Reg Loss: -0.5986 | Total: -0.0449\n","\n","===== RUN 2/10 =====\n","Epoch 0 | DGI Loss: 0.7120 | Reg Loss: -0.2448 | Total: 0.6875\n","Epoch 500 | DGI Loss: 0.1134 | Reg Loss: -0.5960 | Total: 0.0538\n","Epoch 1000 | DGI Loss: 0.0554 | Reg Loss: -0.6066 | Total: -0.0052\n","Epoch 1500 | DGI Loss: 0.0580 | Reg Loss: -0.6045 | Total: -0.0024\n","Epoch 2000 | DGI Loss: 0.0270 | Reg Loss: -0.6068 | Total: -0.0337\n","Epoch 2500 | DGI Loss: 0.0507 | Reg Loss: -0.6021 | Total: -0.0095\n","\n","===== RUN 3/10 =====\n","Epoch 0 | DGI Loss: 0.6970 | Reg Loss: -0.2503 | Total: 0.6719\n","Epoch 500 | DGI Loss: 0.1376 | Reg Loss: -0.5910 | Total: 0.0785\n","Epoch 1000 | DGI Loss: 0.0728 | Reg Loss: -0.5961 | Total: 0.0131\n","Epoch 1500 | DGI Loss: 0.0327 | Reg Loss: -0.5997 | Total: -0.0273\n","Epoch 2000 | DGI Loss: 0.0397 | Reg Loss: -0.6003 | Total: -0.0203\n","Epoch 2500 | DGI Loss: 0.0194 | Reg Loss: -0.5973 | Total: -0.0404\n","\n","===== RUN 4/10 =====\n","Epoch 0 | DGI Loss: 0.7074 | Reg Loss: -0.2500 | Total: 0.6824\n","Epoch 500 | DGI Loss: 0.1682 | Reg Loss: -0.5974 | Total: 0.1085\n","Epoch 1000 | DGI Loss: 0.0687 | Reg Loss: -0.6048 | Total: 0.0082\n","Epoch 1500 | DGI Loss: 0.0303 | Reg Loss: -0.6101 | Total: -0.0307\n","Epoch 2000 | DGI Loss: 0.0211 | Reg Loss: -0.6070 | Total: -0.0396\n","Epoch 2500 | DGI Loss: 0.0302 | Reg Loss: -0.6080 | Total: -0.0306\n","\n","===== RUN 5/10 =====\n","Epoch 0 | DGI Loss: 0.7116 | Reg Loss: -0.2462 | Total: 0.6870\n","Epoch 500 | DGI Loss: 0.1334 | Reg Loss: -0.5923 | Total: 0.0741\n","Epoch 1000 | DGI Loss: 0.0633 | Reg Loss: -0.5977 | Total: 0.0035\n","Epoch 1500 | DGI Loss: 0.0192 | Reg Loss: -0.6025 | Total: -0.0410\n","Epoch 2000 | DGI Loss: 0.0239 | Reg Loss: -0.6029 | Total: -0.0364\n","Epoch 2500 | DGI Loss: 0.0300 | Reg Loss: -0.6040 | Total: -0.0304\n","\n","===== RUN 6/10 =====\n","Epoch 0 | DGI Loss: 0.7073 | Reg Loss: -0.2506 | Total: 0.6823\n","Epoch 500 | DGI Loss: 0.1468 | Reg Loss: -0.6078 | Total: 0.0860\n","Epoch 1000 | DGI Loss: 0.0517 | Reg Loss: -0.6137 | Total: -0.0096\n","Epoch 1500 | DGI Loss: 0.0788 | Reg Loss: -0.5979 | Total: 0.0190\n","Epoch 2000 | DGI Loss: 0.0352 | Reg Loss: -0.6162 | Total: -0.0264\n","Epoch 2500 | DGI Loss: 0.0339 | Reg Loss: -0.6181 | Total: -0.0279\n","\n","===== RUN 7/10 =====\n","Epoch 0 | DGI Loss: 0.7093 | Reg Loss: -0.2529 | Total: 0.6840\n","Epoch 500 | DGI Loss: 0.1343 | Reg Loss: -0.5945 | Total: 0.0749\n","Epoch 1000 | DGI Loss: 0.0584 | Reg Loss: -0.5982 | Total: -0.0014\n","Epoch 1500 | DGI Loss: 0.0408 | Reg Loss: -0.6013 | Total: -0.0194\n","Epoch 2000 | DGI Loss: 0.0271 | Reg Loss: -0.6027 | Total: -0.0331\n","Epoch 2500 | DGI Loss: 0.0265 | Reg Loss: -0.6025 | Total: -0.0338\n","\n","===== RUN 8/10 =====\n","Epoch 0 | DGI Loss: 0.6992 | Reg Loss: -0.2665 | Total: 0.6725\n","Epoch 500 | DGI Loss: 0.1484 | Reg Loss: -0.6065 | Total: 0.0877\n","Epoch 1000 | DGI Loss: 0.0467 | Reg Loss: -0.6131 | Total: -0.0146\n","Epoch 1500 | DGI Loss: 0.0306 | Reg Loss: -0.6166 | Total: -0.0310\n","Epoch 2000 | DGI Loss: 0.0237 | Reg Loss: -0.6147 | Total: -0.0378\n","Epoch 2500 | DGI Loss: 0.0308 | Reg Loss: -0.6186 | Total: -0.0311\n","\n","===== RUN 9/10 =====\n","Epoch 0 | DGI Loss: 0.7042 | Reg Loss: -0.2524 | Total: 0.6790\n","Epoch 500 | DGI Loss: 0.1430 | Reg Loss: -0.5907 | Total: 0.0839\n","Epoch 1000 | DGI Loss: 0.0795 | Reg Loss: -0.5997 | Total: 0.0196\n","Epoch 1500 | DGI Loss: 0.0495 | Reg Loss: -0.5930 | Total: -0.0098\n","Epoch 2000 | DGI Loss: 0.0151 | Reg Loss: -0.6042 | Total: -0.0453\n","Epoch 2500 | DGI Loss: 0.0311 | Reg Loss: -0.6045 | Total: -0.0294\n","\n","===== RUN 10/10 =====\n","Epoch 0 | DGI Loss: 0.7090 | Reg Loss: -0.2511 | Total: 0.6839\n","Epoch 500 | DGI Loss: 0.1727 | Reg Loss: -0.5933 | Total: 0.1134\n","Epoch 1000 | DGI Loss: 0.0583 | Reg Loss: -0.5984 | Total: -0.0016\n","Epoch 1500 | DGI Loss: 0.0336 | Reg Loss: -0.6019 | Total: -0.0266\n","Epoch 2000 | DGI Loss: 0.0195 | Reg Loss: -0.5987 | Total: -0.0404\n","Epoch 2500 | DGI Loss: 0.0079 | Reg Loss: -0.6092 | Total: -0.0531\n","\n","===== FINAL RESULTS OVER 10 RUNS =====\n","Accuracy: 0.6035 ± 0.1384\n","Accuracy (Inverted): 0.3965 ± 0.1384\n","Precision: 0.7625 ± 0.0496\n","Recall: 0.6742 ± 0.2800\n","F1: 0.6701 ± 0.2241\n","Log Loss: 4.7333 ± 2.2437\n"]}]},{"cell_type":"code","execution_count":171,"metadata":{"id":"_5dlbdoCkE0w","executionInfo":{"status":"ok","timestamp":1767033195499,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["# print(y_subset)"]},{"cell_type":"code","source":["# import numpy as np\n","# import torch\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","# from torch.optim import AdamW\n","# from torch.optim.lr_scheduler import StepLR\n","# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","\n","# hidden_dim   = 256\n","# cut          = 0\n","# dropout      = 0.25\n","# num_runs     = 10\n","# num_epochs   = 8000\n","# lambda_list  = [0.001]\n","# base_seed    = 42\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# node_feats = node_feats.to(device)\n","# edge_index = edge_index.to(device)\n","# A = A.to(device)\n","\n","# # Use the y_subset created earlier\n","# y_subset_np = y_subset.astype(int)\n","\n","# N, feats_dim = node_feats.size(0), node_feats.size(1)\n","\n","# all_results = []\n","# bce_loss = nn.BCEWithLogitsLoss()\n","\n","# for lam in lambda_list:\n","#     print(f\"\\n================ LAMBDA = {lam} ================\\n\")\n","\n","#     acc_scores, prec_scores, rec_scores, f1_scores, log_losses = [], [], [], [], []\n","\n","#     for run in range(num_runs):\n","#         print(f\"\\n--- Run {run+1}/{num_runs} ---\")\n","\n","#         seed = base_seed + run\n","#         torch.manual_seed(seed)\n","#         np.random.seed(seed)\n","#         if torch.cuda.is_available():\n","#             torch.cuda.manual_seed_all(seed)\n","\n","\n","#         model = DGI_with_classifier(feats_dim, hidden_dim, n_classes=2, cut=cut, dropout=dropout).to(device)\n","#         optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","#         scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","\n","#         for epoch in range(num_epochs + 1):\n","#             model.train()\n","#             optimizer.zero_grad()\n","\n","#             perm = torch.randperm(N, device=device)\n","#             corrupt_features = node_feats[perm]\n","\n","#             logits, embeddings = model(node_feats, corrupt_features, edge_index)\n","\n","#             lbl = torch.cat([torch.ones(N, device=device), torch.zeros(N, device=device)])\n","#             dgi_loss = bce_loss(logits.squeeze(), lbl)\n","#             reg_loss = model.Reg_loss(A, embeddings)\n","\n","#             loss = dgi_loss + lam * reg_loss\n","\n","#             if epoch % 500 == 0:\n","#                 print(f\"Epoch {epoch:4d} | DGI: {dgi_loss.item():.4f} | Reg: {reg_loss.item():.4f} | \"\n","#                       f\"λ*Reg: {(lam * reg_loss).item():.4f} | Total: {loss.item():.4f}\")\n","\n","#             loss.backward()\n","#             optimizer.step()\n","#             scheduler.step()\n","\n","#         model.eval()\n","#         with torch.no_grad():\n","#             emb = model.get_embeddings(node_feats, edge_index)\n","#             logits_cls = model.classifier(emb)                   # [N, 2]\n","#             class_probabilities = F.softmax(logits_cls, dim=1).cpu().numpy()\n","#             y_pred = np.argmax(class_probabilities, axis=1)\n","\n","#         acc  = accuracy_score(y_subset_np, y_pred)\n","#         acc_inv = accuracy_score(y_subset_np, 1 - y_pred)\n","\n","#         if acc_inv > acc:\n","#             acc = acc_inv\n","#             y_pred = 1 - y_pred\n","#             class_probabilities = class_probabilities[:, ::-1]\n","\n","#         prec = precision_score(y_subset_np, y_pred, zero_division=0)\n","#         rec  = recall_score(y_subset_np, y_pred, zero_division=0)\n","#         f1   = f1_score(y_subset_np, y_pred, zero_division=0)\n","#         ll   = log_loss(y_subset_np, class_probabilities)\n","\n","#         print(f\"Run {run+1} | Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | LogLoss: {ll:.4f}\")\n","\n","#         acc_scores.append(acc)\n","#         prec_scores.append(prec)\n","#         rec_scores.append(rec)\n","#         f1_scores.append(f1)\n","#         log_losses.append(ll)\n","\n","#     lambda_results = {\n","#         \"lambda\": lam,\n","#         \"accuracy\":  (float(np.mean(acc_scores)), float(np.std(acc_scores))),\n","#         \"precision\": (float(np.mean(prec_scores)), float(np.std(prec_scores))),\n","#         \"recall\":    (float(np.mean(rec_scores)), float(np.std(rec_scores))),\n","#         \"f1\":        (float(np.mean(f1_scores)),  float(np.std(f1_scores))),\n","#         \"log_loss\":  (float(np.mean(log_losses)), float(np.std(log_losses))),\n","#     }\n","#     all_results.append(lambda_results)\n","\n","#     print(f\"\\n--- RESULTS FOR LAMBDA = {lam} ---\")\n","#     print(f\"Accuracy : {lambda_results['accuracy'][0]:.4f} ± {lambda_results['accuracy'][1]:.4f}\")\n","#     print(f\"Precision: {lambda_results['precision'][0]:.4f} ± {lambda_results['precision'][1]:.4f}\")\n","#     print(f\"Recall   : {lambda_results['recall'][0]:.4f} ± {lambda_results['recall'][1]:.4f}\")\n","#     print(f\"F1 Score : {lambda_results['f1'][0]:.4f} ± {lambda_results['f1'][1]:.4f}\")\n","#     print(f\"Log Loss : {lambda_results['log_loss'][0]:.4f} ± {lambda_results['log_loss'][1]:.4f}\")\n","\n","# print(\"\\n================ FINAL SUMMARY FOR ALL LAMBDAS ================\\n\")\n","# print(f\"{'Lambda':>8} | {'Accuracy':>18} | {'Precision':>18} | {'Recall':>18} | {'F1 Score':>18} | {'Log Loss':>18}\")\n","# print(\"-\" * 108)\n","# for res in all_results:\n","#     print(f\"{res['lambda']:>8} | \"\n","#           f\"{res['accuracy'][0]:.4f} ± {res['accuracy'][1]:.4f} | \"\n","#           f\"{res['precision'][0]:.4f} ± {res['precision'][1]:.4f} | \"\n","#           f\"{res['recall'][0]:.4f} ± {res['recall'][1]:.4f} | \"\n","#           f\"{res['f1'][0]:.4f} ± {res['f1'][1]:.4f} | \"\n","#           f\"{res['log_loss'][0]:.4f} ± {res['log_loss'][1]:.4f}\")"],"metadata":{"id":"3QHecuH8zuzG","executionInfo":{"status":"ok","timestamp":1767033195501,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":172,"outputs":[]},{"cell_type":"code","execution_count":173,"metadata":{"id":"u2TNZi1qljP0","executionInfo":{"status":"ok","timestamp":1767033195503,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["# import numpy as np\n","# import torch\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","# from torch.optim import AdamW\n","# from torch.optim.lr_scheduler import StepLR\n","# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","\n","# hidden_dim   = 256\n","# cut          = 0\n","# dropout      = 0.25\n","# num_runs     = 10\n","# num_epochs   = 8000\n","# lambda_list  = [0.001, 0.005, 0.009, 0.01, 0.05, 0.09, 0.1, 0.3, 0.5, 0.9, 1, 2, 5, 8]\n","# base_seed    = 42\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# node_feats = node_feats.to(device)\n","# edge_index = edge_index.to(device)\n","# A = A.to(device)\n","\n","# # Use the y_subset created earlier\n","# y_subset_np = y_subset.astype(int)\n","\n","# N, feats_dim = node_feats.size(0), node_feats.size(1)\n","\n","# all_results = []\n","# bce_loss = nn.BCEWithLogitsLoss()\n","\n","# for lam in lambda_list:\n","#     print(f\"\\n================ LAMBDA = {lam} ================\\n\")\n","\n","#     acc_scores, prec_scores, rec_scores, f1_scores, log_losses = [], [], [], [], []\n","\n","#     for run in range(num_runs):\n","#         print(f\"\\n--- Run {run+1}/{num_runs} ---\")\n","\n","#         seed = base_seed + run\n","#         torch.manual_seed(seed)\n","#         np.random.seed(seed)\n","#         if torch.cuda.is_available():\n","#             torch.cuda.manual_seed_all(seed)\n","\n","\n","#         model = DGI_with_classifier(feats_dim, hidden_dim, n_classes=2, cut=cut, dropout=dropout).to(device)\n","#         optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","#         scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","\n","#         for epoch in range(num_epochs + 1):\n","#             model.train()\n","#             optimizer.zero_grad()\n","\n","#             perm = torch.randperm(N, device=device)\n","#             corrupt_features = node_feats[perm]\n","\n","#             logits, embeddings = model(node_feats, corrupt_features, edge_index)\n","\n","#             lbl = torch.cat([torch.ones(N, device=device), torch.zeros(N, device=device)])\n","#             dgi_loss = bce_loss(logits.squeeze(), lbl)\n","#             reg_loss = model.Reg_loss(A, embeddings)\n","\n","#             loss = dgi_loss + lam * reg_loss\n","\n","#             if epoch % 500 == 0:\n","#                 print(f\"Epoch {epoch:4d} | DGI: {dgi_loss.item():.4f} | Reg: {reg_loss.item():.4f} | \"\n","#                       f\"λ*Reg: {(lam * reg_loss).item():.4f} | Total: {loss.item():.4f}\")\n","\n","#             loss.backward()\n","#             optimizer.step()\n","#             scheduler.step()\n","\n","#         model.eval()\n","#         with torch.no_grad():\n","#             emb = model.get_embeddings(node_feats, edge_index)\n","#             logits_cls = model.classifier(emb)                   # [N, 2]\n","#             class_probabilities = F.softmax(logits_cls, dim=1).cpu().numpy()\n","#             y_pred = np.argmax(class_probabilities, axis=1)\n","\n","#         acc  = accuracy_score(y_subset_np, y_pred)\n","#         acc_inv = accuracy_score(y_subset_np, 1 - y_pred)\n","\n","#         if acc_inv > acc:\n","#             acc = acc_inv\n","#             y_pred = 1 - y_pred\n","#             class_probabilities = class_probabilities[:, ::-1]\n","\n","#         prec = precision_score(y_subset_np, y_pred, zero_division=0)\n","#         rec  = recall_score(y_subset_np, y_pred, zero_division=0)\n","#         f1   = f1_score(y_subset_np, y_pred, zero_division=0)\n","#         ll   = log_loss(y_subset_np, class_probabilities)\n","\n","#         print(f\"Run {run+1} | Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | LogLoss: {ll:.4f}\")\n","\n","#         acc_scores.append(acc)\n","#         prec_scores.append(prec)\n","#         rec_scores.append(rec)\n","#         f1_scores.append(f1)\n","#         log_losses.append(ll)\n","\n","#     lambda_results = {\n","#         \"lambda\": lam,\n","#         \"accuracy\":  (float(np.mean(acc_scores)), float(np.std(acc_scores))),\n","#         \"precision\": (float(np.mean(prec_scores)), float(np.std(prec_scores))),\n","#         \"recall\":    (float(np.mean(rec_scores)), float(np.std(rec_scores))),\n","#         \"f1\":        (float(np.mean(f1_scores)),  float(np.std(f1_scores))),\n","#         \"log_loss\":  (float(np.mean(log_losses)), float(np.std(log_losses))),\n","#     }\n","#     all_results.append(lambda_results)\n","\n","#     print(f\"\\n--- RESULTS FOR LAMBDA = {lam} ---\")\n","#     print(f\"Accuracy : {lambda_results['accuracy'][0]:.4f} ± {lambda_results['accuracy'][1]:.4f}\")\n","#     print(f\"Precision: {lambda_results['precision'][0]:.4f} ± {lambda_results['precision'][1]:.4f}\")\n","#     print(f\"Recall   : {lambda_results['recall'][0]:.4f} ± {lambda_results['recall'][1]:.4f}\")\n","#     print(f\"F1 Score : {lambda_results['f1'][0]:.4f} ± {lambda_results['f1'][1]:.4f}\")\n","#     print(f\"Log Loss : {lambda_results['log_loss'][0]:.4f} ± {lambda_results['log_loss'][1]:.4f}\")\n","\n","# print(\"\\n================ FINAL SUMMARY FOR ALL LAMBDAS ================\\n\")\n","# print(f\"{'Lambda':>8} | {'Accuracy':>18} | {'Precision':>18} | {'Recall':>18} | {'F1 Score':>18} | {'Log Loss':>18}\")\n","# print(\"-\" * 108)\n","# for res in all_results:\n","#     print(f\"{res['lambda']:>8} | \"\n","#           f\"{res['accuracy'][0]:.4f} ± {res['accuracy'][1]:.4f} | \"\n","#           f\"{res['precision'][0]:.4f} ± {res['precision'][1]:.4f} | \"\n","#           f\"{res['recall'][0]:.4f} ± {res['recall'][1]:.4f} | \"\n","#           f\"{res['f1'][0]:.4f} ± {res['f1'][1]:.4f} | \"\n","#           f\"{res['log_loss'][0]:.4f} ± {res['log_loss'][1]:.4f}\")"]},{"cell_type":"code","execution_count":173,"metadata":{"id":"kIl9se1WkE0x","executionInfo":{"status":"ok","timestamp":1767033195505,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"}},"nbformat":4,"nbformat_minor":0}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LnXugizcVF7YMwomBw6YdBVslSX-PZ5b","timestamp":1757999148178},{"file_id":"1xgCbwtUlHV4PAYwxz76Mn_28K3QQYJcf","timestamp":1757865194724},{"file_id":"1VPHKG4LE-G4v1fRMT3t7s-91n2Nya0Qw","timestamp":1757864576935}],"authorship_tag":"ABX9TyP/WQIsrm/q2JR1qY4o2EIV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn # Import torch.nn\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","from sklearn.cluster import SpectralClustering\n","from sklearn.neighbors import NearestNeighbors\n","from scipy.sparse import lil_matrix\n","from scipy.optimize import linear_sum_assignment\n","from multiprocessing import Pool, cpu_count\n","from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset\n","from torchvision import models"],"metadata":{"id":"eGjt-z6ky5wd","executionInfo":{"status":"ok","timestamp":1757999478205,"user_tz":-330,"elapsed":2766,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["k_neighbors = 20\n","random_state = 42\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","num_samples_per_class = 300"],"metadata":{"id":"wXwvK-eV5cku","executionInfo":{"status":"ok","timestamp":1757999478209,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def set_seed(seed):\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)"],"metadata":{"id":"xk7BOAJf5e60","executionInfo":{"status":"ok","timestamp":1757999478250,"user_tz":-330,"elapsed":34,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def cluster_accuracy(y_true, y_pred):\n","    y_true = y_true.astype(np.int64)\n","    D = max(y_pred.max(), y_true.max()) + 1\n","    w = np.zeros((D, D), dtype=np.int64)\n","    for i in range(y_pred.size):\n","        w[y_pred[i], y_true[i]] += 1\n","    ind = linear_sum_assignment(w.max() - w)\n","    ind = np.array(ind).T\n","    return sum([w[i, j] for i, j in ind]) / y_pred.size"],"metadata":{"id":"0zZfBxkIy961","executionInfo":{"status":"ok","timestamp":1757999478254,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def hungarian_map(y_true, y_pred):\n","    y_true = y_true.astype(np.int64)\n","    D = max(y_pred.max(), y_true.max()) + 1\n","    w = np.zeros((D, D), dtype=np.int64)\n","    for i in range(y_pred.size):\n","        w[y_pred[i], y_true[i]] += 1\n","    ind = linear_sum_assignment(w.max() - w)\n","    ind = np.array(ind).T\n","    new_pred = np.zeros_like(y_pred, dtype=np.int64)\n","    for i, j in ind:\n","        new_pred[y_pred == i] = j\n","    return new_pred"],"metadata":{"id":"8sxm84cVy_us","executionInfo":{"status":"ok","timestamp":1757999479147,"user_tz":-330,"elapsed":7,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def compute_similarity_for_points(points, data, neighbors, max_dis):\n","    n = data.shape[0]\n","    local_similarity_matrix = lil_matrix((n, n), dtype=np.float32)\n","    neighbor_sets = {i: set(neighbors[i]) for i in points}\n","    for i in points:\n","        i_neighbors = neighbor_sets[i]\n","        point_i = data[i]\n","        for j in neighbors[i]:\n","            if j in neighbor_sets:\n","                j_neighbors = neighbor_sets[j]\n","            else:\n","                j_neighbors = set(neighbors[j])\n","            shared_neighbors = i_neighbors & j_neighbors\n","            if shared_neighbors:\n","                shared_idx = list(shared_neighbors)\n","                shared_points = data[shared_idx]\n","                point_j = data[j]\n","                d_i = np.linalg.norm(shared_points - point_i[np.newaxis, :], axis=1) / (max_dis + 1e-12)\n","                d_j = np.linalg.norm(shared_points - point_j[np.newaxis, :], axis=1) / (max_dis + 1e-12)\n","                d = 0.5 * (d_i + d_j)\n","                similarity = np.sum(np.exp(-d * d))\n","                if similarity > 0:\n","                    local_similarity_matrix[i, j] = similarity\n","    return local_similarity_matrix"],"metadata":{"id":"F1UOkqZSzB5M","executionInfo":{"status":"ok","timestamp":1757999480086,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def compute_similarity(data, k):\n","    n = data.shape[0]\n","    nn_model = NearestNeighbors(n_neighbors=k, algorithm='auto')\n","    nn_model.fit(data)\n","    distances, neighbors = nn_model.kneighbors(data)\n","    max_dis = np.max(distances) if distances.size else 1.0\n","    num_processes = max(1, cpu_count() - 1)\n","    points_split = np.array_split(range(n), num_processes)\n","    args = [(points, data, neighbors, max_dis) for points in points_split]\n","    with Pool(processes=num_processes) as pool:\n","        results = pool.starmap(compute_similarity_for_points, args)\n","    similarity_matrix = results[0]\n","    for mat in results[1:]:\n","        similarity_matrix = similarity_matrix + mat\n","    similarity_matrix = similarity_matrix.maximum(similarity_matrix.transpose())\n","    if similarity_matrix.data.size > 0:\n","        similarity_matrix.data = similarity_matrix.data / similarity_matrix.max()\n","    similarity_matrix.setdiag(1.0 + 1e-15)\n","    return similarity_matrix.tocsr()"],"metadata":{"id":"BRqf_f-KzENT","executionInfo":{"status":"ok","timestamp":1757999481207,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def compute_threshold_matrix(data, k):\n","    n = data.shape[0]\n","    similarity_matrix = compute_similarity(data, k)\n","    density = np.zeros(n, dtype=np.float32)\n","    top_k_indices = []\n","    for i in range(n):\n","        start, end = similarity_matrix.indptr[i], similarity_matrix.indptr[i+1]\n","        row_data = similarity_matrix.data[start:end]\n","        row_idx = similarity_matrix.indices[start:end]\n","        if row_data.size == 0:\n","            top_k_indices.append(np.array([], dtype=int))\n","            continue\n","        order = np.argsort(-row_data)\n","        sorted_idx = row_idx[order]\n","        sorted_data = row_data[order]\n","        k_eff = min(k, sorted_data.size)\n","        density[i] = np.sum(sorted_data[:k_eff])\n","        top_k_indices.append(sorted_idx)\n","    if density.max() > 0:\n","        density = density / density.max()\n","    nearest_neighbor_ranks = np.full(n, -1, dtype=int)\n","    for i in range(n):\n","        cur = density[i]\n","        for rank, nb in enumerate(top_k_indices[i]):\n","            if density[nb] > cur:\n","                nearest_neighbor_ranks[i] = rank\n","                break\n","    leader_points = np.full(n, -1, dtype=int)\n","    degree = density.copy()\n","    max_rank = int(nearest_neighbor_ranks.max()) if nearest_neighbor_ranks.max() >= 0 else 1\n","    sorted_by_density_indices = np.argsort(density)\n","    for i in sorted_by_density_indices:\n","        if nearest_neighbor_ranks[i] != -1:\n","            neighbor_idx = top_k_indices[i][nearest_neighbor_ranks[i]]\n","            contribution = degree[i] * np.exp(- (float(nearest_neighbor_ranks[i]) / float(max_rank))**2)\n","            degree[neighbor_idx] += contribution\n","    for i in range(n):\n","        if nearest_neighbor_ranks[i] != -1:\n","            neighbor_idx = top_k_indices[i][nearest_neighbor_ranks[i]]\n","            if degree[i] < degree[neighbor_idx]:\n","                leader_points[i] = neighbor_idx\n","    core_points = np.where(leader_points == -1)[0]\n","    core_idx_mapping = np.full(n, -1, dtype=int)\n","    core_idx_mapping[core_points] = np.arange(core_points.shape[0], dtype=int)\n","    visited = np.zeros(n, dtype=bool)\n","    for i in range(n):\n","        if visited[i]:\n","            continue\n","        if leader_points[i] == -1:\n","            leader_points[i] = i\n","            visited[i] = True\n","            continue\n","        cur = i\n","        stack = []\n","        while leader_points[cur] != -1 and leader_points[cur] != cur:\n","            stack.append(cur)\n","            visited[cur] = True\n","            cur = leader_points[cur]\n","        if leader_points[cur] == -1:\n","            leader_points[cur] = cur\n","        visited[cur] = True\n","        core = cur\n","        while stack:\n","            node = stack.pop()\n","            leader_points[node] = core\n","    S_coo = similarity_matrix.tocoo()\n","    rows, cols, vals = S_coo.row, S_coo.col, S_coo.data\n","    mask = rows < cols\n","    rows, cols, vals = rows[mask], cols[mask], vals[mask]\n","    weights = vals * density[rows] * density[cols]\n","    core_i = leader_points[rows]\n","    core_j = leader_points[cols]\n","    inter_mask = core_i != core_j\n","    core_i = core_i[inter_mask]\n","    core_j = core_j[inter_mask]\n","    weights = weights[inter_mask]\n","    core_i_mapped = core_idx_mapping[core_i]\n","    core_j_mapped = core_idx_mapping[core_j]\n","    valid_mask = (core_i_mapped >= 0) & (core_j_mapped >= 0)\n","    core_i_mapped = core_i_mapped[valid_mask].astype(int)\n","    core_j_mapped = core_j_mapped[valid_mask].astype(int)\n","    weights = weights[valid_mask]\n","    edges = list(zip(weights.tolist(), core_i_mapped.tolist(), core_j_mapped.tolist()))\n","    edges.sort(reverse=True, key=lambda x: x[0])\n","    m = core_points.shape[0]\n","    if m == 0:\n","        return np.zeros((0, 0), dtype=np.float32), leader_points, core_idx_mapping\n","    threshold_matrix = np.zeros((m, m), dtype=np.float32)\n","    core_labels = np.arange(m, dtype=int)\n","    for sim, i, j in edges:\n","        if core_labels[i] != core_labels[j]:\n","            label_i = core_labels[i]\n","            label_j = core_labels[j]\n","            comp_i = (core_labels == label_i)\n","            comp_j = (core_labels == label_j)\n","            threshold_matrix[np.ix_(comp_i, comp_j)] = sim\n","            core_labels[comp_i] = label_j\n","    threshold_matrix = np.maximum(threshold_matrix, threshold_matrix.T)\n","    np.fill_diagonal(threshold_matrix, 1.0 + 1e-15)\n","    return threshold_matrix, leader_points, core_idx_mapping"],"metadata":{"id":"NsN2TW6fzJij","executionInfo":{"status":"ok","timestamp":1757999482534,"user_tz":-330,"elapsed":6,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def tango(data, cluster_num, k, run_seed=None):\n","    threshold_matrix, leader_points, core_idx_mapping = compute_threshold_matrix(data, k)\n","    rng = run_seed if run_seed is not None else None\n","    if threshold_matrix.size == 0 or threshold_matrix.shape[0] < cluster_num:\n","        S_full = compute_similarity(data, k).toarray()\n","        clustering = SpectralClustering(\n","            n_clusters=cluster_num,\n","            affinity='precomputed',\n","            assign_labels='kmeans',\n","            random_state=run_seed\n","        )\n","        labels_full = clustering.fit_predict(S_full)\n","        return labels_full\n","    clustering = SpectralClustering(\n","        n_clusters=cluster_num,\n","        affinity='precomputed',\n","        assign_labels='kmeans',\n","        random_state=run_seed\n","    )\n","    core_labels = clustering.fit_predict(threshold_matrix)\n","    labels_full = core_labels[core_idx_mapping[leader_points]]\n","    return labels_full"],"metadata":{"id":"hm8Z0cTXzMTD","executionInfo":{"status":"ok","timestamp":1757999485896,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def main():\n","    set_seed(random_state)\n","\n","    # Load PneumoniaMNIST\n","    data = np.load('/home/snu/Downloads/breastmnist_224.npz', allow_pickle=True)\n","    all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","    all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","    images = all_images.astype(np.float32) / 255.0\n","    images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N, 3, 224, 224)\n","    labels = all_labels.astype(np.int64)\n","\n","    # Select balanced subset\n","    selected_indices = []\n","    classes = np.unique(labels)\n","    for c in classes:\n","        class_idx = np.where(labels == c)[0]\n","        chosen = np.random.choice(class_idx, size=min(num_samples_per_class, len(class_idx)), replace=False)\n","        selected_indices.extend(chosen)\n","\n","    selected_indices = np.array(selected_indices)\n","    images = images[selected_indices]\n","    labels = labels[selected_indices]\n","\n","    dataset = TensorDataset(torch.tensor(images), torch.tensor(labels))\n","    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n","\n","    # ====== Load ResNet-18 (pretrained) ======\n","    resnet = models.resnet18(pretrained=True)\n","    resnet.fc = nn.Identity()  # remove final classification layer\n","    resnet = resnet.to(device)\n","    resnet.eval()\n","\n","    # ====== Extract ResNet features ======\n","    feats, y_list = [], []\n","    with torch.no_grad():\n","        for imgs, lbls in loader:\n","            imgs = imgs.to(device).float()\n","            f = resnet(imgs)\n","            feats.append(f.cpu())\n","            y_list.append(lbls)\n","\n","    X = torch.cat(feats, dim=0).numpy().astype(np.float32)\n","    y = torch.cat(y_list, dim=0).numpy().astype(np.int64)\n","\n","    # Shuffle\n","    perm = np.random.permutation(len(X))\n","    X, y = X[perm], y[perm]\n","    print(\"Balanced subset:\", X.shape, y.shape)\n","\n","    # Apply TANGO\n","    y_pred = tango(X, cluster_num=len(np.unique(y)), k=k_neighbors)\n","    y_pred_aligned = hungarian_map(y, y_pred)\n","\n","    n_classes = len(np.unique(y))\n","    y_proba = np.zeros((len(y), n_classes), dtype=float)\n","    for idx, lab in enumerate(y_pred_aligned):\n","        if 0 <= lab < n_classes:\n","            y_proba[idx, lab] = 1.0\n","        else:\n","            y_proba[idx, :] = 1.0 / n_classes\n","\n","    acc = accuracy_score(y, y_pred_aligned)\n","    if n_classes == 2:\n","        acc_inv = accuracy_score(y, 1 - y_pred_aligned)\n","        if acc_inv > acc:\n","            acc = acc_inv\n","            y_pred_aligned = 1 - y_pred_aligned\n","\n","    prec = precision_score(y, y_pred_aligned, zero_division=0)\n","    rec = recall_score(y, y_pred_aligned, zero_division=0)\n","    f1 = f1_score(y, y_pred_aligned, zero_division=0)\n","    ll = log_loss(y, y_proba)\n","\n","    print(\"==== TANGO results on PneumoniaMNIST features ====\")\n","    print(f\"Accuracy: {acc:.4f}\")\n","    print(f\"Precision: {prec:.4f}\")\n","    print(f\"Recall: {rec:.4f}\")\n","    print(f\"F1: {f1:.4f}\")\n","    print(f\"LogLoss: {ll:.6f}\")\n","\n","    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"log_loss\": ll}"],"metadata":{"id":"jMbIphf7zOYD","executionInfo":{"status":"ok","timestamp":1757999500074,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    num_runs = 10\n","    all_results = {\"accuracy\": [], \"precision\": [], \"recall\": [], \"f1\": [], \"log_loss\": []}\n","    for run in range(num_runs):\n","        print(f\"\\n--- Run {run+1}/{num_runs} ---\")\n","        set_seed(run)\n","        res = main()\n","        for k in all_results.keys():\n","            all_results[k].append(res[k])\n","\n","    print(\"\\n=== FINAL SUMMARY ===\")\n","    for metric, vals in all_results.items():\n","        print(f\"{metric:>10} | mean={np.mean(vals):.4f} ± {np.std(vals):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xpvX-FBVztx7","executionInfo":{"status":"ok","timestamp":1757999521866,"user_tz":-330,"elapsed":17652,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"9430be63-12a7-40c7-febd-b644b765fc38"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Run 1/10 ---\n"]},{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Balanced subset: (510, 512) (510,)\n","==== TANGO results on PneumoniaMNIST features ====\n","Accuracy: 0.5039\n","Precision: 0.5556\n","Recall: 0.7833\n","F1: 0.6501\n","LogLoss: 17.880479\n","\n","--- Run 2/10 ---\n"]},{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Balanced subset: (510, 512) (510,)\n","==== TANGO results on PneumoniaMNIST features ====\n","Accuracy: 0.5039\n","Precision: 0.5556\n","Recall: 0.7833\n","F1: 0.6501\n","LogLoss: 17.880479\n","\n","--- Run 3/10 ---\n"]},{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Balanced subset: (510, 512) (510,)\n","==== TANGO results on PneumoniaMNIST features ====\n","Accuracy: 0.5039\n","Precision: 0.5556\n","Recall: 0.7833\n","F1: 0.6501\n","LogLoss: 17.880479\n","\n","--- Run 4/10 ---\n"]},{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Balanced subset: (510, 512) (510,)\n","==== TANGO results on PneumoniaMNIST features ====\n","Accuracy: 0.5039\n","Precision: 0.5556\n","Recall: 0.7833\n","F1: 0.6501\n","LogLoss: 17.880479\n","\n","--- Run 5/10 ---\n"]},{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Balanced subset: (510, 512) (510,)\n","==== TANGO results on PneumoniaMNIST features ====\n","Accuracy: 0.5039\n","Precision: 0.5556\n","Recall: 0.7833\n","F1: 0.6501\n","LogLoss: 17.880479\n","\n","--- Run 6/10 ---\n"]},{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Balanced subset: (510, 512) (510,)\n","==== TANGO results on PneumoniaMNIST features ====\n","Accuracy: 0.5039\n","Precision: 0.5556\n","Recall: 0.7833\n","F1: 0.6501\n","LogLoss: 17.880479\n","\n","--- Run 7/10 ---\n"]},{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Balanced subset: (510, 512) (510,)\n","==== TANGO results on PneumoniaMNIST features ====\n","Accuracy: 0.5039\n","Precision: 0.5556\n","Recall: 0.7833\n","F1: 0.6501\n","LogLoss: 17.880479\n","\n","--- Run 8/10 ---\n"]},{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Balanced subset: (510, 512) (510,)\n","==== TANGO results on PneumoniaMNIST features ====\n","Accuracy: 0.5039\n","Precision: 0.5556\n","Recall: 0.7833\n","F1: 0.6501\n","LogLoss: 17.880479\n","\n","--- Run 9/10 ---\n"]},{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Balanced subset: (510, 512) (510,)\n","==== TANGO results on PneumoniaMNIST features ====\n","Accuracy: 0.5039\n","Precision: 0.5556\n","Recall: 0.7833\n","F1: 0.6501\n","LogLoss: 17.880479\n","\n","--- Run 10/10 ---\n"]},{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Balanced subset: (510, 512) (510,)\n","==== TANGO results on PneumoniaMNIST features ====\n","Accuracy: 0.5039\n","Precision: 0.5556\n","Recall: 0.7833\n","F1: 0.6501\n","LogLoss: 17.880479\n","\n","=== FINAL SUMMARY ===\n","  accuracy | mean=0.5039 ± 0.0000\n"," precision | mean=0.5556 ± 0.0000\n","    recall | mean=0.7833 ± 0.0000\n","        f1 | mean=0.6501 ± 0.0000\n","  log_loss | mean=17.8805 ± 0.0000\n"]}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1DYm4Tp4UyHbU8L50J7PRjTRJ2TSWOTK7","timestamp":1757588815346},{"file_id":"1iv_1nsUx_qiDP79wUJxi5TUAhxQvjBQa","timestamp":1757585571289},{"file_id":"1Fx6b-3_Pg91hKqbv4D6qOccsxa0bCUVN","timestamp":1757570085656},{"file_id":"1Mahacib0G1vRdLzwGphqF56BtT95ijlV","timestamp":1749058471371},{"file_id":"16E8IQLzm44N7b3kAaZeiEu-8WumVsP4R","timestamp":1745690568611},{"file_id":"1oxb_9gwPbrwgQZheblJOOX6gdOVM0Fuf","timestamp":1745065170929},{"file_id":"1egsySsyRJlVCc7FmFO04YKowEO-MK3jQ","timestamp":1743783497798},{"file_id":"18zwBHYwMgYxbkHvZYDHKtTM1PkuT7ACk","timestamp":1743779759481},{"file_id":"18xxNJDLcJndTxx-laCpvq_2AdGc4rK2D","timestamp":1743695341564}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCsIte6uO5cI","executionInfo":{"status":"ok","timestamp":1766583319853,"user_tz":-330,"elapsed":10,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"53e426e7-4675-44c9-8d4c-abda60c8578c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.0+cu121\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset\n","import numpy as np\n","import random\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, log_loss\n","from munkres import Munkres"],"metadata":{"id":"NVVONHsFU-6B","executionInfo":{"status":"ok","timestamp":1766583319864,"user_tz":-330,"elapsed":10,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def set_seed(seed=42):\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n","set_seed(42)"],"metadata":{"id":"kljbbZlgVAaY","executionInfo":{"status":"ok","timestamp":1766583319867,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["class PairDataset(Dataset):\n","    def __init__(self, pairs, labels):\n","        self.pairs = pairs\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.pairs)\n","\n","    def __getitem__(self, idx):\n","        return self.pairs[idx][0], self.pairs[idx][1], self.labels[idx]"],"metadata":{"id":"AgnEa8DtVCPQ","executionInfo":{"status":"ok","timestamp":1766583319922,"user_tz":-330,"elapsed":53,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["class SiameseNet(nn.Module):\n","    def __init__(self, input_dim, hidden_dim=256):\n","        super().__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward_once(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return self.fc3(x)\n","\n","    def forward(self, x1, x2):\n","        out1 = self.forward_once(x1)\n","        out2 = self.forward_once(x2)\n","        dist = F.pairwise_distance(out1, out2)\n","        return dist, out1, out2"],"metadata":{"id":"JrGPVPwAVEYp","executionInfo":{"status":"ok","timestamp":1766583319926,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["class OrthoLinear(nn.Module):\n","    def __init__(self, in_dim, out_dim, eps=1e-2):\n","        super().__init__()\n","        self.fc = nn.Linear(in_dim, out_dim)\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        Y_tilde = self.fc(x)\n","        gram = Y_tilde.T @ Y_tilde + self.eps * torch.eye(Y_tilde.shape[1], device=x.device)\n","        L = torch.linalg.cholesky(gram)\n","        L_inv = torch.inverse(L)\n","        return Y_tilde @ L_inv.T"],"metadata":{"id":"_1kj7EJMVHXJ","executionInfo":{"status":"ok","timestamp":1766583319929,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["class SpectralNet(nn.Module):\n","    def __init__(self, input_dim, n_clusters, hidden_dim=256):\n","        super().__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        self.ortho = OrthoLinear(hidden_dim, n_clusters)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return self.ortho(x)"],"metadata":{"id":"J0uANbEzepmO","executionInfo":{"status":"ok","timestamp":1766583319985,"user_tz":-330,"elapsed":55,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["def contrastive_loss(distance, label, margin=1.0):\n","    pos = label * torch.pow(distance, 2)\n","    neg = (1 - label) * torch.pow(torch.clamp(margin - distance, min=0.0), 2)\n","    return torch.mean(pos + neg)\n","\n","def spectral_loss(Y, W):\n","    D = torch.diag(W.sum(axis=1))\n","    L = D - W\n","    num = torch.trace(Y.T @ L @ Y)\n","    denom = torch.trace(Y.T @ D @ Y)\n","    return num / (denom + 1e-12)"],"metadata":{"id":"YqSLWlunVLyR","executionInfo":{"status":"ok","timestamp":1766583319998,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def compute_affinity(X, scale, n_neighbors=20):\n","    nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1).fit(X)\n","    distances, indices = nbrs.kneighbors(X)\n","    distances, indices = distances[:, 1:], indices[:, 1:]\n","    W = np.zeros((len(X), len(X)))\n","    for i in range(len(X)):\n","        for j in range(n_neighbors):\n","            W[i, indices[i, j]] = np.exp(-distances[i, j] ** 2 / (2 * scale ** 2))\n","            W[indices[i, j], i] = W[i, indices[i, j]]\n","    return W\n","\n","def compute_scale(X, n_neighbors=20):\n","    nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1).fit(X)\n","    distances, _ = nbrs.kneighbors(X)\n","    return np.median(distances[:, -1])\n","\n","def calculate_accuracy(y_pred, y_true, n_clusters):\n","    cm = confusion_matrix(y_true, y_pred)\n","    cost = np.zeros((n_clusters, n_clusters))\n","    for i in range(n_clusters):\n","        for j in range(n_clusters):\n","            cost[i, j] = cm[:, j].sum() - cm[i, j]\n","    m = Munkres()\n","    mapping = m.compute(cost.tolist())\n","    new_labels = np.zeros_like(y_pred)\n","    for row, col in mapping:\n","        new_labels[y_pred == row] = col\n","    return (new_labels == y_true).mean()"],"metadata":{"id":"FdKCDe1wVOg5","executionInfo":{"status":"ok","timestamp":1766583320001,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def train_siamese(siamese_net, dataloader, epochs=50, lr=1e-3, device='cpu'):\n","    siamese_net.to(device)\n","    opt = optim.Adam(siamese_net.parameters(), lr=lr)\n","    for ep in range(epochs):\n","        siamese_net.train()\n","        total_loss = 0.0\n","        for x1, x2, labels in dataloader:\n","            x1 = x1.to(device).float()\n","            x2 = x2.to(device).float()\n","            labels = labels.to(device).float()\n","            dist, _, _ = siamese_net(x1, x2)\n","            loss = contrastive_loss(dist, labels)\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","            total_loss += loss.item() * x1.size(0)\n","        avg_loss = total_loss / len(dataloader.dataset)\n","        print(f\"[Siamese] Epoch {ep + 1}/{epochs}, Avg Loss={avg_loss:.6f}\")\n","    siamese_net.to('cpu')\n","    return siamese_net\n","\n","def train_spectral(spectral_net, X_train, W, epochs=50, lr=1e-3, tol=1e-6, device='cpu'):\n","    spectral_net.to(device)\n","    opt = optim.Adam([\n","        {'params': spectral_net.fc1.parameters()},\n","        {'params': spectral_net.fc2.parameters()},\n","        {'params': spectral_net.ortho.fc.parameters()}\n","    ], lr=lr)\n","\n","    X_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)\n","    W_tensor = torch.tensor(W, dtype=torch.float32, device=device)\n","\n","    prev_loss = float('inf')\n","    for ep in range(epochs):\n","        spectral_net.train()\n","        Y = spectral_net(X_tensor)  # (n_samples, n_clusters)\n","        loss = spectral_loss(Y, W_tensor)\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","\n","        loss_item = loss.item()\n","        print(f\"[SpectralNet] Epoch {ep + 1}/{epochs}, Loss={loss_item:.8f}\")\n","\n","        if abs(prev_loss - loss_item) < tol:\n","            print(\"SpectralNet converged (tol reached).\")\n","            break\n","        prev_loss = loss_item\n","    spectral_net.to('cpu')\n","    return spectral_net"],"metadata":{"id":"Xnh7Xw37WA7e","executionInfo":{"status":"ok","timestamp":1766583320049,"user_tz":-330,"elapsed":45,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def main():\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    # ====== Load PneumoniaMNIST ======\n","    data = np.load('/home/snu/Downloads/breastmnist_224.npz', allow_pickle=True)\n","    all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","    all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","    images = all_images.astype(np.float32) / 255.0\n","    images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N, 3, 224, 224)\n","    labels = all_labels.astype(np.int64)\n","\n","    # ====== Select 2000 samples per class ======\n","    selected_indices = []\n","    num_per_class = 1000\n","    classes = np.unique(labels)\n","    for c in classes:\n","        class_idx = np.where(labels == c)[0]\n","        chosen = np.random.choice(class_idx, size=min(num_per_class, len(class_idx)), replace=False)\n","        selected_indices.extend(chosen)\n","\n","    selected_indices = np.array(selected_indices)\n","    images = images[selected_indices]\n","    labels = labels[selected_indices]\n","\n","    # ====== Create dataset ======\n","    dataset = TensorDataset(torch.tensor(images), torch.tensor(labels))\n","    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n","\n","    # ====== Load ViT-DINO ======\n","    vit = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n","    vit.eval().to(device)\n","\n","    feats, y_list = [], []\n","    with torch.no_grad():\n","        for imgs, lbls in loader:\n","            imgs = imgs.to(device).float()\n","            f = vit(imgs)\n","            if isinstance(f, (list, tuple)):\n","                f = f[0]\n","            feats.append(f.cpu())\n","            y_list.append(lbls)\n","\n","    X = torch.cat(feats, dim=0).numpy().astype(np.float32)\n","    y = torch.cat(y_list, dim=0).numpy().astype(np.int64)\n","\n","    # Shuffle\n","    perm = np.random.permutation(len(X))\n","    X, y = X[perm], y[perm]\n","    print(\"Balanced subset:\", X.shape, y.shape)\n","\n","    num_nodes, num_feats = X.shape\n","    n_clusters = 2\n","    hidden_dim = 256\n","    batch_size = 16\n","    n_neighbors = 20\n","\n","    # ====== Build siamese pairs ======\n","    pairs, labels_pairs = [], []\n","    nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1).fit(X)\n","    distances, indices = nbrs.kneighbors(X)\n","    for i in range(len(X)):\n","        for j in indices[i, 1:]:\n","            pairs.append([X[i], X[j]])\n","            labels_pairs.append(1)\n","        all_indices = set(range(len(X)))\n","        neighbor_set = set(indices[i, 1:])\n","        non_neighbors = list(all_indices - neighbor_set - {i})\n","        j = np.random.choice(non_neighbors)\n","        pairs.append([X[i], X[j]])\n","        labels_pairs.append(0)\n","\n","    dataset_pairs = PairDataset(pairs, labels_pairs)\n","    dataloader_pairs = DataLoader(dataset_pairs, batch_size=batch_size, shuffle=True)\n","\n","    # ====== Train Siamese ======\n","    siamese = SiameseNet(num_feats, hidden_dim)\n","    siamese = train_siamese(siamese, dataloader_pairs, epochs=50, device=device)\n","\n","    with torch.no_grad():\n","        X_embed = siamese.forward_once(torch.tensor(X, dtype=torch.float32)).numpy()\n","\n","    # ====== Train SpectralNet ======\n","    scale = compute_scale(X_embed, n_neighbors=n_neighbors)\n","    W = compute_affinity(X_embed, scale, n_neighbors=n_neighbors)\n","    spectral = SpectralNet(num_feats, n_clusters, hidden_dim)\n","    spectral = train_spectral(spectral, X, W, epochs=50, device=device)\n","\n","    with torch.no_grad():\n","        Y = spectral(torch.tensor(X, dtype=torch.float32)).numpy()\n","        y_pred_proba = F.softmax(torch.tensor(Y), dim=1).numpy()\n","\n","    kmeans = KMeans(n_clusters=n_clusters, n_init=20)\n","    y_pred = kmeans.fit_predict(Y)\n","\n","    acc_score = calculate_accuracy(y_pred, y, n_clusters)\n","    acc_score_inverted = calculate_accuracy(1 - y_pred, y, n_clusters)\n","    if acc_score_inverted > acc_score:\n","        acc_score = acc_score_inverted\n","        y_pred = 1 - y_pred\n","\n","    prec = precision_score(y, y_pred)\n","    rec = recall_score(y, y_pred)\n","    f1 = f1_score(y, y_pred)\n","    ll = log_loss(y, y_pred_proba)\n","\n","    print(\"Final clustering accuracy:\", acc_score)\n","    print(\"Precision:\", prec)\n","    print(\"Recall:\", rec)\n","    print(\"F1 Score:\", f1)\n","    print(\"Log Loss:\", ll)\n","\n","    return {\"accuracy\": acc_score, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"log_loss\": ll}\n","\n","# --------------------------\n","# Multi-runs\n","# --------------------------\n","if __name__ == \"__main__\":\n","    num_runs = 10\n","    all_results = {\"accuracy\": [], \"precision\": [], \"recall\": [], \"f1\": [], \"log_loss\": []}\n","    for run in range(num_runs):\n","        print(f\"\\n--- Run {run+1}/{num_runs} ---\")\n","        set_seed(run)\n","        res = main()\n","        for k in all_results.keys():\n","            all_results[k].append(res[k])\n","\n","    print(\"\\n=== FINAL SUMMARY ===\")\n","    for metric, vals in all_results.items():\n","        print(f\"{metric:>10} | mean={np.mean(vals):.4f} ± {np.std(vals):.4f}\")\n"],"metadata":{"id":"fvJELGsSVinr","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"969899dc-7583-4e23-dc91-62b2a4de2130","executionInfo":{"status":"error","timestamp":1766583327398,"user_tz":-330,"elapsed":7347,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Run 1/10 ---\n"]},{"output_type":"stream","name":"stderr","text":["Using cache found in /home/snu/.cache/torch/hub/facebookresearch_dino_main\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.72 GiB of which 46.62 MiB is free. Process 235935 has 3.78 GiB memory in use. Process 239319 has 694.00 MiB memory in use. Process 239627 has 1.38 GiB memory in use. Process 239987 has 1.38 GiB memory in use. Process 240113 has 694.00 MiB memory in use. Including non-PyTorch memory, this process has 1.98 GiB memory in use. Process 241651 has 2.11 GiB memory in use. Process 242043 has 3.21 GiB memory in use. Of the allocated memory 1.68 GiB is allocated by PyTorch, and 57.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 124\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_runs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m set_seed(run)\n\u001b[0;32m--> 124\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m all_results\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    126\u001b[0m     all_results[k]\u001b[38;5;241m.\u001b[39mappend(res[k])\n","Cell \u001b[0;32mIn[37], line 32\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# ====== Load ViT-DINO ======\u001b[39;00m\n\u001b[1;32m     31\u001b[0m vit \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebookresearch/dino:main\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdino_vitb16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mvit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m feats, y_list \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n","File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (1 times)]\u001b[0m\n","File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n","File \u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.72 GiB of which 46.62 MiB is free. Process 235935 has 3.78 GiB memory in use. Process 239319 has 694.00 MiB memory in use. Process 239627 has 1.38 GiB memory in use. Process 239987 has 1.38 GiB memory in use. Process 240113 has 694.00 MiB memory in use. Including non-PyTorch memory, this process has 1.98 GiB memory in use. Process 241651 has 2.11 GiB memory in use. Process 242043 has 3.21 GiB memory in use. Of the allocated memory 1.68 GiB is allocated by PyTorch, and 57.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"markdown","source":["=== FINAL SUMMARY ===\n","  accuracy | mean=0.5271 ± 0.0186\n"," precision | mean=0.6707 ± 0.0621\n","    recall | mean=0.3043 ± 0.2325\n","        f1 | mean=0.3661 ± 0.1580\n","  log_loss | mean=0.6926 ± 0.0041 (batch size = 32)"],"metadata":{"id":"kYAUvr44e_6d"}},{"cell_type":"markdown","source":["=== FINAL SUMMARY ===\n","  accuracy | mean=0.5439 ± 0.0262\n"," precision | mean=0.6301 ± 0.0744\n","    recall | mean=0.3763 ± 0.3009\n","        f1 | mean=0.3889 ± 0.2028\n","  log_loss | mean=0.6909 ± 0.0050(batch size = 16)"],"metadata":{"id":"orqy5ClYmzuN"}},{"cell_type":"code","source":[],"metadata":{"id":"2NEvYcGsfokJ","executionInfo":{"status":"aborted","timestamp":1766583327447,"user_tz":-330,"elapsed":7634,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":null,"outputs":[]}]}
{"cells":[{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"TXOLlhisilDx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install -q torch_geometric\n","# !pip install -q class_resolver\n","# !pip3 install pymatting\n"],"metadata":{"id":"tAONEptfind3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"VSYEATM8HJ2u","executionInfo":{"status":"ok","timestamp":1766992819210,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import random\n","import copy\n","import scipy.sparse as sp\n","\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","from torchvision import models\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","\n","# torch-geometric imports\n","from torch_geometric.nn import GATConv\n","from torch_geometric.data import Data"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"vVdNNNJreeQ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766992822003,"user_tz":-330,"elapsed":8,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"75b36dc0-522f-4ab8-9463-a82642296218"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available: True\n","GPU Name: NVIDIA RTX A4000\n"]}],"source":["import torch\n","print(\"CUDA available:\", torch.cuda.is_available())\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"JinL9v8LHM8o","executionInfo":{"status":"ok","timestamp":1766992823468,"user_tz":-330,"elapsed":42,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["data = np.load('/home/snu/Downloads/breastmnist_224.npz', allow_pickle=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":406,"status":"ok","timestamp":1766992828193,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"xrNOqnjlHUXo","outputId":"67fd6e47-94fa-43e5-9927-70c7d460489a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Images, labels shapes: torch.Size([780, 3, 224, 224]) torch.Size([780])\n"]}],"source":["all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","images = all_images.astype(np.float32) / 255.0\n","images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N,3,224,224)\n","\n","X = torch.tensor(images)\n","y = torch.tensor(all_labels).long()\n","print(\"Images, labels shapes:\", X.shape, y.shape)\n","\n","dataset = TensorDataset(X, y)\n","class0_indices = [i for i in range(len(y)) if y[i] == 0]\n","class1_indices = [i for i in range(len(y)) if y[i] == 1]\n","\n","random.seed(42)\n","sampled_class0 = random.sample(class0_indices, min(1000, len(class0_indices)))\n","sampled_class1 = random.sample(class1_indices, min(1000, len(class1_indices)))\n","\n","combined_indices = sampled_class0 + sampled_class1\n","random.shuffle(combined_indices)\n","\n","final_dataset = Subset(dataset, combined_indices)\n","final_loader = DataLoader(final_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19379,"status":"ok","timestamp":1766992850715,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"egLJ3D9jHmdP","outputId":"f493f739-6680-494e-84c6-52b5e1b2f2e6","scrolled":true},"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /home/snu/.cache/torch/hub/facebookresearch_dino_main\n"]},{"output_type":"stream","name":"stdout","text":["Feature shape: (780, 768)\n","Label shape: (780,)\n"]}],"source":["import torch\n","import timm\n","import numpy as np\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","vit = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n","vit.eval().to(device)\n","\n","vit_feats = []\n","y_list = []\n","\n","with torch.no_grad():\n","    for imgs, lbls in final_loader:\n","        imgs = imgs.to(device)\n","        feats = vit(imgs)\n","        vit_feats.append(feats.cpu())\n","        y_list.extend(lbls.cpu().tolist())\n","\n","F = torch.cat(vit_feats, dim=0).numpy().astype(np.float32)\n","y_labels = np.array(y_list).astype(np.int64)\n","\n","print(\"Feature shape:\", F.shape)\n","print(\"Label shape:\", y_labels.shape)\n","features = F"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"UHJ387UneeQ2","executionInfo":{"status":"ok","timestamp":1766992854974,"user_tz":-330,"elapsed":47,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def sim(h1, h2, tau=0.2):\n","    z1 = nnFn.normalize(h1, dim=-1, p=2)\n","    z2 = nnFn.normalize(h2, dim=-1, p=2)\n","    return torch.mm(z1, z2.t()) / tau\n","\n","def contrastive_loss_wo_cross_network(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    intra_sim = f(sim(h1, h1))\n","    inter_sim = f(sim(h1, h2))\n","    return -torch.log(inter_sim.diag() /\n","                     (intra_sim.sum(dim=-1) + inter_sim.sum(dim=-1) - intra_sim.diag()))\n","\n","def contrastive_loss_wo_cross_view(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    cross_sim = f(sim(h1, z))\n","    return -torch.log(cross_sim.diag() / cross_sim.sum(dim=-1))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"AEcGcMk8eeQ2","executionInfo":{"status":"ok","timestamp":1766992858716,"user_tz":-330,"elapsed":12,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.PReLU(), # nn.ELU()\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ZH7dcLiNeeQ3","executionInfo":{"status":"ok","timestamp":1766992860300,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch_geometric.nn import GATConv\n","\n","class GATEncoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ, cut=0, heads=1):\n","        super(GATEncoder, self).__init__()\n","        self.device = device\n","        self.activ = activ\n","        self.cut = cut\n","        self.heads = heads\n","        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True)\n","        self.bn1 = nn.BatchNorm1d(hidden_dim * heads)\n","        self.dropout1 = nn.Dropout(0.3)\n","        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=heads, concat=True)\n","        self.bn2 = nn.BatchNorm1d(hidden_dim * heads)\n","        self.dropout2 = nn.Dropout(0.3)\n","        self.gat3 = GATConv(hidden_dim * heads, hidden_dim, heads=1, concat=False)\n","        self.bn3 = nn.BatchNorm1d(hidden_dim)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","\n","        x = self.gat1(x, edge_index)\n","        x = self.dropout1(x)\n","        x = self.bn1(x)\n","\n","        x = self.gat2(x, edge_index)\n","        x = self.dropout2(x)\n","        x = self.bn2(x)\n","\n","        x = self.gat3(x, edge_index)\n","        x = self.dropout3(x)\n","        x = self.bn3(x)\n","\n","        logits = self.mlp(x)\n","        return logits\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"DqH_j0szeeQ3","executionInfo":{"status":"ok","timestamp":1766992864845,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class EMA():  # Moving Average update\n","    def __init__(self, beta):\n","        super().__init__()\n","        self.beta = beta\n","\n","    def update_average(self, old, new):\n","        if old is None:\n","            return new\n","        return old * self.beta + (1 - self.beta) * new\n","\n","def update_moving_average(ema_updater, ma_model, current_model):\n","    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n","        old_weight, up_weight = ma_params.data, current_params.data\n","        ma_params.data = ema_updater.update_average(old_weight, up_weight)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"fLr3BCPkeeQ3","executionInfo":{"status":"ok","timestamp":1766992866186,"user_tz":-330,"elapsed":7,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","from torch_geometric.nn import GATConv\n","import copy\n","\n","class GAT(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ, cut=0,\n","                 heads=1, moving_average_decay=0.5):\n","        super(GAT, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","        self.cut = cut\n","        self.beta = 0.6\n","\n","\n","        self.online_encoder = GATEncoder(input_dim, hidden_dim, device, activ, cut, heads)\n","        self.target_encoder = copy.deepcopy(self.online_encoder)\n","\n","\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_dim)\n","\n","        self.loss = self.cut_loss if cut else self.modularity_loss\n","        self.target_ema_updater = EMA(moving_average_decay)\n","\n","    def reset_moving_average(self):\n","        del self.target_encoder\n","        self.target_encoder = None\n","\n","    def update_ma(self):\n","        assert self.target_encoder is not None, 'target encoder has not been created yet'\n","        update_moving_average(self.target_ema_updater, self.target_encoder, self.online_encoder)\n","\n","    def forward(self, data1, data2):\n","\n","        x1 = self.online_encoder(data1)\n","        logits1 = self.online_predictor(x1)\n","        S1 = nnFn.softmax(logits1, dim=1)\n","\n","\n","        x2 = self.online_encoder(data2)\n","        logits2 = self.online_predictor(x2)\n","        S2 = nnFn.softmax(logits2, dim=1)\n","\n","        with torch.no_grad():\n","            target_proj_one = self.target_encoder(data1).detach()\n","            target_proj_two = self.target_encoder(data2).detach()\n","\n","\n","        l1 = self.beta * contrastive_loss_wo_cross_network(x1, x2, target_proj_two) + \\\n","          (1.0 - self.beta) * contrastive_loss_wo_cross_view(x1, x2, target_proj_two)\n","\n","        l2 = self.beta * contrastive_loss_wo_cross_network(x2, x1, target_proj_one) + \\\n","          (1.0 - self.beta) * contrastive_loss_wo_cross_view(x2, x1, target_proj_one)\n","\n","        return S1, S2, logits1, logits2, l1, l2\n","\n","    def modularity_loss(self, A, S):\n","        C = nnFn.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A)\n","        B = A - torch.ger(d, d) / (2 * m)\n","\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        k = torch.norm(I_S)\n","        n = S.shape[0]\n","\n","        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n","\n","        return modularity_term + collapse_reg_term\n","\n","    def cut_loss(self, A, S):\n","        S = nnFn.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / den)\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n","\n","        return mincut_loss + ortho_loss"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"X4_3_cvSeeQ4","executionInfo":{"status":"ok","timestamp":1766992873428,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def create_adj(features, cut, alpha=1.0):\n","    \"\"\"Return a dense W0 matrix (only once), as you originally used for A1 / unsup loss.\n","       We still create the dense matrix once, but all augmentations below work with edge_index.\n","    \"\"\"\n","    F_norm = features / np.linalg.norm(features, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = (W * (W >= alpha)).astype(np.float32)\n","    return W"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"PfC51cQDeeQ4","executionInfo":{"status":"ok","timestamp":1766992875711,"user_tz":-330,"elapsed":11,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def edge_index_from_dense(W):\n","    \"\"\"Return edge_index as numpy array shape (2, E) and edge_weight vector.\"\"\"\n","    rows, cols = np.nonzero(W > 0)\n","    edge_index = np.vstack([rows, cols]).astype(np.int64)\n","    edge_weight = W[rows, cols].astype(np.float32)\n","    return edge_index, edge_weight"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"JsXN7D23eeQ4","executionInfo":{"status":"ok","timestamp":1766992877065,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def build_adj_list(edge_index_np, num_nodes):\n","    \"\"\"Build adjacency list: list of neighbor arrays for each node (numpy).\"\"\"\n","    adj = [[] for _ in range(num_nodes)]\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    for s, d in zip(src, dst):\n","        adj[s].append(d)\n","    # convert to numpy arrays for speed\n","    adj = [np.array(neis, dtype=np.int64) if len(neis) > 0 else np.array([], dtype=np.int64) for neis in adj]\n","    return adj"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"qR_yaOfWeeQ4","executionInfo":{"status":"ok","timestamp":1766992880710,"user_tz":-330,"elapsed":8,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=None):\n","    \"\"\"Randomly drop edges from edge_index. Returns new edge_index (2 x E') and edge_weight placeholder.\"\"\"\n","    rng = np.random.default_rng(seed)\n","    E = edge_index_np.shape[1]\n","    keep_mask = rng.random(E) >= drop_percent\n","    new_edge_index = edge_index_np[:, keep_mask]\n","    return new_edge_index"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"o5dCZStEeeQ4","executionInfo":{"status":"ok","timestamp":1766992882284,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def aug_subgraph_edge_index(features_np, edge_index_np, adj_list, drop_percent=0.2, seed=None):\n","    \"\"\"\n","    Sample a subgraph by selecting s_node_num nodes via neighbor expansion (BFS-like),\n","    then return (sub_features, sub_edge_index) with node ids remapped to [0..s-1].\n","    \"\"\"\n","    rng = np.random.default_rng(seed)\n","    num_nodes = features_np.shape[0]\n","    s_node_num = int(num_nodes * (1 - drop_percent))\n","    if s_node_num < 1:\n","        s_node_num = 1\n","\n","    # choose a random center node\n","    center_node = int(rng.integers(0, num_nodes))\n","    sub_nodes = [center_node]\n","    front_idx = 0\n","\n","    # BFS-like expansion using adjacency list until we reach s_node_num\n","    while len(sub_nodes) < s_node_num and front_idx < len(sub_nodes):\n","        cur = sub_nodes[front_idx]\n","        neighbors = adj_list[cur]\n","        if neighbors.size > 0:\n","            # shuffle neighbors and try to add new ones\n","            nbrs_shuffled = neighbors.copy()\n","            rng.shuffle(nbrs_shuffled)\n","            for nb in nbrs_shuffled:\n","                if nb not in sub_nodes:\n","                    sub_nodes.append(int(nb))\n","                    if len(sub_nodes) >= s_node_num:\n","                        break\n","        front_idx += 1\n","        # if BFS stalls (no new neighbors), add random nodes\n","        if front_idx >= len(sub_nodes) and len(sub_nodes) < s_node_num:\n","            remaining = [n for n in range(num_nodes) if n not in sub_nodes]\n","            if not remaining:\n","                break\n","            add = int(rng.choice(remaining))\n","            sub_nodes.append(add)\n","\n","    sub_nodes = sorted(set(sub_nodes))\n","    node_map = {old: new for new, old in enumerate(sub_nodes)}\n","\n","    # induce edges that have both ends in sub_nodes\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    mask_src_in = np.isin(src, sub_nodes)\n","    mask_dst_in = np.isin(dst, sub_nodes)\n","    mask = mask_src_in & mask_dst_in\n","    sel_src = src[mask]\n","    sel_dst = dst[mask]\n","    # remap\n","    remapped_src = np.array([node_map[int(s)] for s in sel_src], dtype=np.int64)\n","    remapped_dst = np.array([node_map[int(d)] for d in sel_dst], dtype=np.int64)\n","    new_edge_index = np.vstack([remapped_src, remapped_dst])\n","    # sub features\n","    sub_features = features_np[sub_nodes, :].astype(np.float32)\n","    return sub_features, new_edge_index"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"WjxU6EEKeeQ4","executionInfo":{"status":"ok","timestamp":1766992896050,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def load_data_from_edge_index(node_feats_np, edge_index_np, device):\n","    \"\"\"Return PyG Data with torch tensors. edge_index_np is (2, E) numpy.\"\"\"\n","    node_feats = torch.from_numpy(node_feats_np).float()\n","    edge_index = torch.from_numpy(edge_index_np.astype(np.int64)).long()\n","    return node_feats, edge_index"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"_hBfbNCzDXtq","executionInfo":{"status":"ok","timestamp":1766992902262,"user_tz":-330,"elapsed":10,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["# Required Parameters\n","cut = 1 # Consider n-cut loss OR Modularity loss (by default cut = 0)\n","alpha = 0.73 # Edge creation Threshold\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","K = 2  # Number of clusters\n","np.random.seed(42)\n","# Define all activation functions to test\n","define_activations = [\"SELU\", \"SiLU\", \"GELU\", \"ELU\", \"RELU\"]\n","activ = \"ELU\"\n","num_epochs = 5000\n","base_seed = 42\n","lambda_contrastive = 0.005\n","feats_dim = features.shape[1]"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1766992904816,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"XEKC0_x4Da-3","outputId":"59a29a47-009b-4086-f3be-212034e988f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data0: Data(x=[780, 768], edge_index=[2, 266936])\n"]}],"source":["W0 = create_adj(features, cut, alpha)  # shape (N, N) dense\n","A1 = torch.from_numpy(W0).float().to(device)\n","\n","edge_index_np, edge_weight_np = edge_index_from_dense(W0)  # numpy edge_index (2, E)\n","num_nodes = features.shape[0]\n","adj_list = build_adj_list(edge_index_np, num_nodes)  # adjacency list for fast subgraph sampling\n","\n","# convert features to numpy (we'll slice them in augmentations)\n","features_np = features.copy()\n","\n","# Build initial Data object (full graph)\n","node_feats_full, edge_index_full = load_data_from_edge_index(features_np, edge_index_np, device)\n","data0 = Data(x=node_feats_full.to(device), edge_index=edge_index_full.to(device))\n","print(\"Data0:\", data0)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sGbMVrM5Dcbk","outputId":"0a41d407-4209-461e-a194-90fe31dd547c","executionInfo":{"status":"ok","timestamp":1766993948115,"user_tz":-330,"elapsed":1039411,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Total: -0.2643 | Unsup: -0.2708 | Cont: 6.4680\n","Epoch 100 | Total: -0.5846 | Unsup: -0.5910 | Cont: 6.4031\n","Epoch 200 | Total: -0.5703 | Unsup: -0.5768 | Cont: 6.4957\n","Epoch 300 | Total: -0.5880 | Unsup: -0.5945 | Cont: 6.4627\n","Epoch 400 | Total: -0.5534 | Unsup: -0.5599 | Cont: 6.4278\n","Epoch 500 | Total: -0.5856 | Unsup: -0.5920 | Cont: 6.4143\n","Epoch 600 | Total: -0.5926 | Unsup: -0.5990 | Cont: 6.4348\n","Epoch 700 | Total: -0.5890 | Unsup: -0.5955 | Cont: 6.4911\n","Epoch 800 | Total: -0.5915 | Unsup: -0.5980 | Cont: 6.4779\n","Epoch 900 | Total: -0.5935 | Unsup: -0.5999 | Cont: 6.4415\n","Epoch 1000 | Total: -0.5911 | Unsup: -0.5975 | Cont: 6.4337\n","Epoch 1100 | Total: -0.5847 | Unsup: -0.5911 | Cont: 6.4495\n","Epoch 1200 | Total: -0.5913 | Unsup: -0.5978 | Cont: 6.4977\n","Epoch 1300 | Total: -0.5915 | Unsup: -0.5980 | Cont: 6.4995\n","Epoch 1400 | Total: -0.5837 | Unsup: -0.5902 | Cont: 6.4539\n","Epoch 1500 | Total: -0.5919 | Unsup: -0.5983 | Cont: 6.4717\n","Epoch 1600 | Total: -0.5947 | Unsup: -0.6012 | Cont: 6.4754\n","Epoch 1700 | Total: -0.5902 | Unsup: -0.5966 | Cont: 6.4166\n","Epoch 1800 | Total: -0.5842 | Unsup: -0.5907 | Cont: 6.5131\n","Epoch 1900 | Total: -0.5941 | Unsup: -0.6005 | Cont: 6.4109\n","Epoch 2000 | Total: -0.5946 | Unsup: -0.6010 | Cont: 6.4368\n","Epoch 2100 | Total: -0.5761 | Unsup: -0.5825 | Cont: 6.4652\n","Epoch 2200 | Total: -0.5855 | Unsup: -0.5919 | Cont: 6.4513\n","Epoch 2300 | Total: -0.5849 | Unsup: -0.5914 | Cont: 6.4892\n","Epoch 2400 | Total: -0.5870 | Unsup: -0.5935 | Cont: 6.4715\n"]}],"source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","feats_dim = features.shape[1]\n","model = GAT(feats_dim, 256, K, device, activ, cut).to(device)\n","optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","# Seeds\n","np.random.seed(42)\n","random.seed(42)\n","torch.manual_seed(42)\n","\n","# Training hyperparams (you can reduce num_epochs for debugging)\n","num_epochs = 2500\n","lambda_contrastive = 0.001\n","\n","for epoch in range(num_epochs):\n","    # --- Augmentations using edge_index or adjacency list (fast, sparse) ---\n","    # 1) Random edge drop on edge_index\n","    W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","\n","    # 2) Subgraph via adjacency list (returns sub_features and sub_edge_index)\n","    W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","    features_aug2 = features_np.copy()\n","\n","    # 3) Feature augmentations (keep these as numpy operations)\n","    # Feature dropout (column-wise)\n","    rng = np.random.default_rng(epoch)\n","    mask = rng.random(features_np.shape) >= 0.2\n","    features_aug1 = (features_np * mask.astype(np.float32))\n","\n","    # Feature cell dropout (random cell zeroing)\n","    aug_feat2 = features_np.copy()\n","    num_nodes_local, feat_dim = aug_feat2.shape\n","    drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","    # random positions to zero\n","    flat_idx = rng.choice(num_nodes_local * feat_dim, size=drop_feat_num, replace=False)\n","    rows = (flat_idx // feat_dim)\n","    cols = (flat_idx % feat_dim)\n","    aug_feat2[rows, cols] = 0.0\n","    features_aug2_feat = aug_feat2.astype(np.float32)\n","\n","    # --- Build PyG Data objects for the two views ---\n","    # view1: features_aug1 with W_aug1_edge_index\n","    node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","    data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","\n","    # view2: features_aug2 (from subgraph) and its edge_index\n","    node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, W_aug2_edge_index, device)\n","    data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","    # --- Training step ---\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","    unsup_loss = model.loss(A1, logits1)\n","    cont_loss = ((l1 + l2) / 2).mean()\n","    total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","    total_loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","    model.update_ma()\n","\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} | Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"jpYmDT0aDeG3","executionInfo":{"status":"ok","timestamp":1766993948495,"user_tz":-330,"elapsed":360,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["model.eval()\n","with torch.no_grad():\n","    S1, _, logits1, _, _, _ = model(data0, data0)\n","    y_pred_proba = nnFn.softmax(logits1, dim=1).cpu().numpy()\n","    y_pred = np.argmax(y_pred_proba, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbofKb5oDhyj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766933753051,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"6110f152-7562-481b-8aa4-677cb9969c63"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 1]\n","[0.99999607 0.99999976 0.9999974  0.999637   0.99909294 0.9999367\n"," 0.9999887  0.99294287 0.99983037 0.9937949  0.97240496 1.\n"," 0.9998271  0.99999964 0.9976131  0.9897048  0.99975306 0.9392869\n"," 0.99840087 0.997712  ]\n"]}],"source":["print(y_pred[:20])\n","print(y_pred_proba.max(axis=-1)[:20])"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"n1HmfThBDifY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766993948792,"user_tz":-330,"elapsed":295,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"15092dbd-767f-4d56-eb51-074bed92e6b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Score: 0.5705128205128205\n","Precision Score: 0.7944862155388471\n","Recall Score: 0.5561403508771929\n","F1 Score: 0.6542827657378741\n","Log Loss: 3.7110529462344983\n"]}],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","acc_score = accuracy_score(y_labels, y_pred)\n","acc_score_inverted = accuracy_score(y_labels, 1 - y_pred)\n","if acc_score_inverted > acc_score:\n","    acc_score = acc_score_inverted\n","    y_pred = 1 - y_pred\n","\n","prec_score = precision_score(y_labels, y_pred)\n","rec_score = recall_score(y_labels, y_pred)\n","f1 = f1_score(y_labels, y_pred)\n","log_loss_value = log_loss(y_labels, y_pred_proba)\n","\n","print(\"Accuracy Score:\", acc_score)\n","print(\"Precision Score:\", prec_score)\n","print(\"Recall Score:\", rec_score)\n","print(\"F1 Score:\", f1)\n","print(\"Log Loss:\", log_loss_value)"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","\n","NUM_RUNS = 10\n","\n","acc_list = []\n","prec_list = []\n","rec_list = []\n","f1_list = []\n","logloss_list = []\n","\n","for run in range(NUM_RUNS):\n","    print(f\"\\n===== RUN {run+1}/{NUM_RUNS} =====\")\n","\n","    from torch.optim.lr_scheduler import StepLR\n","    from torch.optim import AdamW\n","\n","    feats_dim = features.shape[1]\n","    model = GAT(feats_dim, 256, K, device, activ, cut).to(device)\n","    optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","    scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","    # Seeds\n","    np.random.seed(42 + run)\n","    random.seed(42 + run)\n","    torch.manual_seed(42 + run)\n","\n","    num_epochs = 2500\n","    lambda_contrastive = 0.5\n","\n","    for epoch in range(num_epochs):\n","        # -------- augmentations --------\n","        W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","        W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","\n","        rng = np.random.default_rng(epoch)\n","        mask = rng.random(features_np.shape) >= 0.2\n","        features_aug1 = (features_np * mask.astype(np.float32))\n","\n","        aug_feat2 = features_np.copy()\n","        n_nodes, feat_dim = aug_feat2.shape\n","        drop_feat_num = int(n_nodes * feat_dim * 0.2)\n","        flat_idx = rng.choice(n_nodes * feat_dim, size=drop_feat_num, replace=False)\n","        rows = flat_idx // feat_dim\n","        cols = flat_idx % feat_dim\n","        aug_feat2[rows, cols] = 0.0\n","        features_aug2 = aug_feat2.astype(np.float32)\n","\n","        node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","        data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","\n","        node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, W_aug2_edge_index, device)\n","        data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","        # -------- training --------\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","        unsup_loss = model.loss(A1, logits1)\n","        cont_loss = ((l1 + l2) / 2).mean()\n","        total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","        total_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        model.update_ma()\n","\n","        if epoch % 100 == 0:\n","            print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} \"\n","                  f\"| Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")\n","\n","    # -------- evaluation --------\n","    model.eval()\n","    with torch.no_grad():\n","        S1, _, logits1, _, _, _ = model(data0, data0)\n","        y_pred_proba = nnFn.softmax(logits1, dim=1).cpu().numpy()\n","        y_pred = np.argmax(y_pred_proba, axis=1)\n","\n","    acc = accuracy_score(y_labels, y_pred)\n","    acc_inv = accuracy_score(y_labels, 1 - y_pred)\n","    if acc_inv > acc:   # flip if class labels reversed\n","        acc = acc_inv\n","        y_pred = 1 - y_pred\n","\n","    prec = precision_score(y_labels, y_pred)\n","    rec = recall_score(y_labels, y_pred)\n","    f1 = f1_score(y_labels, y_pred)\n","    ll = log_loss(y_labels, y_pred_proba)\n","\n","    acc_list.append(acc)\n","    prec_list.append(prec)\n","    rec_list.append(rec)\n","    f1_list.append(f1)\n","    logloss_list.append(ll)\n","\n","# -------- mean ± std printing --------\n","def mean_std(a):\n","    return np.mean(a), np.std(a)\n","\n","print(\"\\n===== FINAL RESULTS OVER 10 RUNS =====\")\n","m, s = mean_std(acc_list);     print(f\"Accuracy: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(prec_list);    print(f\"Precision: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(rec_list);     print(f\"Recall: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(f1_list);      print(f\"F1: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(logloss_list); print(f\"Log Loss: {m:.4f} ± {s:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UpzMqignfgoW","executionInfo":{"status":"ok","timestamp":1767002828624,"user_tz":-330,"elapsed":8397225,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"6c96a06a-0b3c-4c88-dadb-dc363c451a08"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== RUN 1/10 =====\n","Epoch 0 | Total: 3.1134 | Unsup: -0.2692 | Cont: 6.7650\n","Epoch 100 | Total: 2.1614 | Unsup: -0.5573 | Cont: 5.4373\n","Epoch 200 | Total: 2.0959 | Unsup: -0.5821 | Cont: 5.3560\n","Epoch 300 | Total: 2.0572 | Unsup: -0.5901 | Cont: 5.2947\n","Epoch 400 | Total: 2.0168 | Unsup: -0.5886 | Cont: 5.2109\n","Epoch 500 | Total: 1.9535 | Unsup: -0.5816 | Cont: 5.0702\n","Epoch 600 | Total: 1.9209 | Unsup: -0.5898 | Cont: 5.0214\n","Epoch 700 | Total: 1.8989 | Unsup: -0.5899 | Cont: 4.9776\n","Epoch 800 | Total: 1.8808 | Unsup: -0.5913 | Cont: 4.9443\n","Epoch 900 | Total: 1.8767 | Unsup: -0.5849 | Cont: 4.9232\n","Epoch 1000 | Total: 1.9025 | Unsup: -0.5832 | Cont: 4.9715\n","Epoch 1100 | Total: 1.8599 | Unsup: -0.5908 | Cont: 4.9014\n","Epoch 1200 | Total: 1.8624 | Unsup: -0.5894 | Cont: 4.9036\n","Epoch 1300 | Total: 1.8799 | Unsup: -0.5932 | Cont: 4.9462\n","Epoch 1400 | Total: 1.8681 | Unsup: -0.5949 | Cont: 4.9261\n","Epoch 1500 | Total: 1.8673 | Unsup: -0.5945 | Cont: 4.9236\n","Epoch 1600 | Total: 1.8631 | Unsup: -0.5927 | Cont: 4.9117\n","Epoch 1700 | Total: 1.8565 | Unsup: -0.5895 | Cont: 4.8920\n","Epoch 1800 | Total: 1.8792 | Unsup: -0.5912 | Cont: 4.9407\n","Epoch 1900 | Total: 1.8539 | Unsup: -0.5940 | Cont: 4.8958\n","Epoch 2000 | Total: 1.8762 | Unsup: -0.5811 | Cont: 4.9144\n","Epoch 2100 | Total: 1.8663 | Unsup: -0.5943 | Cont: 4.9212\n","Epoch 2200 | Total: 1.8691 | Unsup: -0.5837 | Cont: 4.9057\n","Epoch 2300 | Total: 1.8497 | Unsup: -0.5935 | Cont: 4.8864\n","Epoch 2400 | Total: 1.8555 | Unsup: -0.5916 | Cont: 4.8941\n","\n","===== RUN 2/10 =====\n","Epoch 0 | Total: 3.0178 | Unsup: -0.2709 | Cont: 6.5774\n","Epoch 100 | Total: 2.1729 | Unsup: -0.5549 | Cont: 5.4557\n","Epoch 200 | Total: 2.0858 | Unsup: -0.5716 | Cont: 5.3148\n","Epoch 300 | Total: 2.0026 | Unsup: -0.5700 | Cont: 5.1452\n","Epoch 400 | Total: 1.8978 | Unsup: -0.5885 | Cont: 4.9725\n","Epoch 500 | Total: 1.8936 | Unsup: -0.5844 | Cont: 4.9559\n","Epoch 600 | Total: 1.8637 | Unsup: -0.5911 | Cont: 4.9096\n","Epoch 700 | Total: 1.8581 | Unsup: -0.5864 | Cont: 4.8891\n","Epoch 800 | Total: 1.8680 | Unsup: -0.5842 | Cont: 4.9044\n","Epoch 900 | Total: 1.8493 | Unsup: -0.5889 | Cont: 4.8763\n","Epoch 1000 | Total: 1.8494 | Unsup: -0.5824 | Cont: 4.8636\n","Epoch 1100 | Total: 1.8387 | Unsup: -0.5965 | Cont: 4.8706\n","Epoch 1200 | Total: 1.8325 | Unsup: -0.5930 | Cont: 4.8511\n","Epoch 1300 | Total: 1.8535 | Unsup: -0.5931 | Cont: 4.8932\n","Epoch 1400 | Total: 1.8344 | Unsup: -0.5912 | Cont: 4.8512\n","Epoch 1500 | Total: 1.8579 | Unsup: -0.5918 | Cont: 4.8994\n","Epoch 1600 | Total: 1.8298 | Unsup: -0.5904 | Cont: 4.8406\n","Epoch 1700 | Total: 1.8298 | Unsup: -0.5944 | Cont: 4.8486\n","Epoch 1800 | Total: 1.8415 | Unsup: -0.5927 | Cont: 4.8685\n","Epoch 1900 | Total: 1.8352 | Unsup: -0.5894 | Cont: 4.8492\n","Epoch 2000 | Total: 1.8343 | Unsup: -0.5973 | Cont: 4.8632\n","Epoch 2100 | Total: 1.8280 | Unsup: -0.5984 | Cont: 4.8529\n","Epoch 2200 | Total: 1.8312 | Unsup: -0.5951 | Cont: 4.8526\n","Epoch 2300 | Total: 1.8263 | Unsup: -0.5955 | Cont: 4.8437\n","Epoch 2400 | Total: 1.8337 | Unsup: -0.5924 | Cont: 4.8522\n","\n","===== RUN 3/10 =====\n","Epoch 0 | Total: 3.2041 | Unsup: -0.2603 | Cont: 6.9289\n","Epoch 100 | Total: 2.1269 | Unsup: -0.5606 | Cont: 5.3751\n","Epoch 200 | Total: 1.9587 | Unsup: -0.5820 | Cont: 5.0815\n","Epoch 300 | Total: 1.9025 | Unsup: -0.5873 | Cont: 4.9797\n","Epoch 400 | Total: 1.9006 | Unsup: -0.5913 | Cont: 4.9839\n","Epoch 500 | Total: 1.8629 | Unsup: -0.5927 | Cont: 4.9112\n","Epoch 600 | Total: 1.8253 | Unsup: -0.5965 | Cont: 4.8437\n","Epoch 700 | Total: 1.8406 | Unsup: -0.5966 | Cont: 4.8744\n","Epoch 800 | Total: 1.8304 | Unsup: -0.5973 | Cont: 4.8554\n","Epoch 900 | Total: 1.8257 | Unsup: -0.5957 | Cont: 4.8427\n","Epoch 1000 | Total: 1.8215 | Unsup: -0.5974 | Cont: 4.8379\n","Epoch 1100 | Total: 1.8121 | Unsup: -0.5978 | Cont: 4.8197\n","Epoch 1200 | Total: 1.8183 | Unsup: -0.5993 | Cont: 4.8351\n","Epoch 1300 | Total: 1.8054 | Unsup: -0.5998 | Cont: 4.8106\n","Epoch 1400 | Total: 1.8073 | Unsup: -0.5996 | Cont: 4.8138\n","Epoch 1500 | Total: 1.8161 | Unsup: -0.5997 | Cont: 4.8316\n","Epoch 1600 | Total: 1.8260 | Unsup: -0.5839 | Cont: 4.8199\n","Epoch 1700 | Total: 1.8042 | Unsup: -0.5991 | Cont: 4.8066\n","Epoch 1800 | Total: 1.8082 | Unsup: -0.5934 | Cont: 4.8033\n","Epoch 1900 | Total: 1.8172 | Unsup: -0.5999 | Cont: 4.8342\n","Epoch 2000 | Total: 1.8141 | Unsup: -0.5972 | Cont: 4.8226\n","Epoch 2100 | Total: 1.8185 | Unsup: -0.5964 | Cont: 4.8299\n","Epoch 2200 | Total: 1.8102 | Unsup: -0.5968 | Cont: 4.8139\n","Epoch 2300 | Total: 1.8041 | Unsup: -0.6011 | Cont: 4.8103\n","Epoch 2400 | Total: 1.8102 | Unsup: -0.5960 | Cont: 4.8125\n","\n","===== RUN 4/10 =====\n","Epoch 0 | Total: 3.2183 | Unsup: -0.2595 | Cont: 6.9556\n","Epoch 100 | Total: 2.1585 | Unsup: -0.5583 | Cont: 5.4336\n","Epoch 200 | Total: 1.9999 | Unsup: -0.5817 | Cont: 5.1632\n","Epoch 300 | Total: 1.9439 | Unsup: -0.5919 | Cont: 5.0716\n","Epoch 400 | Total: 1.8989 | Unsup: -0.5945 | Cont: 4.9870\n","Epoch 500 | Total: 1.8715 | Unsup: -0.5955 | Cont: 4.9340\n","Epoch 600 | Total: 1.8530 | Unsup: -0.5979 | Cont: 4.9019\n","Epoch 700 | Total: 1.8513 | Unsup: -0.6009 | Cont: 4.9046\n","Epoch 800 | Total: 1.8436 | Unsup: -0.5977 | Cont: 4.8826\n","Epoch 900 | Total: 1.8486 | Unsup: -0.6027 | Cont: 4.9025\n","Epoch 1000 | Total: 1.8291 | Unsup: -0.6015 | Cont: 4.8613\n","Epoch 1100 | Total: 1.8216 | Unsup: -0.6001 | Cont: 4.8433\n","Epoch 1200 | Total: 1.8416 | Unsup: -0.6010 | Cont: 4.8853\n","Epoch 1300 | Total: 1.8193 | Unsup: -0.6004 | Cont: 4.8394\n","Epoch 1400 | Total: 1.8208 | Unsup: -0.6031 | Cont: 4.8478\n","Epoch 1500 | Total: 1.8522 | Unsup: -0.5978 | Cont: 4.9000\n","Epoch 1600 | Total: 1.8386 | Unsup: -0.6007 | Cont: 4.8787\n","Epoch 1700 | Total: 1.8248 | Unsup: -0.5967 | Cont: 4.8430\n","Epoch 1800 | Total: 1.8465 | Unsup: -0.6001 | Cont: 4.8931\n","Epoch 1900 | Total: 1.8326 | Unsup: -0.6004 | Cont: 4.8660\n","Epoch 2000 | Total: 1.8271 | Unsup: -0.6007 | Cont: 4.8557\n","Epoch 2100 | Total: 1.8296 | Unsup: -0.6027 | Cont: 4.8648\n","Epoch 2200 | Total: 1.8562 | Unsup: -0.5995 | Cont: 4.9114\n","Epoch 2300 | Total: 1.8226 | Unsup: -0.6028 | Cont: 4.8507\n","Epoch 2400 | Total: 1.8263 | Unsup: -0.6026 | Cont: 4.8578\n","\n","===== RUN 5/10 =====\n","Epoch 0 | Total: 3.3725 | Unsup: -0.2669 | Cont: 7.2788\n","Epoch 100 | Total: 2.2161 | Unsup: -0.5280 | Cont: 5.4883\n","Epoch 200 | Total: 2.0201 | Unsup: -0.5740 | Cont: 5.1884\n","Epoch 300 | Total: 1.9604 | Unsup: -0.5773 | Cont: 5.0754\n","Epoch 400 | Total: 1.9347 | Unsup: -0.5817 | Cont: 5.0329\n","Epoch 500 | Total: 1.8928 | Unsup: -0.5848 | Cont: 4.9552\n","Epoch 600 | Total: 1.8683 | Unsup: -0.5895 | Cont: 4.9156\n","Epoch 700 | Total: 1.8794 | Unsup: -0.5877 | Cont: 4.9341\n","Epoch 800 | Total: 1.8578 | Unsup: -0.5873 | Cont: 4.8902\n","Epoch 900 | Total: 1.8752 | Unsup: -0.5863 | Cont: 4.9231\n","Epoch 1000 | Total: 1.8583 | Unsup: -0.5870 | Cont: 4.8907\n","Epoch 1100 | Total: 1.8381 | Unsup: -0.5907 | Cont: 4.8575\n","Epoch 1200 | Total: 1.8608 | Unsup: -0.5869 | Cont: 4.8954\n","Epoch 1300 | Total: 1.8452 | Unsup: -0.5892 | Cont: 4.8688\n","Epoch 1400 | Total: 1.8477 | Unsup: -0.5911 | Cont: 4.8775\n","Epoch 1500 | Total: 1.8535 | Unsup: -0.5891 | Cont: 4.8852\n","Epoch 1600 | Total: 1.8791 | Unsup: -0.5907 | Cont: 4.9396\n","Epoch 1700 | Total: 1.8372 | Unsup: -0.5865 | Cont: 4.8474\n","Epoch 1800 | Total: 1.8481 | Unsup: -0.5890 | Cont: 4.8741\n","Epoch 1900 | Total: 1.8796 | Unsup: -0.5852 | Cont: 4.9296\n","Epoch 2000 | Total: 1.8522 | Unsup: -0.5913 | Cont: 4.8871\n","Epoch 2100 | Total: 1.8467 | Unsup: -0.5893 | Cont: 4.8720\n","Epoch 2200 | Total: 1.8462 | Unsup: -0.5888 | Cont: 4.8699\n","Epoch 2300 | Total: 1.8375 | Unsup: -0.5919 | Cont: 4.8588\n","Epoch 2400 | Total: 1.8481 | Unsup: -0.5910 | Cont: 4.8781\n","\n","===== RUN 6/10 =====\n","Epoch 0 | Total: 3.2964 | Unsup: -0.2427 | Cont: 7.0782\n","Epoch 100 | Total: 2.1608 | Unsup: -0.5594 | Cont: 5.4403\n","Epoch 200 | Total: 1.9679 | Unsup: -0.5791 | Cont: 5.0941\n","Epoch 300 | Total: 1.9323 | Unsup: -0.5912 | Cont: 5.0470\n","Epoch 400 | Total: 1.8974 | Unsup: -0.5870 | Cont: 4.9688\n","Epoch 500 | Total: 1.8855 | Unsup: -0.5943 | Cont: 4.9597\n","Epoch 600 | Total: 1.8514 | Unsup: -0.5956 | Cont: 4.8939\n","Epoch 700 | Total: 1.8716 | Unsup: -0.5940 | Cont: 4.9313\n","Epoch 800 | Total: 1.8478 | Unsup: -0.5960 | Cont: 4.8876\n","Epoch 900 | Total: 1.8755 | Unsup: -0.5920 | Cont: 4.9351\n","Epoch 1000 | Total: 1.8453 | Unsup: -0.5953 | Cont: 4.8813\n","Epoch 1100 | Total: 1.8422 | Unsup: -0.5974 | Cont: 4.8792\n","Epoch 1200 | Total: 1.8766 | Unsup: -0.5971 | Cont: 4.9473\n","Epoch 1300 | Total: 1.8337 | Unsup: -0.5972 | Cont: 4.8618\n","Epoch 1400 | Total: 1.8340 | Unsup: -0.5965 | Cont: 4.8611\n","Epoch 1500 | Total: 1.8547 | Unsup: -0.5975 | Cont: 4.9044\n","Epoch 1600 | Total: 1.8442 | Unsup: -0.5977 | Cont: 4.8838\n","Epoch 1700 | Total: 1.8264 | Unsup: -0.5968 | Cont: 4.8464\n","Epoch 1800 | Total: 1.8270 | Unsup: -0.5976 | Cont: 4.8492\n","Epoch 1900 | Total: 1.8574 | Unsup: -0.5947 | Cont: 4.9043\n","Epoch 2000 | Total: 1.8336 | Unsup: -0.5940 | Cont: 4.8553\n","Epoch 2100 | Total: 1.8525 | Unsup: -0.5938 | Cont: 4.8927\n","Epoch 2200 | Total: 1.8459 | Unsup: -0.5929 | Cont: 4.8777\n","Epoch 2300 | Total: 1.8380 | Unsup: -0.5987 | Cont: 4.8733\n","Epoch 2400 | Total: 1.8292 | Unsup: -0.5964 | Cont: 4.8512\n","\n","===== RUN 7/10 =====\n","Epoch 0 | Total: 3.2344 | Unsup: -0.2601 | Cont: 6.9890\n","Epoch 100 | Total: 2.1335 | Unsup: -0.5547 | Cont: 5.3766\n","Epoch 200 | Total: 1.9558 | Unsup: -0.5736 | Cont: 5.0588\n","Epoch 300 | Total: 1.9127 | Unsup: -0.5803 | Cont: 4.9859\n","Epoch 400 | Total: 1.8959 | Unsup: -0.5835 | Cont: 4.9587\n","Epoch 500 | Total: 1.8714 | Unsup: -0.5880 | Cont: 4.9189\n","Epoch 600 | Total: 1.8609 | Unsup: -0.5929 | Cont: 4.9076\n","Epoch 700 | Total: 1.8698 | Unsup: -0.5878 | Cont: 4.9152\n","Epoch 800 | Total: 1.8462 | Unsup: -0.5927 | Cont: 4.8777\n","Epoch 900 | Total: 1.8568 | Unsup: -0.5944 | Cont: 4.9026\n","Epoch 1000 | Total: 1.8516 | Unsup: -0.5958 | Cont: 4.8947\n","Epoch 1100 | Total: 1.8340 | Unsup: -0.5943 | Cont: 4.8567\n","Epoch 1200 | Total: 1.8417 | Unsup: -0.5892 | Cont: 4.8619\n","Epoch 1300 | Total: 1.8290 | Unsup: -0.5967 | Cont: 4.8513\n","Epoch 1400 | Total: 1.8351 | Unsup: -0.5942 | Cont: 4.8587\n","Epoch 1500 | Total: 1.8447 | Unsup: -0.5951 | Cont: 4.8795\n","Epoch 1600 | Total: 1.8525 | Unsup: -0.5959 | Cont: 4.8968\n","Epoch 1700 | Total: 1.8261 | Unsup: -0.5949 | Cont: 4.8420\n","Epoch 1800 | Total: 1.8253 | Unsup: -0.5960 | Cont: 4.8426\n","Epoch 1900 | Total: 1.8455 | Unsup: -0.5938 | Cont: 4.8786\n","Epoch 2000 | Total: 1.8434 | Unsup: -0.5947 | Cont: 4.8762\n","Epoch 2100 | Total: 1.8379 | Unsup: -0.5970 | Cont: 4.8697\n","Epoch 2200 | Total: 1.8649 | Unsup: -0.5821 | Cont: 4.8940\n","Epoch 2300 | Total: 1.8453 | Unsup: -0.5947 | Cont: 4.8800\n","Epoch 2400 | Total: 1.8426 | Unsup: -0.5957 | Cont: 4.8766\n","\n","===== RUN 8/10 =====\n","Epoch 0 | Total: 3.0373 | Unsup: -0.2530 | Cont: 6.5807\n","Epoch 100 | Total: 2.1083 | Unsup: -0.5682 | Cont: 5.3531\n","Epoch 200 | Total: 1.9063 | Unsup: -0.5855 | Cont: 4.9835\n","Epoch 300 | Total: 1.8759 | Unsup: -0.5870 | Cont: 4.9259\n","Epoch 400 | Total: 1.8561 | Unsup: -0.5872 | Cont: 4.8866\n","Epoch 500 | Total: 1.8310 | Unsup: -0.5932 | Cont: 4.8485\n","Epoch 600 | Total: 1.8184 | Unsup: -0.5988 | Cont: 4.8345\n","Epoch 700 | Total: 1.8137 | Unsup: -0.5910 | Cont: 4.8094\n","Epoch 800 | Total: 1.7963 | Unsup: -0.5998 | Cont: 4.7922\n","Epoch 900 | Total: 1.7946 | Unsup: -0.5989 | Cont: 4.7871\n","Epoch 1000 | Total: 1.7947 | Unsup: -0.5977 | Cont: 4.7848\n","Epoch 1100 | Total: 1.7760 | Unsup: -0.5990 | Cont: 4.7500\n","Epoch 1200 | Total: 1.7939 | Unsup: -0.5946 | Cont: 4.7770\n","Epoch 1300 | Total: 1.7735 | Unsup: -0.5988 | Cont: 4.7447\n","Epoch 1400 | Total: 1.7802 | Unsup: -0.5999 | Cont: 4.7601\n","Epoch 1500 | Total: 1.7905 | Unsup: -0.5931 | Cont: 4.7671\n","Epoch 1600 | Total: 1.7932 | Unsup: -0.5937 | Cont: 4.7738\n","Epoch 1700 | Total: 1.7807 | Unsup: -0.5986 | Cont: 4.7586\n","Epoch 1800 | Total: 1.7857 | Unsup: -0.5992 | Cont: 4.7698\n","Epoch 1900 | Total: 1.7803 | Unsup: -0.5984 | Cont: 4.7574\n","Epoch 2000 | Total: 1.7701 | Unsup: -0.5992 | Cont: 4.7386\n","Epoch 2100 | Total: 1.7655 | Unsup: -0.5986 | Cont: 4.7281\n","Epoch 2200 | Total: 1.7995 | Unsup: -0.5966 | Cont: 4.7922\n","Epoch 2300 | Total: 1.8021 | Unsup: -0.5979 | Cont: 4.8000\n","Epoch 2400 | Total: 1.7787 | Unsup: -0.5973 | Cont: 4.7520\n","\n","===== RUN 9/10 =====\n","Epoch 0 | Total: 3.3162 | Unsup: -0.2516 | Cont: 7.1355\n","Epoch 100 | Total: 2.1496 | Unsup: -0.5519 | Cont: 5.4030\n","Epoch 200 | Total: 1.9479 | Unsup: -0.5756 | Cont: 5.0470\n","Epoch 300 | Total: 1.9222 | Unsup: -0.5772 | Cont: 4.9986\n","Epoch 400 | Total: 1.8854 | Unsup: -0.5847 | Cont: 4.9401\n","Epoch 500 | Total: 1.8689 | Unsup: -0.5850 | Cont: 4.9078\n","Epoch 600 | Total: 1.8449 | Unsup: -0.5874 | Cont: 4.8645\n","Epoch 700 | Total: 1.8385 | Unsup: -0.5893 | Cont: 4.8556\n","Epoch 800 | Total: 1.8394 | Unsup: -0.5877 | Cont: 4.8543\n","Epoch 900 | Total: 1.8527 | Unsup: -0.5920 | Cont: 4.8893\n","Epoch 1000 | Total: 1.8284 | Unsup: -0.5914 | Cont: 4.8396\n","Epoch 1100 | Total: 1.8275 | Unsup: -0.5925 | Cont: 4.8401\n","Epoch 1200 | Total: 1.8340 | Unsup: -0.5917 | Cont: 4.8515\n","Epoch 1300 | Total: 1.8343 | Unsup: -0.5909 | Cont: 4.8503\n","Epoch 1400 | Total: 1.8247 | Unsup: -0.5940 | Cont: 4.8374\n","Epoch 1500 | Total: 1.8374 | Unsup: -0.5882 | Cont: 4.8513\n","Epoch 1600 | Total: 1.8315 | Unsup: -0.5931 | Cont: 4.8492\n","Epoch 1700 | Total: 1.8287 | Unsup: -0.5900 | Cont: 4.8374\n","Epoch 1800 | Total: 1.8250 | Unsup: -0.5940 | Cont: 4.8380\n","Epoch 1900 | Total: 1.8274 | Unsup: -0.5912 | Cont: 4.8372\n","Epoch 2000 | Total: 1.8216 | Unsup: -0.5948 | Cont: 4.8327\n","Epoch 2100 | Total: 1.8321 | Unsup: -0.5910 | Cont: 4.8462\n","Epoch 2200 | Total: 1.8338 | Unsup: -0.5908 | Cont: 4.8492\n","Epoch 2300 | Total: 1.8205 | Unsup: -0.5957 | Cont: 4.8323\n","Epoch 2400 | Total: 1.8358 | Unsup: -0.5889 | Cont: 4.8495\n","\n","===== RUN 10/10 =====\n","Epoch 0 | Total: 2.9980 | Unsup: -0.2570 | Cont: 6.5101\n","Epoch 100 | Total: 2.1010 | Unsup: -0.5591 | Cont: 5.3203\n","Epoch 200 | Total: 1.9272 | Unsup: -0.5769 | Cont: 5.0081\n","Epoch 300 | Total: 1.8828 | Unsup: -0.5855 | Cont: 4.9366\n","Epoch 400 | Total: 1.8672 | Unsup: -0.5894 | Cont: 4.9132\n","Epoch 500 | Total: 1.8393 | Unsup: -0.5940 | Cont: 4.8665\n","Epoch 600 | Total: 1.8012 | Unsup: -0.5984 | Cont: 4.7992\n","Epoch 700 | Total: 1.7837 | Unsup: -0.5960 | Cont: 4.7594\n","Epoch 800 | Total: 1.7747 | Unsup: -0.6003 | Cont: 4.7502\n","Epoch 900 | Total: 1.7809 | Unsup: -0.6000 | Cont: 4.7618\n","Epoch 1000 | Total: 1.7764 | Unsup: -0.5957 | Cont: 4.7442\n","Epoch 1100 | Total: 1.7650 | Unsup: -0.6000 | Cont: 4.7299\n","Epoch 1200 | Total: 1.7530 | Unsup: -0.5984 | Cont: 4.7029\n","Epoch 1300 | Total: 1.7544 | Unsup: -0.5967 | Cont: 4.7021\n","Epoch 1400 | Total: 1.7694 | Unsup: -0.5973 | Cont: 4.7335\n","Epoch 1500 | Total: 1.7607 | Unsup: -0.5979 | Cont: 4.7171\n","Epoch 1600 | Total: 1.7643 | Unsup: -0.5980 | Cont: 4.7246\n","Epoch 1700 | Total: 1.7477 | Unsup: -0.5985 | Cont: 4.6926\n","Epoch 1800 | Total: 1.7976 | Unsup: -0.5873 | Cont: 4.7697\n","Epoch 1900 | Total: 1.7488 | Unsup: -0.5977 | Cont: 4.6931\n","Epoch 2000 | Total: 1.7467 | Unsup: -0.6010 | Cont: 4.6956\n","Epoch 2100 | Total: 1.7508 | Unsup: -0.5995 | Cont: 4.7007\n","Epoch 2200 | Total: 1.7593 | Unsup: -0.5971 | Cont: 4.7128\n","Epoch 2300 | Total: 1.7591 | Unsup: -0.5971 | Cont: 4.7123\n","Epoch 2400 | Total: 1.7407 | Unsup: -0.5982 | Cont: 4.6779\n","\n","===== FINAL RESULTS OVER 10 RUNS =====\n","Accuracy: 0.6279 ± 0.0657\n","Precision: 0.7881 ± 0.0350\n","Recall: 0.6781 ± 0.1316\n","F1: 0.7203 ± 0.0735\n","Log Loss: 5.4928 ± 1.9279\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","\n","NUM_RUNS = 10\n","\n","acc_list = []\n","prec_list = []\n","rec_list = []\n","f1_list = []\n","logloss_list = []\n","\n","for run in range(NUM_RUNS):\n","    print(f\"\\n===== RUN {run+1}/{NUM_RUNS} =====\")\n","\n","    from torch.optim.lr_scheduler import StepLR\n","    from torch.optim import AdamW\n","\n","    feats_dim = features.shape[1]\n","    model = ARMA(feats_dim, 256, K, device, activ, cut).to(device)\n","    optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","    scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","    # Seeds\n","    np.random.seed(42 + run)\n","    random.seed(42 + run)\n","    torch.manual_seed(42 + run)\n","\n","    num_epochs = 2500\n","    lambda_contrastive = 0.001\n","\n","    for epoch in range(num_epochs):\n","        # -------- augmentations --------\n","        W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","        W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","\n","        rng = np.random.default_rng(epoch)\n","        mask = rng.random(features_np.shape) >= 0.2\n","        features_aug1 = (features_np * mask.astype(np.float32))\n","\n","        aug_feat2 = features_np.copy()\n","        n_nodes, feat_dim = aug_feat2.shape\n","        drop_feat_num = int(n_nodes * feat_dim * 0.2)\n","        flat_idx = rng.choice(n_nodes * feat_dim, size=drop_feat_num, replace=False)\n","        rows = flat_idx // feat_dim\n","        cols = flat_idx % feat_dim\n","        aug_feat2[rows, cols] = 0.0\n","        features_aug2 = aug_feat2.astype(np.float32)\n","\n","        node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","        data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","\n","        node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, W_aug2_edge_index, device)\n","        data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","        # -------- training --------\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","        unsup_loss = model.loss(A1, logits1)\n","        cont_loss = ((l1 + l2) / 2).mean()\n","        total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","        total_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        model.update_ma()\n","\n","        if epoch % 100 == 0:\n","            print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} \"\n","                  f\"| Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")\n","\n","    # -------- evaluation --------\n","    model.eval()\n","    with torch.no_grad():\n","        S1, _, logits1, _, _, _ = model(data0, data0)\n","        y_pred_proba = nnFn.softmax(logits1, dim=1).cpu().numpy()\n","        y_pred = np.argmax(y_pred_proba, axis=1)\n","\n","    acc = accuracy_score(y_labels, y_pred)\n","    acc_inv = accuracy_score(y_labels, 1 - y_pred)\n","    if acc_inv > acc:   # flip if class labels reversed\n","        acc = acc_inv\n","        y_pred = 1 - y_pred\n","\n","    prec = precision_score(y_labels, y_pred)\n","    rec = recall_score(y_labels, y_pred)\n","    f1 = f1_score(y_labels, y_pred)\n","    ll = log_loss(y_labels, y_pred_proba)\n","\n","    acc_list.append(acc)\n","    prec_list.append(prec)\n","    rec_list.append(rec)\n","    f1_list.append(f1)\n","    logloss_list.append(ll)\n","\n","# -------- mean ± std printing --------\n","def mean_std(a):\n","    return np.mean(a), np.std(a)\n","\n","print(\"\\n===== FINAL RESULTS OVER 10 RUNS =====\")\n","m, s = mean_std(acc_list);     print(f\"Accuracy: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(prec_list);    print(f\"Precision: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(rec_list);     print(f\"Recall: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(f1_list);      print(f\"F1: {m:.4f} ± {s:.4f}\")\n","m, s = mean_std(logloss_list); print(f\"Log Loss: {m:.4f} ± {s:.4f}\")\n"],"metadata":{"id":"0xhXm8SXVUX4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5M6xJcWeeQ5"},"outputs":[],"source":["# num_runs = 10\n","# num_epochs = 5000\n","# lr = 1e-4\n","# weight_decay = 1e-4\n","# lambda_list = [0.001, 0.005, 0.009, 0.01, 0.05, 0.09, 0.1, 0.3, 0.5, 0.9, 1, 2, 5, 8]\n","# base_seed = 42\n","\n","# all_results = []\n","\n","# for lam in lambda_list:\n","#     print(f\"\\n================ LAMBDA = {lam} ================\\n\")\n","\n","#     acc_scores, prec_scores, rec_scores, f1_scores, log_losses = [], [], [], [], []\n","\n","#     for run in range(num_runs):\n","#         print(f\"\\n--- Run {run + 1}/{num_runs} ---\")\n","#         torch.manual_seed(base_seed + run)\n","#         np.random.seed(base_seed + run)\n","#         random.seed(base_seed + run)\n","\n","#         # --- Model Setup ---\n","#         model = GAT(feats_dim, 256, K, device, activ, cut).to(device)\n","#         optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","#         scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","#         for epoch in range(num_epochs):\n","#             # 1) Two random edge augmentations\n","#             W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","#             W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","\n","#             # 2) Feature augmentations\n","#             rng = np.random.default_rng(epoch)\n","#             mask = rng.random(features_np.shape) >= 0.2\n","#             features_aug1 = (features_np * mask.astype(np.float32))\n","#             features_aug2 = features_np.copy()\n","#             num_nodes_local, feat_dim = features_aug2.shape\n","#             drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","#             flat_idx = rng.choice(num_nodes_local * feat_dim, size=drop_feat_num, replace=False)\n","#             rows = (flat_idx // feat_dim)\n","#             cols = (flat_idx % feat_dim)\n","#             features_aug2[rows, cols] = 0.0\n","#             features_aug2_feat = features_aug2.astype(np.float32)\n","\n","#             # 3) Build Data views\n","#             node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","#             data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","#             node_feats2, edge_index2 = load_data_from_edge_index(features_aug2_feat, W_aug2_edge_index, device)\n","#             data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","#             # --- Training step ---\n","#             model.train()\n","#             optimizer.zero_grad()\n","\n","#             S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","#             unsup_loss = model.loss(A1, logits1)\n","#             cont_loss = ((l1 + l2) / 2).mean()\n","#             total_loss = unsup_loss + lam * cont_loss\n","\n","#             total_loss.backward()\n","#             optimizer.step()\n","#             scheduler.step()\n","#             model.update_ma()\n","\n","#             if epoch % 500 == 0:\n","#                 print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} | Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")\n","\n","#         # --- Evaluation ---\n","#         model.eval()\n","#         with torch.no_grad():\n","#             S1, _, logits1, _, _, _ = model(data0, data0)\n","#             y_pred_proba = nnFn.softmax(logits1, dim=1).cpu().numpy()\n","#             y_pred = np.argmax(y_pred_proba, axis=1)\n","\n","#         acc = accuracy_score(y_labels, y_pred)\n","#         acc_inv = accuracy_score(y_labels, 1 - y_pred)\n","#         if acc_inv > acc:\n","#             acc = acc_inv\n","#             y_pred = 1 - y_pred\n","\n","#         prec = precision_score(y_labels, y_pred)\n","#         rec = recall_score(y_labels, y_pred)\n","#         f1 = f1_score(y_labels, y_pred)\n","#         ll = log_loss(y_labels, y_pred_proba)\n","\n","#         acc_scores.append(acc)\n","#         prec_scores.append(prec)\n","#         rec_scores.append(rec)\n","#         f1_scores.append(f1)\n","#         log_losses.append(ll)\n","\n","#         print(f\"Run {run + 1} Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n","\n","#     # --- Aggregate Results ---\n","#     lambda_results = {\n","#         \"lambda\": lam,\n","#         \"accuracy\": (np.mean(acc_scores), np.std(acc_scores)),\n","#         \"precision\": (np.mean(prec_scores), np.std(prec_scores)),\n","#         \"recall\": (np.mean(rec_scores), np.std(rec_scores)),\n","#         \"f1\": (np.mean(f1_scores), np.std(f1_scores)),\n","#         \"log_loss\": (np.mean(log_losses), np.std(log_losses))\n","#     }\n","#     all_results.append(lambda_results)\n","\n","#     print(f\"\\n--- RESULTS FOR LAMBDA = {lam} ---\")\n","#     print(f\"Accuracy: {lambda_results['accuracy'][0]:.4f} ± {lambda_results['accuracy'][1]:.4f}\")\n","#     print(f\"Precision: {lambda_results['precision'][0]:.4f} ± {lambda_results['precision'][1]:.4f}\")\n","#     print(f\"Recall: {lambda_results['recall'][0]:.4f} ± {lambda_results['recall'][1]:.4f}\")\n","#     print(f\"F1 Score: {lambda_results['f1'][0]:.4f} ± {lambda_results['f1'][1]:.4f}\")\n","#     print(f\"Log Loss: {lambda_results['log_loss'][0]:.4f} ± {lambda_results['log_loss'][1]:.4f}\")\n","\n","# # ==========================================================\n","# # === Final Summary ===\n","# # ==========================================================\n","# print(\"\\n================ FINAL SUMMARY FOR ALL LAMBDAS ================\\n\")\n","# print(f\"{'Lambda':>8} | {'Accuracy':>18} | {'Precision':>18} | {'Recall':>18} | {'F1 Score':>18} | {'Log Loss':>18}\")\n","# print(\"-\" * 108)\n","# for res in all_results:\n","#     print(f\"{res['lambda']:>8} | \"\n","#           f\"{res['accuracy'][0]:.4f} ± {res['accuracy'][1]:.4f} | \"\n","#           f\"{res['precision'][0]:.4f} ± {res['precision'][1]:.4f} | \"\n","#           f\"{res['recall'][0]:.4f} ± {res['recall'][1]:.4f} | \"\n","#           f\"{res['f1'][0]:.4f} ± {res['f1'][1]:.4f} | \"\n","#           f\"{res['log_loss'][0]:.4f} ± {res['log_loss'][1]:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ApTGKLsMeeQ5"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import to_undirected\n",
        "from torch_sparse import SparseTensor\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    normalized_mutual_info_score,\n",
        "    adjusted_rand_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score\n",
        ")\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "xPQBieSGZCdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab5c1bd-b867-4a91-a6a8-913a175f412a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/snu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "setup_seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "zH55EF8cZEKg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fa_patients = np.load(\"/home/snu/Downloads/NIFD_Patients_FA_Histogram_Feature.npy\", allow_pickle=True)\n",
        "fa_controls = np.load(\"/home/snu/Downloads/NIFD_Control_FA_Histogram_Feature.npy\", allow_pickle=True)\n",
        "\n",
        "X = np.vstack([fa_patients, fa_controls]).astype(np.float32)\n",
        "y = np.hstack([\n",
        "    np.zeros(len(fa_patients), dtype=np.int64),\n",
        "    np.ones(len(fa_controls), dtype=np.int64)\n",
        "])\n",
        "np.random.seed(42)\n",
        "perm = np.random.permutation(X.shape[0])\n",
        "X = X[perm]\n",
        "y = y[perm]\n",
        "N, F_dim = X.shape\n",
        "print(\"Nodes:\", N, \"Features:\", F_dim)\n",
        "\n",
        "x = torch.from_numpy(X).to(device)\n",
        "y_torch = torch.from_numpy(y).to(device)"
      ],
      "metadata": {
        "id": "yHz4PNN3ZGnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3070e474-1a88-4b3c-ef75-7818f2afa3d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes: 146 Features: 180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fa_patients.shape)\n",
        "print(fa_controls.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vs-be8VdjMv",
        "outputId": "42e4fd1d-c3ad-4955-8807-a8ecfb9b5b3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(98, 180)\n",
            "(48, 180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_adj(features, alpha=0.5):\n",
        "    f = features / np.linalg.norm(features, axis=1, keepdims=True)\n",
        "    W = np.dot(f, f.T)\n",
        "    W = (W >= alpha).astype(np.float32)\n",
        "    return W\n",
        "\n",
        "W = create_adj(X, alpha=0.5)\n",
        "\n",
        "rows, cols = np.nonzero(W)\n",
        "edge_index = torch.tensor([rows, cols], dtype=torch.long)\n",
        "edge_index = to_undirected(edge_index).to(device)\n",
        "\n",
        "adj = SparseTensor(\n",
        "    row=edge_index[0],\n",
        "    col=edge_index[1],\n",
        "    sparse_sizes=(N, N)\n",
        ").fill_value(1.).to(device)"
      ],
      "metadata": {
        "id": "G4NhuZrda_02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24696885-57e7-4ca6-e0d6-c213f62f0abe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_687862/3636632323.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  edge_index = torch.tensor([rows, cols], dtype=torch.long)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sim(batch, adj, wt=20, wl=2):\n",
        "    rowptr, col, _ = adj.csr()\n",
        "    batch_size = batch.shape[0]\n",
        "    batch_repeat = batch.repeat(wt)\n",
        "    rw = adj.random_walk(batch_repeat, wl)[:, 1:]\n",
        "    rw = rw.t().reshape(-1, batch_size).t()\n",
        "\n",
        "    row, col_, val = [], [], []\n",
        "    for i in range(batch.shape[0]):\n",
        "        rw_nodes, rw_times = torch.unique(rw[i], return_counts=True)\n",
        "        row += [batch[i].item()] * rw_nodes.shape[0]\n",
        "        col_ += rw_nodes.tolist()\n",
        "        val += rw_times.tolist()\n",
        "\n",
        "    adj_rw = SparseTensor(\n",
        "        row=torch.tensor(row),\n",
        "        col=torch.tensor(col_),\n",
        "        value=torch.tensor(val),\n",
        "        sparse_sizes=(batch.shape[0], batch.shape[0])\n",
        "    )\n",
        "    adj_rw = adj_rw.set_diag(0.)\n",
        "    return adj_rw"
      ],
      "metadata": {
        "id": "R43yuSoZbE8X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mask(adj):\n",
        "    mean = adj.mean(dim=1)\n",
        "    mask = (adj.storage.value() -\n",
        "            mean[adj.storage.row()]) > -1e-10\n",
        "    return SparseTensor(\n",
        "        row=adj.storage.row()[mask],\n",
        "        col=adj.storage.col()[mask],\n",
        "        value=adj.storage.value()[mask],\n",
        "        sparse_sizes=adj.sizes()\n",
        "    )\n",
        "\n",
        "def scale(z):\n",
        "    zmin = z.min(dim=1, keepdim=True)[0]\n",
        "    zmax = z.max(dim=1, keepdim=True)[0]\n",
        "    return (z - zmin) / (zmax - zmin + 1e-12)\n"
      ],
      "metadata": {
        "id": "719DxBZObJHf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MAGILoss(nn.Module):\n",
        "    def __init__(self, tau=0.3):\n",
        "        super().__init__()\n",
        "        self.tau = tau\n",
        "\n",
        "    def forward(self, z, mask):\n",
        "        dot = torch.mm(z, z.t()) / self.tau\n",
        "        dot = dot - dot.max(dim=1, keepdim=True)[0].detach()\n",
        "\n",
        "        logits_mask = torch.ones_like(dot) - torch.eye(z.size(0), device=z.device)\n",
        "        exp_logits = torch.exp(dot) * logits_mask\n",
        "        log_prob = dot - torch.log(exp_logits.sum(1, keepdim=True))\n",
        "\n",
        "        row, col = mask.storage.row(), mask.storage.col()\n",
        "        loss = -log_prob[row, col].mean()\n",
        "        return loss"
      ],
      "metadata": {
        "id": "wI0W4CNrbNbY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.conv = GCNConv(in_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv(x, edge_index)\n",
        "        x = F.leaky_relu(x, 0.5)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-dR_PLulbOBG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_runs = 10\n",
        "epochs = 5000\n",
        "\n",
        "acc_list, prec_list, rec_list, f1_list, auc_list = [], [], [], [], []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"\\n========== Run {run+1}/{n_runs} ==========\")\n",
        "\n",
        "    setup_seed(42 + run)\n",
        "\n",
        "    encoder = Encoder(F_dim, 256).to(device)\n",
        "    criterion = MAGILoss(tau=0.3)\n",
        "    optimizer = torch.optim.Adam(\n",
        "        encoder.parameters(), lr=5e-4, weight_decay=1e-3\n",
        "    )\n",
        "\n",
        "    batch = torch.arange(N, device=device)\n",
        "    adj_rw = get_sim(batch, adj)\n",
        "    mask = get_mask(adj_rw)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        encoder.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        z = encoder(x, edge_index)\n",
        "        z = scale(z)\n",
        "        z = F.normalize(z, dim=1)\n",
        "\n",
        "        loss = criterion(z, mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 500 == 0:\n",
        "            print(f\"Run {run+1} | Epoch {epoch} | Loss {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "    encoder.eval()\n",
        "    with torch.no_grad():\n",
        "        z = encoder(x, edge_index)\n",
        "        z = scale(z)\n",
        "        z = F.normalize(z, dim=1).cpu().numpy()\n",
        "\n",
        "    kmeans = KMeans(n_clusters=2, n_init=20, random_state=run)\n",
        "    y_pred = kmeans.fit_predict(z)\n",
        "\n",
        "    acc1 = accuracy_score(y, y_pred)\n",
        "    acc2 = accuracy_score(y, 1 - y_pred)\n",
        "    if acc2 > acc1:\n",
        "        y_pred = 1 - y_pred\n",
        "\n",
        "    acc  = accuracy_score(y, y_pred)\n",
        "    prec = precision_score(y, y_pred)\n",
        "    rec  = recall_score(y, y_pred)\n",
        "    f1   = f1_score(y, y_pred)\n",
        "\n",
        "\n",
        "    acc_list.append(acc)\n",
        "    prec_list.append(prec)\n",
        "    rec_list.append(rec)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "\n",
        "    print(\n",
        "        f\"Run {run+1} → \"\n",
        "        f\"ACC: {acc:.4f}, \"\n",
        "        f\"PREC: {prec:.4f}, \"\n",
        "        f\"REC: {rec:.4f}, \"\n",
        "        f\"F1: {f1:.4f}, \"\n",
        "    )\n",
        "print(\"\\n===== MAGI + K-Means (10 Runs) =====\")\n",
        "print(f\"ACC : {np.mean(acc_list):.4f} \\u00b1 {np.std(acc_list):.4f}\")\n",
        "print(f\"PREC: {np.mean(prec_list):.4f} \\u00b1 {np.std(prec_list):.4f}\")\n",
        "print(f\"REC : {np.mean(rec_list):.4f} \\u00b1 {np.std(rec_list):.4f}\")\n",
        "print(f\"F1  : {np.mean(f1_list):.4f} \\u00b1 {np.std(f1_list):.4f}\")"
      ],
      "metadata": {
        "id": "U9UKCTM-bRRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f981d82-836b-4753-c981-6a1b12045858"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== Run 1/10 ==========\n",
            "Run 1 | Epoch 0 | Loss 4.9767\n",
            "Run 1 | Epoch 500 | Loss 4.9767\n",
            "Run 1 | Epoch 1000 | Loss 4.9766\n",
            "Run 1 | Epoch 1500 | Loss 4.9766\n",
            "Run 1 | Epoch 2000 | Loss 4.9766\n",
            "Run 1 | Epoch 2500 | Loss 4.9766\n",
            "Run 1 | Epoch 3000 | Loss 4.9766\n",
            "Run 1 | Epoch 3500 | Loss 4.9766\n",
            "Run 1 | Epoch 4000 | Loss 4.9766\n",
            "Run 1 | Epoch 4500 | Loss 4.9766\n",
            "Run 1 → ACC: 0.6781, PREC: 0.5294, REC: 0.1875, F1: 0.2769, \n",
            "\n",
            "========== Run 2/10 ==========\n",
            "Run 2 | Epoch 0 | Loss 4.9767\n",
            "Run 2 | Epoch 500 | Loss 4.9767\n",
            "Run 2 | Epoch 1000 | Loss 4.9767\n",
            "Run 2 | Epoch 1500 | Loss 4.9767\n",
            "Run 2 | Epoch 2000 | Loss 4.9767\n",
            "Run 2 | Epoch 2500 | Loss 4.9767\n",
            "Run 2 | Epoch 3000 | Loss 4.9767\n",
            "Run 2 | Epoch 3500 | Loss 4.9767\n",
            "Run 2 | Epoch 4000 | Loss 4.9767\n",
            "Run 2 | Epoch 4500 | Loss 4.9767\n",
            "Run 2 → ACC: 0.6644, PREC: 0.0000, REC: 0.0000, F1: 0.0000, \n",
            "\n",
            "========== Run 3/10 ==========\n",
            "Run 3 | Epoch 0 | Loss 4.9767\n",
            "Run 3 | Epoch 500 | Loss 4.9767\n",
            "Run 3 | Epoch 1000 | Loss 4.9767\n",
            "Run 3 | Epoch 1500 | Loss 4.9767\n",
            "Run 3 | Epoch 2000 | Loss 4.9767\n",
            "Run 3 | Epoch 2500 | Loss 4.9767\n",
            "Run 3 | Epoch 3000 | Loss 4.9767\n",
            "Run 3 | Epoch 3500 | Loss 4.9767\n",
            "Run 3 | Epoch 4000 | Loss 4.9767\n",
            "Run 3 | Epoch 4500 | Loss 4.9767\n",
            "Run 3 → ACC: 0.6644, PREC: 0.0000, REC: 0.0000, F1: 0.0000, \n",
            "\n",
            "========== Run 4/10 ==========\n",
            "Run 4 | Epoch 0 | Loss 4.9767\n",
            "Run 4 | Epoch 500 | Loss 4.9767\n",
            "Run 4 | Epoch 1000 | Loss 4.9767\n",
            "Run 4 | Epoch 1500 | Loss 4.9767\n",
            "Run 4 | Epoch 2000 | Loss 4.9767\n",
            "Run 4 | Epoch 2500 | Loss 4.9767\n",
            "Run 4 | Epoch 3000 | Loss 4.9767\n",
            "Run 4 | Epoch 3500 | Loss 4.9767\n",
            "Run 4 | Epoch 4000 | Loss 4.9767\n",
            "Run 4 | Epoch 4500 | Loss 4.9767\n",
            "Run 4 → ACC: 0.6575, PREC: 0.0000, REC: 0.0000, F1: 0.0000, \n",
            "\n",
            "========== Run 5/10 ==========\n",
            "Run 5 | Epoch 0 | Loss 4.9767\n",
            "Run 5 | Epoch 500 | Loss 4.9767\n",
            "Run 5 | Epoch 1000 | Loss 4.9767\n",
            "Run 5 | Epoch 1500 | Loss 4.9767\n",
            "Run 5 | Epoch 2000 | Loss 4.9767\n",
            "Run 5 | Epoch 2500 | Loss 4.9767\n",
            "Run 5 | Epoch 3000 | Loss 4.9767\n",
            "Run 5 | Epoch 3500 | Loss 4.9767\n",
            "Run 5 | Epoch 4000 | Loss 4.9767\n",
            "Run 5 | Epoch 4500 | Loss 4.9767\n",
            "Run 5 → ACC: 0.6712, PREC: 0.5000, REC: 0.1875, F1: 0.2727, \n",
            "\n",
            "========== Run 6/10 ==========\n",
            "Run 6 | Epoch 0 | Loss 4.9767\n",
            "Run 6 | Epoch 500 | Loss 4.9767\n",
            "Run 6 | Epoch 1000 | Loss 4.9767\n",
            "Run 6 | Epoch 1500 | Loss 4.9767\n",
            "Run 6 | Epoch 2000 | Loss 4.9767\n",
            "Run 6 | Epoch 2500 | Loss 4.9767\n",
            "Run 6 | Epoch 3000 | Loss 4.9767\n",
            "Run 6 | Epoch 3500 | Loss 4.9767\n",
            "Run 6 | Epoch 4000 | Loss 4.9767\n",
            "Run 6 | Epoch 4500 | Loss 4.9767\n",
            "Run 6 → ACC: 0.6575, PREC: 0.0000, REC: 0.0000, F1: 0.0000, \n",
            "\n",
            "========== Run 7/10 ==========\n",
            "Run 7 | Epoch 0 | Loss 4.9767\n",
            "Run 7 | Epoch 500 | Loss 4.9767\n",
            "Run 7 | Epoch 1000 | Loss 4.9767\n",
            "Run 7 | Epoch 1500 | Loss 4.9767\n",
            "Run 7 | Epoch 2000 | Loss 4.9767\n",
            "Run 7 | Epoch 2500 | Loss 4.9767\n",
            "Run 7 | Epoch 3000 | Loss 4.9767\n",
            "Run 7 | Epoch 3500 | Loss 4.9767\n",
            "Run 7 | Epoch 4000 | Loss 4.9767\n",
            "Run 7 | Epoch 4500 | Loss 4.9767\n",
            "Run 7 → ACC: 0.6712, PREC: 0.5000, REC: 0.1875, F1: 0.2727, \n",
            "\n",
            "========== Run 8/10 ==========\n",
            "Run 8 | Epoch 0 | Loss 4.9767\n",
            "Run 8 | Epoch 500 | Loss 4.9767\n",
            "Run 8 | Epoch 1000 | Loss 4.9767\n",
            "Run 8 | Epoch 1500 | Loss 4.9767\n",
            "Run 8 | Epoch 2000 | Loss 4.9767\n",
            "Run 8 | Epoch 2500 | Loss 4.9767\n",
            "Run 8 | Epoch 3000 | Loss 4.9767\n",
            "Run 8 | Epoch 3500 | Loss 4.9767\n",
            "Run 8 | Epoch 4000 | Loss 4.9767\n",
            "Run 8 | Epoch 4500 | Loss 4.9767\n",
            "Run 8 → ACC: 0.6644, PREC: 0.0000, REC: 0.0000, F1: 0.0000, \n",
            "\n",
            "========== Run 9/10 ==========\n",
            "Run 9 | Epoch 0 | Loss 4.9767\n",
            "Run 9 | Epoch 500 | Loss 4.9767\n",
            "Run 9 | Epoch 1000 | Loss 4.9767\n",
            "Run 9 | Epoch 1500 | Loss 4.9767\n",
            "Run 9 | Epoch 2000 | Loss 4.9767\n",
            "Run 9 | Epoch 2500 | Loss 4.9767\n",
            "Run 9 | Epoch 3000 | Loss 4.9767\n",
            "Run 9 | Epoch 3500 | Loss 4.9767\n",
            "Run 9 | Epoch 4000 | Loss 4.9767\n",
            "Run 9 | Epoch 4500 | Loss 4.9767\n",
            "Run 9 → ACC: 0.6644, PREC: 0.0000, REC: 0.0000, F1: 0.0000, \n",
            "\n",
            "========== Run 10/10 ==========\n",
            "Run 10 | Epoch 0 | Loss 4.9767\n",
            "Run 10 | Epoch 500 | Loss 4.9767\n",
            "Run 10 | Epoch 1000 | Loss 4.9767\n",
            "Run 10 | Epoch 1500 | Loss 4.9767\n",
            "Run 10 | Epoch 2000 | Loss 4.9767\n",
            "Run 10 | Epoch 2500 | Loss 4.9767\n",
            "Run 10 | Epoch 3000 | Loss 4.9767\n",
            "Run 10 | Epoch 3500 | Loss 4.9767\n",
            "Run 10 | Epoch 4000 | Loss 4.9767\n",
            "Run 10 | Epoch 4500 | Loss 4.9767\n",
            "Run 10 → ACC: 0.6644, PREC: 0.0000, REC: 0.0000, F1: 0.0000, \n",
            "\n",
            "===== MAGI + K-Means (10 Runs) =====\n",
            "ACC : 0.6658 ± 0.0060\n",
            "PREC: 0.1529 ± 0.2337\n",
            "REC : 0.0563 ± 0.0859\n",
            "F1  : 0.0822 ± 0.1256\n"
          ]
        }
      ]
    }
  ]
}
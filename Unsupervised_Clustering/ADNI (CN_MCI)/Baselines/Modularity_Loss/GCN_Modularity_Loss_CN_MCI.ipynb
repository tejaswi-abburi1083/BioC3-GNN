{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP32kYymaLCFbtj3Qp0GxHj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch.optim as optim\n","from tqdm import tqdm\n","import numpy as np\n","import torch\n","from PIL import Image\n","import cv2\n","import matplotlib.pyplot as plt\n","from numpy import asarray\n","import tifffile as tiff\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","import torch_geometric.nn as pyg_nn\n","from torch_geometric.data import Data\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","from sklearn.manifold import TSNE\n","import random\n","from torch_geometric.nn import GCNConv\n","import copy"],"metadata":{"id":"SsU4lAgwawlX","executionInfo":{"status":"ok","timestamp":1763212752525,"user_tz":-330,"elapsed":2256,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b0e43e59-d0ae-4d5c-f420-45f083939a71"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","/home/snu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}]},{"cell_type":"code","source":["fa_feature_path = \"/home/snu/Downloads/Histogram_CN_FA_20bin_updated.npy\"\n","Histogram_feature_CN_FA_array = np.load(fa_feature_path, allow_pickle=True)\n","\n","# Load MCI features\n","fa_feature_path = \"/home/snu/Downloads/Histogram_MCI_FA_20bin_updated.npy\"\n","Histogram_feature_MCI_FA_array = np.load(fa_feature_path, allow_pickle=True)\n","\n","# Combine features and labels\n","X = np.vstack([Histogram_feature_CN_FA_array, Histogram_feature_MCI_FA_array])\n","y = np.hstack([\n","    np.zeros(Histogram_feature_CN_FA_array.shape[0], dtype=np.int64),\n","    np.ones(Histogram_feature_MCI_FA_array.shape[0], dtype=np.int64)\n","])\n","\n","np.random.seed(42)\n","perm = np.random.permutation(X.shape[0])\n","X = X[perm]\n","y = y[perm]\n","num_nodes, num_feats = X.shape\n","print(f\"Features: {X.shape}, Labels: {y.shape}\")"],"metadata":{"id":"NI1htyS0azbl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763212752574,"user_tz":-330,"elapsed":45,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"87532eb3-9778-4bd5-f8cb-7636771f040c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Features: (300, 180), Labels: (300,)\n"]}]},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.PReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"dBYEvLGWa3X9","executionInfo":{"status":"ok","timestamp":1763212752578,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class GCNEncoder(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ):\n","        super(GCNEncoder, self).__init__()\n","        self.device = device\n","        self.gcn1 = GCNConv(input_dim, hidden_dim)\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.gcn1(x, edge_index)\n","        x = self.dropout(x)\n","        x = self.batchnorm(x)\n","        logits = self.mlp(x)\n","        return logits"],"metadata":{"id":"cQ9R67iva8Q1","executionInfo":{"status":"ok","timestamp":1763212753970,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class GCN(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ):\n","        super(GCN, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","        self.cut = 0   # always modularity\n","\n","        self.online_encoder = GCNEncoder(input_dim, hidden_dim, device, activ)\n","\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_size=hidden_dim)\n","\n","        # attach modularity loss\n","        self.loss = self.modularity_loss\n","\n","    def forward(self, data):\n","        x = self.online_encoder(data)\n","        logits = self.online_predictor(x)\n","        S = nnFn.softmax(logits, dim=1)\n","        return S, logits\n","\n","    def modularity_loss(self, A, S):\n","        C = nnFn.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A)\n","        B = A - torch.ger(d, d) / (2 * m)\n","\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        k = torch.norm(I_S)\n","        n = S.shape[0]\n","\n","        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n","\n","        return modularity_term + collapse_reg_term\n"],"metadata":{"id":"LE3sGgD0bBKN","executionInfo":{"status":"ok","timestamp":1763212755511,"user_tz":-330,"elapsed":7,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def create_adj(F, cut, alpha=1):\n","    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = W - (W.max() / alpha)\n","    return W"],"metadata":{"id":"hdzUOpOMbKbW","executionInfo":{"status":"ok","timestamp":1763212757748,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def load_data(adj, node_feats):\n","    node_feats = torch.from_numpy(node_feats)\n","    edge_index = torch.from_numpy(np.array(np.nonzero((adj > 0))))\n","    row, col = edge_index\n","    edge_weight = torch.from_numpy(adj[row, col])\n","    return node_feats, edge_index, edge_weight"],"metadata":{"id":"TDs0v74QbQQu","executionInfo":{"status":"ok","timestamp":1763212758467,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["features = X.astype(np.float32)\n","print(features.shape, features.dtype)\n","\n","cut = 0\n","alpha = 0.92\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","feats_dim = 180\n","K = 2\n","\n","W0 = create_adj(features, 0, alpha)\n","node_feats, edge_index, _ = load_data(W0, features)\n","data0 = Data(x=node_feats, edge_index=edge_index).to(device)\n","A1 = torch.from_numpy(W0).float().to(device)\n","print(data0)"],"metadata":{"id":"qJur6H5qbUbu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763212762319,"user_tz":-330,"elapsed":105,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"ee974c24-9afd-456f-f756-15171b9beb11"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["(300, 180) float32\n","Data(x=[300, 180], edge_index=[2, 13604])\n"]}]},{"cell_type":"code","source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","model = GCN(feats_dim, 256, K, device, \"ELU\").to(device)\n","optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","num_epochs = 5000\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    S, logits = model(data0)\n","    unsup_loss = model.loss(A1, logits)\n","\n","    total_loss = unsup_loss\n","    total_loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch} | Loss: {total_loss:.4f}\")\n"],"metadata":{"id":"J3jQXcTvbbOP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763212806879,"user_tz":-330,"elapsed":38019,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"ced32833-e8e7-49ab-8cef-55f483bbd54d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Loss: -0.2761\n","Epoch 100 | Loss: -0.4470\n","Epoch 200 | Loss: -0.4503\n","Epoch 300 | Loss: -0.4516\n","Epoch 400 | Loss: -0.4522\n","Epoch 500 | Loss: -0.4527\n","Epoch 600 | Loss: -0.4531\n","Epoch 700 | Loss: -0.4531\n","Epoch 800 | Loss: -0.4534\n","Epoch 900 | Loss: -0.4533\n","Epoch 1000 | Loss: -0.4532\n","Epoch 1100 | Loss: -0.4534\n","Epoch 1200 | Loss: -0.4534\n","Epoch 1300 | Loss: -0.4535\n","Epoch 1400 | Loss: -0.4536\n","Epoch 1500 | Loss: -0.4534\n","Epoch 1600 | Loss: -0.4535\n","Epoch 1700 | Loss: -0.4536\n","Epoch 1800 | Loss: -0.4535\n","Epoch 1900 | Loss: -0.4536\n","Epoch 2000 | Loss: -0.4534\n","Epoch 2100 | Loss: -0.4535\n","Epoch 2200 | Loss: -0.4534\n","Epoch 2300 | Loss: -0.4536\n","Epoch 2400 | Loss: -0.4534\n","Epoch 2500 | Loss: -0.4536\n","Epoch 2600 | Loss: -0.4535\n","Epoch 2700 | Loss: -0.4535\n","Epoch 2800 | Loss: -0.4534\n","Epoch 2900 | Loss: -0.4537\n","Epoch 3000 | Loss: -0.4536\n","Epoch 3100 | Loss: -0.4536\n","Epoch 3200 | Loss: -0.4535\n","Epoch 3300 | Loss: -0.4535\n","Epoch 3400 | Loss: -0.4535\n","Epoch 3500 | Loss: -0.4535\n","Epoch 3600 | Loss: -0.4535\n","Epoch 3700 | Loss: -0.4535\n","Epoch 3800 | Loss: -0.4535\n","Epoch 3900 | Loss: -0.4535\n","Epoch 4000 | Loss: -0.4537\n","Epoch 4100 | Loss: -0.4534\n","Epoch 4200 | Loss: -0.4536\n","Epoch 4300 | Loss: -0.4537\n","Epoch 4400 | Loss: -0.4537\n","Epoch 4500 | Loss: -0.4537\n","Epoch 4600 | Loss: -0.4536\n","Epoch 4700 | Loss: -0.4536\n","Epoch 4800 | Loss: -0.4536\n","Epoch 4900 | Loss: -0.4537\n"]}]},{"cell_type":"code","source":["model.eval()\n","with torch.no_grad():\n","    S, logits = model(data0)\n","    y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","    y_pred_proba = nnFn.softmax(logits, dim=1).cpu().numpy()\n","\n","\n","acc_score = accuracy_score(y, y_pred)\n","acc_score_inverted = accuracy_score(y, 1 - y_pred)\n","\n","if acc_score_inverted > acc_score:\n","    acc_score = acc_score_inverted\n","    y_pred = 1 - y_pred\n","\n","prec_score = precision_score(y, y_pred)\n","rec_score = recall_score(y, y_pred)\n","f1 = f1_score(y, y_pred)\n","log_loss_value = log_loss(y, y_pred_proba)\n","\n","print(\"Accuracy:\", acc_score)\n","print(\"Precision:\", prec_score)\n","print(\"Recall:\", rec_score)\n","print(\"F1:\", f1)\n","print(\"Log Loss:\", log_loss_value)"],"metadata":{"id":"kjJzNRNcbZd2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763212806930,"user_tz":-330,"elapsed":48,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"0f831112-d6d2-48f5-ad00-52d360c2b5f6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.75\n","Precision: 0.8026315789473685\n","Recall: 0.7305389221556886\n","F1: 0.7648902821316614\n","Log Loss: 6.559525478557995\n"]}]},{"cell_type":"code","source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","results = []\n","\n","for run_seed in range(10):\n","    print(\"\\n================ Run\", run_seed, \"================\")\n","\n","    # Set seeds for reproducibility\n","    np.random.seed(run_seed)\n","    torch.manual_seed(run_seed)\n","    random.seed(run_seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(run_seed)\n","\n","    # Shuffle features and labels\n","    perm = np.random.permutation(X.shape[0])\n","    features = X[perm].astype(np.float32)\n","    labels = y[perm]\n","\n","    cut = 0\n","    alpha = 0.92\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    feats_dim = 180\n","    K = 2\n","\n","    W0 = create_adj(features, cut, alpha)\n","    node_feats, edge_index, _ = load_data(W0, features)\n","    data0 = Data(x=node_feats, edge_index=edge_index).to(device)\n","    A1 = torch.from_numpy(W0).float().to(device)\n","\n","    model = GCN(feats_dim, 256, K, device, \"ELU\").to(device)\n","    optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","    scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","    num_epochs = 5000\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","\n","        S, logits = model(data0)\n","        unsup_loss = model.loss(A1, logits)\n","\n","        unsup_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        if epoch % 1000 == 0:\n","            print(f\"Epoch {epoch} | Loss: {unsup_loss:.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        S, logits = model(data0)\n","        y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","        y_pred_proba = nnFn.softmax(logits, dim=1).cpu().numpy()\n","\n","    acc_score = accuracy_score(labels, y_pred)\n","    acc_score_inverted = accuracy_score(labels, 1 - y_pred)\n","\n","    if acc_score_inverted > acc_score:\n","        acc_score = acc_score_inverted\n","        y_pred = 1 - y_pred\n","\n","    prec_score = precision_score(labels, y_pred)\n","    rec_score = recall_score(labels, y_pred)\n","    f1 = f1_score(labels, y_pred)\n","    log_loss_value = log_loss(labels, y_pred_proba)\n","\n","    print(\"Accuracy:\", acc_score, \"Precision:\", prec_score, \"Recall:\", rec_score, \"F1:\", f1)\n","\n","    results.append({\n","        \"seed\": run_seed,\n","        \"accuracy\": acc_score,\n","        \"precision\": prec_score,\n","        \"recall\": rec_score,\n","        \"f1\": f1,\n","        \"log_loss\": log_loss_value\n","    })\n","\n","accs = [r[\"accuracy\"] for r in results]\n","precisions = [r[\"precision\"] for r in results]\n","recalls = [r[\"recall\"] for r in results]\n","f1s = [r[\"f1\"] for r in results]\n","\n","print(\"\\n===== Final Results across 10 runs =====\")\n","print(\"Accuracy: mean=\", np.mean(accs), \"std=\", np.std(accs))\n","print(\"Precision: mean=\", np.mean(precisions), \"std=\", np.std(precisions))\n","print(\"Recall: mean=\", np.mean(recalls), \"std=\", np.std(recalls))\n","print(\"F1: mean=\", np.mean(f1s), \"std=\", np.std(f1s))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-pwzW2ZZQTL","executionInfo":{"status":"ok","timestamp":1763213174406,"user_tz":-330,"elapsed":345865,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"715110e8-c0e8-479f-caec-e174c14976a8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================ Run 0 ================\n","Epoch 0 | Loss: -0.2698\n","Epoch 1000 | Loss: -0.4534\n","Epoch 2000 | Loss: -0.4538\n","Epoch 3000 | Loss: -0.4536\n","Epoch 4000 | Loss: -0.4538\n","Accuracy: 0.7533333333333333 Precision: 0.8079470198675497 Recall: 0.7305389221556886 F1: 0.7672955974842768\n","\n","================ Run 1 ================\n","Epoch 0 | Loss: -0.2701\n","Epoch 1000 | Loss: -0.4537\n","Epoch 2000 | Loss: -0.4539\n","Epoch 3000 | Loss: -0.4535\n","Epoch 4000 | Loss: -0.4539\n","Accuracy: 0.7466666666666667 Precision: 0.7973856209150327 Recall: 0.7305389221556886 F1: 0.7625\n","\n","================ Run 2 ================\n","Epoch 0 | Loss: -0.2745\n","Epoch 1000 | Loss: -0.4529\n","Epoch 2000 | Loss: -0.4536\n","Epoch 3000 | Loss: -0.4536\n","Epoch 4000 | Loss: -0.4534\n","Accuracy: 0.75 Precision: 0.8026315789473685 Recall: 0.7305389221556886 F1: 0.7648902821316614\n","\n","================ Run 3 ================\n","Epoch 0 | Loss: -0.2808\n","Epoch 1000 | Loss: -0.4537\n","Epoch 2000 | Loss: -0.4539\n","Epoch 3000 | Loss: -0.4536\n","Epoch 4000 | Loss: -0.4537\n","Accuracy: 0.75 Precision: 0.8026315789473685 Recall: 0.7305389221556886 F1: 0.7648902821316614\n","\n","================ Run 4 ================\n","Epoch 0 | Loss: -0.2795\n","Epoch 1000 | Loss: -0.4534\n","Epoch 2000 | Loss: -0.4537\n","Epoch 3000 | Loss: -0.4537\n","Epoch 4000 | Loss: -0.4539\n","Accuracy: 0.75 Precision: 0.8026315789473685 Recall: 0.7305389221556886 F1: 0.7648902821316614\n","\n","================ Run 5 ================\n","Epoch 0 | Loss: -0.2863\n","Epoch 1000 | Loss: -0.4541\n","Epoch 2000 | Loss: -0.4538\n","Epoch 3000 | Loss: -0.4537\n","Epoch 4000 | Loss: -0.4537\n","Accuracy: 0.75 Precision: 0.8026315789473685 Recall: 0.7305389221556886 F1: 0.7648902821316614\n","\n","================ Run 6 ================\n","Epoch 0 | Loss: -0.2772\n","Epoch 1000 | Loss: -0.4535\n","Epoch 2000 | Loss: -0.4535\n","Epoch 3000 | Loss: -0.4537\n","Epoch 4000 | Loss: -0.4537\n","Accuracy: 0.7533333333333333 Precision: 0.8079470198675497 Recall: 0.7305389221556886 F1: 0.7672955974842768\n","\n","================ Run 7 ================\n","Epoch 0 | Loss: -0.2844\n","Epoch 1000 | Loss: -0.4539\n","Epoch 2000 | Loss: -0.4540\n","Epoch 3000 | Loss: -0.4542\n","Epoch 4000 | Loss: -0.4540\n","Accuracy: 0.75 Precision: 0.8026315789473685 Recall: 0.7305389221556886 F1: 0.7648902821316614\n","\n","================ Run 8 ================\n","Epoch 0 | Loss: -0.2857\n","Epoch 1000 | Loss: -0.4539\n","Epoch 2000 | Loss: -0.4540\n","Epoch 3000 | Loss: -0.4539\n","Epoch 4000 | Loss: -0.4540\n","Accuracy: 0.7533333333333333 Precision: 0.8079470198675497 Recall: 0.7305389221556886 F1: 0.7672955974842768\n","\n","================ Run 9 ================\n","Epoch 0 | Loss: -0.2461\n","Epoch 1000 | Loss: -0.4533\n","Epoch 2000 | Loss: -0.4536\n","Epoch 3000 | Loss: -0.4533\n","Epoch 4000 | Loss: -0.4534\n","Accuracy: 0.7466666666666667 Precision: 0.8013245033112583 Recall: 0.7245508982035929 F1: 0.7610062893081762\n","\n","===== Final Results across 10 runs =====\n","Accuracy: mean= 0.7503333333333334 std= 0.0023333333333333097\n","Precision: mean= 0.8035709078565783 std= 0.003242944201286531\n","Recall: mean= 0.7299401197604791 std= 0.0017964071856287234\n","F1: mean= 0.7649844492419314 std= 0.0019510715084752966\n"]}]},{"cell_type":"markdown","source":["SELU"],"metadata":{"id":"-hyphrDPsg3U"}},{"cell_type":"code","source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","results = []\n","\n","for run_seed in range(10):\n","    print(\"\\n================ Run\", run_seed, \"================\")\n","\n","    # Set seeds for reproducibility\n","    np.random.seed(run_seed)\n","    torch.manual_seed(run_seed)\n","    random.seed(run_seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(run_seed)\n","\n","    # Shuffle features and labels\n","    perm = np.random.permutation(X.shape[0])\n","    features = X[perm].astype(np.float32)\n","    labels = y[perm]\n","\n","    cut = 0\n","    alpha = 0.92\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    feats_dim = 180\n","    K = 2\n","\n","    W0 = create_adj(features, cut, alpha)\n","    node_feats, edge_index, _ = load_data(W0, features)\n","    data0 = Data(x=node_feats, edge_index=edge_index).to(device)\n","    A1 = torch.from_numpy(W0).float().to(device)\n","\n","    model = GCN(feats_dim, 256, K, device, \"SELU\").to(device)\n","    optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","    scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","    num_epochs = 5000\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","\n","        S, logits = model(data0)\n","        unsup_loss = model.loss(A1, logits)\n","\n","        unsup_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        if epoch % 1000 == 0:\n","            print(f\"Epoch {epoch} | Loss: {unsup_loss:.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        S, logits = model(data0)\n","        y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","        y_pred_proba = nnFn.softmax(logits, dim=1).cpu().numpy()\n","\n","    acc_score = accuracy_score(labels, y_pred)\n","    acc_score_inverted = accuracy_score(labels, 1 - y_pred)\n","\n","    if acc_score_inverted > acc_score:\n","        acc_score = acc_score_inverted\n","        y_pred = 1 - y_pred\n","\n","    prec_score = precision_score(labels, y_pred)\n","    rec_score = recall_score(labels, y_pred)\n","    f1 = f1_score(labels, y_pred)\n","    log_loss_value = log_loss(labels, y_pred_proba)\n","\n","    print(\"Accuracy:\", acc_score, \"Precision:\", prec_score, \"Recall:\", rec_score, \"F1:\", f1)\n","\n","    results.append({\n","        \"seed\": run_seed,\n","        \"accuracy\": acc_score,\n","        \"precision\": prec_score,\n","        \"recall\": rec_score,\n","        \"f1\": f1,\n","        \"log_loss\": log_loss_value\n","    })\n","\n","accs = [r[\"accuracy\"] for r in results]\n","precisions = [r[\"precision\"] for r in results]\n","recalls = [r[\"recall\"] for r in results]\n","f1s = [r[\"f1\"] for r in results]\n","\n","print(\"\\n===== Final Results across 10 runs =====\")\n","print(\"Accuracy: mean=\", np.mean(accs), \"std=\", np.std(accs))\n","print(\"Precision: mean=\", np.mean(precisions), \"std=\", np.std(precisions))\n","print(\"Recall: mean=\", np.mean(recalls), \"std=\", np.std(recalls))\n","print(\"F1: mean=\", np.mean(f1s), \"std=\", np.std(f1s))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vACXAjbjshpk","executionInfo":{"status":"ok","timestamp":1763213544421,"user_tz":-330,"elapsed":351309,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"4fd09468-9f64-4850-9299-d915888489c3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================ Run 0 ================\n","Epoch 0 | Loss: -0.2698\n","Epoch 1000 | Loss: -0.4534\n","Epoch 2000 | Loss: -0.4538\n","Epoch 3000 | Loss: -0.4536\n","Epoch 4000 | Loss: -0.4538\n","Accuracy: 0.7533333333333333 Precision: 0.8079470198675497 Recall: 0.7305389221556886 F1: 0.7672955974842768\n","\n","================ Run 1 ================\n","Epoch 0 | Loss: -0.2701\n","Epoch 1000 | Loss: -0.4537\n","Epoch 2000 | Loss: -0.4539\n","Epoch 3000 | Loss: -0.4535\n","Epoch 4000 | Loss: -0.4539\n","Accuracy: 0.7466666666666667 Precision: 0.7973856209150327 Recall: 0.7305389221556886 F1: 0.7625\n","\n","================ Run 2 ================\n","Epoch 0 | Loss: -0.2745\n","Epoch 1000 | Loss: -0.4529\n","Epoch 2000 | Loss: -0.4536\n","Epoch 3000 | Loss: -0.4536\n","Epoch 4000 | Loss: -0.4534\n","Accuracy: 0.75 Precision: 0.8026315789473685 Recall: 0.7305389221556886 F1: 0.7648902821316614\n","\n","================ Run 3 ================\n","Epoch 0 | Loss: -0.2808\n","Epoch 1000 | Loss: -0.4537\n","Epoch 2000 | Loss: -0.4539\n","Epoch 3000 | Loss: -0.4536\n","Epoch 4000 | Loss: -0.4537\n","Accuracy: 0.75 Precision: 0.8026315789473685 Recall: 0.7305389221556886 F1: 0.7648902821316614\n","\n","================ Run 4 ================\n","Epoch 0 | Loss: -0.2795\n","Epoch 1000 | Loss: -0.4534\n","Epoch 2000 | Loss: -0.4537\n","Epoch 3000 | Loss: -0.4537\n","Epoch 4000 | Loss: -0.4539\n","Accuracy: 0.75 Precision: 0.8026315789473685 Recall: 0.7305389221556886 F1: 0.7648902821316614\n","\n","================ Run 5 ================\n","Epoch 0 | Loss: -0.2863\n","Epoch 1000 | Loss: -0.4541\n","Epoch 2000 | Loss: -0.4538\n","Epoch 3000 | Loss: -0.4537\n","Epoch 4000 | Loss: -0.4537\n","Accuracy: 0.75 Precision: 0.8026315789473685 Recall: 0.7305389221556886 F1: 0.7648902821316614\n","\n","================ Run 6 ================\n","Epoch 0 | Loss: -0.2772\n","Epoch 1000 | Loss: -0.4535\n","Epoch 2000 | Loss: -0.4535\n","Epoch 3000 | Loss: -0.4537\n","Epoch 4000 | Loss: -0.4537\n","Accuracy: 0.7533333333333333 Precision: 0.8079470198675497 Recall: 0.7305389221556886 F1: 0.7672955974842768\n","\n","================ Run 7 ================\n","Epoch 0 | Loss: -0.2844\n","Epoch 1000 | Loss: -0.4539\n","Epoch 2000 | Loss: -0.4540\n","Epoch 3000 | Loss: -0.4542\n","Epoch 4000 | Loss: -0.4540\n","Accuracy: 0.75 Precision: 0.8026315789473685 Recall: 0.7305389221556886 F1: 0.7648902821316614\n","\n","================ Run 8 ================\n","Epoch 0 | Loss: -0.2857\n","Epoch 1000 | Loss: -0.4539\n","Epoch 2000 | Loss: -0.4540\n","Epoch 3000 | Loss: -0.4539\n","Epoch 4000 | Loss: -0.4540\n","Accuracy: 0.7533333333333333 Precision: 0.8079470198675497 Recall: 0.7305389221556886 F1: 0.7672955974842768\n","\n","================ Run 9 ================\n","Epoch 0 | Loss: -0.2461\n","Epoch 1000 | Loss: -0.4533\n","Epoch 2000 | Loss: -0.4536\n","Epoch 3000 | Loss: -0.4533\n","Epoch 4000 | Loss: -0.4534\n","Accuracy: 0.7466666666666667 Precision: 0.8013245033112583 Recall: 0.7245508982035929 F1: 0.7610062893081762\n","\n","===== Final Results across 10 runs =====\n","Accuracy: mean= 0.7503333333333334 std= 0.0023333333333333097\n","Precision: mean= 0.8035709078565783 std= 0.003242944201286531\n","Recall: mean= 0.7299401197604791 std= 0.0017964071856287234\n","F1: mean= 0.7649844492419314 std= 0.0019510715084752966\n"]}]}]}
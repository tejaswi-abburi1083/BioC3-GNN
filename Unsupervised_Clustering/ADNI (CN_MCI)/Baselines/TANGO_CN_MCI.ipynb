{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNUZlLMbrpHvnT+LEql6lGG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","from sklearn.cluster import SpectralClustering\n","from sklearn.neighbors import NearestNeighbors\n","from scipy.sparse import lil_matrix\n","from multiprocessing import Pool, cpu_count\n","from scipy.optimize import linear_sum_assignment\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_score,\n","    recall_score,\n","    f1_score,\n","    log_loss,\n",")"],"metadata":{"id":"eGjt-z6ky5wd","executionInfo":{"status":"ok","timestamp":1758518837667,"user_tz":-330,"elapsed":8,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["cn_path = \"/home/snu/Downloads/Histogram_CN_FA_20bin_updated.npy\"\n","mci_path = \"/home/snu/Downloads/Histogram_MCI_FA_20bin_updated.npy\"\n","k_neighbors = 20\n","random_state = 42"],"metadata":{"id":"ZWGk-s2Py8BU","executionInfo":{"status":"ok","timestamp":1758518838899,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def cluster_accuracy(y_true, y_pred):\n","    y_true = y_true.astype(np.int64)\n","    D = max(y_pred.max(), y_true.max()) + 1\n","    w = np.zeros((D, D), dtype=np.int64)\n","    for i in range(y_pred.size):\n","        w[y_pred[i], y_true[i]] += 1\n","    ind = linear_sum_assignment(w.max() - w)\n","    ind = np.array(ind).T\n","    return sum([w[i, j] for i, j in ind]) / y_pred.size"],"metadata":{"id":"0zZfBxkIy961","executionInfo":{"status":"ok","timestamp":1758518839448,"user_tz":-330,"elapsed":18,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def hungarian_map(y_true, y_pred):\n","    y_true = y_true.astype(np.int64)\n","    D = max(y_pred.max(), y_true.max()) + 1\n","    w = np.zeros((D, D), dtype=np.int64)\n","    for i in range(y_pred.size):\n","        w[y_pred[i], y_true[i]] += 1\n","    ind = linear_sum_assignment(w.max() - w)\n","    ind = np.array(ind).T\n","    new_pred = np.zeros_like(y_pred, dtype=np.int64)\n","    for i, j in ind:\n","        new_pred[y_pred == i] = j\n","    return new_pred"],"metadata":{"id":"8sxm84cVy_us","executionInfo":{"status":"ok","timestamp":1758518840484,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def compute_similarity_for_points(points, data, neighbors, max_dis):\n","    n = data.shape[0]\n","    local_similarity_matrix = lil_matrix((n, n), dtype=np.float32)\n","    neighbor_sets = {i: set(neighbors[i]) for i in points}\n","    for i in points:\n","        i_neighbors = neighbor_sets[i]\n","        point_i = data[i]\n","        for j in neighbors[i]:\n","            if j in neighbor_sets:\n","                j_neighbors = neighbor_sets[j]\n","            else:\n","                j_neighbors = set(neighbors[j])\n","            shared_neighbors = i_neighbors & j_neighbors\n","            if shared_neighbors:\n","                shared_idx = list(shared_neighbors)\n","                shared_points = data[shared_idx]\n","                point_j = data[j]\n","                d_i = np.linalg.norm(shared_points - point_i[np.newaxis, :], axis=1) / (max_dis + 1e-12)\n","                d_j = np.linalg.norm(shared_points - point_j[np.newaxis, :], axis=1) / (max_dis + 1e-12)\n","                d = 0.5 * (d_i + d_j)\n","                similarity = np.sum(np.exp(-d * d))\n","                if similarity > 0:\n","                    local_similarity_matrix[i, j] = similarity\n","    return local_similarity_matrix"],"metadata":{"id":"F1UOkqZSzB5M","executionInfo":{"status":"ok","timestamp":1758518841356,"user_tz":-330,"elapsed":14,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def compute_similarity(data, k):\n","    n = data.shape[0]\n","    nn_model = NearestNeighbors(n_neighbors=k, algorithm='auto')\n","    nn_model.fit(data)\n","    distances, neighbors = nn_model.kneighbors(data)\n","    max_dis = np.max(distances) if distances.size else 1.0\n","    num_processes = max(1, cpu_count() - 1)\n","    points_split = np.array_split(range(n), num_processes)\n","    args = [(points, data, neighbors, max_dis) for points in points_split]\n","    with Pool(processes=num_processes) as pool:\n","        results = pool.starmap(compute_similarity_for_points, args)\n","    similarity_matrix = results[0]\n","    for mat in results[1:]:\n","        similarity_matrix = similarity_matrix + mat\n","    similarity_matrix = similarity_matrix.maximum(similarity_matrix.transpose())\n","    if similarity_matrix.data.size > 0:\n","        similarity_matrix.data = similarity_matrix.data / similarity_matrix.max()\n","    similarity_matrix.setdiag(1.0 + 1e-15)\n","    return similarity_matrix.tocsr()"],"metadata":{"id":"BRqf_f-KzENT","executionInfo":{"status":"ok","timestamp":1758518842962,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def compute_threshold_matrix(data, k):\n","    n = data.shape[0]\n","    similarity_matrix = compute_similarity(data, k)\n","    density = np.zeros(n, dtype=np.float32)\n","    top_k_indices = []\n","    for i in range(n):\n","        start, end = similarity_matrix.indptr[i], similarity_matrix.indptr[i+1]\n","        row_data = similarity_matrix.data[start:end]\n","        row_idx = similarity_matrix.indices[start:end]\n","        if row_data.size == 0:\n","            top_k_indices.append(np.array([], dtype=int))\n","            continue\n","        order = np.argsort(-row_data)\n","        sorted_idx = row_idx[order]\n","        sorted_data = row_data[order]\n","        k_eff = min(k, sorted_data.size)\n","        density[i] = np.sum(sorted_data[:k_eff])\n","        top_k_indices.append(sorted_idx)\n","    if density.max() > 0:\n","        density = density / density.max()\n","    nearest_neighbor_ranks = np.full(n, -1, dtype=int)\n","    for i in range(n):\n","        cur = density[i]\n","        for rank, nb in enumerate(top_k_indices[i]):\n","            if density[nb] > cur:\n","                nearest_neighbor_ranks[i] = rank\n","                break\n","    leader_points = np.full(n, -1, dtype=int)\n","    degree = density.copy()\n","    max_rank = int(nearest_neighbor_ranks.max()) if nearest_neighbor_ranks.max() >= 0 else 1\n","    sorted_by_density_indices = np.argsort(density)\n","    for i in sorted_by_density_indices:\n","        if nearest_neighbor_ranks[i] != -1:\n","            neighbor_idx = top_k_indices[i][nearest_neighbor_ranks[i]]\n","            contribution = degree[i] * np.exp(- (float(nearest_neighbor_ranks[i]) / float(max_rank))**2)\n","            degree[neighbor_idx] += contribution\n","    for i in range(n):\n","        if nearest_neighbor_ranks[i] != -1:\n","            neighbor_idx = top_k_indices[i][nearest_neighbor_ranks[i]]\n","            if degree[i] < degree[neighbor_idx]:\n","                leader_points[i] = neighbor_idx\n","    core_points = np.where(leader_points == -1)[0]\n","    core_idx_mapping = np.full(n, -1, dtype=int)\n","    core_idx_mapping[core_points] = np.arange(core_points.shape[0], dtype=int)\n","    visited = np.zeros(n, dtype=bool)\n","    for i in range(n):\n","        if visited[i]:\n","            continue\n","        if leader_points[i] == -1:\n","            leader_points[i] = i\n","            visited[i] = True\n","            continue\n","        cur = i\n","        stack = []\n","        while leader_points[cur] != -1 and leader_points[cur] != cur:\n","            stack.append(cur)\n","            visited[cur] = True\n","            cur = leader_points[cur]\n","        if leader_points[cur] == -1:\n","            leader_points[cur] = cur\n","        visited[cur] = True\n","        core = cur\n","        while stack:\n","            node = stack.pop()\n","            leader_points[node] = core\n","    S_coo = similarity_matrix.tocoo()\n","    rows, cols, vals = S_coo.row, S_coo.col, S_coo.data\n","    mask = rows < cols\n","    rows, cols, vals = rows[mask], cols[mask], vals[mask]\n","    weights = vals * density[rows] * density[cols]\n","    core_i = leader_points[rows]\n","    core_j = leader_points[cols]\n","    inter_mask = core_i != core_j\n","    core_i = core_i[inter_mask]\n","    core_j = core_j[inter_mask]\n","    weights = weights[inter_mask]\n","    core_i_mapped = core_idx_mapping[core_i]\n","    core_j_mapped = core_idx_mapping[core_j]\n","    valid_mask = (core_i_mapped >= 0) & (core_j_mapped >= 0)\n","    core_i_mapped = core_i_mapped[valid_mask].astype(int)\n","    core_j_mapped = core_j_mapped[valid_mask].astype(int)\n","    weights = weights[valid_mask]\n","    edges = list(zip(weights.tolist(), core_i_mapped.tolist(), core_j_mapped.tolist()))\n","    edges.sort(reverse=True, key=lambda x: x[0])\n","    m = core_points.shape[0]\n","    if m == 0:\n","        return np.zeros((0, 0), dtype=np.float32), leader_points, core_idx_mapping\n","    threshold_matrix = np.zeros((m, m), dtype=np.float32)\n","    core_labels = np.arange(m, dtype=int)\n","    for sim, i, j in edges:\n","        if core_labels[i] != core_labels[j]:\n","            label_i = core_labels[i]\n","            label_j = core_labels[j]\n","            comp_i = (core_labels == label_i)\n","            comp_j = (core_labels == label_j)\n","            threshold_matrix[np.ix_(comp_i, comp_j)] = sim\n","            core_labels[comp_i] = label_j\n","    threshold_matrix = np.maximum(threshold_matrix, threshold_matrix.T)\n","    np.fill_diagonal(threshold_matrix, 1.0 + 1e-15)\n","    return threshold_matrix, leader_points, core_idx_mapping"],"metadata":{"id":"NsN2TW6fzJij","executionInfo":{"status":"ok","timestamp":1758518844142,"user_tz":-330,"elapsed":41,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def tango(data, cluster_num, k, run_seed=None):\n","    threshold_matrix, leader_points, core_idx_mapping = compute_threshold_matrix(data, k)\n","    rng = run_seed if run_seed is not None else None\n","    if threshold_matrix.size == 0 or threshold_matrix.shape[0] < cluster_num:\n","        S_full = compute_similarity(data, k).toarray()\n","        clustering = SpectralClustering(\n","            n_clusters=cluster_num,\n","            affinity='precomputed',\n","            assign_labels='kmeans',\n","            random_state=run_seed\n","        )\n","        labels_full = clustering.fit_predict(S_full)\n","        return labels_full\n","    clustering = SpectralClustering(\n","        n_clusters=cluster_num,\n","        affinity='precomputed',\n","        assign_labels='kmeans',\n","        random_state=run_seed\n","    )\n","    core_labels = clustering.fit_predict(threshold_matrix)\n","    labels_full = core_labels[core_idx_mapping[leader_points]]\n","    return labels_full"],"metadata":{"id":"hm8Z0cTXzMTD","executionInfo":{"status":"ok","timestamp":1758518847282,"user_tz":-330,"elapsed":33,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def main():\n","    CN = np.load(cn_path, allow_pickle=True)\n","    MCI = np.load(mci_path, allow_pickle=True)\n","    X_cn = np.array(list(CN))\n","    X_mci = np.array(list(MCI))\n","    X = np.vstack([X_cn, X_mci]).astype(np.float32)\n","    y = np.hstack([np.zeros(X_cn.shape[0], dtype=np.int64), np.ones(X_mci.shape[0], dtype=np.int64)])\n","    np.random.seed(random_state)\n","    perm = np.random.permutation(X.shape[0])\n","    X = X[perm]\n","    y = y[perm]\n","    y_pred = tango(X, cluster_num=len(np.unique(y)), k=k_neighbors)\n","    y_pred_aligned = hungarian_map(y, y_pred)\n","    n_classes = len(np.unique(y))\n","    y_proba = np.zeros((len(y), n_classes), dtype=float)\n","    for idx, lab in enumerate(y_pred_aligned):\n","        if 0 <= lab < n_classes:\n","            y_proba[idx, lab] = 1.0\n","        else:\n","            y_proba[idx, :] = 1.0 / n_classes\n","    acc = accuracy_score(y, y_pred_aligned)\n","    if n_classes == 2:\n","        acc_inv = accuracy_score(y, 1 - y_pred_aligned)\n","        if acc_inv > acc:\n","            acc = acc_inv\n","            y_pred_aligned = 1 - y_pred_aligned\n","    prec = precision_score(y, y_pred_aligned, zero_division=0)\n","    rec = recall_score(y, y_pred_aligned, zero_division=0)\n","    f1 = f1_score(y, y_pred_aligned, zero_division=0)\n","    ll = log_loss(y, y_proba)\n","    print(\"==== TANGO results on your features ====\")\n","    print(f\"Accuracy: {acc:.4f}\")\n","    print(f\"Precision: {prec:.4f}\")\n","    print(f\"Recall: {rec:.4f}\")\n","    print(f\"F1: {f1:.4f}\")\n","    print(f\"LogLoss: {ll:.6f}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMbIphf7zOYD","executionInfo":{"status":"ok","timestamp":1758518872974,"user_tz":-330,"elapsed":633,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"d81af66b-474b-4183-c7d8-1239985cd7a4"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["==== TANGO results on your features ====\n","Accuracy: 0.6167\n","Precision: 0.5956\n","Recall: 0.9701\n","F1: 0.7380\n","LogLoss: 13.816734\n"]}]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    import torch, random\n","\n","    num_runs = 10\n","    all_results = {\"accuracy\": [], \"precision\": [], \"recall\": [], \"f1\": [], \"log_loss\": []}\n","\n","    for run in range(num_runs):\n","        print(f\"\\n--- Run {run+1}/{num_runs} ---\")\n","        torch.manual_seed(run)\n","        np.random.seed(run)\n","        random.seed(run)\n","        if torch.cuda.is_available():\n","            torch.cuda.manual_seed_all(run)\n","\n","        CN = np.load(cn_path, allow_pickle=True)\n","        MCI = np.load(mci_path, allow_pickle=True)\n","        X_cn = np.array(list(CN))\n","        X_mci = np.array(list(MCI))\n","        X = np.vstack([X_cn, X_mci]).astype(np.float32)\n","        y = np.hstack([np.zeros(X_cn.shape[0], dtype=np.int64), np.ones(X_mci.shape[0], dtype=np.int64)])\n","        np.random.seed(random_state)\n","        perm = np.random.permutation(X.shape[0])\n","        X = X[perm]\n","        y = y[perm]\n","        y_pred = tango(X, cluster_num=len(np.unique(y)), k=k_neighbors)\n","        y_pred_aligned = hungarian_map(y, y_pred)\n","        n_classes = len(np.unique(y))\n","        y_proba = np.zeros((len(y), n_classes), dtype=float)\n","        for idx, lab in enumerate(y_pred_aligned):\n","            if 0 <= lab < n_classes:\n","                y_proba[idx, lab] = 1.0\n","            else:\n","                y_proba[idx, :] = 1.0 / n_classes\n","        acc = accuracy_score(y, y_pred_aligned)\n","        if n_classes == 2:\n","            acc_inv = accuracy_score(y, 1 - y_pred_aligned)\n","            if acc_inv > acc:\n","                acc = acc_inv\n","                y_pred_aligned = 1 - y_pred_aligned\n","        prec = precision_score(y, y_pred_aligned, zero_division=0)\n","        rec = recall_score(y, y_pred_aligned, zero_division=0)\n","        f1 = f1_score(y, y_pred_aligned, zero_division=0)\n","        ll = log_loss(y, y_proba)\n","\n","        print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}, LogLoss: {ll:.6f}\")\n","\n","        all_results[\"accuracy\"].append(acc)\n","        all_results[\"precision\"].append(prec)\n","        all_results[\"recall\"].append(rec)\n","        all_results[\"f1\"].append(f1)\n","        all_results[\"log_loss\"].append(ll)\n","\n","    print(\"\\n================ FINAL SUMMARY ================\\n\")\n","    print(f\"{'Metric':>12} | {'Mean':>10} ± {'Std':<10}\")\n","    print(\"-\" * 40)\n","    for metric, values in all_results.items():\n","        print(f\"{metric:>12} | {np.mean(values):10.4f} ± {np.std(values):<10.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xpvX-FBVztx7","executionInfo":{"status":"ok","timestamp":1758518932151,"user_tz":-330,"elapsed":5022,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"3b134e1f-8404-40df-90b5-ad5d4e2bb821"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Run 1/10 ---\n","Accuracy: 0.6167, Precision: 0.5956, Recall: 0.9701, F1: 0.7380, LogLoss: 13.816734\n","\n","--- Run 2/10 ---\n","Accuracy: 0.6167, Precision: 0.5956, Recall: 0.9701, F1: 0.7380, LogLoss: 13.816734\n","\n","--- Run 3/10 ---\n","Accuracy: 0.6167, Precision: 0.5956, Recall: 0.9701, F1: 0.7380, LogLoss: 13.816734\n","\n","--- Run 4/10 ---\n","Accuracy: 0.6167, Precision: 0.5956, Recall: 0.9701, F1: 0.7380, LogLoss: 13.816734\n","\n","--- Run 5/10 ---\n","Accuracy: 0.6167, Precision: 0.5956, Recall: 0.9701, F1: 0.7380, LogLoss: 13.816734\n","\n","--- Run 6/10 ---\n","Accuracy: 0.6167, Precision: 0.5956, Recall: 0.9701, F1: 0.7380, LogLoss: 13.816734\n","\n","--- Run 7/10 ---\n","Accuracy: 0.6167, Precision: 0.5956, Recall: 0.9701, F1: 0.7380, LogLoss: 13.816734\n","\n","--- Run 8/10 ---\n","Accuracy: 0.6167, Precision: 0.5956, Recall: 0.9701, F1: 0.7380, LogLoss: 13.816734\n","\n","--- Run 9/10 ---\n","Accuracy: 0.6167, Precision: 0.5956, Recall: 0.9701, F1: 0.7380, LogLoss: 13.816734\n","\n","--- Run 10/10 ---\n","Accuracy: 0.6167, Precision: 0.5956, Recall: 0.9701, F1: 0.7380, LogLoss: 13.816734\n","\n","================ FINAL SUMMARY ================\n","\n","      Metric |       Mean ± Std       \n","----------------------------------------\n","    accuracy |     0.6167 ± 0.0000    \n","   precision |     0.5956 ± 0.0000    \n","      recall |     0.9701 ± 0.0000    \n","          f1 |     0.7380 ± 0.0000    \n","    log_loss |    13.8167 ± 0.0000    \n"]}]}]}
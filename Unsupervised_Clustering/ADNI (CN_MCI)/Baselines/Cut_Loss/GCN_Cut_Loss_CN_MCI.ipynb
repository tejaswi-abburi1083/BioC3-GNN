{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP1tfr/Edh0Z+Szu00Oqh56"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch.optim as optim\n","from tqdm import tqdm\n","import numpy as np\n","import torch\n","from PIL import Image\n","import cv2\n","import matplotlib.pyplot as plt\n","from numpy import asarray\n","import tifffile as tiff\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","import torch_geometric.nn as pyg_nn\n","from torch_geometric.data import Data\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","from sklearn.manifold import TSNE\n","import random\n","from torch_geometric.nn import GCNConv\n","import copy"],"metadata":{"id":"SsU4lAgwawlX","executionInfo":{"status":"ok","timestamp":1763968188544,"user_tz":-330,"elapsed":10,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["fa_feature_path = \"/home/snu/Downloads/Histogram_CN_FA_20bin_updated.npy\"\n","Histogram_feature_CN_FA_array = np.load(fa_feature_path, allow_pickle=True)\n","\n","# Load MCI features\n","fa_feature_path = \"/home/snu/Downloads/Histogram_MCI_FA_20bin_updated.npy\"\n","Histogram_feature_MCI_FA_array = np.load(fa_feature_path, allow_pickle=True)\n","\n","# Combine features and labels\n","X = np.vstack([Histogram_feature_CN_FA_array, Histogram_feature_MCI_FA_array])\n","y = np.hstack([\n","    np.zeros(Histogram_feature_CN_FA_array.shape[0], dtype=np.int64),\n","    np.ones(Histogram_feature_MCI_FA_array.shape[0], dtype=np.int64)\n","])\n","\n","np.random.seed(42)\n","perm = np.random.permutation(X.shape[0])\n","X = X[perm]\n","y = y[perm]\n","num_nodes, num_feats = X.shape\n","print(f\"Features: {X.shape}, Labels: {y.shape}\")"],"metadata":{"id":"NI1htyS0azbl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763968189212,"user_tz":-330,"elapsed":6,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"fcecb9f0-592b-4362-decd-ba4c7b62bebf"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Features: (300, 180), Labels: (300,)\n"]}]},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.PReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"dBYEvLGWa3X9","executionInfo":{"status":"ok","timestamp":1763968191079,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class GCNEncoder(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ):\n","        super(GCNEncoder, self).__init__()\n","        self.device = device\n","        self.gcn1 = GCNConv(input_dim, hidden_dim)\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.gcn1(x, edge_index)\n","        x = self.dropout(x)\n","        x = self.batchnorm(x)\n","        logits = self.mlp(x)\n","        return logits"],"metadata":{"id":"cQ9R67iva8Q1","executionInfo":{"status":"ok","timestamp":1763968192214,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class GCN(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ):\n","        super(GCN, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","        self.cut = 0   # always modularity\n","\n","        self.online_encoder = GCNEncoder(input_dim, hidden_dim, device, activ)\n","\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_size=hidden_dim)\n","\n","\n","        self.loss = self.cut_loss\n","\n","    def forward(self, data):\n","        x = self.online_encoder(data)\n","        logits = self.online_predictor(x)\n","        S = nnFn.softmax(logits, dim=1)\n","        return S, logits\n","\n","    def cut_loss(self, A, S):\n","        S = nnFn.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / den)\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n","\n","        return mincut_loss + ortho_loss"],"metadata":{"id":"LE3sGgD0bBKN","executionInfo":{"status":"ok","timestamp":1763968341937,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def create_adj(F, cut, alpha=1):\n","    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = W - (W.max() / alpha)\n","    return W"],"metadata":{"id":"hdzUOpOMbKbW","executionInfo":{"status":"ok","timestamp":1763968343375,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def load_data(adj, node_feats):\n","    node_feats = torch.from_numpy(node_feats)\n","    edge_index = torch.from_numpy(np.array(np.nonzero((adj > 0))))\n","    row, col = edge_index\n","    edge_weight = torch.from_numpy(adj[row, col])\n","    return node_feats, edge_index, edge_weight"],"metadata":{"id":"TDs0v74QbQQu","executionInfo":{"status":"ok","timestamp":1763968344122,"user_tz":-330,"elapsed":9,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["features = X.astype(np.float32)\n","print(features.shape, features.dtype)\n","\n","cut = 0\n","alpha = 0.92\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","feats_dim = 180\n","K = 2\n","\n","W0 = create_adj(features, 0, alpha)\n","node_feats, edge_index, _ = load_data(W0, features)\n","data0 = Data(x=node_feats, edge_index=edge_index).to(device)\n","A1 = torch.from_numpy(W0).float().to(device)\n","print(data0)"],"metadata":{"id":"qJur6H5qbUbu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763968344860,"user_tz":-330,"elapsed":32,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"a291cc12-2a35-444a-b263-60a47f06a3c2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["(300, 180) float32\n","Data(x=[300, 180], edge_index=[2, 13604])\n"]}]},{"cell_type":"code","source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","model = GCN(feats_dim, 256, K, device, \"ELU\").to(device)\n","optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","num_epochs = 5000\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    S, logits = model(data0)\n","    unsup_loss = model.loss(A1, logits)\n","\n","    total_loss = unsup_loss\n","    total_loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch} | Loss: {total_loss:.4f}\")\n"],"metadata":{"id":"J3jQXcTvbbOP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763968406771,"user_tz":-330,"elapsed":60687,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"3d990e57-61b9-4c98-fa7f-f25f159c6a6a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Loss: -0.2384\n","Epoch 100 | Loss: -0.7726\n","Epoch 200 | Loss: -0.7943\n","Epoch 300 | Loss: -0.8004\n","Epoch 400 | Loss: -0.8037\n","Epoch 500 | Loss: -0.8018\n","Epoch 600 | Loss: -0.8067\n","Epoch 700 | Loss: -0.8056\n","Epoch 800 | Loss: -0.8062\n","Epoch 900 | Loss: -0.8046\n","Epoch 1000 | Loss: -0.8068\n","Epoch 1100 | Loss: -0.8064\n","Epoch 1200 | Loss: -0.8072\n","Epoch 1300 | Loss: -0.8090\n","Epoch 1400 | Loss: -0.8088\n","Epoch 1500 | Loss: -0.8087\n","Epoch 1600 | Loss: -0.8045\n","Epoch 1700 | Loss: -0.8077\n","Epoch 1800 | Loss: -0.8050\n","Epoch 1900 | Loss: -0.8086\n","Epoch 2000 | Loss: -0.8060\n","Epoch 2100 | Loss: -0.8074\n","Epoch 2200 | Loss: -0.8074\n","Epoch 2300 | Loss: -0.8076\n","Epoch 2400 | Loss: -0.8087\n","Epoch 2500 | Loss: -0.8064\n","Epoch 2600 | Loss: -0.8085\n","Epoch 2700 | Loss: -0.8080\n","Epoch 2800 | Loss: -0.8080\n","Epoch 2900 | Loss: -0.8075\n","Epoch 3000 | Loss: -0.8052\n","Epoch 3100 | Loss: -0.8062\n","Epoch 3200 | Loss: -0.8071\n","Epoch 3300 | Loss: -0.8093\n","Epoch 3400 | Loss: -0.8087\n","Epoch 3500 | Loss: -0.8076\n","Epoch 3600 | Loss: -0.8058\n","Epoch 3700 | Loss: -0.8097\n","Epoch 3800 | Loss: -0.8080\n","Epoch 3900 | Loss: -0.8086\n","Epoch 4000 | Loss: -0.8075\n","Epoch 4100 | Loss: -0.8081\n","Epoch 4200 | Loss: -0.8095\n","Epoch 4300 | Loss: -0.8074\n","Epoch 4400 | Loss: -0.8062\n","Epoch 4500 | Loss: -0.8072\n","Epoch 4600 | Loss: -0.8077\n","Epoch 4700 | Loss: -0.8088\n","Epoch 4800 | Loss: -0.8089\n","Epoch 4900 | Loss: -0.8072\n"]}]},{"cell_type":"code","source":["model.eval()\n","with torch.no_grad():\n","    S, logits = model(data0)\n","    y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","    y_pred_proba = nnFn.softmax(logits, dim=1).cpu().numpy()\n","\n","\n","acc_score = accuracy_score(y, y_pred)\n","acc_score_inverted = accuracy_score(y, 1 - y_pred)\n","\n","if acc_score_inverted > acc_score:\n","    acc_score = acc_score_inverted\n","    y_pred = 1 - y_pred\n","\n","prec_score = precision_score(y, y_pred)\n","rec_score = recall_score(y, y_pred)\n","f1 = f1_score(y, y_pred)\n","log_loss_value = log_loss(y, y_pred_proba)\n","\n","print(\"Accuracy:\", acc_score)\n","print(\"Precision:\", prec_score)\n","print(\"Recall:\", rec_score)\n","print(\"F1:\", f1)\n","print(\"Log Loss:\", log_loss_value)"],"metadata":{"id":"kjJzNRNcbZd2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763968406819,"user_tz":-330,"elapsed":44,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"53adea12-76f6-4e86-aacb-821e7b55e6ca"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.58\n","Precision: 0.6357615894039735\n","Recall: 0.5748502994011976\n","F1: 0.6037735849056604\n","Log Loss: 5.104417148302252\n"]}]},{"cell_type":"code","source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","results = []\n","\n","for run_seed in range(10):\n","    print(\"\\n================ Run\", run_seed, \"================\")\n","\n","    # Set seeds for reproducibility\n","    np.random.seed(run_seed)\n","    torch.manual_seed(run_seed)\n","    random.seed(run_seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(run_seed)\n","\n","    # Shuffle features and labels\n","    perm = np.random.permutation(X.shape[0])\n","    features = X[perm].astype(np.float32)\n","    labels = y[perm]\n","\n","    cut = 0\n","    alpha = 0.92\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    feats_dim = 180\n","    K = 2\n","\n","    W0 = create_adj(features, cut, alpha)\n","    node_feats, edge_index, _ = load_data(W0, features)\n","    data0 = Data(x=node_feats, edge_index=edge_index).to(device)\n","    A1 = torch.from_numpy(W0).float().to(device)\n","\n","    model = GCN(feats_dim, 256, K, device, \"ELU\").to(device)\n","    optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","    scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","    num_epochs = 5000\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","\n","        S, logits = model(data0)\n","        unsup_loss = model.loss(A1, logits)\n","\n","        unsup_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        if epoch % 1000 == 0:\n","            print(f\"Epoch {epoch} | Loss: {unsup_loss:.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        S, logits = model(data0)\n","        y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","        y_pred_proba = nnFn.softmax(logits, dim=1).cpu().numpy()\n","\n","    acc_score = accuracy_score(labels, y_pred)\n","    acc_score_inverted = accuracy_score(labels, 1 - y_pred)\n","\n","    if acc_score_inverted > acc_score:\n","        acc_score = acc_score_inverted\n","        y_pred = 1 - y_pred\n","\n","    prec_score = precision_score(labels, y_pred)\n","    rec_score = recall_score(labels, y_pred)\n","    f1 = f1_score(labels, y_pred)\n","    log_loss_value = log_loss(labels, y_pred_proba)\n","\n","    print(\"Accuracy:\", acc_score, \"Precision:\", prec_score, \"Recall:\", rec_score, \"F1:\", f1)\n","\n","    results.append({\n","        \"seed\": run_seed,\n","        \"accuracy\": acc_score,\n","        \"precision\": prec_score,\n","        \"recall\": rec_score,\n","        \"f1\": f1,\n","        \"log_loss\": log_loss_value\n","    })\n","\n","accs = [r[\"accuracy\"] for r in results]\n","precisions = [r[\"precision\"] for r in results]\n","recalls = [r[\"recall\"] for r in results]\n","f1s = [r[\"f1\"] for r in results]\n","\n","print(\"\\n===== Final Results across 10 runs =====\")\n","print(\"Accuracy: mean=\", np.mean(accs), \"std=\", np.std(accs))\n","print(\"Precision: mean=\", np.mean(precisions), \"std=\", np.std(precisions))\n","print(\"Recall: mean=\", np.mean(recalls), \"std=\", np.std(recalls))\n","print(\"F1: mean=\", np.mean(f1s), \"std=\", np.std(f1s))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-pwzW2ZZQTL","executionInfo":{"status":"ok","timestamp":1763968999160,"user_tz":-330,"elapsed":592338,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"4a6eb271-baee-437b-d2aa-8a7e057c4642"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================ Run 0 ================\n","Epoch 0 | Loss: -0.2301\n","Epoch 1000 | Loss: -0.8447\n","Epoch 2000 | Loss: -0.8450\n","Epoch 3000 | Loss: -0.8444\n","Epoch 4000 | Loss: -0.8441\n","Accuracy: 0.7533333333333333 Precision: 0.803921568627451 Recall: 0.7365269461077845 F1: 0.76875\n","\n","================ Run 1 ================\n","Epoch 0 | Loss: -0.2235\n","Epoch 1000 | Loss: -0.8439\n","Epoch 2000 | Loss: -0.8436\n","Epoch 3000 | Loss: -0.8435\n","Epoch 4000 | Loss: -0.8447\n","Accuracy: 0.7366666666666667 Precision: 0.7933333333333333 Recall: 0.7125748502994012 F1: 0.750788643533123\n","\n","================ Run 2 ================\n","Epoch 0 | Loss: -0.2265\n","Epoch 1000 | Loss: -0.8440\n","Epoch 2000 | Loss: -0.8458\n","Epoch 3000 | Loss: -0.8429\n","Epoch 4000 | Loss: -0.8450\n","Accuracy: 0.7533333333333333 Precision: 0.8120805369127517 Recall: 0.7245508982035929 F1: 0.7658227848101266\n","\n","================ Run 3 ================\n","Epoch 0 | Loss: -0.2256\n","Epoch 1000 | Loss: -0.8329\n","Epoch 2000 | Loss: -0.8352\n","Epoch 3000 | Loss: -0.8343\n","Epoch 4000 | Loss: -0.8360\n","Accuracy: 0.7766666666666666 Precision: 0.8472222222222222 Recall: 0.7305389221556886 F1: 0.7845659163987139\n","\n","================ Run 4 ================\n","Epoch 0 | Loss: -0.2201\n","Epoch 1000 | Loss: -0.8437\n","Epoch 2000 | Loss: -0.8442\n","Epoch 3000 | Loss: -0.8454\n","Epoch 4000 | Loss: -0.8450\n","Accuracy: 0.7766666666666666 Precision: 0.8378378378378378 Recall: 0.7425149700598802 F1: 0.7873015873015873\n","\n","================ Run 5 ================\n","Epoch 0 | Loss: -0.2483\n","Epoch 1000 | Loss: -0.8431\n","Epoch 2000 | Loss: -0.8430\n","Epoch 3000 | Loss: -0.8436\n","Epoch 4000 | Loss: -0.8433\n","Accuracy: 0.7833333333333333 Precision: 0.8493150684931506 Recall: 0.7425149700598802 F1: 0.792332268370607\n","\n","================ Run 6 ================\n","Epoch 0 | Loss: -0.2192\n","Epoch 1000 | Loss: -0.8428\n","Epoch 2000 | Loss: -0.8441\n","Epoch 3000 | Loss: -0.8429\n","Epoch 4000 | Loss: -0.8438\n","Accuracy: 0.78 Precision: 0.8435374149659864 Recall: 0.7425149700598802 F1: 0.7898089171974523\n","\n","================ Run 7 ================\n","Epoch 0 | Loss: -0.2214\n","Epoch 1000 | Loss: -0.8443\n","Epoch 2000 | Loss: -0.8436\n","Epoch 3000 | Loss: -0.8470\n","Epoch 4000 | Loss: -0.8448\n","Accuracy: 0.7533333333333333 Precision: 0.8120805369127517 Recall: 0.7245508982035929 F1: 0.7658227848101266\n","\n","================ Run 8 ================\n","Epoch 0 | Loss: -0.2294\n","Epoch 1000 | Loss: -0.8437\n","Epoch 2000 | Loss: -0.8446\n","Epoch 3000 | Loss: -0.8439\n","Epoch 4000 | Loss: -0.8443\n","Accuracy: 0.7466666666666667 Precision: 0.8013245033112583 Recall: 0.7245508982035929 F1: 0.7610062893081762\n","\n","================ Run 9 ================\n","Epoch 0 | Loss: -0.2244\n","Epoch 1000 | Loss: -0.8424\n","Epoch 2000 | Loss: -0.8454\n","Epoch 3000 | Loss: -0.8428\n","Epoch 4000 | Loss: -0.8437\n","Accuracy: 0.75 Precision: 0.8066666666666666 Recall: 0.7245508982035929 F1: 0.7634069400630915\n","\n","===== Final Results across 10 runs =====\n","Accuracy: mean= 0.761 std= 0.015638272140986526\n","Precision: mean= 0.8207319689283409 std= 0.02022097429009313\n","Recall: mean= 0.7305389221556886 std= 0.009655398500956333\n","F1: mean= 0.7729606131793004 std= 0.013582614597156753\n"]}]}]}
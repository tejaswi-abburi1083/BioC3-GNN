{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN34Py64+9+MR9vNYj8TJRx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwoaLtJ20ypP","executionInfo":{"status":"ok","timestamp":1744307482658,"user_tz":-330,"elapsed":28913,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"c261bb9a-6fb9-4140-8031-3c3efc0c1d5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s0g4Zvqx0-e1","executionInfo":{"status":"ok","timestamp":1744307497848,"user_tz":-330,"elapsed":5461,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"2ea53223-b514-4e34-d913-cce64657033f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0+cu124\n"]}]},{"cell_type":"code","source":["!pip install -q torch_geometric\n","!pip install -q class_resolver\n","!pip3 install pymatting\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UpSLBjh00-sU","executionInfo":{"status":"ok","timestamp":1744307512386,"user_tz":-330,"elapsed":11470,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"25eae238-ae3b-4750-9676-bf1780fc3838"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pymatting\n","  Downloading PyMatting-1.1.13-py3-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymatting) (2.0.2)\n","Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from pymatting) (11.1.0)\n","Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.11/dist-packages (from pymatting) (0.60.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pymatting) (1.14.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba!=0.49.0->pymatting) (0.43.0)\n","Downloading PyMatting-1.1.13-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pymatting\n","Successfully installed pymatting-1.1.13\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","from scipy import sparse\n","from scipy.sparse.linalg import eigsh"],"metadata":{"id":"UASHRSle1JSO","executionInfo":{"status":"ok","timestamp":1758517656488,"user_tz":-330,"elapsed":458,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["fa_feature_path = \"/home/snu/Downloads/Histogram_CN_FA_20bin_updated.npy\"\n","Histogram_feature_CN_FA_array = np.load(fa_feature_path, allow_pickle=True)\n","\n","# Load MCI features\n","fa_feature_path = \"/home/snu/Downloads/Histogram_MCI_FA_20bin_updated.npy\"\n","Histogram_feature_MCI_FA_array = np.load(fa_feature_path, allow_pickle=True)\n","\n","# Combine features and labels\n","X = np.vstack([Histogram_feature_CN_FA_array, Histogram_feature_MCI_FA_array])\n","y = np.hstack([\n","    np.zeros(Histogram_feature_CN_FA_array.shape[0], dtype=np.int64),\n","    np.ones(Histogram_feature_MCI_FA_array.shape[0], dtype=np.int64)\n","])\n","np.random.seed(42)\n","perm = np.random.permutation(X.shape[0])\n","X = X[perm]\n","y = y[perm]\n","num_nodes, num_feats = X.shape\n","print(f\"Features: {X.shape}, Labels: {y.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cEf2bBz1QHS","executionInfo":{"status":"ok","timestamp":1758517657343,"user_tz":-330,"elapsed":7,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"bcf969a0-1d24-46e0-cbaf-ba1251d3498b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Features: (300, 180), Labels: (300,)\n"]}]},{"cell_type":"code","source":["# F = np.concatenate((Histogram_feature_CN_FA_array, Histogram_feature_MCI_FA_array), axis=0)\n","# F = F.astype(np.float32)\n","# print(\"Combined Shape:\", F.shape)\n","F = X\n","F = F.astype(np.float32)\n","print(\"Final Shape:\", F.shape)\n","print(\"Data Type:\", F.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cVxdFJgQ2FIc","executionInfo":{"status":"ok","timestamp":1758517658599,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"e2e2d5b3-1665-46ee-8033-157282ecb985"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Shape: (300, 180)\n","Data Type: float32\n"]}]},{"cell_type":"code","source":["def tokencut_on_features(F_array, alpha=1e-6):\n","    \"\"\"\n","    Apply TokenCut clustering to feature matrix F_array (shape: N × D).\n","    Returns binary labels (0/1) for each node.\n","    \"\"\"\n","    N, D = F_array.shape\n","\n","    # 1. Normalize features row-wise\n","    norms = np.linalg.norm(F_array, axis=1, keepdims=True) + 1e-10\n","    F_norm = F_array / norms\n","\n","    # 2. Construct cosine similarity matrix (fully connected)\n","    W = np.dot(F_norm, F_norm.T)\n","    W = W + alpha  # stabilizer\n","\n","    # 3. Normalized Laplacian: L = I - D^{-1/2} W D^{-1/2}  where, W is the similarity matrix and D is the degree matrix\n","    d = np.sum(W, axis=1)\n","    d_inv_sqrt = np.diag(1.0 / np.sqrt(d + 1e-10))\n","    L = np.eye(N) - d_inv_sqrt @ W @ d_inv_sqrt\n","\n","    # Sparse for efficiency\n","    L_sparse = sparse.csr_matrix(L)\n","\n","    # 4. Compute the Fiedler vector, i.e., the second smallest eigenvector of L.\n","    vals, vecs = eigsh(L_sparse, k=2, which='SM')\n","    fiedler = vecs[:, 1]\n","\n","    # 5. Threshold by mean\n","    threshold = fiedler.mean()\n","    labels = (fiedler > threshold).astype(np.int64)\n","\n","    return labels, fiedler"],"metadata":{"id":"VqomdaTs2R4C","executionInfo":{"status":"ok","timestamp":1758517659905,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["labels, scores = tokencut_on_features(X)\n","\n","# Evaluate\n","y_pred = labels\n","acc = accuracy_score(y, y_pred)\n","inv_acc = accuracy_score(y, 1 - y_pred)\n","if inv_acc > acc:\n","    y_pred = 1 - y_pred\n","    acc = inv_acc\n","\n","prec = precision_score(y, y_pred)\n","rec = recall_score(y, y_pred)\n","f1 = f1_score(y, y_pred)\n","\n","# Normalize fiedler vector for log_loss\n","probs = (scores - scores.min()) / (scores.max() - scores.min() + 1e-10)\n","logloss = log_loss(y, probs)\n","\n","print(\"===== TokenCut Results =====\")\n","print(\"Accuracy Score:\", acc)\n","print(\"Precision Score:\", prec)\n","print(\"Recall Score:\", rec)\n","print(\"F1 Score:\", f1)\n","print(\"Log Loss:\", logloss)"],"metadata":{"id":"GZ5FMCXP2-1H","executionInfo":{"status":"ok","timestamp":1758517661199,"user_tz":-330,"elapsed":35,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"112a1a83-70de-476e-e623-b6df6bcad25e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["===== TokenCut Results =====\n","Accuracy Score: 0.7133333333333334\n","Precision Score: 0.7755102040816326\n","Recall Score: 0.6826347305389222\n","F1 Score: 0.7261146496815286\n","Log Loss: 0.6643915285975587\n"]}]},{"cell_type":"code","source":["print(probs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wekkix0Y5W7l","executionInfo":{"status":"ok","timestamp":1758517662865,"user_tz":-330,"elapsed":6,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"8d133e45-c4ff-4858-9f37-b3b8c8bbf4fe"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.56038965 0.45153542 0.56819757 0.25090124 0.80869724 0.27962045\n"," 0.23182833 0.49845767 0.68776726 0.74532917 0.92072797 0.53579252\n"," 0.5347969  0.52795231 0.68464033 0.8184013  0.18218133 0.34313183\n"," 0.70506029 0.6376309  0.35396407 0.62699401 0.64009375 0.44472168\n"," 0.46158665 0.64107119 0.86676501 0.36195474 0.73982243 0.55754895\n"," 0.39699456 0.91485441 0.40767919 0.3238898  0.5324294  0.71827439\n"," 0.57293381 0.24407741 0.07960541 0.22160597 0.4715257  0.4256618\n"," 0.74172426 0.22423884 0.37329396 0.49033131 0.09141882 0.52734184\n"," 0.35159649 0.3440712  0.86958134 0.61545597 0.44056599 0.3446243\n"," 0.69397634 0.24543503 0.14501474 0.28761577 0.2211638  0.30548682\n"," 0.5301392  0.27973884 0.44568238 0.69071665 0.31364444 0.27460204\n"," 0.         0.48874551 0.28132637 0.42405744 0.17536995 0.38962483\n"," 0.89556645 0.47038352 0.65435242 0.21017389 0.34427238 0.27055536\n"," 0.30793437 0.28250027 0.48596228 0.5103926  0.18666664 0.30830102\n"," 0.22649314 0.08148583 0.25886847 0.14565677 0.34305951 0.2143136\n"," 0.40211032 0.18076488 0.38399749 0.61718314 0.14540764 0.09275395\n"," 0.40718811 0.70757495 0.46813507 0.40262414 0.73554321 0.30659892\n"," 0.14554824 0.79328505 0.57609357 0.54147249 1.         0.33827363\n"," 0.59962888 0.67424053 0.34033804 0.27978445 0.42407358 0.55483756\n"," 0.66394791 0.1945577  0.18094296 0.59705281 0.19275405 0.13333609\n"," 0.09654243 0.46111731 0.59025529 0.52324721 0.56422366 0.08677372\n"," 0.09280818 0.24197828 0.07492692 0.44817727 0.2951594  0.4311265\n"," 0.24866181 0.34354879 0.25370081 0.67648014 0.53991639 0.05447649\n"," 0.67633718 0.12549702 0.23790701 0.51536871 0.94071025 0.470432\n"," 0.54489335 0.51923096 0.24119431 0.45434167 0.58885434 0.45622419\n"," 0.35479051 0.04932146 0.65680511 0.40955437 0.58351713 0.64201731\n"," 0.50164461 0.38205832 0.07694066 0.15106906 0.94075217 0.51264926\n"," 0.3198441  0.13502229 0.23576357 0.6456839  0.76560452 0.44507715\n"," 0.44454633 0.17342527 0.70577973 0.67446001 0.58222748 0.31806134\n"," 0.23241029 0.71344822 0.43630541 0.16835284 0.44157035 0.5611355\n"," 0.24621433 0.72941484 0.71027781 0.47710471 0.47478678 0.55286978\n"," 0.49262636 0.4831559  0.14095779 0.1276769  0.42720362 0.15980967\n"," 0.41439037 0.00231345 0.70467076 0.54643127 0.15511708 0.98539337\n"," 0.17370043 0.66642096 0.22339028 0.44783387 0.61585158 0.46559276\n"," 0.52375137 0.03780869 0.53607163 0.63985506 0.3708351  0.52952616\n"," 0.58736277 0.1002962  0.77441546 0.07561375 0.18897629 0.28637134\n"," 0.30051211 0.83874572 0.87588125 0.01708502 0.15076588 0.3198417\n"," 0.70429975 0.22904508 0.18231799 0.25873495 0.15272792 0.26604693\n"," 0.66979291 0.88040713 0.09730354 0.14182185 0.55952327 0.44700822\n"," 0.28621048 0.22617234 0.23256477 0.1077882  0.71999344 0.58894008\n"," 0.55504861 0.39257544 0.52951736 0.57441087 0.56371664 0.73785019\n"," 0.10832281 0.38243347 0.06835519 0.24887204 0.25984099 0.22666475\n"," 0.52757343 0.16297887 0.245212   0.48117107 0.07312919 0.29677247\n"," 0.50935499 0.36455713 0.26699634 0.32096715 0.28882311 0.25145724\n"," 0.3311728  0.61904749 0.1431906  0.74516108 0.52489176 0.10211261\n"," 0.26651679 0.30992053 0.8076647  0.52958347 0.76166034 0.80493975\n"," 0.56490496 0.32879714 0.42127205 0.65547448 0.26577048 0.21939582\n"," 0.48620965 0.3219783  0.51890438 0.32900707 0.41066783 0.25603532\n"," 0.7210843  0.25499698 0.72337653 0.67390026 0.26084602 0.69430716\n"," 0.39651315 0.39229266 0.36556108 0.30387151 0.37614227 0.32950552]\n"]}]},{"cell_type":"code","source":["num_runs = 10\n","acc_scores, prec_scores, rec_scores, f1_scores, log_losses = [], [], [], [], []\n","\n","for run in range(num_runs):\n","    print(f\"\\n--- Run {run+1}/{num_runs} ---\")\n","    np.random.seed(run)\n","    perm = np.random.permutation(X.shape[0])\n","    X_run = X[perm]\n","    y_run = y[perm]\n","\n","    labels, scores = tokencut_on_features(X_run)\n","\n","    # Align labels to ground truth\n","    y_pred = labels\n","    acc = accuracy_score(y_run, y_pred)\n","    inv_acc = accuracy_score(y_run, 1 - y_pred)\n","    if inv_acc > acc:\n","        y_pred = 1 - y_pred\n","        acc = inv_acc\n","\n","    prec = precision_score(y_run, y_pred)\n","    rec = recall_score(y_run, y_pred)\n","    f1 = f1_score(y_run, y_pred)\n","    probs = (scores - scores.min()) / (scores.max() - scores.min() + 1e-10)\n","    logloss = log_loss(y_run, probs)\n","\n","    acc_scores.append(acc)\n","    prec_scores.append(prec)\n","    rec_scores.append(rec)\n","    f1_scores.append(f1)\n","    log_losses.append(logloss)\n","\n","    print(f\"Run {run+1} | Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f} | LogLoss: {logloss:.4f}\")\n","\n","print(\"\\n================ FINAL SUMMARY ================\\n\")\n","print(f\"{'Metric':>15} | {'Mean':>10} ± {'Std':<10}\")\n","print(\"-\" * 50)\n","print(f\"{'Accuracy':>15} | {np.mean(acc_scores):.4f} ± {np.std(acc_scores):.4f}\")\n","print(f\"{'Precision':>15} | {np.mean(prec_scores):.4f} ± {np.std(prec_scores):.4f}\")\n","print(f\"{'Recall':>15} | {np.mean(rec_scores):.4f} ± {np.std(rec_scores):.4f}\")\n","print(f\"{'F1 Score':>15} | {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n","print(f\"{'Log Loss':>15} | {np.mean(log_losses):.4f} ± {np.std(log_losses):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Yvu-ibHxvjx","executionInfo":{"status":"ok","timestamp":1758517664755,"user_tz":-330,"elapsed":93,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"2f010cea-1a84-4570-e835-ec6544c91592"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Run 1/10 ---\n","Run 1 | Acc: 0.7133 | Prec: 0.7755 | Rec: 0.6826 | F1: 0.7261 | LogLoss: 1.2168\n","\n","--- Run 2/10 ---\n","Run 2 | Acc: 0.7133 | Prec: 0.7755 | Rec: 0.6826 | F1: 0.7261 | LogLoss: 0.6644\n","\n","--- Run 3/10 ---\n","Run 3 | Acc: 0.7133 | Prec: 0.7755 | Rec: 0.6826 | F1: 0.7261 | LogLoss: 1.2168\n","\n","--- Run 4/10 ---\n","Run 4 | Acc: 0.7133 | Prec: 0.7755 | Rec: 0.6826 | F1: 0.7261 | LogLoss: 0.6644\n","\n","--- Run 5/10 ---\n","Run 5 | Acc: 0.7133 | Prec: 0.7755 | Rec: 0.6826 | F1: 0.7261 | LogLoss: 0.6644\n","\n","--- Run 6/10 ---\n","Run 6 | Acc: 0.7133 | Prec: 0.7755 | Rec: 0.6826 | F1: 0.7261 | LogLoss: 1.2168\n","\n","--- Run 7/10 ---\n","Run 7 | Acc: 0.7133 | Prec: 0.7755 | Rec: 0.6826 | F1: 0.7261 | LogLoss: 1.2168\n","\n","--- Run 8/10 ---\n","Run 8 | Acc: 0.7133 | Prec: 0.7755 | Rec: 0.6826 | F1: 0.7261 | LogLoss: 1.2168\n","\n","--- Run 9/10 ---\n","Run 9 | Acc: 0.7133 | Prec: 0.7755 | Rec: 0.6826 | F1: 0.7261 | LogLoss: 1.2168\n","\n","--- Run 10/10 ---\n","Run 10 | Acc: 0.7133 | Prec: 0.7755 | Rec: 0.6826 | F1: 0.7261 | LogLoss: 1.2168\n","\n","================ FINAL SUMMARY ================\n","\n","         Metric |       Mean ± Std       \n","--------------------------------------------------\n","       Accuracy | 0.7133 ± 0.0000\n","      Precision | 0.7755 ± 0.0000\n","         Recall | 0.6826 ± 0.0000\n","       F1 Score | 0.7261 ± 0.0000\n","       Log Loss | 1.0511 ± 0.2531\n"]}]}]}
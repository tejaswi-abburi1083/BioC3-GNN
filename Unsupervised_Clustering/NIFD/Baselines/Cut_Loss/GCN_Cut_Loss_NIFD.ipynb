{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMYfrYMKKZ1PSuVPl41ToO3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch.optim as optim\n","from tqdm import tqdm\n","import numpy as np\n","import torch\n","from PIL import Image\n","import cv2\n","import matplotlib.pyplot as plt\n","from numpy import asarray\n","import tifffile as tiff\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","import torch_geometric.nn as pyg_nn\n","from torch_geometric.data import Data\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","from sklearn.manifold import TSNE\n","import random\n","from torch_geometric.nn import GCNConv\n","import copy"],"metadata":{"id":"SsU4lAgwawlX","executionInfo":{"status":"ok","timestamp":1764151625296,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["fa_patients_path = \"/home/snu/Downloads/NIFD_Patients_FA_Histogram_Feature.npy\"\n","Patients_FA_array = np.load(fa_patients_path, allow_pickle=True)\n","\n","fa_controls_path = \"/home/snu/Downloads/NIFD_Control_FA_Histogram_Feature.npy\"\n","Controls_FA_array = np.load(fa_controls_path, allow_pickle=True)\n","\n","X = np.vstack([Controls_FA_array, Patients_FA_array])\n","y = np.hstack([\n","    np.zeros(Controls_FA_array.shape[0], dtype=np.int64),  # 0 = Control\n","    np.ones(Patients_FA_array.shape[0], dtype=np.int64)    # 1 = Patient\n","])\n","\n","np.random.seed(42)\n","perm = np.random.permutation(X.shape[0])\n","X = X[perm]\n","y = y[perm]"],"metadata":{"id":"NI1htyS0azbl","executionInfo":{"status":"ok","timestamp":1764151627082,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.PReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"dBYEvLGWa3X9","executionInfo":{"status":"ok","timestamp":1764151627742,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class GCNEncoder(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ):\n","        super(GCNEncoder, self).__init__()\n","        self.device = device\n","        self.gcn1 = GCNConv(input_dim, hidden_dim)\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.gcn1(x, edge_index)\n","        x = self.dropout(x)\n","        x = self.batchnorm(x)\n","        logits = self.mlp(x)\n","        return logits"],"metadata":{"id":"cQ9R67iva8Q1","executionInfo":{"status":"ok","timestamp":1764151629888,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class GCN(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ):\n","        super(GCN, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","        self.cut = 0   # always modularity\n","\n","        self.online_encoder = GCNEncoder(input_dim, hidden_dim, device, activ)\n","\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_size=hidden_dim)\n","\n","        # attach modularity loss\n","        self.loss = self.cut_loss\n","\n","    def forward(self, data):\n","        x = self.online_encoder(data)\n","        logits = self.online_predictor(x)\n","        S = nnFn.softmax(logits, dim=1)\n","        return S, logits\n","\n","    def cut_loss(self, A, S):\n","        S = nnFn.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / den)\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n","\n","        return mincut_loss + ortho_loss"],"metadata":{"id":"LE3sGgD0bBKN","executionInfo":{"status":"ok","timestamp":1764151650919,"user_tz":-330,"elapsed":47,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def create_adj(F, cut, alpha=1):\n","    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = W - (W.max() / alpha)\n","    return W"],"metadata":{"id":"hdzUOpOMbKbW","executionInfo":{"status":"ok","timestamp":1764151653513,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def load_data(adj, node_feats):\n","    node_feats = torch.from_numpy(node_feats)\n","    edge_index = torch.from_numpy(np.array(np.nonzero((adj > 0))))\n","    row, col = edge_index\n","    edge_weight = torch.from_numpy(adj[row, col])\n","    return node_feats, edge_index, edge_weight"],"metadata":{"id":"TDs0v74QbQQu","executionInfo":{"status":"ok","timestamp":1764151654162,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["features = X.astype(np.float32)\n","print(features.shape, features.dtype)\n","\n","cut = 0\n","alpha = 0.5\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","feats_dim = 180\n","K = 2\n","\n","W0 = create_adj(features, 0, alpha)\n","node_feats, edge_index, _ = load_data(W0, features)\n","data0 = Data(x=node_feats, edge_index=edge_index).to(device)\n","A1 = torch.from_numpy(W0).float().to(device)\n","print(data0)"],"metadata":{"id":"qJur6H5qbUbu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764151655523,"user_tz":-330,"elapsed":77,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"5d951f2e-f2de-4da8-d3c6-8e39113646e4"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["(146, 180) float32\n","Data(x=[146, 180], edge_index=[2, 21256])\n"]}]},{"cell_type":"code","source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","model = GCN(feats_dim, 512, K, device, \"ELU\").to(device)\n","optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","num_epochs = 5000\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    S, logits = model(data0)\n","    unsup_loss = model.loss(A1, logits)\n","\n","    total_loss = unsup_loss\n","    total_loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch} | Loss: {total_loss:.4f}\")\n"],"metadata":{"id":"J3jQXcTvbbOP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764151696582,"user_tz":-330,"elapsed":38628,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"3a9f03c6-33b4-4a01-989b-381224e0aea7"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Loss: -0.2334\n","Epoch 100 | Loss: -0.4416\n","Epoch 200 | Loss: -0.4543\n","Epoch 300 | Loss: -0.4571\n","Epoch 400 | Loss: -0.4536\n","Epoch 500 | Loss: -0.4267\n","Epoch 600 | Loss: -0.4588\n","Epoch 700 | Loss: -0.4459\n","Epoch 800 | Loss: -0.4226\n","Epoch 900 | Loss: -0.4617\n","Epoch 1000 | Loss: -0.4667\n","Epoch 1100 | Loss: -0.4467\n","Epoch 1200 | Loss: -0.4686\n","Epoch 1300 | Loss: -0.4562\n","Epoch 1400 | Loss: -0.4474\n","Epoch 1500 | Loss: -0.4697\n","Epoch 1600 | Loss: -0.4636\n","Epoch 1700 | Loss: -0.4315\n","Epoch 1800 | Loss: -0.4362\n","Epoch 1900 | Loss: -0.4636\n","Epoch 2000 | Loss: -0.4475\n","Epoch 2100 | Loss: -0.4607\n","Epoch 2200 | Loss: -0.4570\n","Epoch 2300 | Loss: -0.4371\n","Epoch 2400 | Loss: -0.4697\n","Epoch 2500 | Loss: -0.4326\n","Epoch 2600 | Loss: -0.4465\n","Epoch 2700 | Loss: -0.4651\n","Epoch 2800 | Loss: -0.4411\n","Epoch 2900 | Loss: -0.4601\n","Epoch 3000 | Loss: -0.4581\n","Epoch 3100 | Loss: -0.4591\n","Epoch 3200 | Loss: -0.4451\n","Epoch 3300 | Loss: -0.4679\n","Epoch 3400 | Loss: -0.4647\n","Epoch 3500 | Loss: -0.4566\n","Epoch 3600 | Loss: -0.4644\n","Epoch 3700 | Loss: -0.4546\n","Epoch 3800 | Loss: -0.4539\n","Epoch 3900 | Loss: -0.4424\n","Epoch 4000 | Loss: -0.4734\n","Epoch 4100 | Loss: -0.3844\n","Epoch 4200 | Loss: -0.4690\n","Epoch 4300 | Loss: -0.4699\n","Epoch 4400 | Loss: -0.4448\n","Epoch 4500 | Loss: -0.4413\n","Epoch 4600 | Loss: -0.4500\n","Epoch 4700 | Loss: -0.4553\n","Epoch 4800 | Loss: -0.4581\n","Epoch 4900 | Loss: -0.4466\n"]}]},{"cell_type":"code","source":["model.eval()\n","with torch.no_grad():\n","    S, logits = model(data0)\n","    y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","    y_pred_proba = nnFn.softmax(logits, dim=1).cpu().numpy()\n","\n","\n","acc_score = accuracy_score(y, y_pred)\n","acc_score_inverted = accuracy_score(y, 1 - y_pred)\n","\n","if acc_score_inverted > acc_score:\n","    acc_score = acc_score_inverted\n","    y_pred = 1 - y_pred\n","\n","prec_score = precision_score(y, y_pred)\n","rec_score = recall_score(y, y_pred)\n","f1 = f1_score(y, y_pred)\n","log_loss_value = log_loss(y, y_pred_proba)\n","\n","print(\"Accuracy:\", acc_score)\n","print(\"Precision:\", prec_score)\n","print(\"Recall:\", rec_score)\n","print(\"F1:\", f1)\n","print(\"Log Loss:\", log_loss_value)"],"metadata":{"id":"kjJzNRNcbZd2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764151696595,"user_tz":-330,"elapsed":10,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"e47405fc-987c-4ebe-8fc3-ef75dd504acc"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.678082191780822\n","Precision: 0.6976744186046512\n","Recall: 0.9183673469387755\n","F1: 0.7929515418502202\n","Log Loss: 0.9225416084231663\n"]}]},{"cell_type":"code","source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","results = []\n","\n","for run_seed in range(10):\n","    print(\"\\n================ Run\", run_seed, \"================\")\n","\n","    # Set seeds for reproducibility\n","    np.random.seed(run_seed)\n","    torch.manual_seed(run_seed)\n","    random.seed(run_seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(run_seed)\n","\n","    # Shuffle features and labels\n","    perm = np.random.permutation(X.shape[0])\n","    features = X[perm].astype(np.float32)\n","    labels = y[perm]\n","\n","    cut = 0\n","    alpha = 0.5\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    feats_dim = 180\n","    K = 2\n","\n","    W0 = create_adj(features, cut, alpha)\n","    node_feats, edge_index, _ = load_data(W0, features)\n","    data0 = Data(x=node_feats, edge_index=edge_index).to(device)\n","    A1 = torch.from_numpy(W0).float().to(device)\n","\n","    model = GCN(feats_dim, 512, K, device, \"ELU\").to(device)\n","    optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","    scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","    num_epochs = 5000\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","\n","        S, logits = model(data0)\n","        unsup_loss = model.loss(A1, logits)\n","\n","        unsup_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        if epoch % 1000 == 0:\n","            print(f\"Epoch {epoch} | Loss: {unsup_loss:.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        S, logits = model(data0)\n","        y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","        y_pred_proba = nnFn.softmax(logits, dim=1).cpu().numpy()\n","\n","    acc_score = accuracy_score(labels, y_pred)\n","    acc_score_inverted = accuracy_score(labels, 1 - y_pred)\n","\n","    if acc_score_inverted > acc_score:\n","        acc_score = acc_score_inverted\n","        y_pred = 1 - y_pred\n","\n","    prec_score = precision_score(labels, y_pred)\n","    rec_score = recall_score(labels, y_pred)\n","    f1 = f1_score(labels, y_pred)\n","    log_loss_value = log_loss(labels, y_pred_proba)\n","\n","    print(\"Accuracy:\", acc_score, \"Precision:\", prec_score, \"Recall:\", rec_score, \"F1:\", f1)\n","\n","    results.append({\n","        \"seed\": run_seed,\n","        \"accuracy\": acc_score,\n","        \"precision\": prec_score,\n","        \"recall\": rec_score,\n","        \"f1\": f1,\n","        \"log_loss\": log_loss_value\n","    })\n","\n","accs = [r[\"accuracy\"] for r in results]\n","precisions = [r[\"precision\"] for r in results]\n","recalls = [r[\"recall\"] for r in results]\n","f1s = [r[\"f1\"] for r in results]\n","\n","print(\"\\n===== Final Results across 10 runs =====\")\n","print(\"Accuracy: mean=\", np.mean(accs), \"std=\", np.std(accs))\n","print(\"Precision: mean=\", np.mean(precisions), \"std=\", np.std(precisions))\n","print(\"Recall: mean=\", np.mean(recalls), \"std=\", np.std(recalls))\n","print(\"F1: mean=\", np.mean(f1s), \"std=\", np.std(f1s))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-pwzW2ZZQTL","executionInfo":{"status":"ok","timestamp":1764152138404,"user_tz":-330,"elapsed":441807,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"b35a20c3-92fe-45b0-9c16-c1f67df2cf3e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================ Run 0 ================\n","Epoch 0 | Loss: -0.2355\n","Epoch 1000 | Loss: -0.4474\n","Epoch 2000 | Loss: -0.4326\n","Epoch 3000 | Loss: -0.4564\n","Epoch 4000 | Loss: -0.4566\n","Accuracy: 0.6712328767123288 Precision: 0.6953125 Recall: 0.9081632653061225 F1: 0.7876106194690266\n","\n","================ Run 1 ================\n","Epoch 0 | Loss: -0.2346\n","Epoch 1000 | Loss: -0.4626\n","Epoch 2000 | Loss: -0.4550\n","Epoch 3000 | Loss: -0.4619\n","Epoch 4000 | Loss: -0.4366\n","Accuracy: 0.6712328767123288 Precision: 0.7016129032258065 Recall: 0.8877551020408163 F1: 0.7837837837837838\n","\n","================ Run 2 ================\n","Epoch 0 | Loss: -0.2363\n","Epoch 1000 | Loss: -0.4524\n","Epoch 2000 | Loss: -0.4643\n","Epoch 3000 | Loss: -0.4642\n","Epoch 4000 | Loss: -0.4470\n","Accuracy: 0.684931506849315 Precision: 0.7063492063492064 Recall: 0.9081632653061225 F1: 0.7946428571428571\n","\n","================ Run 3 ================\n","Epoch 0 | Loss: -0.2345\n","Epoch 1000 | Loss: -0.4702\n","Epoch 2000 | Loss: -0.4690\n","Epoch 3000 | Loss: -0.4638\n","Epoch 4000 | Loss: -0.4574\n","Accuracy: 0.678082191780822 Precision: 0.6976744186046512 Recall: 0.9183673469387755 F1: 0.7929515418502202\n","\n","================ Run 4 ================\n","Epoch 0 | Loss: -0.2354\n","Epoch 1000 | Loss: -0.4617\n","Epoch 2000 | Loss: -0.4639\n","Epoch 3000 | Loss: -0.4650\n","Epoch 4000 | Loss: -0.4694\n","Accuracy: 0.6438356164383562 Precision: 0.6619718309859155 Recall: 0.9591836734693877 F1: 0.7833333333333333\n","\n","================ Run 5 ================\n","Epoch 0 | Loss: -0.2320\n","Epoch 1000 | Loss: -0.4686\n","Epoch 2000 | Loss: -0.4524\n","Epoch 3000 | Loss: -0.4486\n","Epoch 4000 | Loss: -0.4695\n","Accuracy: 0.678082191780822 Precision: 0.6976744186046512 Recall: 0.9183673469387755 F1: 0.7929515418502202\n","\n","================ Run 6 ================\n","Epoch 0 | Loss: -0.2351\n","Epoch 1000 | Loss: -0.4533\n","Epoch 2000 | Loss: -0.4679\n","Epoch 3000 | Loss: -0.4626\n","Epoch 4000 | Loss: -0.4380\n","Accuracy: 0.6438356164383562 Precision: 0.6619718309859155 Recall: 0.9591836734693877 F1: 0.7833333333333333\n","\n","================ Run 7 ================\n","Epoch 0 | Loss: -0.2364\n","Epoch 1000 | Loss: -0.4754\n","Epoch 2000 | Loss: -0.4462\n","Epoch 3000 | Loss: -0.4623\n","Epoch 4000 | Loss: -0.4647\n","Accuracy: 0.684931506849315 Precision: 0.7063492063492064 Recall: 0.9081632653061225 F1: 0.7946428571428571\n","\n","================ Run 8 ================\n","Epoch 0 | Loss: -0.2325\n","Epoch 1000 | Loss: -0.4777\n","Epoch 2000 | Loss: -0.4169\n","Epoch 3000 | Loss: -0.4292\n","Epoch 4000 | Loss: -0.4602\n","Accuracy: 0.684931506849315 Precision: 0.7063492063492064 Recall: 0.9081632653061225 F1: 0.7946428571428571\n","\n","================ Run 9 ================\n","Epoch 0 | Loss: -0.2347\n","Epoch 1000 | Loss: -0.4613\n","Epoch 2000 | Loss: -0.4574\n","Epoch 3000 | Loss: -0.4447\n","Epoch 4000 | Loss: -0.4430\n","Accuracy: 0.678082191780822 Precision: 0.704 Recall: 0.8979591836734694 F1: 0.7892376681614349\n","\n","===== Final Results across 10 runs =====\n","Accuracy: mean= 0.6719178082191781 std= 0.014833156046375135\n","Precision: mean= 0.6939265521454558 std= 0.016418719874648876\n","Recall: mean= 0.9173469387755102 std= 0.022564637130097924\n","F1: mean= 0.7897130393209923 std= 0.004637764803336824\n"]}]}]}
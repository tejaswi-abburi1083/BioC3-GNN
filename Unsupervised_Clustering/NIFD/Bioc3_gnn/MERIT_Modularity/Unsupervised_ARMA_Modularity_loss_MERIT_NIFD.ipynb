{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1zGlxwGg4iMa_xamU0iNpYMLUaSniKus2","timestamp":1756119500914},{"file_id":"1Mahacib0G1vRdLzwGphqF56BtT95ijlV","timestamp":1749058471371},{"file_id":"16E8IQLzm44N7b3kAaZeiEu-8WumVsP4R","timestamp":1745690568611},{"file_id":"1oxb_9gwPbrwgQZheblJOOX6gdOVM0Fuf","timestamp":1745065170929},{"file_id":"1egsySsyRJlVCc7FmFO04YKowEO-MK3jQ","timestamp":1743783497798},{"file_id":"18zwBHYwMgYxbkHvZYDHKtTM1PkuT7ACk","timestamp":1743779759481},{"file_id":"18xxNJDLcJndTxx-laCpvq_2AdGc4rK2D","timestamp":1743695341564}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"T5aSgvBjOxj8"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCsIte6uO5cI","executionInfo":{"status":"ok","timestamp":1768994802884,"user_tz":-330,"elapsed":879,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"45996335-7ce9-40e3-d94e-edbfce490ef6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.0+cu121\n"]}]},{"cell_type":"code","source":["# !pip install -q torch_geometric\n","# !pip install -q class_resolver\n","# !pip3 install pymatting"],"metadata":{"id":"x8mZcDISO8cx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","from tqdm import tqdm\n","import numpy as np\n","import torch\n","# import util\n","from PIL import Image\n","import cv2\n","import matplotlib.pyplot as plt\n","from numpy import asarray\n","import tifffile as tiff\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","import torch_geometric.nn as pyg_nn\n","from torch_geometric.data import Data\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","from sklearn.manifold import TSNE\n","import random\n","from torch_geometric.nn import ARMAConv\n","import copy"],"metadata":{"id":"I_51Esj6O_Jo","executionInfo":{"status":"ok","timestamp":1769433532697,"user_tz":-330,"elapsed":11,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":130,"outputs":[]},{"cell_type":"code","source":["# === Load Patients ===\n","fa_patients_path = \"/home/snu/Downloads/NIFD_Patients_FA_Histogram_Feature.npy\"\n","Patients_FA_array = np.load(fa_patients_path, allow_pickle=True)\n","\n","# === Load Controls ===\n","fa_controls_path = \"/home/snu/Downloads/NIFD_Control_FA_Histogram_Feature.npy\"\n","Controls_FA_array = np.load(fa_controls_path, allow_pickle=True)\n","\n","print(\"Patients Shape:\", Patients_FA_array.shape)\n","print(\"Controls Shape:\", Controls_FA_array.shape)\n","\n","# === Combine features and labels ===\n","X = np.vstack([Controls_FA_array, Patients_FA_array])\n","y = np.hstack([\n","    np.zeros(Controls_FA_array.shape[0], dtype=np.int64),  # 0 = Control\n","    np.ones(Patients_FA_array.shape[0], dtype=np.int64)    # 1 = Patient\n","])\n","\n","# Shuffle\n","np.random.seed(42)\n","perm = np.random.permutation(X.shape[0])\n","X = X[perm]\n","y = y[perm]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQr5l2viT-h4","executionInfo":{"status":"ok","timestamp":1769433534316,"user_tz":-330,"elapsed":6,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"f4648eb8-c9ab-4798-bfe0-a937739bbe3b"},"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["Patients Shape: (98, 180)\n","Controls Shape: (48, 180)\n"]}]},{"cell_type":"markdown","source":["## 1 layer"],"metadata":{"id":"qGTVC3dfl6gQ"}},{"cell_type":"code","source":["def sim(h1, h2, tau = 0.2):\n","    z1 = nnFn.normalize(h1, dim=-1, p=2)\n","    z2 = nnFn.normalize(h2, dim=-1, p=2)\n","    return torch.mm(z1, z2.t()) / tau\n","\n","def contrastive_loss_wo_cross_network(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    intra_sim = f(sim(h1, h1))\n","    inter_sim = f(sim(h1, h2))\n","    return -torch.log(inter_sim.diag() /\n","                     (intra_sim.sum(dim=-1) + inter_sim.sum(dim=-1) - intra_sim.diag()))\n","\n","def contrastive_loss_wo_cross_view(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    cross_sim = f(sim(h1, z))\n","    return -torch.log(cross_sim.diag() / cross_sim.sum(dim=-1))"],"metadata":{"id":"xr_ZShMtTI0w","executionInfo":{"status":"ok","timestamp":1769433535878,"user_tz":-330,"elapsed":10,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":132,"outputs":[]},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.ELU(), # nn.ELU()\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"9u3KA8lBUaWX","executionInfo":{"status":"ok","timestamp":1769433536652,"user_tz":-330,"elapsed":7,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["class ARMAEncoder(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ=\"ELU\", num_stacks=1, num_layers=3):\n","        super(ARMAEncoder, self).__init__()\n","        self.device = device\n","        # Define all activation functions\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"ELU\": nnFn.elu,\n","            \"RELU\": nnFn.relu\n","        }\n","        # Get the activation function based on the input string\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","        self.arma = ARMAConv(\n","            in_channels=input_dim,\n","            out_channels=hidden_dim,\n","            num_stacks=num_stacks,   # number of parallel stacks\n","            num_layers=num_layers,   # depth per stack\n","            act=self.act,               # nonlinearity inside ARMA\n","            shared_weights=True,     # weight sharing across layers\n","            dropout=0.2             # ARMA-internal dropout\n","        )\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(0.2)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.arma(x, edge_index)\n","        x = self.dropout(x)\n","        x = self.batchnorm(x)\n","        logits = self.mlp(x)\n","        return logits"],"metadata":{"id":"YaY22OlFZkb1","executionInfo":{"status":"ok","timestamp":1769433538529,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":134,"outputs":[]},{"cell_type":"code","source":["class EMA(): # Moving Average update\n","\n","    def __init__(self, beta):\n","        super().__init__()\n","        self.beta = beta\n","\n","    def update_average(self, old, new):\n","        # old: old model parameter\n","        # new: new model parameter\n","        if old is None:\n","            return new\n","        return old * self.beta + (1 - self.beta) * new\n","\n","def update_moving_average(ema_updater, ma_model, current_model):\n","    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n","        old_weight, up_weight = ma_params.data, current_params.data\n","        ma_params.data = ema_updater.update_average(old_weight, up_weight)"],"metadata":{"id":"ykP3A7hbVvGR","executionInfo":{"status":"ok","timestamp":1769433540331,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":135,"outputs":[]},{"cell_type":"code","source":["class ARMA(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ, moving_average_decay=0.5, cut=True):\n","        super(ARMA, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","        self.cut = cut\n","        self.beta = 0.6\n","\n","        self.online_encoder = ARMAEncoder(input_dim, hidden_dim, device, activ)\n","        self.target_encoder = copy.deepcopy(self.online_encoder)\n","\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","        # Predictor head\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_dim)\n","\n","        # Loss selection\n","        self.loss = self.cut_loss if cut else self.modularity_loss\n","        self.target_ema_updater = EMA(moving_average_decay)\n","\n","    def reset_moving_average(self):\n","        del self.target_encoder\n","        self.target_encoder = None\n","\n","    def update_ma(self):\n","        assert self.target_encoder is not None, 'target encoder has not been created yet'\n","        update_moving_average(self.target_ema_updater, self.target_encoder, self.online_encoder)\n","\n","    def forward(self, data1, data2):\n","        x1 = self.online_encoder(data1)\n","        logits1 = self.online_predictor(x1)\n","        S1 = nnFn.softmax(logits1, dim=1)\n","\n","        x2 = self.online_encoder(data2)\n","        logits2 = self.online_predictor(x2)\n","        S2 = nnFn.softmax(logits2, dim=1)\n","\n","        with torch.no_grad():\n","            target_proj_one = self.target_encoder(data1).detach()\n","            target_proj_two = self.target_encoder(data2).detach()\n","\n","        l1 = self.beta * contrastive_loss_wo_cross_network(x1, x2, target_proj_two) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x1, x2, target_proj_two)\n","\n","        l2 = self.beta * contrastive_loss_wo_cross_network(x2, x1, target_proj_one) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x2, x1, target_proj_one)\n","\n","        return S1, S2, logits1, logits2, l1, l2\n","\n","    def modularity_loss(self, A, S):\n","        C = nnFn.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A)\n","        B = A - torch.ger(d, d) / (2 * m)\n","\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        k = torch.tensor(self.num_clusters, dtype=torch.float32, device=self.device)\n","        n = S.shape[0]\n","\n","        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n","\n","        return modularity_term + collapse_reg_term\n","\n","    def cut_loss(self, A, S):\n","        S = nnFn.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / den)\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n","\n","        return mincut_loss + ortho_loss"],"metadata":{"id":"FB6kC-IdmxN4","executionInfo":{"status":"ok","timestamp":1769433541180,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":136,"outputs":[]},{"cell_type":"code","source":["def create_adj(features, cut, alpha=1.0):\n","    \"\"\"Return a dense W0 matrix (only once), as you originally used for A1 / unsup loss.\n","       We still create the dense matrix once, but all augmentations below work with edge_index.\n","    \"\"\"\n","    F_norm = features / np.linalg.norm(features, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = (W * (W >= alpha)).astype(np.float32)\n","    return W"],"metadata":{"id":"JsS6_ScmXAv4","executionInfo":{"status":"ok","timestamp":1769433543677,"user_tz":-330,"elapsed":9,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":137,"outputs":[]},{"cell_type":"code","source":["def edge_index_from_dense(W):\n","    \"\"\"Return edge_index as numpy array shape (2, E) and edge_weight vector.\"\"\"\n","    rows, cols = np.nonzero(W > 0)\n","    edge_index = np.vstack([rows, cols]).astype(np.int64)\n","    edge_weight = W[rows, cols].astype(np.float32)\n","    return edge_index, edge_weight"],"metadata":{"id":"9jH65Y3G5iUe","executionInfo":{"status":"ok","timestamp":1769433544281,"user_tz":-330,"elapsed":13,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":138,"outputs":[]},{"cell_type":"code","source":["def build_adj_list(edge_index_np, num_nodes):\n","    \"\"\"Build adjacency list: list of neighbor arrays for each node (numpy).\"\"\"\n","    adj = [[] for _ in range(num_nodes)]\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    for s, d in zip(src, dst):\n","        adj[s].append(d)\n","    # convert to numpy arrays for speed\n","    adj = [np.array(neis, dtype=np.int64) if len(neis) > 0 else np.array([], dtype=np.int64) for neis in adj]\n","    return adj"],"metadata":{"id":"BdE1jYIp5iXd","executionInfo":{"status":"ok","timestamp":1769433544853,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":139,"outputs":[]},{"cell_type":"code","source":["def aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=None):\n","    \"\"\"Randomly drop edges from edge_index. Returns new edge_index (2 x E') and edge_weight placeholder.\"\"\"\n","    rng = np.random.default_rng(seed)\n","    E = edge_index_np.shape[1]\n","    keep_mask = rng.random(E) >= drop_percent\n","    new_edge_index = edge_index_np[:, keep_mask]\n","    return new_edge_index"],"metadata":{"id":"yabOBb-K5iac","executionInfo":{"status":"ok","timestamp":1769433545963,"user_tz":-330,"elapsed":8,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":140,"outputs":[]},{"cell_type":"code","source":["def aug_subgraph_edge_index(features_np, edge_index_np, adj_list, drop_percent=0.2, seed=None):\n","    \"\"\"\n","    Sample a subgraph by selecting s_node_num nodes via neighbor expansion (BFS-like),\n","    then return (sub_features, sub_edge_index) with node ids remapped to [0..s-1].\n","    \"\"\"\n","    rng = np.random.default_rng(seed)\n","    num_nodes = features_np.shape[0]\n","    s_node_num = int(num_nodes * (1 - drop_percent))\n","    if s_node_num < 1:\n","        s_node_num = 1\n","\n","    # choose a random center node\n","    center_node = int(rng.integers(0, num_nodes))\n","    sub_nodes = [center_node]\n","    front_idx = 0\n","\n","    # BFS-like expansion using adjacency list until we reach s_node_num\n","    while len(sub_nodes) < s_node_num and front_idx < len(sub_nodes):\n","        cur = sub_nodes[front_idx]\n","        neighbors = adj_list[cur]\n","        if neighbors.size > 0:\n","            # shuffle neighbors and try to add new ones\n","            nbrs_shuffled = neighbors.copy()\n","            rng.shuffle(nbrs_shuffled)\n","            for nb in nbrs_shuffled:\n","                if nb not in sub_nodes:\n","                    sub_nodes.append(int(nb))\n","                    if len(sub_nodes) >= s_node_num:\n","                        break\n","        front_idx += 1\n","        # if BFS stalls (no new neighbors), add random nodes\n","        if front_idx >= len(sub_nodes) and len(sub_nodes) < s_node_num:\n","            remaining = [n for n in range(num_nodes) if n not in sub_nodes]\n","            if not remaining:\n","                break\n","            add = int(rng.choice(remaining))\n","            sub_nodes.append(add)\n","\n","    sub_nodes = sorted(set(sub_nodes))\n","    node_map = {old: new for new, old in enumerate(sub_nodes)}\n","\n","    # induce edges that have both ends in sub_nodes\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    mask_src_in = np.isin(src, sub_nodes)\n","    mask_dst_in = np.isin(dst, sub_nodes)\n","    mask = mask_src_in & mask_dst_in\n","    sel_src = src[mask]\n","    sel_dst = dst[mask]\n","    # remap\n","    remapped_src = np.array([node_map[int(s)] for s in sel_src], dtype=np.int64)\n","    remapped_dst = np.array([node_map[int(d)] for d in sel_dst], dtype=np.int64)\n","    new_edge_index = np.vstack([remapped_src, remapped_dst])\n","    # sub features\n","    sub_features = features_np[sub_nodes, :].astype(np.float32)\n","    return sub_features, new_edge_index"],"metadata":{"id":"QVbBbiOP5icz","executionInfo":{"status":"ok","timestamp":1769436015827,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":151,"outputs":[]},{"cell_type":"code","source":["def load_data_from_edge_index(node_feats_np, edge_index_np, device):\n","    \"\"\"Return PyG Data with torch tensors. edge_index_np is (2, E) numpy.\"\"\"\n","    node_feats = torch.from_numpy(node_feats_np).float().to(device)\n","    edge_index = torch.from_numpy(edge_index_np.astype(np.int64)).long().to(device)\n","    return node_feats, edge_index"],"metadata":{"id":"7P0lDiEV5pHE","executionInfo":{"status":"ok","timestamp":1769436017133,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":152,"outputs":[]},{"cell_type":"markdown","source":["# Data Loading and preprocessing"],"metadata":{"id":"MGmFFoeAQ4A_"}},{"cell_type":"code","source":["print(X.shape)\n","print(y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHyh6gF-Q2CH","executionInfo":{"status":"ok","timestamp":1769436018449,"user_tz":-330,"elapsed":13,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"1b32df9c-f8ad-4010-b7c6-ca53bc5361fd"},"execution_count":153,"outputs":[{"output_type":"stream","name":"stdout","text":["(146, 180)\n","(146,)\n"]}]},{"cell_type":"code","source":["features = X\n","#features = np.concatenate((Histogram_feature_CN_FA_array, Histogram_feature_MCI_FA_array), axis=0)\n","features = features.astype(np.float32)\n","print(features.shape, features.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C6ixOkliQ6y2","executionInfo":{"status":"ok","timestamp":1769436019032,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"7ecd12dc-1429-495c-e76b-8f0a7cf97246"},"execution_count":154,"outputs":[{"output_type":"stream","name":"stdout","text":["(146, 180) float32\n"]}]},{"cell_type":"code","source":["# # Required Parameters\n","# cut = 0  # Consider n-cut loss OR Modularity loss\n","# alpha = 0.9 # Edge creation Threshold\n","# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","# feats_dim = 180  # 20-bin\n","# K = 2  # Number of clusters\n","# epoch = [2500, 60, 100]  # Training epochs for different phases\n","\n","# # Define all activation functions to test\n","# define_activations = [\"SELU\", \"SiLU\", \"GELU\", \"ELU\", \"RELU\"]\n","# activ = \"ELU\""],"metadata":{"id":"AKB32JBdIbF4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Required Parameters\n","cut = 0  # Consider n-cut loss OR Modularity loss\n","alpha = 0.5 # Edge creation Threshold\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","feats_dim = 180  # 20-bin\n","K = 2  # Number of clusters\n","epoch = [2500, 60, 100]  # Training epochs for different phases\n","\n","# Define all activation functions to test\n","define_activations = [\"SELU\", \"SiLU\", \"GELU\", \"ELU\", \"RELU\"]\n","activ = \"ReLU\""],"metadata":{"id":"DdEsfaCeRKdm","executionInfo":{"status":"ok","timestamp":1769436024860,"user_tz":-330,"elapsed":44,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":155,"outputs":[]},{"cell_type":"code","source":["print(features.shape)"],"metadata":{"id":"YOS22Jo7spbj","executionInfo":{"status":"ok","timestamp":1769414450609,"user_tz":-330,"elapsed":12,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"92029e25-d780-4648-c8ea-2eec73089bd6","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(146, 180)\n"]}]},{"cell_type":"code","source":["F_norm = features / np.linalg.norm(features, axis=1, keepdims=True)\n","W = np.dot(F_norm, F_norm.T)\n","print(np.array(np.nonzero(W>0.6)).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tORSJ9G5saNu","executionInfo":{"status":"ok","timestamp":1769414451353,"user_tz":-330,"elapsed":20,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"92625eaa-1983-484a-ad12-8ae2a0741439"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 20520)\n"]}]},{"cell_type":"code","source":["F_norm = features / np.linalg.norm(features, axis=1, keepdims=True)\n","W = np.dot(F_norm, F_norm.T)\n","print(W)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CTwFu2gkYqt3","executionInfo":{"status":"ok","timestamp":1769414452614,"user_tz":-330,"elapsed":15,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"d2838873-765a-4a6e-96c4-c4af0ef80201"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.99999994 0.8497284  0.90970075 ... 0.8536243  0.85516846 0.87134004]\n"," [0.8497284  0.9999999  0.89257383 ... 0.8011868  0.8645267  0.86090064]\n"," [0.90970075 0.89257383 1.0000001  ... 0.8730685  0.8966978  0.92472154]\n"," ...\n"," [0.8536243  0.8011868  0.8730685  ... 1.0000001  0.8663177  0.903542  ]\n"," [0.85516846 0.8645267  0.8966978  ... 0.8663177  1.         0.9069954 ]\n"," [0.87134004 0.86090064 0.92472154 ... 0.903542   0.9069954  1.0000004 ]]\n"]}]},{"cell_type":"code","source":["W0 = create_adj(features, cut, alpha)  # shape (N, N) dense\n","A1 = torch.from_numpy(W0).float().to(device)\n","\n","edge_index_np, edge_weight_np = edge_index_from_dense(W0)  # numpy edge_index (2, E)\n","num_nodes = features.shape[0]\n","adj_list = build_adj_list(edge_index_np, num_nodes)  # adjacency list for fast subgraph sampling\n","\n","# convert features to numpy (we'll slice them in augmentations)\n","features_np = features.copy()\n","\n","# Build initial Data object (full graph)\n","node_feats_full, edge_index_full = load_data_from_edge_index(features_np, edge_index_np, device)\n","data0 = Data(x=node_feats_full, edge_index=edge_index_full).to(device) # Modified to move the entire Data object to device\n","print(\"Data0:\", data0)"],"metadata":{"id":"Ya4xuSn3i1BH","executionInfo":{"status":"ok","timestamp":1769436026635,"user_tz":-330,"elapsed":30,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8911caa9-065b-48ac-cada-05bf5b69a8f9"},"execution_count":156,"outputs":[{"output_type":"stream","name":"stdout","text":["Data0: Data(x=[146, 180], edge_index=[2, 21256])\n"]}]},{"cell_type":"markdown","source":["# Model initialization"],"metadata":{"id":"PuJLS4CgR8-u"}},{"cell_type":"markdown","source":["## Contrastive Loss"],"metadata":{"id":"QZov9rTSOzyV"}},{"cell_type":"code","source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","import torch.nn as nn\n","\n","model = ARMA(feats_dim, 512, K, device, activ, cut=cut).to(device)\n","optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)\n","scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","criterion = nn.CrossEntropyLoss()\n","\n","num_epochs = 5000\n","lambda_contrastive = 5\n","np.random.seed(42)\n","random.seed(42)\n","torch.manual_seed(42)\n","for epoch in range(num_epochs):\n","    # --- Augmentations using edge_index or adjacency list (fast, sparse) ---\n","    # 1) Random edge drop on edge_index\n","    W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","\n","    # 2) Subgraph via adjacency list (returns sub_features and sub_edge_index)\n","    W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","    features_aug2 = features_np.copy()\n","\n","    # 3) Feature augmentations (keep these as numpy operations)\n","    # Feature dropout (column-wise)\n","    rng = np.random.default_rng(epoch)\n","    mask = rng.random(features_np.shape) >= 0.2\n","    features_aug1 = (features_np * mask.astype(np.float32))\n","\n","    # Feature cell dropout (random cell zeroing)\n","    aug_feat2 = features_np.copy()\n","    num_nodes_local, feat_dim = aug_feat2.shape\n","    drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","    # random positions to zero\n","    flat_idx = rng.choice(num_nodes_local * feat_dim, size=drop_feat_num, replace=False)\n","    rows = (flat_idx // feat_dim)\n","    cols = (flat_idx % feat_dim)\n","    aug_feat2[rows, cols] = 0.0\n","    features_aug2_feat = aug_feat2.astype(np.float32)\n","\n","    # --- Build PyG Data objects for the two views ---\n","    # view1: features_aug1 with W_aug1_edge_index\n","    node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","    data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","\n","    # view2: features_aug2 (from subgraph) and its edge_index\n","    node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, W_aug2_edge_index, device)\n","    data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","    # --- Training step ---\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","    unsup_loss = model.loss(A1, logits1)\n","    cont_loss = ((l1 + l2) / 2).mean()\n","    total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","    total_loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","    model.update_ma()\n","\n","    if epoch % 500 == 0:\n","        print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} | Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XW57ZES1L1UW","executionInfo":{"status":"ok","timestamp":1768994959009,"user_tz":-330,"elapsed":153868,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"a54c418f-d667-4956-df42-da28ff3e6fa2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Total: 23.1427 | Unsup: -0.1245 | Cont: 4.6534\n","Epoch 500 | Total: 15.3088 | Unsup: -0.1255 | Cont: 3.0869\n","Epoch 1000 | Total: 14.8127 | Unsup: -0.1254 | Cont: 2.9876\n","Epoch 1500 | Total: 14.8691 | Unsup: -0.1256 | Cont: 2.9989\n","Epoch 2000 | Total: 14.7174 | Unsup: -0.1256 | Cont: 2.9686\n","Epoch 2500 | Total: 14.6271 | Unsup: -0.1255 | Cont: 2.9505\n","Epoch 3000 | Total: 14.7193 | Unsup: -0.1256 | Cont: 2.9690\n","Epoch 3500 | Total: 14.9747 | Unsup: -0.1254 | Cont: 3.0200\n","Epoch 4000 | Total: 14.9320 | Unsup: -0.1255 | Cont: 3.0115\n","Epoch 4500 | Total: 14.6499 | Unsup: -0.1246 | Cont: 2.9549\n"]}]},{"cell_type":"code","source":["model.eval()\n","with torch.no_grad():\n","        S1, _, logits1,_,_,_ = model(data0, data0)\n","        y_pred = torch.argmax(logits1, dim=1).cpu().numpy()\n","        y_pred_proba = nnFn.softmax(logits1, dim=1).cpu().numpy()\n","        print(y_pred)\n","        print(y_pred_proba.max(axis=-1))"],"metadata":{"id":"6ty1p11xXxaM","executionInfo":{"status":"ok","timestamp":1768994959015,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5fdbbaf7-4657-433e-fd52-c0e1a3a7889e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 0\n"," 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0\n"," 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1\n"," 0 1 1 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1]\n","[0.79750353 0.80936307 0.6255742  0.86420965 0.95961064 0.53711087\n"," 0.672389   0.99692696 0.9836182  0.70995593 0.68219125 0.74776655\n"," 0.8474082  0.9970264  0.8885844  0.76887125 0.968958   0.674992\n"," 0.99913776 0.9991248  0.94821376 0.96652436 0.9844753  0.76632285\n"," 0.7327698  0.7379519  0.99964976 0.95043534 0.8616088  0.9460018\n"," 0.9942062  0.92018986 0.9837658  0.79500943 0.99641716 0.9557953\n"," 0.93378633 0.9879429  0.99693775 0.9954704  0.8796477  0.95274174\n"," 0.70073175 0.99708575 0.9785938  0.7900141  0.99451125 0.9486738\n"," 0.5305002  0.95891756 0.99583876 0.9985197  0.69888717 0.97796226\n"," 0.8866171  0.64600986 0.799302   0.9443127  0.9964051  0.99840254\n"," 0.78518075 0.9778307  0.85135984 0.7473455  0.6942498  0.97433245\n"," 0.92194986 0.73653996 0.9798922  0.6342469  0.9955812  0.9791084\n"," 0.96633285 0.9462558  0.9173644  0.5406941  0.96878237 0.9855053\n"," 0.82302386 0.9998307  0.6018462  0.9609862  0.9335793  0.5971918\n"," 0.9654587  0.9536088  0.94804025 0.7709644  0.7733179  0.58813953\n"," 0.9775788  0.994288   0.97089404 0.85080916 0.9169484  0.73665595\n"," 0.7507923  0.6275265  0.9813167  0.9094196  0.66735697 0.91624165\n"," 0.9865348  0.9773562  0.7358912  0.6542287  0.7211576  0.69052786\n"," 0.7920656  0.9691188  0.7889088  0.97220075 0.91343045 0.9520226\n"," 0.9881911  0.952602   0.83950126 0.9807131  0.92676604 0.9041052\n"," 0.7540362  0.98569137 0.9066464  0.87133    0.9431946  0.6287137\n"," 0.7013089  0.81206125 0.8676576  0.6259048  0.542056   0.9729346\n"," 0.8841581  0.9966286  0.690964   0.85376704 0.64356416 0.994414\n"," 0.9811054  0.5765136  0.9776058  0.66821736 0.78192383 0.959947\n"," 0.52345705 0.8166019 ]\n"]}]},{"cell_type":"code","source":["acc_score = accuracy_score(y, y_pred)\n","acc_score_inverted = accuracy_score(y, 1 - y_pred)\n","\n","print(\"Accuracy Score:\", acc_score)\n","print(\"Accuracy Score Inverted:\", acc_score_inverted)\n","\n","if acc_score_inverted > acc_score:\n","    acc_score = acc_score_inverted\n","    y_pred = 1 - y_pred\n","\n","prec_score = precision_score(y, y_pred)\n","rec_score = recall_score(y, y_pred)\n","f1 = f1_score(y, y_pred)\n","log_loss_value = log_loss(y, y_pred_proba)\n","\n","print(\"Precision Score:\", prec_score)\n","print(\"Recall Score:\", rec_score)\n","print(\"F1 Score:\", f1)\n","print(\"Log Loss:\", log_loss_value)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WoiV1peZa1kb","executionInfo":{"status":"ok","timestamp":1768994959020,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"d0cdb989-1295-49e9-ff9a-746738cd52e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Score: 0.2876712328767123\n","Accuracy Score Inverted: 0.7123287671232876\n","Precision Score: 0.8888888888888888\n","Recall Score: 0.6530612244897959\n","F1 Score: 0.7529411764705882\n","Log Loss: 2.2595413369054995\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import random\n","import torch\n","import torch.nn as nn\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import StepLR\n","from sklearn.metrics import (\n","    accuracy_score, precision_score,\n","    recall_score, f1_score, log_loss\n",")\n","\n","NUM_RUNS = 10\n","num_epochs = 5000\n","lambda_contrastive = 5\n","\n","acc_list, prec_list, rec_list, f1_list, logloss_list = [], [], [], [], []\n","\n","for run in range(NUM_RUNS):\n","    print(f\"\\n===== Run {run + 1}/{NUM_RUNS} =====\")\n","\n","    # --------------------\n","    # Set seeds per run\n","    # --------------------\n","    seed = 42 + run\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","\n","    # --------------------\n","    # Model / optimizer\n","    # --------------------\n","    model = ARMA(feats_dim, 512, K, device, activ, cut=cut).to(device)\n","    optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","    scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    # --------------------\n","    # Training loop\n","    # --------------------\n","    for epoch in range(num_epochs):\n","        # --- Edge augmentations ---\n","        W_aug1_edge_index = aug_random_edge_edge_index(\n","            edge_index_np, drop_percent=0.2, seed=epoch\n","        )\n","        W_aug2_edge_index = aug_random_edge_edge_index(\n","            edge_index_np, drop_percent=0.2, seed=epoch + 999\n","        )\n","\n","        # --- Feature augmentations ---\n","        rng = np.random.default_rng(epoch)\n","\n","        mask = rng.random(features_np.shape) >= 0.2\n","        features_aug1 = features_np * mask.astype(np.float32)\n","\n","        aug_feat2 = features_np.copy()\n","        num_nodes_local, feat_dim = aug_feat2.shape\n","        drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","        flat_idx = rng.choice(num_nodes_local * feat_dim, size=drop_feat_num, replace=False)\n","        rows = flat_idx // feat_dim\n","        cols = flat_idx % feat_dim\n","        aug_feat2[rows, cols] = 0.0\n","        features_aug2 = aug_feat2.astype(np.float32)\n","\n","        # --- PyG data ---\n","        node_feats1, edge_index1 = load_data_from_edge_index(\n","            features_aug1, W_aug1_edge_index, device\n","        )\n","        node_feats2, edge_index2 = load_data_from_edge_index(\n","            features_aug2, W_aug2_edge_index, device\n","        )\n","\n","        data1 = Data(x=node_feats1, edge_index=edge_index1)\n","        data2 = Data(x=node_feats2, edge_index=edge_index2)\n","\n","        # --- Optimization ---\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","        unsup_loss = model.loss(A1, logits1)\n","        cont_loss = ((l1 + l2) / 2).mean()\n","        total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","        total_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        model.update_ma()\n","\n","    # --------------------\n","    # Evaluation\n","    # --------------------\n","    model.eval()\n","    with torch.no_grad():\n","        _, _, logits, _, _, _ = model(data0, data0)\n","\n","        y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","        y_pred_proba = nnFn.softmax(logits, dim=1).cpu().numpy()\n","\n","    acc = accuracy_score(y, y_pred)\n","    acc_inv = accuracy_score(y, 1 - y_pred)\n","\n","    if acc_inv > acc:\n","        y_pred = 1 - y_pred\n","        acc = acc_inv\n","\n","    prec = precision_score(y, y_pred)\n","    rec = recall_score(y, y_pred)\n","    f1 = f1_score(y, y_pred)\n","    ll = log_loss(y, y_pred_proba)\n","\n","    acc_list.append(acc)\n","    prec_list.append(prec)\n","    rec_list.append(rec)\n","    f1_list.append(f1)\n","    logloss_list.append(ll)\n","\n","# --------------------\n","# Final statistics\n","# --------------------\n","def mean_std(x):\n","    return np.mean(x), np.std(x)\n","\n","print(\"\\n===== Final Results (Mean ± Std over 10 runs) =====\")\n","print(f\"Accuracy : {mean_std(acc_list)[0]:.4f} ± {mean_std(acc_list)[1]:.4f}\")\n","print(f\"Precision: {mean_std(prec_list)[0]:.4f} ± {mean_std(prec_list)[1]:.4f}\")\n","print(f\"Recall   : {mean_std(rec_list)[0]:.4f} ± {mean_std(rec_list)[1]:.4f}\")\n","print(f\"F1 Score : {mean_std(f1_list)[0]:.4f} ± {mean_std(f1_list)[1]:.4f}\")\n","print(f\"Log Loss : {mean_std(logloss_list)[0]:.4f} ± {mean_std(logloss_list)[1]:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mAY8hjCyJ-8v","executionInfo":{"status":"ok","timestamp":1769437572187,"user_tz":-330,"elapsed":1541838,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"6b2eee3e-aee0-4223-d3f4-88b5bf68b5b6"},"execution_count":157,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== Run 1/10 =====\n","\n","===== Run 2/10 =====\n","\n","===== Run 3/10 =====\n","\n","===== Run 4/10 =====\n","\n","===== Run 5/10 =====\n","\n","===== Run 6/10 =====\n","\n","===== Run 7/10 =====\n","\n","===== Run 8/10 =====\n","\n","===== Run 9/10 =====\n","\n","===== Run 10/10 =====\n","\n","===== Final Results (Mean ± Std over 10 runs) =====\n","Accuracy : 0.7014 ± 0.0070\n","Precision: 0.8865 ± 0.0088\n","Recall   : 0.6367 ± 0.0114\n","F1 Score : 0.7410 ± 0.0074\n","Log Loss : 1.5207 ± 0.7498\n"]}]},{"cell_type":"markdown","source":[" activ = SELU,\n"," ===== Final Results (Mean ± Std over 10 runs) =====\n","Accuracy : 0.6952 ± 0.0134\n","Precision: 0.8823 ± 0.0238\n","Recall   : 0.6306 ± 0.0110\n","F1 Score : 0.7353 ± 0.0099 \\\n","activ = ReLU\n","===== Final Results (Mean ± Std over 10 runs) =====\n","Accuracy : 0.7014 ± 0.0070\n","Precision: 0.8865 ± 0.0088\n","Recall   : 0.6367 ± 0.0114\n","F1 Score : 0.7410 ± 0.0074\n","\n"],"metadata":{"id":"rOom10TPmqln"}},{"cell_type":"code","source":["import numpy as np\n","import random\n","import torch\n","import torch.nn as nn\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import StepLR\n","from sklearn.metrics import (\n","    accuracy_score, precision_score,\n","    recall_score, f1_score, log_loss\n",")\n","\n","# --------------------\n","# Experiment settings\n","# --------------------\n","NUM_RUNS = 10\n","num_epochs = 5000\n","lambda_list = [0.001, 0.01, 0.09, 0.3, 2, 5]\n","\n","# --------------------\n","# Helper\n","# --------------------\n","def mean_std(x):\n","    return np.mean(x), np.std(x)\n","\n","# ====================\n","# Lambda loop\n","# ====================\n","for lambda_contrastive in lambda_list:\n","\n","    print(f\"\\n\\n==============================\")\n","    print(f\" Lambda = {lambda_contrastive}\")\n","    print(f\"==============================\")\n","\n","    acc_list, prec_list, rec_list, f1_list, logloss_list = [], [], [], [], []\n","\n","    # ====================\n","    # Runs loop\n","    # ====================\n","    for run in range(NUM_RUNS):\n","        print(f\"\\n===== Run {run + 1}/{NUM_RUNS} =====\")\n","\n","        # --------------------\n","        # Set seeds per run\n","        # --------------------\n","        seed = 42 + run\n","        np.random.seed(seed)\n","        random.seed(seed)\n","        torch.manual_seed(seed)\n","\n","        # --------------------\n","        # Model / optimizer\n","        # --------------------\n","        model = ARMA(feats_dim, 512, K, device, activ, cut=cut).to(device)\n","        optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","        scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","        criterion = nn.CrossEntropyLoss()\n","\n","        # --------------------\n","        # Training loop\n","        # --------------------\n","        for epoch in range(num_epochs):\n","\n","            # --- Edge augmentations ---\n","            W_aug1_edge_index = aug_random_edge_edge_index(\n","                edge_index_np, drop_percent=0.2, seed=epoch\n","            )\n","            W_aug2_edge_index = aug_random_edge_edge_index(\n","                edge_index_np, drop_percent=0.2, seed=epoch + 999\n","            )\n","\n","            # --- Feature augmentations ---\n","            rng = np.random.default_rng(epoch)\n","\n","            mask = rng.random(features_np.shape) >= 0.2\n","            features_aug1 = features_np * mask.astype(np.float32)\n","\n","            aug_feat2 = features_np.copy()\n","            num_nodes_local, feat_dim = aug_feat2.shape\n","            drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","\n","            flat_idx = rng.choice(\n","                num_nodes_local * feat_dim,\n","                size=drop_feat_num,\n","                replace=False\n","            )\n","            rows = flat_idx // feat_dim\n","            cols = flat_idx % feat_dim\n","            aug_feat2[rows, cols] = 0.0\n","            features_aug2 = aug_feat2.astype(np.float32)\n","\n","            # --- PyG data ---\n","            node_feats1, edge_index1 = load_data_from_edge_index(\n","                features_aug1, W_aug1_edge_index, device\n","            )\n","            node_feats2, edge_index2 = load_data_from_edge_index(\n","                features_aug2, W_aug2_edge_index, device\n","            )\n","\n","            data1 = Data(x=node_feats1, edge_index=edge_index1)\n","            data2 = Data(x=node_feats2, edge_index=edge_index2)\n","\n","            # --- Optimization ---\n","            model.train()\n","            optimizer.zero_grad()\n","\n","            S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","            unsup_loss = model.loss(A1, logits1)\n","            cont_loss = ((l1 + l2) / 2).mean()\n","\n","            total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","            total_loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","            model.update_ma()\n","\n","        # --------------------\n","        # Evaluation\n","        # --------------------\n","        model.eval()\n","        with torch.no_grad():\n","            _, _, logits, _, _, _ = model(data0, data0)\n","\n","            y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","            y_pred_proba = nnFn.softmax(logits, dim=1).cpu().numpy()\n","\n","        acc = accuracy_score(y, y_pred)\n","        acc_inv = accuracy_score(y, 1 - y_pred)\n","\n","        if acc_inv > acc:\n","            y_pred = 1 - y_pred\n","            acc = acc_inv\n","\n","        prec = precision_score(y, y_pred)\n","        rec = recall_score(y, y_pred)\n","        f1 = f1_score(y, y_pred)\n","        ll = log_loss(y, y_pred_proba)\n","\n","        acc_list.append(acc)\n","        prec_list.append(prec)\n","        rec_list.append(rec)\n","        f1_list.append(f1)\n","        logloss_list.append(ll)\n","\n","    # ====================\n","    # Final statistics per lambda\n","    # ====================\n","    print(\"\\n===== Final Results =====\")\n","    print(f\"Lambda     : {lambda_contrastive}\")\n","    print(f\"Accuracy   : {mean_std(acc_list)[0]:.4f} ± {mean_std(acc_list)[1]:.4f}\")\n","    print(f\"Precision  : {mean_std(prec_list)[0]:.4f} ± {mean_std(prec_list)[1]:.4f}\")\n","    print(f\"Recall     : {mean_std(rec_list)[0]:.4f} ± {mean_std(rec_list)[1]:.4f}\")\n","    print(f\"F1 Score   : {mean_std(f1_list)[0]:.4f} ± {mean_std(f1_list)[1]:.4f}\")\n","    print(f\"Log Loss   : {mean_std(logloss_list)[0]:.4f} ± {mean_std(logloss_list)[1]:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kb7GfhAwWUXf","executionInfo":{"status":"ok","timestamp":1769427148409,"user_tz":-330,"elapsed":10773968,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"e1a99a7d-c2a7-4b19-8f75-4a9b3d4bf318"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","==============================\n"," Lambda = 0.001\n","==============================\n","\n","===== Run 1/10 =====\n","\n","===== Run 2/10 =====\n","\n","===== Run 3/10 =====\n","\n","===== Run 4/10 =====\n","\n","===== Run 5/10 =====\n","\n","===== Run 6/10 =====\n","\n","===== Run 7/10 =====\n","\n","===== Run 8/10 =====\n","\n","===== Run 9/10 =====\n","\n","===== Run 10/10 =====\n","\n","===== Final Results =====\n","Lambda     : 0.001\n","Accuracy   : 0.7000 ± 0.0181\n","Precision  : 0.8944 ± 0.0240\n","Recall     : 0.6276 ± 0.0153\n","F1 Score   : 0.7374 ± 0.0154\n","Log Loss   : 1.4168 ± 0.6406\n","\n","\n","==============================\n"," Lambda = 0.01\n","==============================\n","\n","===== Run 1/10 =====\n","\n","===== Run 2/10 =====\n","\n","===== Run 3/10 =====\n","\n","===== Run 4/10 =====\n","\n","===== Run 5/10 =====\n","\n","===== Run 6/10 =====\n","\n","===== Run 7/10 =====\n","\n","===== Run 8/10 =====\n","\n","===== Run 9/10 =====\n","\n","===== Run 10/10 =====\n","\n","===== Final Results =====\n","Lambda     : 0.01\n","Accuracy   : 0.7021 ± 0.0134\n","Precision  : 0.8866 ± 0.0139\n","Recall     : 0.6378 ± 0.0123\n","F1 Score   : 0.7418 ± 0.0121\n","Log Loss   : 1.3301 ± 0.7023\n","\n","\n","==============================\n"," Lambda = 0.09\n","==============================\n","\n","===== Run 1/10 =====\n","\n","===== Run 2/10 =====\n","\n","===== Run 3/10 =====\n","\n","===== Run 4/10 =====\n","\n","===== Run 5/10 =====\n","\n","===== Run 6/10 =====\n","\n","===== Run 7/10 =====\n","\n","===== Run 8/10 =====\n","\n","===== Run 9/10 =====\n","\n","===== Run 10/10 =====\n","\n","===== Final Results =====\n","Lambda     : 0.09\n","Accuracy   : 0.7000 ± 0.0080\n","Precision  : 0.8839 ± 0.0077\n","Recall     : 0.6367 ± 0.0094\n","F1 Score   : 0.7402 ± 0.0077\n","Log Loss   : 1.5202 ± 0.7506\n","\n","\n","==============================\n"," Lambda = 0.3\n","==============================\n","\n","===== Run 1/10 =====\n","\n","===== Run 2/10 =====\n","\n","===== Run 3/10 =====\n","\n","===== Run 4/10 =====\n","\n","===== Run 5/10 =====\n","\n","===== Run 6/10 =====\n","\n","===== Run 7/10 =====\n","\n","===== Run 8/10 =====\n","\n","===== Run 9/10 =====\n","\n","===== Run 10/10 =====\n","\n","===== Final Results =====\n","Lambda     : 0.3\n","Accuracy   : 0.7027 ± 0.0063\n","Precision  : 0.8868 ± 0.0088\n","Recall     : 0.6388 ± 0.0104\n","F1 Score   : 0.7425 ± 0.0066\n","Log Loss   : 1.5206 ± 0.7500\n","\n","\n","==============================\n"," Lambda = 2\n","==============================\n","\n","===== Run 1/10 =====\n","\n","===== Run 2/10 =====\n","\n","===== Run 3/10 =====\n","\n","===== Run 4/10 =====\n","\n","===== Run 5/10 =====\n","\n","===== Run 6/10 =====\n","\n","===== Run 7/10 =====\n","\n","===== Run 8/10 =====\n","\n","===== Run 9/10 =====\n","\n","===== Run 10/10 =====\n","\n","===== Final Results =====\n","Lambda     : 2\n","Accuracy   : 0.7007 ± 0.0075\n","Precision  : 0.8863 ± 0.0093\n","Recall     : 0.6357 ± 0.0103\n","F1 Score   : 0.7403 ± 0.0074\n","Log Loss   : 1.5207 ± 0.7498\n","\n","\n","==============================\n"," Lambda = 5\n","==============================\n","\n","===== Run 1/10 =====\n","\n","===== Run 2/10 =====\n","\n","===== Run 3/10 =====\n","\n","===== Run 4/10 =====\n","\n","===== Run 5/10 =====\n","\n","===== Run 6/10 =====\n","\n","===== Run 7/10 =====\n","\n","===== Run 8/10 =====\n","\n","===== Run 9/10 =====\n","\n","===== Run 10/10 =====\n","\n","===== Final Results =====\n","Lambda     : 5\n","Accuracy   : 0.7014 ± 0.0070\n","Precision  : 0.8865 ± 0.0088\n","Recall     : 0.6367 ± 0.0114\n","F1 Score   : 0.7410 ± 0.0074\n","Log Loss   : 1.5207 ± 0.7498\n"]}]},{"cell_type":"markdown","source":["Alpha = 0.2,\n","Accuracy : 0.6068 ± 0.0694\n","Precision: 0.7713 ± 0.0621\n","Recall   : 0.5867 ± 0.0616\n","F1 Score : 0.6664 ± 0.0628 \\\n","Alpha = 0.6,\n","Accuracy : 0.5726 ± 0.0119\n","Precision: 0.7631 ± 0.0200\n","Recall   : 0.5276 ± 0.0112\n","F1 Score : 0.6236 ± 0.0092 \\\n","alpha = 0.55\n","Accuracy : 0.6562 ± 0.0067\n","Precision: 0.8505 ± 0.0060\n","Recall   : 0.5918 ± 0.0129\n","F1 Score : 0.6979 ± 0.0085 \\\n","alpha = 0.8\n","Accuracy : 0.5205 ± 0.0390\n","Precision: 0.6879 ± 0.0461\n","Recall   : 0.5255 ± 0.0215\n","F1 Score : 0.5956 ± 0.0298 \\\n","alpha = 0.9\n","Accuracy : 0.5096 ± 0.0045\n","Precision: 0.6812 ± 0.0091\n","Recall   : 0.5071 ± 0.0158\n","F1 Score : 0.5812 ± 0.0081"],"metadata":{"id":"ykQ0clhZP73N"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","from torch_geometric.data import Data\n","import random\n","import scipy.sparse as sp\n","from copy import deepcopy\n","from typing import Dict, List\n","\n","# -------------------- Hyperparameters --------------------\n","num_runs = 10\n","num_epochs = 5000\n","lr = 1e-4\n","weight_decay = 1e-4\n","lambda_list = [0.001, 0.01, 0.09, 0.3, 2, 5]\n","# lambda_list =[5]\n","base_seed = 42\n","eval_every_epochs = 500  # set to None to evaluate only at end of each run\n","activ = 'ELU'\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","all_results: List[Dict] = []\n","\n","# -------------------- Loop over different lambda values --------------------\n","for lam in lambda_list:\n","    print(f\"\\n================ LAMBDA = {lam} ================\\n\")\n","\n","    # store per-lambda per-run metrics\n","    acc_scores: List[float] = []\n","    prec_scores: List[float] = []\n","    rec_scores: List[float] = []\n","    f1_scores: List[float] = []\n","    log_losses: List[float] = []\n","\n","    for run in range(num_runs):\n","        # -------------------- Reproducibility --------------------\n","        seed = base_seed + run\n","        torch.manual_seed(seed)\n","        np.random.seed(seed)\n","        random.seed(seed)\n","        if torch.cuda.is_available():\n","            torch.cuda.manual_seed_all(seed)\n","\n","        print(f\"\\n--- Run {run+1}/{num_runs} (seed={seed}) ---\")\n","\n","\n","        model = ARMA(feats_dim, 512, K, device, activ, cut).to(device)\n","\n","        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","        scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","        lambda_contrastive = lam  # use current lambda\n","\n","        # optional periodic evaluation accumulation (if you prefer)\n","        per_run_accs: List[float] = []\n","        per_run_precs: List[float] = []\n","        per_run_recs: List[float] = []\n","        per_run_f1s: List[float] = []\n","        per_run_log_losses: List[float] = []\n","\n","        # -------------------- Training loop --------------------\n","        for epoch in range(num_epochs):\n","            model.train()\n","            optimizer.zero_grad()\n","\n","            W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","\n","            # 2) Another edge drop (or subgraph)\n","            W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","\n","            # 3) Feature augmentations (numpy ops)\n","            rng = np.random.default_rng(seed + epoch)\n","            mask = rng.random(features_np.shape) >= 0.2\n","            features_aug1 = (features_np * mask.astype(np.float32))\n","\n","            # Feature cell dropout (random cell zeroing)\n","            aug_feat2 = features_np.copy()\n","            num_nodes_local, feat_dim = aug_feat2.shape\n","            drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","            if drop_feat_num > 0:\n","                flat_idx = rng.choice(num_nodes_local * feat_dim, size=drop_feat_num, replace=False)\n","                rows = (flat_idx // feat_dim)\n","                cols = (flat_idx % feat_dim)\n","                aug_feat2[rows, cols] = 0.0\n","            features_aug2 = aug_feat2.astype(np.float32)\n","\n","            # --------------------\n","            # Build PyG Data objects for the two views\n","            # --------------------\n","            node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","            data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","\n","            node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, W_aug2_edge_index, device)\n","            data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","            # --------------------\n","            # Forward pass and losses\n","            # --------------------\n","            # Expected model output: S1, S2, logits1, logits2, l1, l2\n","            S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","            # TODO: adapt model.loss call to your implementation.\n","            # The original code used `unsup_loss = model.loss(A1, logits1)`.\n","            # If your loss expects adjacency or labels, provide A1 or appropriate input.\n","            unsup_loss = model.loss(A1, logits1)  # <-- ensure A1 is defined appropriately\n","\n","            cont_loss = 0.5 * (l1 + l2).mean()\n","            total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","            total_loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            # Optional: if your model uses EMA updates\n","            if hasattr(model, \"update_ma\"):\n","                model.update_ma()\n","\n","            # Periodic console logging\n","            if (eval_every_epochs is not None and epoch % eval_every_epochs == 0) or (epoch == num_epochs - 1):\n","                print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} | Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")\n","\n","                # -------------------- Periodic evaluation (optional) --------------------\n","                # Evaluate on data0 (full graph) if available\n","                if 'data0' in globals():\n","                    model.eval()\n","                    with torch.no_grad():\n","                        # Using data0 twice (as in your original script)\n","                        S1_eval, _, logits_eval, _, _, _ = model(data0, data0)\n","                        y_pred = torch.argmax(logits_eval, dim=1).cpu().numpy()\n","                        y_pred_proba = nnFn.softmax(logits_eval, dim=1).cpu().numpy()\n","\n","                        # If labels 'y' are torch tensor, convert to numpy\n","                        y_true = y.cpu().numpy() if isinstance(y, torch.Tensor) else y\n","\n","                        # check inverted labeling (keeps same behavior you had)\n","                        acc_score = accuracy_score(y_true, y_pred)\n","                        acc_score_inverted = accuracy_score(y_true, 1 - y_pred)\n","                        if acc_score_inverted > acc_score:\n","                            acc_score = acc_score_inverted\n","                            y_pred = 1 - y_pred\n","\n","                        prec_score = precision_score(y_true, y_pred, zero_division=0)\n","                        rec_score = recall_score(y_true, y_pred, zero_division=0)\n","                        f1 = f1_score(y_true, y_pred, zero_division=0)\n","                        try:\n","                            log_loss_value = log_loss(y_true, y_pred_proba)\n","                        except ValueError:\n","                            # fallback if probabilities are degenerate\n","                            log_loss_value = float(\"nan\")\n","\n","                        per_run_accs.append(acc_score)\n","                        per_run_precs.append(prec_score)\n","                        per_run_recs.append(rec_score)\n","                        per_run_f1s.append(f1)\n","                        per_run_log_losses.append(log_loss_value)\n","\n","        # -------------------- End of epochs for this run --------------------\n","        # Final evaluation at end of run if no periodic eval was run\n","        if len(per_run_accs) == 0 and 'data0' in globals():\n","            model.eval()\n","            with torch.no_grad():\n","                S1_eval, _, logits_eval, _, _, _ = model(data0, data0)\n","                y_pred = torch.argmax(logits_eval, dim=1).cpu().numpy()\n","                y_pred_proba = nnFn.softmax(logits_eval, dim=1).cpu().numpy()\n","                y_true = y.cpu().numpy() if isinstance(y, torch.Tensor) else y\n","\n","                acc_score = accuracy_score(y_true, y_pred)\n","                acc_score_inverted = accuracy_score(y_true, 1 - y_pred)\n","                if acc_score_inverted > acc_score:\n","                    acc_score = acc_score_inverted\n","                    y_pred = 1 - y_pred\n","\n","                prec_score = precision_score(y_true, y_pred, zero_division=0)\n","                rec_score = recall_score(y_true, y_pred, zero_division=0)\n","                f1 = f1_score(y_true, y_pred, zero_division=0)\n","                try:\n","                    log_loss_value = log_loss(y_true, y_pred_proba)\n","                except ValueError:\n","                    log_loss_value = float(\"nan\")\n","\n","                per_run_accs.append(acc_score)\n","                per_run_precs.append(prec_score)\n","                per_run_recs.append(rec_score)\n","                per_run_f1s.append(f1)\n","                per_run_log_losses.append(log_loss_value)\n","\n","        # Aggregate run results (mean of periodic evals if there were multiple)\n","        run_acc = float(np.mean(per_run_accs)) if len(per_run_accs) > 0 else float('nan')\n","        run_prec = float(np.mean(per_run_precs)) if len(per_run_precs) > 0 else float('nan')\n","        run_rec = float(np.mean(per_run_recs)) if len(per_run_recs) > 0 else float('nan')\n","        run_f1 = float(np.mean(per_run_f1s)) if len(per_run_f1s) > 0 else float('nan')\n","        run_logloss = float(np.nanmean(per_run_log_losses)) if len(per_run_log_losses) > 0 else float('nan')\n","\n","        acc_scores.append(run_acc)\n","        prec_scores.append(run_prec)\n","        rec_scores.append(run_rec)\n","        f1_scores.append(run_f1)\n","        log_losses.append(run_logloss)\n","\n","        print(f\"Run {run+1} summary -- Acc: {run_acc:.4f}, Prec: {run_prec:.4f}, Rec: {run_rec:.4f}, F1: {run_f1:.4f}, LogLoss: {run_logloss:.4f}\")\n","\n","    # -------------------- Store results for this lambda --------------------\n","    lambda_results = {\n","        \"lambda\": lam,\n","        \"accuracy\": (float(np.nanmean(acc_scores)), float(np.nanstd(acc_scores))),\n","        \"precision\": (float(np.nanmean(prec_scores)), float(np.nanstd(prec_scores))),\n","        \"recall\": (float(np.nanmean(rec_scores)), float(np.nanstd(rec_scores))),\n","        \"f1\": (float(np.nanmean(f1_scores)), float(np.nanstd(f1_scores))),\n","        \"log_loss\": (float(np.nanmean(log_losses)), float(np.nanstd(log_losses)))\n","    }\n","    all_results.append(lambda_results)\n","\n","    print(f\"\\n--- RESULTS FOR LAMBDA = {lam} ---\")\n","    print(f\"Accuracy: {lambda_results['accuracy'][0]:.4f} ± {lambda_results['accuracy'][1]:.4f}\")\n","    print(f\"Precision: {lambda_results['precision'][0]:.4f} ± {lambda_results['precision'][1]:.4f}\")\n","    print(f\"Recall: {lambda_results['recall'][0]:.4f} ± {lambda_results['recall'][1]:.4f}\")\n","    print(f\"F1 Score: {lambda_results['f1'][0]:.4f} ± {lambda_results['f1'][1]:.4f}\")\n","    print(f\"Log Loss: {lambda_results['log_loss'][0]:.4f} ± {lambda_results['log_loss'][1]:.4f}\")\n","\n","# -------------------- Final Summary --------------------\n","print(\"\\n================ FINAL SUMMARY FOR ALL LAMBDAS ================\\n\")\n","print(f\"{'Lambda':>8} | {'Accuracy':>18} | {'Precision':>18} | {'Recall':>18} | {'F1 Score':>18} | {'Log Loss':>18}\")\n","print(\"-\" * 108)\n","for res in all_results:\n","    print(f\"{res['lambda']:>8} | \"\n","          f\"{res['accuracy'][0]:.4f} ± {res['accuracy'][1]:.4f} | \"\n","          f\"{res['precision'][0]:.4f} ± {res['precision'][1]:.4f} | \"\n","          f\"{res['recall'][0]:.4f} ± {res['recall'][1]:.4f} | \"\n","          f\"{res['f1'][0]:.4f} ± {res['f1'][1]:.4f} | \"\n","          f\"{res['log_loss'][0]:.4f} ± {res['log_loss'][1]:.4f}\")\n"],"metadata":{"id":"QkGfWpzwItA0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1769373572388,"user_tz":-330,"elapsed":5352160,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"ce90e9de-e87a-486b-9b59-4fbcd0efc2b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================ LAMBDA = 0.001 ================\n","\n","\n","--- Run 1/10 (seed=42) ---\n","Epoch 0 | Total: -0.2320 | Unsup: -0.2369 | Cont: 4.8765\n","Epoch 500 | Total: -0.4664 | Unsup: -0.4713 | Cont: 4.8955\n","Epoch 1000 | Total: -0.4764 | Unsup: -0.4813 | Cont: 4.8833\n","Epoch 1500 | Total: -0.4651 | Unsup: -0.4699 | Cont: 4.8583\n","Epoch 2000 | Total: -0.4378 | Unsup: -0.4426 | Cont: 4.8090\n","Epoch 2500 | Total: -0.4555 | Unsup: -0.4603 | Cont: 4.8163\n","Epoch 3000 | Total: -0.4737 | Unsup: -0.4785 | Cont: 4.8082\n","Epoch 3500 | Total: -0.4608 | Unsup: -0.4656 | Cont: 4.8192\n","Epoch 4000 | Total: -0.4176 | Unsup: -0.4224 | Cont: 4.8259\n","Epoch 4500 | Total: -0.4620 | Unsup: -0.4669 | Cont: 4.8745\n","Epoch 4999 | Total: -0.4614 | Unsup: -0.4662 | Cont: 4.7840\n","Run 1 summary -- Acc: 0.6245, Prec: 0.7715, Rec: 0.6382, F1: 0.6913, LogLoss: 6.3129\n","\n","--- Run 2/10 (seed=43) ---\n","Epoch 0 | Total: -0.2332 | Unsup: -0.2380 | Cont: 4.8303\n","Epoch 500 | Total: -0.4514 | Unsup: -0.4561 | Cont: 4.7319\n","Epoch 1000 | Total: -0.4731 | Unsup: -0.4778 | Cont: 4.7095\n","Epoch 1500 | Total: -0.4299 | Unsup: -0.4346 | Cont: 4.6800\n","Epoch 2000 | Total: -0.4292 | Unsup: -0.4339 | Cont: 4.7656\n","Epoch 2500 | Total: -0.4620 | Unsup: -0.4666 | Cont: 4.6587\n","Epoch 3000 | Total: -0.4553 | Unsup: -0.4600 | Cont: 4.6949\n","Epoch 3500 | Total: -0.4800 | Unsup: -0.4847 | Cont: 4.6757\n","Epoch 4000 | Total: -0.4502 | Unsup: -0.4548 | Cont: 4.6692\n","Epoch 4500 | Total: -0.4714 | Unsup: -0.4760 | Cont: 4.6140\n","Epoch 4999 | Total: -0.4694 | Unsup: -0.4741 | Cont: 4.7103\n","Run 2 summary -- Acc: 0.6083, Prec: 0.7539, Rec: 0.6289, F1: 0.6787, LogLoss: 4.4890\n","\n","--- Run 3/10 (seed=44) ---\n","Epoch 0 | Total: -0.2328 | Unsup: -0.2376 | Cont: 4.7644\n","Epoch 500 | Total: -0.4224 | Unsup: -0.4272 | Cont: 4.7843\n","Epoch 1000 | Total: -0.4608 | Unsup: -0.4656 | Cont: 4.8275\n","Epoch 1500 | Total: -0.4773 | Unsup: -0.4822 | Cont: 4.8457\n","Epoch 2000 | Total: -0.4681 | Unsup: -0.4729 | Cont: 4.7916\n","Epoch 2500 | Total: -0.4778 | Unsup: -0.4826 | Cont: 4.7358\n","Epoch 3000 | Total: -0.4370 | Unsup: -0.4418 | Cont: 4.8303\n","Epoch 3500 | Total: -0.3644 | Unsup: -0.3691 | Cont: 4.7410\n","Epoch 4000 | Total: -0.4730 | Unsup: -0.4777 | Cont: 4.7730\n","Epoch 4500 | Total: -0.4640 | Unsup: -0.4688 | Cont: 4.7758\n","Epoch 4999 | Total: -0.4635 | Unsup: -0.4683 | Cont: 4.8017\n","Run 3 summary -- Acc: 0.6220, Prec: 0.7732, Rec: 0.6308, F1: 0.6877, LogLoss: 3.3351\n","\n","--- Run 4/10 (seed=45) ---\n","Epoch 0 | Total: -0.2325 | Unsup: -0.2374 | Cont: 4.8677\n","Epoch 500 | Total: -0.4681 | Unsup: -0.4728 | Cont: 4.6432\n","Epoch 1000 | Total: -0.4530 | Unsup: -0.4576 | Cont: 4.6564\n","Epoch 1500 | Total: -0.4744 | Unsup: -0.4791 | Cont: 4.7175\n","Epoch 2000 | Total: -0.4584 | Unsup: -0.4632 | Cont: 4.7051\n","Epoch 2500 | Total: -0.4666 | Unsup: -0.4713 | Cont: 4.6368\n","Epoch 3000 | Total: -0.4668 | Unsup: -0.4714 | Cont: 4.6459\n","Epoch 3500 | Total: -0.4678 | Unsup: -0.4725 | Cont: 4.6931\n","Epoch 4000 | Total: -0.4525 | Unsup: -0.4571 | Cont: 4.5823\n","Epoch 4500 | Total: -0.4635 | Unsup: -0.4682 | Cont: 4.6385\n","Epoch 4999 | Total: -0.4520 | Unsup: -0.4566 | Cont: 4.6327\n","Run 4 summary -- Acc: 0.5243, Prec: 0.6960, Rec: 0.5232, F1: 0.5870, LogLoss: 5.4997\n","\n","--- Run 5/10 (seed=46) ---\n","Epoch 0 | Total: -0.2332 | Unsup: -0.2381 | Cont: 4.8223\n","Epoch 500 | Total: -0.4722 | Unsup: -0.4769 | Cont: 4.6922\n","Epoch 1000 | Total: -0.4740 | Unsup: -0.4787 | Cont: 4.7117\n","Epoch 1500 | Total: -0.4472 | Unsup: -0.4520 | Cont: 4.7341\n","Epoch 2000 | Total: -0.4635 | Unsup: -0.4681 | Cont: 4.6643\n","Epoch 2500 | Total: -0.4373 | Unsup: -0.4420 | Cont: 4.6629\n","Epoch 3000 | Total: -0.4671 | Unsup: -0.4718 | Cont: 4.7337\n","Epoch 3500 | Total: -0.4711 | Unsup: -0.4758 | Cont: 4.7500\n","Epoch 4000 | Total: -0.4815 | Unsup: -0.4862 | Cont: 4.7166\n","Epoch 4500 | Total: -0.4534 | Unsup: -0.4581 | Cont: 4.6997\n","Epoch 4999 | Total: -0.4461 | Unsup: -0.4508 | Cont: 4.7118\n","Run 5 summary -- Acc: 0.6532, Prec: 0.7613, Rec: 0.7134, F1: 0.7321, LogLoss: 3.6533\n","\n","--- Run 6/10 (seed=47) ---\n","Epoch 0 | Total: -0.2336 | Unsup: -0.2385 | Cont: 4.9091\n","Epoch 500 | Total: -0.4570 | Unsup: -0.4618 | Cont: 4.8404\n","Epoch 1000 | Total: -0.4680 | Unsup: -0.4728 | Cont: 4.7803\n","Epoch 1500 | Total: -0.4536 | Unsup: -0.4585 | Cont: 4.8552\n","Epoch 2000 | Total: -0.4715 | Unsup: -0.4764 | Cont: 4.8751\n","Epoch 2500 | Total: -0.4443 | Unsup: -0.4491 | Cont: 4.8059\n","Epoch 3000 | Total: -0.4708 | Unsup: -0.4756 | Cont: 4.7901\n","Epoch 3500 | Total: -0.4418 | Unsup: -0.4466 | Cont: 4.7537\n","Epoch 4000 | Total: -0.4716 | Unsup: -0.4764 | Cont: 4.8111\n","Epoch 4500 | Total: -0.4759 | Unsup: -0.4807 | Cont: 4.8130\n","Epoch 4999 | Total: -0.4739 | Unsup: -0.4786 | Cont: 4.7434\n","Run 6 summary -- Acc: 0.5822, Prec: 0.7483, Rec: 0.5798, F1: 0.6444, LogLoss: 5.5118\n","\n","--- Run 7/10 (seed=48) ---\n","Epoch 0 | Total: -0.2297 | Unsup: -0.2345 | Cont: 4.8019\n","Epoch 500 | Total: -0.4478 | Unsup: -0.4526 | Cont: 4.7908\n","Epoch 1000 | Total: -0.4524 | Unsup: -0.4573 | Cont: 4.8872\n","Epoch 1500 | Total: -0.4622 | Unsup: -0.4670 | Cont: 4.8194\n","Epoch 2000 | Total: -0.4567 | Unsup: -0.4614 | Cont: 4.7837\n","Epoch 2500 | Total: -0.4602 | Unsup: -0.4650 | Cont: 4.8153\n","Epoch 3000 | Total: -0.4637 | Unsup: -0.4685 | Cont: 4.7425\n","Epoch 3500 | Total: -0.4716 | Unsup: -0.4764 | Cont: 4.8815\n","Epoch 4000 | Total: -0.4769 | Unsup: -0.4817 | Cont: 4.8105\n","Epoch 4500 | Total: -0.4577 | Unsup: -0.4625 | Cont: 4.8607\n","Epoch 4999 | Total: -0.4695 | Unsup: -0.4744 | Cont: 4.8597\n","Run 7 summary -- Acc: 0.6843, Prec: 0.7790, Rec: 0.7495, F1: 0.7600, LogLoss: 3.0040\n","\n","--- Run 8/10 (seed=49) ---\n","Epoch 0 | Total: -0.2338 | Unsup: -0.2386 | Cont: 4.8359\n","Epoch 500 | Total: -0.4590 | Unsup: -0.4639 | Cont: 4.8763\n","Epoch 1000 | Total: -0.4718 | Unsup: -0.4766 | Cont: 4.8064\n","Epoch 1500 | Total: -0.4629 | Unsup: -0.4677 | Cont: 4.7889\n","Epoch 2000 | Total: -0.4545 | Unsup: -0.4593 | Cont: 4.7884\n","Epoch 2500 | Total: -0.4648 | Unsup: -0.4696 | Cont: 4.7665\n","Epoch 3000 | Total: -0.4735 | Unsup: -0.4782 | Cont: 4.7037\n","Epoch 3500 | Total: -0.4743 | Unsup: -0.4790 | Cont: 4.6923\n","Epoch 4000 | Total: -0.4556 | Unsup: -0.4604 | Cont: 4.7821\n","Epoch 4500 | Total: -0.4713 | Unsup: -0.4760 | Cont: 4.7359\n","Epoch 4999 | Total: -0.4642 | Unsup: -0.4690 | Cont: 4.8213\n","Run 8 summary -- Acc: 0.6519, Prec: 0.8002, Rec: 0.6558, F1: 0.7157, LogLoss: 3.2124\n","\n","--- Run 9/10 (seed=50) ---\n","Epoch 0 | Total: -0.2320 | Unsup: -0.2369 | Cont: 4.8492\n","Epoch 500 | Total: -0.4533 | Unsup: -0.4580 | Cont: 4.6982\n","Epoch 1000 | Total: -0.4786 | Unsup: -0.4833 | Cont: 4.6976\n","Epoch 1500 | Total: -0.4617 | Unsup: -0.4664 | Cont: 4.7436\n","Epoch 2000 | Total: -0.4691 | Unsup: -0.4738 | Cont: 4.6703\n","Epoch 2500 | Total: -0.4617 | Unsup: -0.4664 | Cont: 4.7548\n","Epoch 3000 | Total: -0.4756 | Unsup: -0.4803 | Cont: 4.7492\n","Epoch 3500 | Total: -0.4667 | Unsup: -0.4714 | Cont: 4.7193\n","Epoch 4000 | Total: -0.4722 | Unsup: -0.4769 | Cont: 4.7130\n","Epoch 4500 | Total: -0.4701 | Unsup: -0.4748 | Cont: 4.7290\n","Epoch 4999 | Total: -0.4630 | Unsup: -0.4677 | Cont: 4.6933\n","Run 9 summary -- Acc: 0.6158, Prec: 0.7783, Rec: 0.6113, F1: 0.6762, LogLoss: 7.1967\n","\n","--- Run 10/10 (seed=51) ---\n","Epoch 0 | Total: -0.2349 | Unsup: -0.2397 | Cont: 4.8245\n","Epoch 500 | Total: -0.4556 | Unsup: -0.4603 | Cont: 4.7697\n","Epoch 1000 | Total: -0.4691 | Unsup: -0.4739 | Cont: 4.8034\n","Epoch 1500 | Total: -0.4568 | Unsup: -0.4616 | Cont: 4.7929\n","Epoch 2000 | Total: -0.4675 | Unsup: -0.4724 | Cont: 4.8671\n","Epoch 2500 | Total: -0.4495 | Unsup: -0.4543 | Cont: 4.7798\n","Epoch 3000 | Total: -0.4736 | Unsup: -0.4785 | Cont: 4.8265\n","Epoch 3500 | Total: -0.4760 | Unsup: -0.4808 | Cont: 4.7915\n","Epoch 4000 | Total: -0.4766 | Unsup: -0.4813 | Cont: 4.7710\n","Epoch 4500 | Total: -0.4735 | Unsup: -0.4783 | Cont: 4.7704\n","Epoch 4999 | Total: -0.4760 | Unsup: -0.4807 | Cont: 4.7716\n","Run 10 summary -- Acc: 0.6413, Prec: 0.7964, Rec: 0.6401, F1: 0.7036, LogLoss: 7.2206\n","\n","--- RESULTS FOR LAMBDA = 0.001 ---\n","Accuracy: 0.6208 ± 0.0418\n","Precision: 0.7658 ± 0.0281\n","Recall: 0.6371 ± 0.0599\n","F1 Score: 0.6877 ± 0.0453\n","Log Loss: 4.9435 ± 1.5487\n","\n","================ LAMBDA = 0.01 ================\n","\n","\n","--- Run 1/10 (seed=42) ---\n","Epoch 0 | Total: -0.1881 | Unsup: -0.2369 | Cont: 4.8765\n","Epoch 500 | Total: -0.4308 | Unsup: -0.4777 | Cont: 4.6848\n","Epoch 1000 | Total: -0.4270 | Unsup: -0.4736 | Cont: 4.6664\n","Epoch 1500 | Total: -0.4313 | Unsup: -0.4775 | Cont: 4.6254\n","Epoch 2000 | Total: -0.4336 | Unsup: -0.4793 | Cont: 4.5707\n","Epoch 2500 | Total: -0.4284 | Unsup: -0.4745 | Cont: 4.6095\n","Epoch 3000 | Total: -0.4329 | Unsup: -0.4786 | Cont: 4.5700\n","Epoch 3500 | Total: -0.4321 | Unsup: -0.4778 | Cont: 4.5706\n","Epoch 4000 | Total: -0.3742 | Unsup: -0.4203 | Cont: 4.6141\n","Epoch 4500 | Total: -0.3799 | Unsup: -0.4263 | Cont: 4.6453\n","Epoch 4999 | Total: -0.4306 | Unsup: -0.4767 | Cont: 4.6043\n","Run 1 summary -- Acc: 0.6102, Prec: 0.7686, Rec: 0.6122, F1: 0.6734, LogLoss: 6.4889\n","\n","--- Run 2/10 (seed=43) ---\n","Epoch 0 | Total: -0.1897 | Unsup: -0.2380 | Cont: 4.8303\n","Epoch 500 | Total: -0.4229 | Unsup: -0.4687 | Cont: 4.5848\n","Epoch 1000 | Total: -0.4277 | Unsup: -0.4734 | Cont: 4.5705\n","Epoch 1500 | Total: -0.4180 | Unsup: -0.4632 | Cont: 4.5176\n","Epoch 2000 | Total: -0.3634 | Unsup: -0.4098 | Cont: 4.6367\n","Epoch 2500 | Total: -0.4033 | Unsup: -0.4484 | Cont: 4.5126\n","Epoch 3000 | Total: -0.4260 | Unsup: -0.4714 | Cont: 4.5350\n","Epoch 3500 | Total: -0.4330 | Unsup: -0.4785 | Cont: 4.5439\n","Epoch 4000 | Total: -0.4176 | Unsup: -0.4629 | Cont: 4.5328\n","Epoch 4500 | Total: -0.4317 | Unsup: -0.4765 | Cont: 4.4804\n","Epoch 4999 | Total: -0.4291 | Unsup: -0.4749 | Cont: 4.5793\n","Run 2 summary -- Acc: 0.6127, Prec: 0.7565, Rec: 0.6345, F1: 0.6832, LogLoss: 4.4841\n","\n","--- Run 3/10 (seed=44) ---\n","Epoch 0 | Total: -0.1900 | Unsup: -0.2376 | Cont: 4.7644\n","Epoch 500 | Total: -0.3676 | Unsup: -0.4146 | Cont: 4.6986\n","Epoch 1000 | Total: -0.4217 | Unsup: -0.4688 | Cont: 4.7153\n","Epoch 1500 | Total: -0.3958 | Unsup: -0.4430 | Cont: 4.7266\n","Epoch 2000 | Total: -0.4270 | Unsup: -0.4737 | Cont: 4.6691\n","Epoch 2500 | Total: -0.4365 | Unsup: -0.4824 | Cont: 4.5906\n","Epoch 3000 | Total: -0.4219 | Unsup: -0.4689 | Cont: 4.7015\n","Epoch 3500 | Total: -0.3469 | Unsup: -0.3933 | Cont: 4.6315\n","Epoch 4000 | Total: -0.4271 | Unsup: -0.4732 | Cont: 4.6062\n","Epoch 4500 | Total: -0.4263 | Unsup: -0.4727 | Cont: 4.6431\n","Epoch 4999 | Total: -0.3950 | Unsup: -0.4417 | Cont: 4.6616\n","Run 3 summary -- Acc: 0.6463, Prec: 0.8060, Rec: 0.6382, F1: 0.7045, LogLoss: 3.0413\n","\n","--- Run 4/10 (seed=45) ---\n","Epoch 0 | Total: -0.1887 | Unsup: -0.2374 | Cont: 4.8677\n","Epoch 500 | Total: -0.4289 | Unsup: -0.4741 | Cont: 4.5166\n","Epoch 1000 | Total: -0.4253 | Unsup: -0.4704 | Cont: 4.5087\n","Epoch 1500 | Total: -0.4324 | Unsup: -0.4780 | Cont: 4.5617\n","Epoch 2000 | Total: -0.4259 | Unsup: -0.4713 | Cont: 4.5395\n","Epoch 2500 | Total: -0.4273 | Unsup: -0.4723 | Cont: 4.5042\n","Epoch 3000 | Total: -0.4198 | Unsup: -0.4644 | Cont: 4.4645\n","Epoch 3500 | Total: -0.4319 | Unsup: -0.4777 | Cont: 4.5793\n","Epoch 4000 | Total: -0.4146 | Unsup: -0.4591 | Cont: 4.4518\n","Epoch 4500 | Total: -0.4165 | Unsup: -0.4613 | Cont: 4.4795\n","Epoch 4999 | Total: -0.3905 | Unsup: -0.4351 | Cont: 4.4651\n","Run 4 summary -- Acc: 0.5268, Prec: 0.6839, Rec: 0.5547, F1: 0.6036, LogLoss: 5.6194\n","\n","--- Run 5/10 (seed=46) ---\n","Epoch 0 | Total: -0.1898 | Unsup: -0.2381 | Cont: 4.8223\n","Epoch 500 | Total: -0.4352 | Unsup: -0.4805 | Cont: 4.5333\n","Epoch 1000 | Total: -0.4333 | Unsup: -0.4792 | Cont: 4.5823\n","Epoch 1500 | Total: -0.4336 | Unsup: -0.4795 | Cont: 4.5877\n","Epoch 2000 | Total: -0.4000 | Unsup: -0.4451 | Cont: 4.5139\n","Epoch 2500 | Total: -0.4222 | Unsup: -0.4676 | Cont: 4.5326\n","Epoch 3000 | Total: -0.3896 | Unsup: -0.4355 | Cont: 4.5840\n","Epoch 3500 | Total: -0.4294 | Unsup: -0.4750 | Cont: 4.5629\n","Epoch 4000 | Total: -0.4313 | Unsup: -0.4767 | Cont: 4.5448\n","Epoch 4500 | Total: -0.4206 | Unsup: -0.4661 | Cont: 4.5494\n","Epoch 4999 | Total: -0.4301 | Unsup: -0.4758 | Cont: 4.5750\n","Run 5 summary -- Acc: 0.6326, Prec: 0.7526, Rec: 0.6837, F1: 0.7114, LogLoss: 4.1185\n","\n","--- Run 6/10 (seed=47) ---\n","Epoch 0 | Total: -0.1894 | Unsup: -0.2385 | Cont: 4.9091\n","Epoch 500 | Total: -0.4259 | Unsup: -0.4727 | Cont: 4.6824\n","Epoch 1000 | Total: -0.4182 | Unsup: -0.4643 | Cont: 4.6166\n","Epoch 1500 | Total: -0.4163 | Unsup: -0.4631 | Cont: 4.6814\n","Epoch 2000 | Total: -0.4266 | Unsup: -0.4734 | Cont: 4.6771\n","Epoch 2500 | Total: -0.3968 | Unsup: -0.4433 | Cont: 4.6509\n","Epoch 3000 | Total: -0.4258 | Unsup: -0.4718 | Cont: 4.6045\n","Epoch 3500 | Total: -0.4211 | Unsup: -0.4669 | Cont: 4.5785\n","Epoch 4000 | Total: -0.4329 | Unsup: -0.4796 | Cont: 4.6636\n","Epoch 4500 | Total: -0.4276 | Unsup: -0.4743 | Cont: 4.6719\n","Epoch 4999 | Total: -0.4274 | Unsup: -0.4732 | Cont: 4.5823\n","Run 6 summary -- Acc: 0.5548, Prec: 0.7389, Rec: 0.5315, F1: 0.6071, LogLoss: 5.4555\n","\n","--- Run 7/10 (seed=48) ---\n","Epoch 0 | Total: -0.1865 | Unsup: -0.2345 | Cont: 4.8019\n","Epoch 500 | Total: -0.4309 | Unsup: -0.4778 | Cont: 4.6884\n","Epoch 1000 | Total: -0.4001 | Unsup: -0.4472 | Cont: 4.7061\n","Epoch 1500 | Total: -0.4282 | Unsup: -0.4747 | Cont: 4.6550\n","Epoch 2000 | Total: -0.3942 | Unsup: -0.4408 | Cont: 4.6576\n","Epoch 2500 | Total: -0.4240 | Unsup: -0.4707 | Cont: 4.6691\n","Epoch 3000 | Total: -0.3917 | Unsup: -0.4378 | Cont: 4.6066\n","Epoch 3500 | Total: -0.4275 | Unsup: -0.4742 | Cont: 4.6716\n","Epoch 4000 | Total: -0.4178 | Unsup: -0.4643 | Cont: 4.6568\n","Epoch 4500 | Total: -0.4136 | Unsup: -0.4606 | Cont: 4.7018\n","Epoch 4999 | Total: -0.4291 | Unsup: -0.4760 | Cont: 4.6820\n","Run 7 summary -- Acc: 0.6737, Prec: 0.7807, Rec: 0.7254, F1: 0.7474, LogLoss: 3.1467\n","\n","--- Run 8/10 (seed=49) ---\n","Epoch 0 | Total: -0.1903 | Unsup: -0.2386 | Cont: 4.8359\n","Epoch 500 | Total: -0.4261 | Unsup: -0.4736 | Cont: 4.7433\n","Epoch 1000 | Total: -0.4348 | Unsup: -0.4812 | Cont: 4.6384\n","Epoch 1500 | Total: -0.4074 | Unsup: -0.4537 | Cont: 4.6229\n","Epoch 2000 | Total: -0.4069 | Unsup: -0.4532 | Cont: 4.6297\n","Epoch 2500 | Total: -0.4318 | Unsup: -0.4776 | Cont: 4.5850\n","Epoch 3000 | Total: -0.4355 | Unsup: -0.4809 | Cont: 4.5389\n","Epoch 3500 | Total: -0.4344 | Unsup: -0.4800 | Cont: 4.5647\n","Epoch 4000 | Total: -0.4309 | Unsup: -0.4770 | Cont: 4.6109\n","Epoch 4500 | Total: -0.4086 | Unsup: -0.4543 | Cont: 4.5718\n","Epoch 4999 | Total: -0.4216 | Unsup: -0.4681 | Cont: 4.6510\n","Run 8 summary -- Acc: 0.6476, Prec: 0.7972, Rec: 0.6512, F1: 0.7116, LogLoss: 3.3585\n","\n","--- Run 9/10 (seed=50) ---\n","Epoch 0 | Total: -0.1884 | Unsup: -0.2369 | Cont: 4.8492\n","Epoch 500 | Total: -0.4062 | Unsup: -0.4521 | Cont: 4.5842\n","Epoch 1000 | Total: -0.4301 | Unsup: -0.4753 | Cont: 4.5254\n","Epoch 1500 | Total: -0.4211 | Unsup: -0.4667 | Cont: 4.5529\n","Epoch 2000 | Total: -0.4233 | Unsup: -0.4684 | Cont: 4.5053\n","Epoch 2500 | Total: -0.4184 | Unsup: -0.4641 | Cont: 4.5686\n","Epoch 3000 | Total: -0.4272 | Unsup: -0.4730 | Cont: 4.5772\n","Epoch 3500 | Total: -0.4274 | Unsup: -0.4731 | Cont: 4.5793\n","Epoch 4000 | Total: -0.4392 | Unsup: -0.4849 | Cont: 4.5689\n","Epoch 4500 | Total: -0.4154 | Unsup: -0.4610 | Cont: 4.5602\n","Epoch 4999 | Total: -0.4211 | Unsup: -0.4662 | Cont: 4.5133\n","Run 9 summary -- Acc: 0.6862, Prec: 0.8005, Rec: 0.7217, F1: 0.7538, LogLoss: 7.7492\n","\n","--- Run 10/10 (seed=51) ---\n","Epoch 0 | Total: -0.1915 | Unsup: -0.2397 | Cont: 4.8245\n","Epoch 500 | Total: -0.3753 | Unsup: -0.4218 | Cont: 4.6475\n","Epoch 1000 | Total: -0.3881 | Unsup: -0.4347 | Cont: 4.6555\n","Epoch 1500 | Total: -0.4148 | Unsup: -0.4610 | Cont: 4.6192\n","Epoch 2000 | Total: -0.4134 | Unsup: -0.4597 | Cont: 4.6362\n","Epoch 2500 | Total: -0.4268 | Unsup: -0.4731 | Cont: 4.6289\n","Epoch 3000 | Total: -0.4220 | Unsup: -0.4684 | Cont: 4.6396\n","Epoch 3500 | Total: -0.4273 | Unsup: -0.4736 | Cont: 4.6295\n","Epoch 4000 | Total: -0.4338 | Unsup: -0.4798 | Cont: 4.5953\n","Epoch 4500 | Total: -0.4069 | Unsup: -0.4529 | Cont: 4.6018\n","Epoch 4999 | Total: -0.4375 | Unsup: -0.4835 | Cont: 4.5972\n","Run 10 summary -- Acc: 0.6650, Prec: 0.8125, Rec: 0.6660, F1: 0.7263, LogLoss: 7.5505\n","\n","--- RESULTS FOR LAMBDA = 0.01 ---\n","Accuracy: 0.6256 ± 0.0487\n","Precision: 0.7697 ± 0.0371\n","Recall: 0.6419 ± 0.0604\n","F1 Score: 0.6922 ± 0.0494\n","Log Loss: 5.1013 ± 1.6667\n","\n","================ LAMBDA = 0.09 ================\n","\n","\n","--- Run 1/10 (seed=42) ---\n","Epoch 0 | Total: 0.2020 | Unsup: -0.2369 | Cont: 4.8765\n","Epoch 500 | Total: -0.1153 | Unsup: -0.4696 | Cont: 3.9374\n","Epoch 1000 | Total: -0.1277 | Unsup: -0.4764 | Cont: 3.8737\n","Epoch 1500 | Total: -0.1249 | Unsup: -0.4744 | Cont: 3.8826\n","Epoch 2000 | Total: -0.1197 | Unsup: -0.4643 | Cont: 3.8282\n","Epoch 2500 | Total: -0.1158 | Unsup: -0.4621 | Cont: 3.8477\n","Epoch 3000 | Total: -0.1380 | Unsup: -0.4808 | Cont: 3.8090\n","Epoch 3500 | Total: -0.1385 | Unsup: -0.4822 | Cont: 3.8194\n","Epoch 4000 | Total: -0.1292 | Unsup: -0.4748 | Cont: 3.8405\n","Epoch 4500 | Total: -0.1098 | Unsup: -0.4540 | Cont: 3.8239\n","Epoch 4999 | Total: -0.1329 | Unsup: -0.4783 | Cont: 3.8381\n","Run 1 summary -- Acc: 0.5778, Prec: 0.7282, Rec: 0.6002, F1: 0.6506, LogLoss: 6.3340\n","\n","--- Run 2/10 (seed=43) ---\n","Epoch 0 | Total: 0.1967 | Unsup: -0.2380 | Cont: 4.8303\n","Epoch 500 | Total: -0.1219 | Unsup: -0.4717 | Cont: 3.8868\n","Epoch 1000 | Total: -0.1365 | Unsup: -0.4834 | Cont: 3.8544\n","Epoch 1500 | Total: -0.1298 | Unsup: -0.4685 | Cont: 3.7627\n","Epoch 2000 | Total: -0.1152 | Unsup: -0.4615 | Cont: 3.8473\n","Epoch 2500 | Total: -0.1308 | Unsup: -0.4707 | Cont: 3.7766\n","Epoch 3000 | Total: -0.1271 | Unsup: -0.4703 | Cont: 3.8132\n","Epoch 3500 | Total: -0.1349 | Unsup: -0.4747 | Cont: 3.7755\n","Epoch 4000 | Total: -0.1098 | Unsup: -0.4537 | Cont: 3.8206\n","Epoch 4500 | Total: -0.1463 | Unsup: -0.4802 | Cont: 3.7094\n","Epoch 4999 | Total: -0.1368 | Unsup: -0.4827 | Cont: 3.8429\n","Run 2 summary -- Acc: 0.5834, Prec: 0.7419, Rec: 0.5918, F1: 0.6502, LogLoss: 4.6188\n","\n","--- Run 3/10 (seed=44) ---\n","Epoch 0 | Total: 0.1912 | Unsup: -0.2376 | Cont: 4.7644\n","Epoch 500 | Total: -0.0974 | Unsup: -0.4508 | Cont: 3.9258\n","Epoch 1000 | Total: -0.1214 | Unsup: -0.4740 | Cont: 3.9183\n","Epoch 1500 | Total: -0.1288 | Unsup: -0.4798 | Cont: 3.8998\n","Epoch 2000 | Total: -0.1233 | Unsup: -0.4681 | Cont: 3.8317\n","Epoch 2500 | Total: -0.1086 | Unsup: -0.4541 | Cont: 3.8381\n","Epoch 3000 | Total: -0.1101 | Unsup: -0.4628 | Cont: 3.9185\n","Epoch 3500 | Total: -0.1236 | Unsup: -0.4721 | Cont: 3.8722\n","Epoch 4000 | Total: -0.1272 | Unsup: -0.4736 | Cont: 3.8493\n","Epoch 4500 | Total: -0.1364 | Unsup: -0.4848 | Cont: 3.8712\n","Epoch 4999 | Total: -0.1279 | Unsup: -0.4774 | Cont: 3.8829\n","Run 3 summary -- Acc: 0.6034, Prec: 0.7664, Rec: 0.6011, F1: 0.6656, LogLoss: 3.9624\n","\n","--- Run 4/10 (seed=45) ---\n","Epoch 0 | Total: 0.2007 | Unsup: -0.2374 | Cont: 4.8677\n","Epoch 500 | Total: -0.1265 | Unsup: -0.4756 | Cont: 3.8785\n","Epoch 1000 | Total: -0.1196 | Unsup: -0.4628 | Cont: 3.8131\n","Epoch 1500 | Total: -0.1206 | Unsup: -0.4695 | Cont: 3.8771\n","Epoch 2000 | Total: -0.1341 | Unsup: -0.4793 | Cont: 3.8354\n","Epoch 2500 | Total: -0.1397 | Unsup: -0.4785 | Cont: 3.7642\n","Epoch 3000 | Total: -0.1428 | Unsup: -0.4835 | Cont: 3.7857\n","Epoch 3500 | Total: -0.1219 | Unsup: -0.4723 | Cont: 3.8934\n","Epoch 4000 | Total: -0.1362 | Unsup: -0.4750 | Cont: 3.7638\n","Epoch 4500 | Total: -0.1330 | Unsup: -0.4749 | Cont: 3.7993\n","Epoch 4999 | Total: -0.1182 | Unsup: -0.4612 | Cont: 3.8107\n","Run 4 summary -- Acc: 0.5461, Prec: 0.6990, Rec: 0.5733, F1: 0.6224, LogLoss: 5.5298\n","\n","--- Run 5/10 (seed=46) ---\n","Epoch 0 | Total: 0.1959 | Unsup: -0.2381 | Cont: 4.8223\n","Epoch 500 | Total: -0.1245 | Unsup: -0.4775 | Cont: 3.9229\n","Epoch 1000 | Total: -0.1309 | Unsup: -0.4814 | Cont: 3.8938\n","Epoch 1500 | Total: -0.1259 | Unsup: -0.4734 | Cont: 3.8620\n","Epoch 2000 | Total: -0.1398 | Unsup: -0.4807 | Cont: 3.7880\n","Epoch 2500 | Total: -0.1333 | Unsup: -0.4756 | Cont: 3.8032\n","Epoch 3000 | Total: -0.0970 | Unsup: -0.4458 | Cont: 3.8764\n","Epoch 3500 | Total: -0.1365 | Unsup: -0.4849 | Cont: 3.8706\n","Epoch 4000 | Total: -0.1211 | Unsup: -0.4641 | Cont: 3.8110\n","Epoch 4500 | Total: -0.1295 | Unsup: -0.4726 | Cont: 3.8116\n","Epoch 4999 | Total: -0.1315 | Unsup: -0.4765 | Cont: 3.8335\n","Run 5 summary -- Acc: 0.5548, Prec: 0.7096, Rec: 0.5761, F1: 0.6281, LogLoss: 5.3852\n","\n","--- Run 6/10 (seed=47) ---\n","Epoch 0 | Total: 0.2033 | Unsup: -0.2385 | Cont: 4.9091\n","Epoch 500 | Total: -0.0761 | Unsup: -0.4326 | Cont: 3.9608\n","Epoch 1000 | Total: -0.1185 | Unsup: -0.4669 | Cont: 3.8720\n","Epoch 1500 | Total: -0.1315 | Unsup: -0.4819 | Cont: 3.8927\n","Epoch 2000 | Total: -0.0799 | Unsup: -0.4298 | Cont: 3.8878\n","Epoch 2500 | Total: -0.1109 | Unsup: -0.4602 | Cont: 3.8817\n","Epoch 3000 | Total: -0.1352 | Unsup: -0.4790 | Cont: 3.8201\n","Epoch 3500 | Total: -0.1114 | Unsup: -0.4506 | Cont: 3.7687\n","Epoch 4000 | Total: -0.1180 | Unsup: -0.4685 | Cont: 3.8948\n","Epoch 4500 | Total: -0.1313 | Unsup: -0.4778 | Cont: 3.8499\n","Epoch 4999 | Total: -0.1364 | Unsup: -0.4806 | Cont: 3.8252\n","Run 6 summary -- Acc: 0.5903, Prec: 0.7460, Rec: 0.6011, F1: 0.6578, LogLoss: 5.9996\n","\n","--- Run 7/10 (seed=48) ---\n","Epoch 0 | Total: 0.1977 | Unsup: -0.2345 | Cont: 4.8019\n","Epoch 500 | Total: -0.1085 | Unsup: -0.4620 | Cont: 3.9274\n","Epoch 1000 | Total: -0.1278 | Unsup: -0.4747 | Cont: 3.8540\n","Epoch 1500 | Total: -0.1284 | Unsup: -0.4744 | Cont: 3.8450\n","Epoch 2000 | Total: -0.1037 | Unsup: -0.4471 | Cont: 3.8163\n","Epoch 2500 | Total: -0.1353 | Unsup: -0.4787 | Cont: 3.8159\n","Epoch 3000 | Total: -0.1425 | Unsup: -0.4800 | Cont: 3.7496\n","Epoch 3500 | Total: -0.1289 | Unsup: -0.4744 | Cont: 3.8392\n","Epoch 4000 | Total: -0.1358 | Unsup: -0.4794 | Cont: 3.8181\n","Epoch 4500 | Total: -0.1170 | Unsup: -0.4657 | Cont: 3.8743\n","Epoch 4999 | Total: -0.1226 | Unsup: -0.4699 | Cont: 3.8587\n","Run 7 summary -- Acc: 0.6152, Prec: 0.7715, Rec: 0.6187, F1: 0.6787, LogLoss: 3.8150\n","\n","--- Run 8/10 (seed=49) ---\n","Epoch 0 | Total: 0.1966 | Unsup: -0.2386 | Cont: 4.8359\n","Epoch 500 | Total: -0.1246 | Unsup: -0.4802 | Cont: 3.9509\n","Epoch 1000 | Total: -0.1279 | Unsup: -0.4775 | Cont: 3.8846\n","Epoch 1500 | Total: -0.1225 | Unsup: -0.4642 | Cont: 3.7959\n","Epoch 2000 | Total: -0.1363 | Unsup: -0.4864 | Cont: 3.8894\n","Epoch 2500 | Total: -0.1100 | Unsup: -0.4568 | Cont: 3.8525\n","Epoch 3000 | Total: -0.1389 | Unsup: -0.4801 | Cont: 3.7914\n","Epoch 3500 | Total: -0.1148 | Unsup: -0.4601 | Cont: 3.8358\n","Epoch 4000 | Total: -0.1252 | Unsup: -0.4734 | Cont: 3.8684\n","Epoch 4500 | Total: -0.1109 | Unsup: -0.4502 | Cont: 3.7693\n","Epoch 4999 | Total: -0.1299 | Unsup: -0.4782 | Cont: 3.8701\n","Run 8 summary -- Acc: 0.6127, Prec: 0.7703, Rec: 0.6160, F1: 0.6789, LogLoss: 3.8114\n","\n","--- Run 9/10 (seed=50) ---\n","Epoch 0 | Total: 0.1996 | Unsup: -0.2369 | Cont: 4.8492\n","Epoch 500 | Total: -0.1101 | Unsup: -0.4581 | Cont: 3.8662\n","Epoch 1000 | Total: -0.1367 | Unsup: -0.4807 | Cont: 3.8221\n","Epoch 1500 | Total: -0.1298 | Unsup: -0.4726 | Cont: 3.8083\n","Epoch 2000 | Total: -0.1192 | Unsup: -0.4639 | Cont: 3.8301\n","Epoch 2500 | Total: -0.1228 | Unsup: -0.4726 | Cont: 3.8864\n","Epoch 3000 | Total: -0.1356 | Unsup: -0.4802 | Cont: 3.8291\n","Epoch 3500 | Total: -0.1385 | Unsup: -0.4830 | Cont: 3.8274\n","Epoch 4000 | Total: -0.1370 | Unsup: -0.4840 | Cont: 3.8559\n","Epoch 4500 | Total: -0.1243 | Unsup: -0.4680 | Cont: 3.8193\n","Epoch 4999 | Total: -0.1321 | Unsup: -0.4771 | Cont: 3.8328\n","Run 9 summary -- Acc: 0.6164, Prec: 0.7714, Rec: 0.6215, F1: 0.6805, LogLoss: 7.5195\n","\n","--- Run 10/10 (seed=51) ---\n","Epoch 0 | Total: 0.1945 | Unsup: -0.2397 | Cont: 4.8245\n","Epoch 500 | Total: -0.0942 | Unsup: -0.4548 | Cont: 4.0067\n","Epoch 1000 | Total: -0.1108 | Unsup: -0.4583 | Cont: 3.8613\n","Epoch 1500 | Total: -0.1272 | Unsup: -0.4760 | Cont: 3.8750\n","Epoch 2000 | Total: -0.1307 | Unsup: -0.4780 | Cont: 3.8590\n","Epoch 2500 | Total: -0.1291 | Unsup: -0.4789 | Cont: 3.8866\n","Epoch 3000 | Total: -0.1309 | Unsup: -0.4817 | Cont: 3.8977\n","Epoch 3500 | Total: -0.1269 | Unsup: -0.4732 | Cont: 3.8475\n","Epoch 4000 | Total: -0.1009 | Unsup: -0.4443 | Cont: 3.8155\n","Epoch 4500 | Total: -0.1154 | Unsup: -0.4620 | Cont: 3.8518\n","Epoch 4999 | Total: -0.1146 | Unsup: -0.4627 | Cont: 3.8681\n","Run 10 summary -- Acc: 0.6283, Prec: 0.7993, Rec: 0.6113, F1: 0.6852, LogLoss: 7.4784\n","\n","--- RESULTS FOR LAMBDA = 0.09 ---\n","Accuracy: 0.5928 ± 0.0260\n","Precision: 0.7504 ± 0.0297\n","Recall: 0.6011 ± 0.0159\n","F1 Score: 0.6598 ± 0.0210\n","Log Loss: 5.4454 ± 1.3324\n","\n","================ LAMBDA = 0.3 ================\n","\n","\n","--- Run 1/10 (seed=42) ---\n","Epoch 0 | Total: 1.2261 | Unsup: -0.2369 | Cont: 4.8765\n","Epoch 500 | Total: 0.5976 | Unsup: -0.4771 | Cont: 3.5823\n","Epoch 1000 | Total: 0.5594 | Unsup: -0.4831 | Cont: 3.4749\n","Epoch 1500 | Total: 0.5916 | Unsup: -0.4720 | Cont: 3.5452\n","Epoch 2000 | Total: 0.5640 | Unsup: -0.4795 | Cont: 3.4784\n","Epoch 2500 | Total: 0.6008 | Unsup: -0.4414 | Cont: 3.4738\n","Epoch 3000 | Total: 0.5474 | Unsup: -0.4811 | Cont: 3.4283\n","Epoch 3500 | Total: 0.5551 | Unsup: -0.4838 | Cont: 3.4630\n","Epoch 4000 | Total: 0.5597 | Unsup: -0.4787 | Cont: 3.4614\n","Epoch 4500 | Total: 0.5751 | Unsup: -0.4633 | Cont: 3.4615\n","Epoch 4999 | Total: 0.5639 | Unsup: -0.4837 | Cont: 3.4921\n","Run 1 summary -- Acc: 0.5355, Prec: 0.6987, Rec: 0.5464, F1: 0.6044, LogLoss: 5.9042\n","\n","--- Run 2/10 (seed=43) ---\n","Epoch 0 | Total: 1.2111 | Unsup: -0.2380 | Cont: 4.8303\n","Epoch 500 | Total: 0.6106 | Unsup: -0.4473 | Cont: 3.5265\n","Epoch 1000 | Total: 0.5817 | Unsup: -0.4810 | Cont: 3.5421\n","Epoch 1500 | Total: 0.5589 | Unsup: -0.4701 | Cont: 3.4301\n","Epoch 2000 | Total: 0.5648 | Unsup: -0.4733 | Cont: 3.4604\n","Epoch 2500 | Total: 0.5419 | Unsup: -0.4843 | Cont: 3.4206\n","Epoch 3000 | Total: 0.5574 | Unsup: -0.4777 | Cont: 3.4505\n","Epoch 3500 | Total: 0.5457 | Unsup: -0.4798 | Cont: 3.4185\n","Epoch 4000 | Total: 0.5891 | Unsup: -0.4474 | Cont: 3.4550\n","Epoch 4500 | Total: 0.5291 | Unsup: -0.4777 | Cont: 3.3562\n","Epoch 4999 | Total: 0.5594 | Unsup: -0.4804 | Cont: 3.4660\n","Run 2 summary -- Acc: 0.6077, Prec: 0.7607, Rec: 0.6178, F1: 0.6741, LogLoss: 4.2877\n","\n","--- Run 3/10 (seed=44) ---\n","Epoch 0 | Total: 1.1917 | Unsup: -0.2376 | Cont: 4.7644\n","Epoch 500 | Total: 0.6067 | Unsup: -0.4585 | Cont: 3.5506\n","Epoch 1000 | Total: 0.5927 | Unsup: -0.4642 | Cont: 3.5230\n","Epoch 1500 | Total: 0.5819 | Unsup: -0.4751 | Cont: 3.5233\n","Epoch 2000 | Total: 0.5705 | Unsup: -0.4686 | Cont: 3.4636\n","Epoch 2500 | Total: 0.5518 | Unsup: -0.4887 | Cont: 3.4685\n","Epoch 3000 | Total: 0.5927 | Unsup: -0.4537 | Cont: 3.4883\n","Epoch 3500 | Total: 0.5649 | Unsup: -0.4745 | Cont: 3.4645\n","Epoch 4000 | Total: 0.5898 | Unsup: -0.4465 | Cont: 3.4545\n","Epoch 4500 | Total: 0.5603 | Unsup: -0.4802 | Cont: 3.4684\n","Epoch 4999 | Total: 0.5675 | Unsup: -0.4797 | Cont: 3.4907\n","Run 3 summary -- Acc: 0.6239, Prec: 0.7804, Rec: 0.6252, F1: 0.6864, LogLoss: 3.7586\n","\n","--- Run 4/10 (seed=45) ---\n","Epoch 0 | Total: 1.2229 | Unsup: -0.2374 | Cont: 4.8677\n","Epoch 500 | Total: 0.5863 | Unsup: -0.4752 | Cont: 3.5383\n","Epoch 1000 | Total: 0.5697 | Unsup: -0.4706 | Cont: 3.4678\n","Epoch 1500 | Total: 0.5920 | Unsup: -0.4645 | Cont: 3.5217\n","Epoch 2000 | Total: 0.5575 | Unsup: -0.4837 | Cont: 3.4706\n","Epoch 2500 | Total: 0.5435 | Unsup: -0.4765 | Cont: 3.3999\n","Epoch 3000 | Total: 0.5351 | Unsup: -0.4857 | Cont: 3.4027\n","Epoch 3500 | Total: 0.5685 | Unsup: -0.4770 | Cont: 3.4848\n","Epoch 4000 | Total: 0.5330 | Unsup: -0.4836 | Cont: 3.3886\n","Epoch 4500 | Total: 0.5598 | Unsup: -0.4769 | Cont: 3.4557\n","Epoch 4999 | Total: 0.5577 | Unsup: -0.4704 | Cont: 3.4270\n","Run 4 summary -- Acc: 0.5336, Prec: 0.6881, Rec: 0.5612, F1: 0.6105, LogLoss: 5.6356\n","\n","--- Run 5/10 (seed=46) ---\n","Epoch 0 | Total: 1.2086 | Unsup: -0.2381 | Cont: 4.8223\n","Epoch 500 | Total: 0.5783 | Unsup: -0.4839 | Cont: 3.5406\n","Epoch 1000 | Total: 0.5768 | Unsup: -0.4752 | Cont: 3.5069\n","Epoch 1500 | Total: 0.5668 | Unsup: -0.4801 | Cont: 3.4896\n","Epoch 2000 | Total: 0.5564 | Unsup: -0.4835 | Cont: 3.4666\n","Epoch 2500 | Total: 0.5500 | Unsup: -0.4767 | Cont: 3.4224\n","Epoch 3000 | Total: 0.6103 | Unsup: -0.4322 | Cont: 3.4752\n","Epoch 3500 | Total: 0.5652 | Unsup: -0.4885 | Cont: 3.5125\n","Epoch 4000 | Total: 0.5540 | Unsup: -0.4776 | Cont: 3.4386\n","Epoch 4500 | Total: 0.5434 | Unsup: -0.4790 | Cont: 3.4082\n","Epoch 4999 | Total: 0.6019 | Unsup: -0.4346 | Cont: 3.4549\n","Run 5 summary -- Acc: 0.5268, Prec: 0.6908, Rec: 0.5380, F1: 0.5959, LogLoss: 6.0402\n","\n","--- Run 6/10 (seed=47) ---\n","Epoch 0 | Total: 1.2342 | Unsup: -0.2385 | Cont: 4.9091\n","Epoch 500 | Total: 0.6504 | Unsup: -0.4282 | Cont: 3.5952\n","Epoch 1000 | Total: 0.5765 | Unsup: -0.4726 | Cont: 3.4972\n","Epoch 1500 | Total: 0.5862 | Unsup: -0.4724 | Cont: 3.5287\n","Epoch 2000 | Total: 0.5849 | Unsup: -0.4659 | Cont: 3.5027\n","Epoch 2500 | Total: 0.5693 | Unsup: -0.4845 | Cont: 3.5126\n","Epoch 3000 | Total: 0.5496 | Unsup: -0.4771 | Cont: 3.4223\n","Epoch 3500 | Total: 0.5599 | Unsup: -0.4705 | Cont: 3.4347\n","Epoch 4000 | Total: 0.5764 | Unsup: -0.4844 | Cont: 3.5358\n","Epoch 4500 | Total: 0.5735 | Unsup: -0.4705 | Cont: 3.4800\n","Epoch 4999 | Total: 0.5679 | Unsup: -0.4754 | Cont: 3.4775\n","Run 6 summary -- Acc: 0.5946, Prec: 0.7474, Rec: 0.6085, F1: 0.6632, LogLoss: 6.0845\n","\n","--- Run 7/10 (seed=48) ---\n","Epoch 0 | Total: 1.2060 | Unsup: -0.2345 | Cont: 4.8019\n","Epoch 500 | Total: 0.5916 | Unsup: -0.4757 | Cont: 3.5576\n","Epoch 1000 | Total: 0.5666 | Unsup: -0.4779 | Cont: 3.4818\n","Epoch 1500 | Total: 0.5548 | Unsup: -0.4788 | Cont: 3.4455\n","Epoch 2000 | Total: 0.5524 | Unsup: -0.4785 | Cont: 3.4364\n","Epoch 2500 | Total: 0.5581 | Unsup: -0.4743 | Cont: 3.4416\n","Epoch 3000 | Total: 0.5291 | Unsup: -0.4781 | Cont: 3.3572\n","Epoch 3500 | Total: 0.5685 | Unsup: -0.4723 | Cont: 3.4693\n","Epoch 4000 | Total: 0.5619 | Unsup: -0.4697 | Cont: 3.4387\n","Epoch 4500 | Total: 0.5697 | Unsup: -0.4811 | Cont: 3.5025\n","Epoch 4999 | Total: 0.5849 | Unsup: -0.4590 | Cont: 3.4798\n","Run 7 summary -- Acc: 0.6283, Prec: 0.7836, Rec: 0.6299, F1: 0.6904, LogLoss: 3.7416\n","\n","--- Run 8/10 (seed=49) ---\n","Epoch 0 | Total: 1.2121 | Unsup: -0.2386 | Cont: 4.8359\n","Epoch 500 | Total: 0.6047 | Unsup: -0.4665 | Cont: 3.5707\n","Epoch 1000 | Total: 0.5851 | Unsup: -0.4739 | Cont: 3.5297\n","Epoch 1500 | Total: 0.5390 | Unsup: -0.4857 | Cont: 3.4157\n","Epoch 2000 | Total: 0.5645 | Unsup: -0.4825 | Cont: 3.4900\n","Epoch 2500 | Total: 0.5938 | Unsup: -0.4610 | Cont: 3.5161\n","Epoch 3000 | Total: 0.5695 | Unsup: -0.4569 | Cont: 3.4213\n","Epoch 3500 | Total: 0.5600 | Unsup: -0.4781 | Cont: 3.4604\n","Epoch 4000 | Total: 0.5683 | Unsup: -0.4787 | Cont: 3.4900\n","Epoch 4500 | Total: 0.5507 | Unsup: -0.4632 | Cont: 3.3798\n","Epoch 4999 | Total: 0.5682 | Unsup: -0.4783 | Cont: 3.4884\n","Run 8 summary -- Acc: 0.6283, Prec: 0.7775, Rec: 0.6382, F1: 0.6955, LogLoss: 3.8791\n","\n","--- Run 9/10 (seed=50) ---\n","Epoch 0 | Total: 1.2179 | Unsup: -0.2369 | Cont: 4.8492\n","Epoch 500 | Total: 0.6055 | Unsup: -0.4500 | Cont: 3.5183\n","Epoch 1000 | Total: 0.5603 | Unsup: -0.4812 | Cont: 3.4716\n","Epoch 1500 | Total: 0.5660 | Unsup: -0.4728 | Cont: 3.4629\n","Epoch 2000 | Total: 0.5874 | Unsup: -0.4532 | Cont: 3.4684\n","Epoch 2500 | Total: 0.5648 | Unsup: -0.4901 | Cont: 3.5160\n","Epoch 3000 | Total: 0.5610 | Unsup: -0.4802 | Cont: 3.4706\n","Epoch 3500 | Total: 0.5574 | Unsup: -0.4817 | Cont: 3.4637\n","Epoch 4000 | Total: 0.5710 | Unsup: -0.4773 | Cont: 3.4943\n","Epoch 4500 | Total: 0.5597 | Unsup: -0.4746 | Cont: 3.4476\n","Epoch 4999 | Total: 0.5754 | Unsup: -0.4718 | Cont: 3.4909\n","Run 9 summary -- Acc: 0.6252, Prec: 0.7876, Rec: 0.6187, F1: 0.6845, LogLoss: 7.4805\n","\n","--- Run 10/10 (seed=51) ---\n","Epoch 0 | Total: 1.2076 | Unsup: -0.2397 | Cont: 4.8245\n","Epoch 500 | Total: 0.6353 | Unsup: -0.4556 | Cont: 3.6363\n","Epoch 1000 | Total: 0.5769 | Unsup: -0.4746 | Cont: 3.5051\n","Epoch 1500 | Total: 0.5781 | Unsup: -0.4714 | Cont: 3.4985\n","Epoch 2000 | Total: 0.5648 | Unsup: -0.4866 | Cont: 3.5046\n","Epoch 2500 | Total: 0.5851 | Unsup: -0.4693 | Cont: 3.5148\n","Epoch 3000 | Total: 0.6002 | Unsup: -0.4616 | Cont: 3.5394\n","Epoch 3500 | Total: 0.5827 | Unsup: -0.4642 | Cont: 3.4895\n","Epoch 4000 | Total: 0.5694 | Unsup: -0.4611 | Cont: 3.4348\n","Epoch 4500 | Total: 0.5685 | Unsup: -0.4655 | Cont: 3.4468\n","Epoch 4999 | Total: 0.5851 | Unsup: -0.4631 | Cont: 3.4941\n","Run 10 summary -- Acc: 0.6563, Prec: 0.8096, Rec: 0.6531, F1: 0.7160, LogLoss: 7.6241\n","\n","--- RESULTS FOR LAMBDA = 0.3 ---\n","Accuracy: 0.5960 ± 0.0445\n","Precision: 0.7524 ± 0.0422\n","Recall: 0.6037 ± 0.0382\n","F1 Score: 0.6621 ± 0.0405\n","Log Loss: 5.4436 ± 1.3943\n","\n","================ LAMBDA = 2 ================\n","\n","\n","--- Run 1/10 (seed=42) ---\n","Epoch 0 | Total: 9.5162 | Unsup: -0.2369 | Cont: 4.8765\n","Epoch 500 | Total: 6.3104 | Unsup: -0.4642 | Cont: 3.3873\n","Epoch 1000 | Total: 6.1008 | Unsup: -0.4748 | Cont: 3.2878\n","Epoch 1500 | Total: 6.2306 | Unsup: -0.4662 | Cont: 3.3484\n","Epoch 2000 | Total: 6.0896 | Unsup: -0.4806 | Cont: 3.2851\n","Epoch 2500 | Total: 6.0636 | Unsup: -0.4692 | Cont: 3.2664\n","Epoch 3000 | Total: 5.9937 | Unsup: -0.4813 | Cont: 3.2375\n","Epoch 3500 | Total: 6.1079 | Unsup: -0.4471 | Cont: 3.2775\n","Epoch 4000 | Total: 6.0210 | Unsup: -0.4857 | Cont: 3.2533\n","Epoch 4500 | Total: 6.0536 | Unsup: -0.4668 | Cont: 3.2602\n","Epoch 4999 | Total: 6.1370 | Unsup: -0.4673 | Cont: 3.3022\n","Run 1 summary -- Acc: 0.6276, Prec: 0.7762, Rec: 0.6382, F1: 0.6931, LogLoss: 7.1433\n","\n","--- Run 2/10 (seed=43) ---\n","Epoch 0 | Total: 9.4225 | Unsup: -0.2380 | Cont: 4.8303\n","Epoch 500 | Total: 6.2655 | Unsup: -0.4691 | Cont: 3.3673\n","Epoch 1000 | Total: 6.2737 | Unsup: -0.4766 | Cont: 3.3751\n","Epoch 1500 | Total: 6.0842 | Unsup: -0.4798 | Cont: 3.2820\n","Epoch 2000 | Total: 6.0881 | Unsup: -0.4676 | Cont: 3.2778\n","Epoch 2500 | Total: 6.0497 | Unsup: -0.4707 | Cont: 3.2602\n","Epoch 3000 | Total: 6.0800 | Unsup: -0.4867 | Cont: 3.2834\n","Epoch 3500 | Total: 6.0276 | Unsup: -0.4815 | Cont: 3.2545\n","Epoch 4000 | Total: 6.1006 | Unsup: -0.4660 | Cont: 3.2833\n","Epoch 4500 | Total: 5.9362 | Unsup: -0.4676 | Cont: 3.2019\n","Epoch 4999 | Total: 6.1033 | Unsup: -0.4827 | Cont: 3.2930\n","Run 2 summary -- Acc: 0.6102, Prec: 0.7625, Rec: 0.6206, F1: 0.6766, LogLoss: 4.3748\n","\n","--- Run 3/10 (seed=44) ---\n","Epoch 0 | Total: 9.2913 | Unsup: -0.2376 | Cont: 4.7644\n","Epoch 500 | Total: 6.2342 | Unsup: -0.4649 | Cont: 3.3496\n","Epoch 1000 | Total: 6.1646 | Unsup: -0.4741 | Cont: 3.3194\n","Epoch 1500 | Total: 6.1602 | Unsup: -0.4790 | Cont: 3.3196\n","Epoch 2000 | Total: 6.0512 | Unsup: -0.4718 | Cont: 3.2615\n","Epoch 2500 | Total: 6.0513 | Unsup: -0.4892 | Cont: 3.2702\n","Epoch 3000 | Total: 6.0826 | Unsup: -0.4625 | Cont: 3.2725\n","Epoch 3500 | Total: 6.0395 | Unsup: -0.4821 | Cont: 3.2608\n","Epoch 4000 | Total: 6.0258 | Unsup: -0.4651 | Cont: 3.2455\n","Epoch 4500 | Total: 6.0050 | Unsup: -0.4835 | Cont: 3.2443\n","Epoch 4999 | Total: 6.0810 | Unsup: -0.4864 | Cont: 3.2837\n","Run 3 summary -- Acc: 0.6382, Prec: 0.7951, Rec: 0.6354, F1: 0.6985, LogLoss: 3.5663\n","\n","--- Run 4/10 (seed=45) ---\n","Epoch 0 | Total: 9.4981 | Unsup: -0.2374 | Cont: 4.8677\n","Epoch 500 | Total: 6.2445 | Unsup: -0.4764 | Cont: 3.3604\n","Epoch 1000 | Total: 6.0851 | Unsup: -0.4788 | Cont: 3.2820\n","Epoch 1500 | Total: 6.1788 | Unsup: -0.4710 | Cont: 3.3249\n","Epoch 2000 | Total: 6.0788 | Unsup: -0.4746 | Cont: 3.2767\n","Epoch 2500 | Total: 5.9382 | Unsup: -0.4731 | Cont: 3.2056\n","Epoch 3000 | Total: 5.9411 | Unsup: -0.4771 | Cont: 3.2091\n","Epoch 3500 | Total: 6.0921 | Unsup: -0.4556 | Cont: 3.2739\n","Epoch 4000 | Total: 5.9540 | Unsup: -0.4726 | Cont: 3.2133\n","Epoch 4500 | Total: 6.0892 | Unsup: -0.4707 | Cont: 3.2799\n","Epoch 4999 | Total: 5.9712 | Unsup: -0.4742 | Cont: 3.2227\n","Run 4 summary -- Acc: 0.5274, Prec: 0.6871, Rec: 0.5464, F1: 0.6003, LogLoss: 5.4303\n","\n","--- Run 5/10 (seed=46) ---\n","Epoch 0 | Total: 9.4065 | Unsup: -0.2381 | Cont: 4.8223\n","Epoch 500 | Total: 6.2452 | Unsup: -0.4837 | Cont: 3.3644\n","Epoch 1000 | Total: 6.1607 | Unsup: -0.4714 | Cont: 3.3161\n","Epoch 1500 | Total: 6.1378 | Unsup: -0.4722 | Cont: 3.3050\n","Epoch 2000 | Total: 6.1193 | Unsup: -0.4846 | Cont: 3.3019\n","Epoch 2500 | Total: 6.0170 | Unsup: -0.4773 | Cont: 3.2471\n","Epoch 3000 | Total: 6.1151 | Unsup: -0.4425 | Cont: 3.2788\n","Epoch 3500 | Total: 6.1806 | Unsup: -0.4908 | Cont: 3.3357\n","Epoch 4000 | Total: 6.0476 | Unsup: -0.4686 | Cont: 3.2581\n","Epoch 4500 | Total: 5.9720 | Unsup: -0.4772 | Cont: 3.2246\n","Epoch 4999 | Total: 6.1206 | Unsup: -0.4285 | Cont: 3.2745\n","Run 5 summary -- Acc: 0.5280, Prec: 0.6934, Rec: 0.5362, F1: 0.5956, LogLoss: 6.0094\n","\n","--- Run 6/10 (seed=47) ---\n","Epoch 0 | Total: 9.5797 | Unsup: -0.2385 | Cont: 4.9091\n","Epoch 500 | Total: 6.3330 | Unsup: -0.4757 | Cont: 3.4044\n","Epoch 1000 | Total: 6.1054 | Unsup: -0.4784 | Cont: 3.2919\n","Epoch 1500 | Total: 6.1872 | Unsup: -0.4796 | Cont: 3.3334\n","Epoch 2000 | Total: 6.1226 | Unsup: -0.4791 | Cont: 3.3008\n","Epoch 2500 | Total: 6.1657 | Unsup: -0.4421 | Cont: 3.3039\n","Epoch 3000 | Total: 5.9250 | Unsup: -0.4784 | Cont: 3.2017\n","Epoch 3500 | Total: 6.0217 | Unsup: -0.4853 | Cont: 3.2535\n","Epoch 4000 | Total: 6.2068 | Unsup: -0.4497 | Cont: 3.3282\n","Epoch 4500 | Total: 6.0820 | Unsup: -0.4726 | Cont: 3.2773\n","Epoch 4999 | Total: 6.1148 | Unsup: -0.4779 | Cont: 3.2964\n","Run 6 summary -- Acc: 0.5212, Prec: 0.6831, Rec: 0.5371, F1: 0.5927, LogLoss: 5.3031\n","\n","--- Run 7/10 (seed=48) ---\n","Epoch 0 | Total: 9.3692 | Unsup: -0.2345 | Cont: 4.8019\n","Epoch 500 | Total: 6.3045 | Unsup: -0.4690 | Cont: 3.3867\n","Epoch 1000 | Total: 6.1219 | Unsup: -0.4773 | Cont: 3.2996\n","Epoch 1500 | Total: 6.0117 | Unsup: -0.4833 | Cont: 3.2475\n","Epoch 2000 | Total: 6.0167 | Unsup: -0.4765 | Cont: 3.2466\n","Epoch 2500 | Total: 6.0259 | Unsup: -0.4758 | Cont: 3.2508\n","Epoch 3000 | Total: 5.8191 | Unsup: -0.4841 | Cont: 3.1516\n","Epoch 3500 | Total: 6.0761 | Unsup: -0.4787 | Cont: 3.2774\n","Epoch 4000 | Total: 6.0158 | Unsup: -0.4752 | Cont: 3.2455\n","Epoch 4500 | Total: 6.1447 | Unsup: -0.4825 | Cont: 3.3136\n","Epoch 4999 | Total: 6.1190 | Unsup: -0.4711 | Cont: 3.2951\n","Run 7 summary -- Acc: 0.6214, Prec: 0.7807, Rec: 0.6197, F1: 0.6827, LogLoss: 3.8529\n","\n","--- Run 8/10 (seed=49) ---\n","Epoch 0 | Total: 9.4331 | Unsup: -0.2386 | Cont: 4.8359\n","Epoch 500 | Total: 6.3030 | Unsup: -0.4683 | Cont: 3.3856\n","Epoch 1000 | Total: 6.2218 | Unsup: -0.4737 | Cont: 3.3477\n","Epoch 1500 | Total: 5.9529 | Unsup: -0.4780 | Cont: 3.2154\n","Epoch 2000 | Total: 6.1097 | Unsup: -0.4713 | Cont: 3.2905\n","Epoch 2500 | Total: 6.1926 | Unsup: -0.4629 | Cont: 3.3278\n","Epoch 3000 | Total: 5.9795 | Unsup: -0.4768 | Cont: 3.2281\n","Epoch 3500 | Total: 6.0587 | Unsup: -0.4800 | Cont: 3.2693\n","Epoch 4000 | Total: 6.1195 | Unsup: -0.4845 | Cont: 3.3020\n","Epoch 4500 | Total: 5.9205 | Unsup: -0.4679 | Cont: 3.1942\n","Epoch 4999 | Total: 6.0822 | Unsup: -0.4814 | Cont: 3.2818\n","Run 8 summary -- Acc: 0.6270, Prec: 0.7849, Rec: 0.6262, F1: 0.6900, LogLoss: 3.6914\n","\n","--- Run 9/10 (seed=50) ---\n","Epoch 0 | Total: 9.4616 | Unsup: -0.2369 | Cont: 4.8492\n","Epoch 500 | Total: 6.2436 | Unsup: -0.4650 | Cont: 3.3543\n","Epoch 1000 | Total: 6.1076 | Unsup: -0.4623 | Cont: 3.2849\n","Epoch 1500 | Total: 6.0902 | Unsup: -0.4745 | Cont: 3.2823\n","Epoch 2000 | Total: 6.0829 | Unsup: -0.4819 | Cont: 3.2824\n","Epoch 2500 | Total: 6.2097 | Unsup: -0.4626 | Cont: 3.3362\n","Epoch 3000 | Total: 6.1153 | Unsup: -0.4738 | Cont: 3.2945\n","Epoch 3500 | Total: 6.0700 | Unsup: -0.4871 | Cont: 3.2785\n","Epoch 4000 | Total: 6.1649 | Unsup: -0.4535 | Cont: 3.3092\n","Epoch 4500 | Total: 6.0392 | Unsup: -0.4614 | Cont: 3.2503\n","Epoch 4999 | Total: 6.1320 | Unsup: -0.4671 | Cont: 3.2995\n","Run 9 summary -- Acc: 0.6102, Prec: 0.7759, Rec: 0.6030, F1: 0.6697, LogLoss: 7.2310\n","\n","--- Run 10/10 (seed=51) ---\n","Epoch 0 | Total: 9.4092 | Unsup: -0.2397 | Cont: 4.8245\n","Epoch 500 | Total: 6.4334 | Unsup: -0.4454 | Cont: 3.4394\n","Epoch 1000 | Total: 6.1685 | Unsup: -0.4551 | Cont: 3.3118\n","Epoch 1500 | Total: 6.1256 | Unsup: -0.4714 | Cont: 3.2985\n","Epoch 2000 | Total: 6.1569 | Unsup: -0.4806 | Cont: 3.3188\n","Epoch 2500 | Total: 6.1629 | Unsup: -0.4825 | Cont: 3.3227\n","Epoch 3000 | Total: 6.2227 | Unsup: -0.4801 | Cont: 3.3514\n","Epoch 3500 | Total: 6.1179 | Unsup: -0.4787 | Cont: 3.2983\n","Epoch 4000 | Total: 6.0199 | Unsup: -0.4554 | Cont: 3.2376\n","Epoch 4500 | Total: 5.9925 | Unsup: -0.4817 | Cont: 3.2371\n","Epoch 4999 | Total: 6.0978 | Unsup: -0.4845 | Cont: 3.2912\n","Run 10 summary -- Acc: 0.6326, Prec: 0.7854, Rec: 0.6364, F1: 0.6956, LogLoss: 7.1191\n","\n","--- RESULTS FOR LAMBDA = 2 ---\n","Accuracy: 0.5944 ± 0.0459\n","Precision: 0.7524 ± 0.0430\n","Recall: 0.5999 ± 0.0406\n","F1 Score: 0.6595 ± 0.0423\n","Log Loss: 5.3721 ± 1.3945\n","\n","================ LAMBDA = 5 ================\n","\n","\n","--- Run 1/10 (seed=42) ---\n","Epoch 0 | Total: 24.1458 | Unsup: -0.2369 | Cont: 4.8765\n","Epoch 500 | Total: 16.4289 | Unsup: -0.4635 | Cont: 3.3785\n","Epoch 1000 | Total: 15.9197 | Unsup: -0.4729 | Cont: 3.2785\n","Epoch 1500 | Total: 16.2198 | Unsup: -0.4692 | Cont: 3.3378\n","Epoch 2000 | Total: 15.8913 | Unsup: -0.4814 | Cont: 3.2745\n","Epoch 2500 | Total: 15.8068 | Unsup: -0.4707 | Cont: 3.2555\n","Epoch 3000 | Total: 15.6533 | Unsup: -0.4815 | Cont: 3.2269\n","Epoch 3500 | Total: 15.8945 | Unsup: -0.4450 | Cont: 3.2679\n","Epoch 4000 | Total: 15.7262 | Unsup: -0.4845 | Cont: 3.2421\n","Epoch 4500 | Total: 15.7779 | Unsup: -0.4705 | Cont: 3.2497\n","Epoch 4999 | Total: 15.9910 | Unsup: -0.4684 | Cont: 3.2919\n","Run 1 summary -- Acc: 0.6283, Prec: 0.7764, Rec: 0.6391, F1: 0.6938, LogLoss: 7.1685\n","\n","--- Run 2/10 (seed=43) ---\n","Epoch 0 | Total: 23.9134 | Unsup: -0.2380 | Cont: 4.8303\n","Epoch 500 | Total: 16.3388 | Unsup: -0.4676 | Cont: 3.3613\n","Epoch 1000 | Total: 16.3580 | Unsup: -0.4744 | Cont: 3.3665\n","Epoch 1500 | Total: 15.8953 | Unsup: -0.4789 | Cont: 3.2748\n","Epoch 2000 | Total: 15.8716 | Unsup: -0.4681 | Cont: 3.2679\n","Epoch 2500 | Total: 15.7928 | Unsup: -0.4701 | Cont: 3.2526\n","Epoch 3000 | Total: 15.8884 | Unsup: -0.4864 | Cont: 3.2750\n","Epoch 3500 | Total: 15.7516 | Unsup: -0.4813 | Cont: 3.2466\n","Epoch 4000 | Total: 15.9046 | Unsup: -0.4664 | Cont: 3.2742\n","Epoch 4500 | Total: 15.5019 | Unsup: -0.4668 | Cont: 3.1937\n","Epoch 4999 | Total: 15.9381 | Unsup: -0.4817 | Cont: 3.2840\n","Run 2 summary -- Acc: 0.6102, Prec: 0.7625, Rec: 0.6206, F1: 0.6766, LogLoss: 4.3526\n","\n","--- Run 3/10 (seed=44) ---\n","Epoch 0 | Total: 23.5846 | Unsup: -0.2376 | Cont: 4.7644\n","Epoch 500 | Total: 16.2343 | Unsup: -0.4633 | Cont: 3.3395\n","Epoch 1000 | Total: 16.0689 | Unsup: -0.4750 | Cont: 3.3088\n","Epoch 1500 | Total: 16.0617 | Unsup: -0.4798 | Cont: 3.3083\n","Epoch 2000 | Total: 15.7802 | Unsup: -0.4710 | Cont: 3.2502\n","Epoch 2500 | Total: 15.8152 | Unsup: -0.4893 | Cont: 3.2609\n","Epoch 3000 | Total: 15.8446 | Unsup: -0.4635 | Cont: 3.2616\n","Epoch 3500 | Total: 15.7703 | Unsup: -0.4820 | Cont: 3.2505\n","Epoch 4000 | Total: 15.7120 | Unsup: -0.4639 | Cont: 3.2352\n","Epoch 4500 | Total: 15.6746 | Unsup: -0.4840 | Cont: 3.2317\n","Epoch 4999 | Total: 15.8746 | Unsup: -0.4862 | Cont: 3.2722\n","Run 3 summary -- Acc: 0.6426, Prec: 0.8015, Rec: 0.6364, F1: 0.7014, LogLoss: 3.5440\n","\n","--- Run 4/10 (seed=45) ---\n","Epoch 0 | Total: 24.1013 | Unsup: -0.2374 | Cont: 4.8677\n","Epoch 500 | Total: 16.2854 | Unsup: -0.4756 | Cont: 3.3522\n","Epoch 1000 | Total: 15.8854 | Unsup: -0.4787 | Cont: 3.2728\n","Epoch 1500 | Total: 16.1036 | Unsup: -0.4717 | Cont: 3.3151\n","Epoch 2000 | Total: 15.8610 | Unsup: -0.4744 | Cont: 3.2671\n","Epoch 2500 | Total: 15.5049 | Unsup: -0.4725 | Cont: 3.1955\n","Epoch 3000 | Total: 15.5208 | Unsup: -0.4774 | Cont: 3.1996\n","Epoch 3500 | Total: 15.8572 | Unsup: -0.4582 | Cont: 3.2631\n","Epoch 4000 | Total: 15.5544 | Unsup: -0.4729 | Cont: 3.2055\n","Epoch 4500 | Total: 15.8818 | Unsup: -0.4699 | Cont: 3.2703\n","Epoch 4999 | Total: 15.5902 | Unsup: -0.4733 | Cont: 3.2127\n","Run 4 summary -- Acc: 0.5280, Prec: 0.6885, Rec: 0.5455, F1: 0.6002, LogLoss: 5.4030\n","\n","--- Run 5/10 (seed=46) ---\n","Epoch 0 | Total: 23.8734 | Unsup: -0.2381 | Cont: 4.8223\n","Epoch 500 | Total: 16.2982 | Unsup: -0.4842 | Cont: 3.3565\n","Epoch 1000 | Total: 16.0644 | Unsup: -0.4695 | Cont: 3.3068\n","Epoch 1500 | Total: 16.0064 | Unsup: -0.4721 | Cont: 3.2957\n","Epoch 2000 | Total: 15.9825 | Unsup: -0.4832 | Cont: 3.2931\n","Epoch 2500 | Total: 15.7173 | Unsup: -0.4768 | Cont: 3.2388\n","Epoch 3000 | Total: 15.9041 | Unsup: -0.4438 | Cont: 3.2696\n","Epoch 3500 | Total: 16.1453 | Unsup: -0.4894 | Cont: 3.3269\n","Epoch 4000 | Total: 15.7769 | Unsup: -0.4680 | Cont: 3.2490\n","Epoch 4500 | Total: 15.5971 | Unsup: -0.4791 | Cont: 3.2152\n","Epoch 4999 | Total: 15.8951 | Unsup: -0.4294 | Cont: 3.2649\n","Run 5 summary -- Acc: 0.5280, Prec: 0.6934, Rec: 0.5362, F1: 0.5956, LogLoss: 5.9638\n","\n","--- Run 6/10 (seed=47) ---\n","Epoch 0 | Total: 24.3071 | Unsup: -0.2385 | Cont: 4.9091\n","Epoch 500 | Total: 16.5003 | Unsup: -0.4754 | Cont: 3.3951\n","Epoch 1000 | Total: 15.9328 | Unsup: -0.4776 | Cont: 3.2821\n","Epoch 1500 | Total: 16.1413 | Unsup: -0.4786 | Cont: 3.3240\n","Epoch 2000 | Total: 15.9788 | Unsup: -0.4783 | Cont: 3.2914\n","Epoch 2500 | Total: 16.0216 | Unsup: -0.4422 | Cont: 3.2928\n","Epoch 3000 | Total: 15.4756 | Unsup: -0.4781 | Cont: 3.1907\n","Epoch 3500 | Total: 15.7390 | Unsup: -0.4841 | Cont: 3.2446\n","Epoch 4000 | Total: 16.1412 | Unsup: -0.4486 | Cont: 3.3180\n","Epoch 4500 | Total: 15.8655 | Unsup: -0.4723 | Cont: 3.2676\n","Epoch 4999 | Total: 15.9611 | Unsup: -0.4766 | Cont: 3.2875\n","Run 6 summary -- Acc: 0.5237, Prec: 0.6847, Rec: 0.5408, F1: 0.5957, LogLoss: 5.2858\n","\n","--- Run 7/10 (seed=48) ---\n","Epoch 0 | Total: 23.7747 | Unsup: -0.2345 | Cont: 4.8019\n","Epoch 500 | Total: 16.4269 | Unsup: -0.4688 | Cont: 3.3791\n","Epoch 1000 | Total: 15.9772 | Unsup: -0.4782 | Cont: 3.2911\n","Epoch 1500 | Total: 15.7044 | Unsup: -0.4844 | Cont: 3.2378\n","Epoch 2000 | Total: 15.7149 | Unsup: -0.4732 | Cont: 3.2376\n","Epoch 2500 | Total: 15.7271 | Unsup: -0.4772 | Cont: 3.2409\n","Epoch 3000 | Total: 15.2218 | Unsup: -0.4836 | Cont: 3.1411\n","Epoch 3500 | Total: 15.8609 | Unsup: -0.4780 | Cont: 3.2678\n","Epoch 4000 | Total: 15.7066 | Unsup: -0.4702 | Cont: 3.2354\n","Epoch 4500 | Total: 16.0393 | Unsup: -0.4820 | Cont: 3.3043\n","Epoch 4999 | Total: 15.9556 | Unsup: -0.4721 | Cont: 3.2855\n","Run 7 summary -- Acc: 0.6220, Prec: 0.7810, Rec: 0.6206, F1: 0.6834, LogLoss: 3.7928\n","\n","--- Run 8/10 (seed=49) ---\n","Epoch 0 | Total: 23.9407 | Unsup: -0.2386 | Cont: 4.8359\n","Epoch 500 | Total: 16.4080 | Unsup: -0.4701 | Cont: 3.3756\n","Epoch 1000 | Total: 16.2186 | Unsup: -0.4748 | Cont: 3.3387\n","Epoch 1500 | Total: 15.5460 | Unsup: -0.4753 | Cont: 3.2043\n","Epoch 2000 | Total: 15.9263 | Unsup: -0.4697 | Cont: 3.2792\n","Epoch 2500 | Total: 16.1262 | Unsup: -0.4622 | Cont: 3.3177\n","Epoch 3000 | Total: 15.6174 | Unsup: -0.4767 | Cont: 3.2188\n","Epoch 3500 | Total: 15.8180 | Unsup: -0.4795 | Cont: 3.2595\n","Epoch 4000 | Total: 15.9750 | Unsup: -0.4847 | Cont: 3.2920\n","Epoch 4500 | Total: 15.4535 | Unsup: -0.4707 | Cont: 3.1848\n","Epoch 4999 | Total: 15.8749 | Unsup: -0.4804 | Cont: 3.2711\n","Run 8 summary -- Acc: 0.6264, Prec: 0.7869, Rec: 0.6224, F1: 0.6883, LogLoss: 3.6544\n","\n","--- Run 9/10 (seed=50) ---\n","Epoch 0 | Total: 24.0094 | Unsup: -0.2369 | Cont: 4.8492\n","Epoch 500 | Total: 16.2605 | Unsup: -0.4695 | Cont: 3.3460\n","Epoch 1000 | Total: 15.9131 | Unsup: -0.4622 | Cont: 3.2751\n","Epoch 1500 | Total: 15.8848 | Unsup: -0.4750 | Cont: 3.2720\n","Epoch 2000 | Total: 15.8830 | Unsup: -0.4827 | Cont: 3.2731\n","Epoch 2500 | Total: 16.1713 | Unsup: -0.4630 | Cont: 3.3269\n","Epoch 3000 | Total: 15.9508 | Unsup: -0.4748 | Cont: 3.2851\n","Epoch 3500 | Total: 15.8622 | Unsup: -0.4866 | Cont: 3.2697\n","Epoch 4000 | Total: 16.0477 | Unsup: -0.4513 | Cont: 3.2998\n","Epoch 4500 | Total: 15.7392 | Unsup: -0.4604 | Cont: 3.2399\n","Epoch 4999 | Total: 15.9801 | Unsup: -0.4682 | Cont: 3.2897\n","Run 9 summary -- Acc: 0.6139, Prec: 0.7775, Rec: 0.6085, F1: 0.6741, LogLoss: 7.1823\n","\n","--- Run 10/10 (seed=51) ---\n","Epoch 0 | Total: 23.8826 | Unsup: -0.2397 | Cont: 4.8245\n","Epoch 500 | Total: 16.7025 | Unsup: -0.4454 | Cont: 3.4296\n","Epoch 1000 | Total: 16.0563 | Unsup: -0.4540 | Cont: 3.3021\n","Epoch 1500 | Total: 15.9656 | Unsup: -0.4697 | Cont: 3.2871\n","Epoch 2000 | Total: 16.0713 | Unsup: -0.4785 | Cont: 3.3100\n","Epoch 2500 | Total: 16.0785 | Unsup: -0.4829 | Cont: 3.3123\n","Epoch 3000 | Total: 16.2241 | Unsup: -0.4809 | Cont: 3.3410\n","Epoch 3500 | Total: 15.9633 | Unsup: -0.4768 | Cont: 3.2880\n","Epoch 4000 | Total: 15.6855 | Unsup: -0.4541 | Cont: 3.2279\n","Epoch 4500 | Total: 15.6476 | Unsup: -0.4821 | Cont: 3.2259\n","Epoch 4999 | Total: 15.9217 | Unsup: -0.4835 | Cont: 3.2810\n","Run 10 summary -- Acc: 0.6333, Prec: 0.7856, Rec: 0.6373, F1: 0.6963, LogLoss: 7.1103\n","\n","--- RESULTS FOR LAMBDA = 5 ---\n","Accuracy: 0.5956 ± 0.0460\n","Precision: 0.7538 ± 0.0435\n","Recall: 0.6007 ± 0.0403\n","F1 Score: 0.6605 ± 0.0422\n","Log Loss: 5.3458 ± 1.4037\n","\n","================ FINAL SUMMARY FOR ALL LAMBDAS ================\n","\n","  Lambda |           Accuracy |          Precision |             Recall |           F1 Score |           Log Loss\n","------------------------------------------------------------------------------------------------------------\n","   0.001 | 0.6208 ± 0.0418 | 0.7658 ± 0.0281 | 0.6371 ± 0.0599 | 0.6877 ± 0.0453 | 4.9435 ± 1.5487\n","    0.01 | 0.6256 ± 0.0487 | 0.7697 ± 0.0371 | 0.6419 ± 0.0604 | 0.6922 ± 0.0494 | 5.1013 ± 1.6667\n","    0.09 | 0.5928 ± 0.0260 | 0.7504 ± 0.0297 | 0.6011 ± 0.0159 | 0.6598 ± 0.0210 | 5.4454 ± 1.3324\n","     0.3 | 0.5960 ± 0.0445 | 0.7524 ± 0.0422 | 0.6037 ± 0.0382 | 0.6621 ± 0.0405 | 5.4436 ± 1.3943\n","       2 | 0.5944 ± 0.0459 | 0.7524 ± 0.0430 | 0.5999 ± 0.0406 | 0.6595 ± 0.0423 | 5.3721 ± 1.3945\n","       5 | 0.5956 ± 0.0460 | 0.7538 ± 0.0435 | 0.6007 ± 0.0403 | 0.6605 ± 0.0422 | 5.3458 ± 1.4037\n"]}]},{"cell_type":"code","source":["from sklearn.manifold import TSNE\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","\n","# ---- Ensure model is in eval mode ----\n","model.eval()\n","\n","# ---- Extract embeddings from full graph ----\n","with torch.no_grad():\n","    embeddings = model.online_encoder(data0)   # shape: [N, hidden_dim]\n","    embeddings = embeddings.cpu().numpy()\n","\n","# ---- Convert labels to numpy ----\n","if isinstance(y, torch.Tensor):\n","    labels = y.cpu().numpy()\n","else:\n","    labels = y\n","\n","# ---- Run t-SNE ----\n","tsne = TSNE(\n","    n_components=2,\n","    perplexity=30,\n","    learning_rate=200,\n","    # n_iter=1000, # Removed n_iter as it seems to be causing an error\n","    init=\"pca\",\n","    random_state=42\n",")\n","\n","embeddings_2d = tsne.fit_transform(embeddings)\n","\n","# ---- Plot t-SNE ----\n","plt.figure(figsize=(6.5, 5.5))\n","\n","scatter = plt.scatter(\n","    embeddings_2d[:, 0],\n","    embeddings_2d[:, 1],\n","    c=labels,\n","    cmap=\"coolwarm\",\n","    s=25,\n","    alpha=0.85\n",")\n","\n","# ---- Legend ----\n","legend = plt.legend(\n","    *scatter.legend_elements(),\n","    title=\"Class\",\n","    loc=\"best\"\n",")\n","plt.gca().add_artist(legend)\n","\n","# ---- Formatting ----\n","plt.title(\"t-SNE of Learned Subject Embeddings(Unsupervised clustering on NIFD)\")\n","plt.xlabel(\"t-SNE Dimension 1\")\n","plt.ylabel(\"t-SNE Dimension 2\")\n","plt.grid(alpha=0.3)\n","plt.tight_layout()\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557},"id":"-1OWmAZpNTXO","executionInfo":{"status":"ok","timestamp":1769060299757,"user_tz":-330,"elapsed":632,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"3e8d5cbc-9428-4648-d82c-4b9ae5eec5cf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 650x550 with 1 Axes>"],"image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","from torch_geometric.data import Data\n","import random\n","import scipy.sparse as sp\n","from copy import deepcopy\n","from typing import Dict, List\n","\n","# -------------------- Hyperparameters --------------------\n","num_runs = 10\n","num_epochs = 5000\n","lr = 1e-4\n","weight_decay = 1e-4\n","# lambda_list = [0.001, 0.005, 0.009, 0.01, 0.05, 0.09, 0.1, 0.3, 0.5, 0.9, 1, 2, 5, 8]\n","lambda_list =[5]\n","base_seed = 42\n","eval_every_epochs = 500  # set to None to evaluate only at end of each run\n","activ = 'ELU'\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","all_results: List[Dict] = []\n","\n","# -------------------- Loop over different lambda values --------------------\n","for lam in lambda_list:\n","    print(f\"\\n================ LAMBDA = {lam} ================\\n\")\n","\n","    # store per-lambda per-run metrics\n","    acc_scores: List[float] = []\n","    prec_scores: List[float] = []\n","    rec_scores: List[float] = []\n","    f1_scores: List[float] = []\n","    log_losses: List[float] = []\n","\n","    for run in range(num_runs):\n","        # -------------------- Reproducibility --------------------\n","        seed = base_seed + run\n","        torch.manual_seed(seed)\n","        np.random.seed(seed)\n","        random.seed(seed)\n","        if torch.cuda.is_available():\n","            torch.cuda.manual_seed_all(seed)\n","\n","        print(f\"\\n--- Run {run+1}/{num_runs} (seed={seed}) ---\")\n","\n","\n","        model = ARMA(feats_dim, 512, K, device, activ, cut).to(device)\n","\n","        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","        scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","        lambda_contrastive = lam  # use current lambda\n","\n","        # optional periodic evaluation accumulation (if you prefer)\n","        per_run_accs: List[float] = []\n","        per_run_precs: List[float] = []\n","        per_run_recs: List[float] = []\n","        per_run_f1s: List[float] = []\n","        per_run_log_losses: List[float] = []\n","\n","        # -------------------- Training loop --------------------\n","        for epoch in range(num_epochs):\n","            model.train()\n","            optimizer.zero_grad()\n","\n","            W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","\n","            # 2) Another edge drop (or subgraph)\n","            W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","\n","            # 3) Feature augmentations (numpy ops)\n","            rng = np.random.default_rng(seed + epoch)\n","            mask = rng.random(features_np.shape) >= 0.2\n","            features_aug1 = (features_np * mask.astype(np.float32))\n","\n","            # Feature cell dropout (random cell zeroing)\n","            aug_feat2 = features_np.copy()\n","            num_nodes_local, feat_dim = aug_feat2.shape\n","            drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","            if drop_feat_num > 0:\n","                flat_idx = rng.choice(num_nodes_local * feat_dim, size=drop_feat_num, replace=False)\n","                rows = (flat_idx // feat_dim)\n","                cols = (flat_idx % feat_dim)\n","                aug_feat2[rows, cols] = 0.0\n","            features_aug2 = aug_feat2.astype(np.float32)\n","\n","            # --------------------\n","            # Build PyG Data objects for the two views\n","            # --------------------\n","            node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","            data1 = Data(x=node_feats1, edge_index=edge_index1).to(device) # Modified to move the entire Data object to device\n","\n","            node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, W_aug2_edge_index, device)\n","            data2 = Data(x=node_feats2, edge_index=edge_index2).to(device) # Modified to move the entire Data object to device\n","\n","            # --------------------\n","            # Forward pass and losses\n","            # --------------------\n","            # Expected model output: S1, S2, logits1, logits2, l1, l2\n","            S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","            # TODO: adapt model.loss call to your implementation.\n","            # The original code used `unsup_loss = model.loss(A1, logits1)`.\n","            # If your loss expects adjacency or labels, provide A1 or appropriate input.\n","            unsup_loss = model.loss(A1, logits1)  # <-- ensure A1 is defined appropriately\n","\n","            cont_loss = 0.5 * (l1 + l2).mean()\n","            total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","            total_loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            # Optional: if your model uses EMA updates\n","            if hasattr(model, \"update_ma\"):\n","                model.update_ma()\n","\n","            # Periodic console logging\n","            if (eval_every_epochs is not None and epoch % eval_every_epochs == 0) or (epoch == num_epochs - 1):\n","                print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} | Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")\n","\n","                # -------------------- Periodic evaluation (optional) --------------------\n","                # Evaluate on data0 (full graph) if available\n","                if 'data0' in globals():\n","                    model.eval()\n","                    with torch.no_grad():\n","                        # Using data0 twice (as in your original script)\n","                        S1_eval, _, logits_eval, _, _, _ = model(data0, data0)\n","                        y_pred = torch.argmax(logits_eval, dim=1).cpu().numpy()\n","                        y_pred_proba = nnFn.softmax(logits_eval, dim=1).cpu().numpy()\n","\n","                        # If labels 'y' are torch tensor, convert to numpy\n","                        y_true = y.cpu().numpy() if isinstance(y, torch.Tensor) else y\n","\n","                        # check inverted labeling (keeps same behavior you had)\n","                        acc_score = accuracy_score(y_true, y_pred)\n","                        acc_score_inverted = accuracy_score(y_true, 1 - y_pred)\n","                        if acc_score_inverted > acc_score:\n","                            acc_score = acc_score_inverted\n","                            y_pred = 1 - y_pred\n","\n","                        prec_score = precision_score(y_true, y_pred, zero_division=0)\n","                        rec_score = recall_score(y_true, y_pred, zero_division=0)\n","                        f1 = f1_score(y_true, y_pred, zero_division=0)\n","                        try:\n","                            log_loss_value = log_loss(y_true, y_pred_proba)\n","                        except ValueError:\n","                            # fallback if probabilities are degenerate\n","                            log_loss_value = float(\"nan\")\n","\n","                        per_run_accs.append(acc_score)\n","                        per_run_precs.append(prec_score)\n","                        per_run_recs.append(rec_score)\n","                        per_run_f1s.append(f1)\n","                        per_run_log_losses.append(log_loss_value)\n","\n","        # -------------------- End of epochs for this run --------------------\n","        # Final evaluation at end of run if no periodic eval was run\n","        if len(per_run_accs) == 0 and 'data0' in globals():\n","            model.eval()\n","            with torch.no_grad():\n","                S1_eval, _, logits_eval, _, _, _ = model(data0, data0)\n","                y_pred = torch.argmax(logits_eval, dim=1).cpu().numpy()\n","                y_pred_proba = nnFn.softmax(logits_eval, dim=1).cpu().numpy()\n","                y_true = y.cpu().numpy() if isinstance(y, torch.Tensor) else y\n","\n","                acc_score = accuracy_score(y_true, y_pred)\n","                acc_score_inverted = accuracy_score(y_true, 1 - y_pred)\n","                if acc_score_inverted > acc_score:\n","                    acc_score = acc_score_inverted\n","                    y_pred = 1 - y_pred\n","\n","                prec_score = precision_score(y_true, y_pred, zero_division=0)\n","                rec_score = recall_score(y_true, y_pred, zero_division=0)\n","                f1 = f1_score(y_true, y_pred, zero_division=0)\n","                try:\n","                    log_loss_value = log_loss(y_true, y_pred_proba)\n","                except ValueError:\n","                    log_loss_value = float(\"nan\")\n","\n","                per_run_accs.append(acc_score)\n","                per_run_precs.append(prec_score)\n","                per_run_recs.append(rec_score)\n","                per_run_f1s.append(f1)\n","                per_run_log_losses.append(log_loss_value)\n","\n","        # Aggregate run results (mean of periodic evals if there were multiple)\n","        run_acc = float(np.mean(per_run_accs)) if len(per_run_accs) > 0 else float('nan')\n","        run_prec = float(np.mean(per_run_precs)) if len(per_run_precs) > 0 else float('nan')\n","        run_rec = float(np.mean(per_run_recs)) if len(per_run_recs) > 0 else float('nan')\n","        run_f1 = float(np.mean(per_run_f1s)) if len(per_run_f1s) > 0 else float('nan')\n","        run_logloss = float(np.nanmean(per_run_log_losses)) if len(per_run_log_losses) > 0 else float('nan')\n","\n","        acc_scores.append(run_acc)\n","        prec_scores.append(run_prec)\n","        rec_scores.append(run_rec)\n","        f1_scores.append(run_f1)\n","        log_losses.append(run_logloss)\n","\n","        print(f\"Run {run+1} summary -- Acc: {run_acc:.4f}, Prec: {run_prec:.4f}, Rec: {run_rec:.4f}, F1: {run_f1:.4f}, LogLoss: {run_logloss:.4f}\")\n","\n","    # -------------------- Store results for this lambda --------------------\n","    lambda_results = {\n","        \"lambda\": lam,\n","        \"accuracy\": (float(np.nanmean(acc_scores)), float(np.nanstd(acc_scores))),\n","        \"precision\": (float(np.nanmean(prec_scores)), float(np.nanstd(prec_scores))),\n","        \"recall\": (float(np.nanmean(rec_scores)), float(np.nanstd(rec_scores))),\n","        \"f1\": (float(np.nanmean(f1_scores)), float(np.nanstd(f1_scores))),\n","        \"log_loss\": (float(np.nanmean(log_losses)), float(np.nanstd(log_losses)))\n","    }\n","    all_results.append(lambda_results)\n","\n","    print(f\"\\n--- RESULTS FOR LAMBDA = {lam} ---\")\n","    print(f\"Accuracy: {lambda_results['accuracy'][0]:.4f} \\u00b1 {lambda_results['accuracy'][1]:.4f}\")\n","    print(f\"Precision: {lambda_results['precision'][0]:.4f} \\u00b1 {lambda_results['precision'][1]:.4f}\")\n","    print(f\"Recall: {lambda_results['recall'][0]:.4f} \\u00b1 {lambda_results['recall'][1]:.4f}\")\n","    print(f\"F1 Score: {lambda_results['f1'][0]:.4f} \\u00b1 {lambda_results['f1'][1]:.4f}\")\n","    print(f\"Log Loss: {lambda_results['log_loss'][0]:.4f} \\u00b1 {lambda_results['log_loss'][1]:.4f}\")\n","\n","# -------------------- Final Summary --------------------\n","print(\"\\n================ FINAL SUMMARY FOR ALL LAMBDAS ================\\n\")\n","print(f\"{'Lambda':>8} | {'Accuracy':>18} | {'Precision':>18} | {'Recall':>18} | {'F1 Score':>18} | {'Log Loss':>18}\")\n","print(\"-\" * 108)\n","for res in all_results:\n","    print(f\"{res['lambda']:>8} | \"\n","          f\"{res['accuracy'][0]:.4f} \\u00b1 {res['accuracy'][1]:.4f} | \"\n","          f\"{res['precision'][0]:.4f} \\u00b1 {res['precision'][1]:.4f} | \"\n","          f\"{res['recall'][0]:.4f} \\u00b1 {res['recall'][1]:.4f} | \"\n","          f\"{res['f1'][0]:.4f} \\u00b1 {res['f1'][1]:.4f} | \"\n","          f\"{res['log_loss'][0]:.4f} \\u00b1 {res['log_loss'][1]:.4f}\")"],"metadata":{"id":"z19N3h-VWRGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","from torch_geometric.data import Data\n","import random\n","import scipy.sparse as sp\n","from typing import List, Dict\n","\n","num_runs = 10\n","num_epochs = 5000\n","lr = 1e-3\n","weight_decay = 1e-5\n","lambda_list = [0.001, 0.005, 0.009, 0.01, 0.05, 0.09, 0.1, 0.3, 0.5, 0.9, 1, 2, 5, 8]\n","base_seed = 42\n","eval_every_epochs = 100  # set to None to evaluate only at end of each run\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","all_results: List[Dict] = []\n","\n","for lam in lambda_list:\n","    print(f\"\\n================ LAMBDA = {lam} ================\\n\")\n","\n","    # store per-lambda per-run metrics\n","    acc_scores: List[float] = []\n","    prec_scores: List[float] = []\n","    rec_scores: List[float] = []\n","    f1_scores: List[float] = []\n","    log_losses: List[float] = []\n","\n","    for run in range(num_runs):\n","        # -------------------- Reproducibility --------------------\n","        seed = base_seed + run\n","        torch.manual_seed(seed)\n","        np.random.seed(seed)\n","        random.seed(seed)\n","        if torch.cuda.is_available():\n","            torch.cuda.manual_seed_all(seed)\n","\n","        print(f\"\\n--- Run {run+1}/{num_runs} (seed={seed}) ---\")\n","\n","\n","        model = ARMA(feats_dim, 512, K, device, activ, cut).to(device)\n","\n","        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","        scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","        lambda_contrastive = lam  # use current lambda\n","\n","        # optional periodic evaluation accumulation (if you prefer)\n","        per_run_accs: List[float] = []\n","        per_run_precs: List[float] = []\n","        per_run_recs: List[float] = []\n","        per_run_f1s: List[float] = []\n","        per_run_log_losses: List[float] = []\n","\n","        # -------------------- Training loop --------------------\n","        for epoch in range(num_epochs):\n","            model.train()\n","            optimizer.zero_grad()\n","\n","            W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","\n","            # 2) Another edge drop (or subgraph)\n","            W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","\n","            # 3) Feature augmentations (numpy ops)\n","            rng = np.random.default_rng(seed + epoch)\n","            mask = rng.random(features_np.shape) >= 0.2\n","            features_aug1 = (features_np * mask.astype(np.float32))\n","\n","            # Feature cell dropout (random cell zeroing)\n","            aug_feat2 = features_np.copy()\n","            num_nodes_local, feat_dim = aug_feat2.shape\n","            drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","            if drop_feat_num > 0:\n","                flat_idx = rng.choice(num_nodes_local * feat_dim, size=drop_feat_num, replace=False)\n","                rows = (flat_idx // feat_dim)\n","                cols = (flat_idx % feat_dim)\n","                aug_feat2[rows, cols] = 0.0\n","            features_aug2 = aug_feat2.astype(np.float32)\n","\n","            # --------------------\n","            # Build PyG Data objects for the two views\n","            # --------------------\n","            node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","            data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","\n","            node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, W_aug2_edge_index, device)\n","            data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","            # --------------------\n","            # Forward pass and losses\n","            # --------------------\n","            # Expected model output: S1, S2, logits1, logits2, l1, l2\n","            S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","            # TODO: adapt model.loss call to your implementation.\n","            # The original code used `unsup_loss = model.loss(A1, logits1)`.\n","            # If your loss expects adjacency or labels, provide A1 or appropriate input.\n","            unsup_loss = model.loss(A1, logits1)  # <-- ensure A1 is defined appropriately\n","\n","            cont_loss = 0.5 * (l1 + l2).mean()\n","            total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","            total_loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","\n","            # Optional: if your model uses EMA updates\n","            if hasattr(model, \"update_ma\"):\n","                model.update_ma()\n","\n","            # Periodic console logging\n","            if (eval_every_epochs is not None and epoch % eval_every_epochs == 0) or (epoch == num_epochs - 1):\n","                print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} | Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")\n","\n","                # -------------------- Periodic evaluation (optional) --------------------\n","                # Evaluate on data0 (full graph) if available\n","                if 'data0' in globals():\n","                    model.eval()\n","                    with torch.no_grad():\n","                        # Using data0 twice (as in your original script)\n","                        S1_eval, _, logits_eval, _, _, _ = model(data0, data0)\n","                        y_pred = torch.argmax(logits_eval, dim=1).cpu().numpy()\n","                        y_pred_proba = nnFn.softmax(logits_eval, dim=1).cpu().numpy()\n","\n","                        # If labels 'y' are torch tensor, convert to numpy\n","                        y_true = y.cpu().numpy() if isinstance(y, torch.Tensor) else y\n","\n","                        # check inverted labeling (keeps same behavior you had)\n","                        acc_score = accuracy_score(y_true, y_pred)\n","                        acc_score_inverted = accuracy_score(y_true, 1 - y_pred)\n","                        if acc_score_inverted > acc_score:\n","                            acc_score = acc_score_inverted\n","                            y_pred = 1 - y_pred\n","\n","                        prec_score = precision_score(y_true, y_pred, zero_division=0)\n","                        rec_score = recall_score(y_true, y_pred, zero_division=0)\n","                        f1 = f1_score(y_true, y_pred, zero_division=0)\n","                        try:\n","                            log_loss_value = log_loss(y_true, y_pred_proba)\n","                        except ValueError:\n","                            # fallback if probabilities are degenerate\n","                            log_loss_value = float(\"nan\")\n","\n","                        per_run_accs.append(acc_score)\n","                        per_run_precs.append(prec_score)\n","                        per_run_recs.append(rec_score)\n","                        per_run_f1s.append(f1)\n","                        per_run_log_losses.append(log_loss_value)\n","\n","        # -------------------- End of epochs for this run --------------------\n","        # Final evaluation at end of run if no periodic eval was run\n","        if len(per_run_accs) == 0 and 'data0' in globals():\n","            model.eval()\n","            with torch.no_grad():\n","                S1_eval, _, logits_eval, _, _, _ = model(data0, data0)\n","                y_pred = torch.argmax(logits_eval, dim=1).cpu().numpy()\n","                y_pred_proba = nnFn.softmax(logits_eval, dim=1).cpu().numpy()\n","                y_true = y.cpu().numpy() if isinstance(y, torch.Tensor) else y\n","\n","                acc_score = accuracy_score(y_true, y_pred)\n","                acc_score_inverted = accuracy_score(y_true, 1 - y_pred)\n","                if acc_score_inverted > acc_score:\n","                    acc_score = acc_score_inverted\n","                    y_pred = 1 - y_pred\n","\n","                prec_score = precision_score(y_true, y_pred, zero_division=0)\n","                rec_score = recall_score(y_true, y_pred, zero_division=0)\n","                f1 = f1_score(y_true, y_pred, zero_division=0)\n","                try:\n","                    log_loss_value = log_loss(y_true, y_pred_proba)\n","                except ValueError:\n","                    log_loss_value = float(\"nan\")\n","\n","                per_run_accs.append(acc_score)\n","                per_run_precs.append(prec_score)\n","                per_run_recs.append(rec_score)\n","                per_run_f1s.append(f1)\n","                per_run_log_losses.append(log_loss_value)\n","\n","        # Aggregate run results (mean of periodic evals if there were multiple)\n","        run_acc = float(np.mean(per_run_accs)) if len(per_run_accs) > 0 else float('nan')\n","        run_prec = float(np.mean(per_run_precs)) if len(per_run_precs) > 0 else float('nan')\n","        run_rec = float(np.mean(per_run_recs)) if len(per_run_recs) > 0 else float('nan')\n","        run_f1 = float(np.mean(per_run_f1s)) if len(per_run_f1s) > 0 else float('nan')\n","        run_logloss = float(np.nanmean(per_run_log_losses)) if len(per_run_log_losses) > 0 else float('nan')\n","\n","        acc_scores.append(run_acc)\n","        prec_scores.append(run_prec)\n","        rec_scores.append(run_rec)\n","        f1_scores.append(run_f1)\n","        log_losses.append(run_logloss)\n","\n","        print(f\"Run {run+1} summary -- Acc: {run_acc:.4f}, Prec: {run_prec:.4f}, Rec: {run_rec:.4f}, F1: {run_f1:.4f}, LogLoss: {run_logloss:.4f}\")\n","\n","    # -------------------- Store results for this lambda --------------------\n","    lambda_results = {\n","        \"lambda\": lam,\n","        \"accuracy\": (float(np.nanmean(acc_scores)), float(np.nanstd(acc_scores))),\n","        \"precision\": (float(np.nanmean(prec_scores)), float(np.nanstd(prec_scores))),\n","        \"recall\": (float(np.nanmean(rec_scores)), float(np.nanstd(rec_scores))),\n","        \"f1\": (float(np.nanmean(f1_scores)), float(np.nanstd(f1_scores))),\n","        \"log_loss\": (float(np.nanmean(log_losses)), float(np.nanstd(log_losses)))\n","    }\n","    all_results.append(lambda_results)\n","\n","    print(f\"\\n--- RESULTS FOR LAMBDA = {lam} ---\")\n","    print(f\"Accuracy: {lambda_results['accuracy'][0]:.4f} ± {lambda_results['accuracy'][1]:.4f}\")\n","    print(f\"Precision: {lambda_results['precision'][0]:.4f} ± {lambda_results['precision'][1]:.4f}\")\n","    print(f\"Recall: {lambda_results['recall'][0]:.4f} ± {lambda_results['recall'][1]:.4f}\")\n","    print(f\"F1 Score: {lambda_results['f1'][0]:.4f} ± {lambda_results['f1'][1]:.4f}\")\n","    print(f\"Log Loss: {lambda_results['log_loss'][0]:.4f} ± {lambda_results['log_loss'][1]:.4f}\")\n","\n","# -------------------- Final Summary --------------------\n","print(\"\\n================ FINAL SUMMARY FOR ALL LAMBDAS ================\\n\")\n","print(f\"{'Lambda':>8} | {'Accuracy':>18} | {'Precision':>18} | {'Recall':>18} | {'F1 Score':>18} | {'Log Loss':>18}\")\n","print(\"-\" * 108)\n","for res in all_results:\n","    print(f\"{res['lambda']:>8} | \"\n","          f\"{res['accuracy'][0]:.4f} ± {res['accuracy'][1]:.4f} | \"\n","          f\"{res['precision'][0]:.4f} ± {res['precision'][1]:.4f} | \"\n","          f\"{res['recall'][0]:.4f} ± {res['recall'][1]:.4f} | \"\n","          f\"{res['f1'][0]:.4f} ± {res['f1'][1]:.4f} | \"\n","          f\"{res['log_loss'][0]:.4f} ± {res['log_loss'][1]:.4f}\")"],"metadata":{"id":"vkUjKes96j_6"},"execution_count":null,"outputs":[]}]}
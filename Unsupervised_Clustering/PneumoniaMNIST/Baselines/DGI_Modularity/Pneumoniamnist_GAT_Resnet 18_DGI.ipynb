{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YXFd7Zsz-3XQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "import random\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQ6KiAvW-5rn",
    "outputId": "f92af273-25d0-46ec-c066-4087a27e9083"
   },
   "outputs": [],
   "source": [
    "#data = np.load('pneumoniamnist_224.npz', allow_pickle=True)\n",
    "data = np.load('pneumoniamnist_224.npz', allow_pickle=True)\n",
    "# Combine train, val, and test sets\n",
    "all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n",
    "all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5856, 3, 224, 224]) torch.Size([5856])\n"
     ]
    }
   ],
   "source": [
    "images = all_images.astype(np.float32) / 255.0\n",
    "images = np.repeat(images[:, None, :, :], 3, axis=1)  # Convert to 3 channels (N, 3, 224, 224)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X = torch.tensor(images)\n",
    "y = torch.tensor(all_labels).long()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, y)\n",
    "class0_indices = [i for i in range(len(y)) if y[i] == 0]\n",
    "class1_indices = [i for i in range(len(y)) if y[i] == 1]\n",
    "\n",
    "random.seed(42)\n",
    "sampled_class0 = random.sample(class0_indices, min(2000, len(class0_indices)))\n",
    "sampled_class1 = random.sample(class1_indices, min(2000, len(class1_indices)))\n",
    "\n",
    "combined_indices = sampled_class0 + sampled_class1\n",
    "random.shuffle(combined_indices)\n",
    "\n",
    "# Final subset\n",
    "final_dataset = Subset(dataset, combined_indices)\n",
    "final_loader = DataLoader(final_dataset, batch_size=64, shuffle=False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/va797/tmp_pyg118/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/home/va797/tmp_pyg118/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (3583, 512)\n",
      "Label shape: (3583,)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # Remove final classification layer\n",
    "resnet = resnet.cuda() if torch.cuda.is_available() else resnet\n",
    "resnet.eval()\n",
    "resnet_feats = []\n",
    "y_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in final_loader:\n",
    "        imgs = imgs.cuda() if torch.cuda.is_available() else imgs\n",
    "        features = resnet(imgs)\n",
    "        resnet_feats.append(features.cpu())\n",
    "        y_list.extend(labels.cpu().tolist())\n",
    "F = torch.cat(resnet_feats, dim=0).numpy().astype(np.float32)\n",
    "y_labels = np.array(y_list).astype(np.float32)\n",
    "\n",
    "print(\"Feature shape:\", F.shape)\n",
    "print(\"Label shape:\", y_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MkKdnnzI-7zI"
   },
   "outputs": [],
   "source": [
    "def create_adj(F, alpha=1):\n",
    "    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n",
    "    W = np.dot(F_norm, F_norm.T)\n",
    "    W = (W >= alpha).astype(np.float32)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Qk8neEfFl7kX"
   },
   "outputs": [],
   "source": [
    "def asymmetrize_random(adj_matrix, seed=None):\n",
    "    \"\"\"\n",
    "    Randomly orient each undirected edge from a symmetric adjacency matrix.\n",
    "    \"\"\"\n",
    "    adj = np.array(adj_matrix, dtype=np.float32)\n",
    "    n = adj.shape[0]\n",
    "    asym = np.zeros((n, n), dtype=np.float32)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if adj[i, j]:\n",
    "                if rng.random() < 0.5:\n",
    "                    asym[i, j] = adj[i, j]\n",
    "                else:\n",
    "                    asym[j, i] = adj[i, j]\n",
    "\n",
    "    return asym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3583, 512], edge_index=[2, 1642013])\n"
     ]
    }
   ],
   "source": [
    "features = F # Use ResNet embeddings\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "W0 = create_adj(features, alpha=0.9)\n",
    "# W_asym = asymmetrize_random(W0, seed=42)\n",
    "node_feats, edge_index = load_data(W0, features)\n",
    "data = Data(x=node_feats, edge_index=edge_index).to(device)\n",
    "A = torch.from_numpy(W0).to(device)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zz160NfE--Tg",
    "outputId": "747750e9-006f-48b7-cf0a-83d772b31669"
   },
   "outputs": [],
   "source": [
    "# features = F # Use ResNet embeddings\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# W0 = create_adj(features, alpha=0.9)\n",
    "# W_asym = asymmetrize_random(W0, seed=42)\n",
    "# node_feats, edge_index = load_data(W_asym, features) # Use ResNet embeddings here as well\n",
    "# data = Data(x=node_feats, edge_index=edge_index).to(device)\n",
    "# A = torch.from_numpy(W_asym).to(device)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nhh413xH_Awp"
   },
   "outputs": [],
   "source": [
    "class GATEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, heads, device, activ):\n",
    "        super(GATEncoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads)\n",
    "        self.batchnorm = nn.BatchNorm1d(hidden_dim * heads)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.mlp = nn.Linear(hidden_dim * heads, hidden_dim * heads)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = self.dropout(x)\n",
    "        x = self.batchnorm(x)\n",
    "        logits = self.mlp(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "t1CWUjjG48t_"
   },
   "outputs": [],
   "source": [
    "class AvgReadout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, seq, msk=None):\n",
    "        if msk is None:\n",
    "            return torch.mean(seq, 0)\n",
    "        else:\n",
    "            msk = torch.unsqueeze(msk, -1)\n",
    "            return torch.sum(seq * msk, 0) / torch.sum(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IbNOUPjg42s9"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super().__init__()\n",
    "        self.f_k = nn.Bilinear(n_h, n_h, 1)\n",
    "        nn.init.xavier_uniform_(self.f_k.weight.data)\n",
    "        if self.f_k.bias is not None:\n",
    "            self.f_k.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, c, h_pl, h_mi):\n",
    "        c_x = torch.unsqueeze(c, 0).expand_as(h_pl)\n",
    "        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 1)\n",
    "        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 1)\n",
    "        logits = torch.cat((sc_1, sc_2), 0)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7X7cwk2N8Al2"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, n_in, n_h, heads, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATEncoder(n_in, n_h, heads=heads, device='cuda' if torch.cuda.is_available() else 'cpu', activ=nn.ELU())\n",
    "        self.read = AvgReadout()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        self.disc = Discriminator(n_h * heads)\n",
    "\n",
    "    def forward(self, seq1, seq2, edge_index):\n",
    "        # Create Data objects for the GATEncoder\n",
    "        data1 = Data(x=seq1, edge_index=edge_index)\n",
    "        data2 = Data(x=seq2, edge_index=edge_index)\n",
    "\n",
    "        h_1 = self.gat1(data1)\n",
    "        c = self.read(h_1)\n",
    "        c = self.sigm(c)\n",
    "        h_2 = self.gat1(data2)\n",
    "        logits = self.disc(c, h_1, h_2)\n",
    "        return logits, h_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yVuaMXM1C9T3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class DGI_with_classifier(DGI):\n",
    "    def __init__(self, n_in, n_h, heads, n_classes=2, cut=0, dropout=0.25):\n",
    "        super().__init__(n_in, n_h, heads, dropout=dropout)\n",
    "        self.classifier = nn.Linear(n_h * heads, n_classes)\n",
    "        self.cut = cut\n",
    "\n",
    "\n",
    "    def get_embeddings(self, node_feats, edge_index):\n",
    "        _, embeddings = self.forward(node_feats, node_feats, edge_index)\n",
    "        return embeddings\n",
    "\n",
    "    def cut_loss(self, A, S):\n",
    "        # ensure tensor\n",
    "        if isinstance(A, np.ndarray):\n",
    "            A = torch.from_numpy(A).float().to(S.device)\n",
    "\n",
    "        S = F.softmax(S, dim=1)   # cluster assignment\n",
    "        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n",
    "        num = torch.trace(A_pool)\n",
    "\n",
    "        D = torch.diag(torch.sum(A, dim=-1))\n",
    "        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n",
    "        den = torch.trace(D_pooled)\n",
    "\n",
    "        mincut_loss = -(num / den)\n",
    "\n",
    "        St_S = torch.matmul(S.t(), S)\n",
    "        I_S = torch.eye(S.shape[1], device=A.device)\n",
    "        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n",
    "\n",
    "        return mincut_loss + ortho_loss\n",
    "\n",
    "    def modularity_loss(self, A, S):\n",
    "        # ensure tensor\n",
    "        if isinstance(A, np.ndarray):\n",
    "            A = torch.from_numpy(A).float().to(S.device)\n",
    "\n",
    "        C = F.softmax(S, dim=1)   # cluster assignment\n",
    "        d = torch.sum(A, dim=1)\n",
    "        m = torch.sum(A)\n",
    "\n",
    "        B = A - torch.outer(d, d) / (2 * m)\n",
    "\n",
    "        I_S = torch.eye(C.shape[1], device=A.device)\n",
    "        k = torch.norm(I_S)\n",
    "        n = S.shape[0]\n",
    "\n",
    "        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n",
    "        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n",
    "\n",
    "        return modularity_term + collapse_reg_term\n",
    "\n",
    "    def Reg_loss(self, A, embeddings):\n",
    "        # classifier output used as soft cluster assignment\n",
    "        logits = self.classifier(embeddings)\n",
    "\n",
    "        if self.cut == 1:\n",
    "            return self.cut_loss(A, logits)\n",
    "        else:\n",
    "            return self.modularity_loss(A, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ClSGTZaA_xt",
    "outputId": "5b7f24b6-9012-4c9a-cf1a-73d43fa430ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | DGI Loss: 0.7157 | Reg Loss: -0.2886 | Total: 0.5714\n",
      "Epoch 500 | DGI Loss: 0.6942 | Reg Loss: -0.4623 | Total: 0.4631\n",
      "Epoch 1000 | DGI Loss: 0.7049 | Reg Loss: -0.4655 | Total: 0.4721\n",
      "Epoch 1500 | DGI Loss: 0.6932 | Reg Loss: -0.4673 | Total: 0.4596\n",
      "Epoch 2000 | DGI Loss: 0.6932 | Reg Loss: -0.4678 | Total: 0.4593\n",
      "Epoch 2500 | DGI Loss: 0.6931 | Reg Loss: -0.4676 | Total: 0.4594\n",
      "Epoch 3000 | DGI Loss: 0.6931 | Reg Loss: -0.4678 | Total: 0.4592\n",
      "Epoch 3500 | DGI Loss: 0.6936 | Reg Loss: -0.4676 | Total: 0.4598\n",
      "Epoch 4000 | DGI Loss: 0.6938 | Reg Loss: -0.4676 | Total: 0.4600\n",
      "Epoch 4500 | DGI Loss: 0.6932 | Reg Loss: -0.4681 | Total: 0.4591\n",
      "Epoch 5000 | DGI Loss: 0.6935 | Reg Loss: -0.4680 | Total: 0.4596\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256\n",
    "cut = 0\n",
    "dropout = 0.25\n",
    "heads = 2\n",
    "# make sure adjacency is a tensor on GPU\n",
    "if isinstance(A, np.ndarray):\n",
    "    A = torch.from_numpy(A).float().to(device)\n",
    "else:\n",
    "    A = A.float().to(device)\n",
    "\n",
    "model = DGI_with_classifier(features.shape[1], hidden_dim, heads=heads, n_classes=2, cut=cut, dropout=dropout).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    perm = torch.randperm(node_feats.size(0))\n",
    "    corrupt_features = node_feats[perm]\n",
    "\n",
    "    logits, embeddings = model(node_feats.to(device), corrupt_features.to(device), edge_index.to(device))\n",
    "\n",
    "    lbl = torch.cat([\n",
    "        torch.ones(node_feats.size(0)),\n",
    "        torch.zeros(node_feats.size(0))\n",
    "    ]).to(device)\n",
    "\n",
    "    dgi_loss = bce_loss(logits.squeeze(), lbl)\n",
    "    reg_loss = model.Reg_loss(A, embeddings)\n",
    "    loss = dgi_loss + 0.5 * reg_loss\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch} | DGI Loss: {dgi_loss.item():.4f} | Reg Loss: {reg_loss.item():.4f} | Total: {loss.item():.4f}\")\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "giN_kiZckBqV"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model.get_embeddings(node_feats.to(device), edge_index.to(device))\n",
    "    class_probabilities = F.softmax(model.classifier(embeddings), dim=1).cpu().numpy()\n",
    "\n",
    "y_pred = np.argmax(class_probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVJYp9cnauDO",
    "outputId": "9481a916-c4d5-4f1b-c711-aace623636b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.11359196204298075\n",
      "Accuracy (inverted): 0.8864080379570193\n",
      "Precision: 0.18488745980707397\n",
      "Recall: 0.1725\n",
      "F1: 0.1784790481117434\n",
      "Log Loss: 10.384787549280185\n"
     ]
    }
   ],
   "source": [
    "# Extract the true labels for the subset used for prediction\n",
    "y_subset = y[combined_indices].cpu().numpy()\n",
    "\n",
    "acc_score = accuracy_score(y_subset, y_pred)\n",
    "acc_score_inverted = accuracy_score(y_subset, 1 - y_pred)\n",
    "prec_score = precision_score(y_subset, y_pred)\n",
    "rec_score = recall_score(y_subset, y_pred)\n",
    "f1 = f1_score(y_subset, y_pred)\n",
    "log_loss_value = log_loss(y_subset, class_probabilities)\n",
    "\n",
    "print(\"Accuracy:\", acc_score)\n",
    "print(\"Accuracy (inverted):\", acc_score_inverted)\n",
    "print(\"Precision:\", prec_score)\n",
    "print(\"Recall:\", rec_score)\n",
    "print(\"F1:\", f1)\n",
    "print(\"Log Loss:\", log_loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2TNZi1qljP0",
    "outputId": "f1c43910-61e1-4aec-8cd0-0f5b2ce46fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ LAMBDA = 0.001 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.0003 | Total: 0.7172\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4092 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4133 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4170 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4163 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4143 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4151 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4175 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4139 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4155 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4166 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 1 | Accuracy: 0.9090 | Precision: 0.9549 | Recall: 0.8785 | F1: 0.9151 | LogLoss: 0.2267\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.0003 | Total: 0.7095\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.3974 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4039 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4072 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4086 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4088 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4066 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4070 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4063 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4079 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4080 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 2 | Accuracy: 0.9037 | Precision: 0.9600 | Recall: 0.8635 | F1: 0.9092 | LogLoss: 0.2355\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.0003 | Total: 0.7124\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.3882 | λ*Reg: -0.0004 | Total: 0.6928\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.3954 | λ*Reg: -0.0004 | Total: 0.6928\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.3962 | λ*Reg: -0.0004 | Total: 0.6928\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.3992 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.3983 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.3985 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.3974 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.3957 | λ*Reg: -0.0004 | Total: 0.6928\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.3965 | λ*Reg: -0.0004 | Total: 0.6928\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.3966 | λ*Reg: -0.0004 | Total: 0.6928\n",
      "Run 3 | Accuracy: 0.8889 | Precision: 0.9293 | Recall: 0.8670 | F1: 0.8971 | LogLoss: 0.2765\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.0003 | Total: 0.7141\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4093 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4190 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4185 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4199 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4209 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4198 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4191 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4194 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4195 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4205 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 4 | Accuracy: 0.8323 | Precision: 0.9191 | Recall: 0.7670 | F1: 0.8362 | LogLoss: 0.4778\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.0003 | Total: 0.7112\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4157 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4228 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4236 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4257 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4235 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4240 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4249 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4243 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4240 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4268 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 5 | Accuracy: 0.8702 | Precision: 0.9637 | Recall: 0.7975 | F1: 0.8728 | LogLoss: 0.3533\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.0003 | Total: 0.7103\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4301 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4360 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4339 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4342 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4355 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4353 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4332 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4356 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4348 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4340 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 6 | Accuracy: 0.9096 | Precision: 0.9671 | Recall: 0.8675 | F1: 0.9146 | LogLoss: 0.2679\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.0003 | Total: 0.7134\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4115 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4176 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4193 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4192 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4194 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4202 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4173 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4202 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4191 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4185 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 7 | Accuracy: 0.8281 | Precision: 0.9230 | Recall: 0.7550 | F1: 0.8306 | LogLoss: 0.4947\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.0003 | Total: 0.7204\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4029 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4110 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4127 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4126 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4140 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4160 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4146 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4144 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4143 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4149 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 8 | Accuracy: 0.8800 | Precision: 0.9230 | Recall: 0.8565 | F1: 0.8885 | LogLoss: 0.3153\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.0003 | Total: 0.7125\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4072 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4108 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4114 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4109 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4091 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4121 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4120 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4100 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4126 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4104 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 9 | Accuracy: 0.9020 | Precision: 0.9459 | Recall: 0.8745 | F1: 0.9088 | LogLoss: 0.2512\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.0003 | Total: 0.7111\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4061 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4140 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4175 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4158 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4153 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4155 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4159 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4164 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4173 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4151 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 10 | Accuracy: 0.8909 | Precision: 0.9589 | Recall: 0.8405 | F1: 0.8958 | LogLoss: 0.3102\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.001 ---\n",
      "Accuracy : 0.8815 ± 0.0283\n",
      "Precision: 0.9445 ± 0.0180\n",
      "Recall   : 0.8367 ± 0.0439\n",
      "F1 Score : 0.8869 ± 0.0294\n",
      "Log Loss : 0.3209 ± 0.0904\n",
      "\n",
      "================ LAMBDA = 0.005 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.0014 | Total: 0.7161\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4454 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4502 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4521 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4523 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4518 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4512 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4526 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4516 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4525 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4515 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Run 1 | Accuracy: 0.9143 | Precision: 0.9495 | Recall: 0.8940 | F1: 0.9209 | LogLoss: 0.3047\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.0014 | Total: 0.7084\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.3664 | λ*Reg: -0.0018 | Total: 0.6913\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4136 | λ*Reg: -0.0021 | Total: 0.6911\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4220 | λ*Reg: -0.0021 | Total: 0.6910\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4228 | λ*Reg: -0.0021 | Total: 0.6910\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4237 | λ*Reg: -0.0021 | Total: 0.6910\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4227 | λ*Reg: -0.0021 | Total: 0.6910\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4220 | λ*Reg: -0.0021 | Total: 0.6910\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4220 | λ*Reg: -0.0021 | Total: 0.6910\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4232 | λ*Reg: -0.0021 | Total: 0.6910\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4247 | λ*Reg: -0.0021 | Total: 0.6910\n",
      "Run 2 | Accuracy: 0.8845 | Precision: 0.9088 | Recall: 0.8815 | F1: 0.8949 | LogLoss: 0.3577\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.0014 | Total: 0.7113\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4398 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4458 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4469 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4488 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4478 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4488 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4483 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4480 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4472 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4468 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Run 3 | Accuracy: 0.9018 | Precision: 0.9383 | Recall: 0.8820 | F1: 0.9093 | LogLoss: 0.3652\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.0014 | Total: 0.7129\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4466 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4548 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4546 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4548 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4554 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4553 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4557 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4554 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4552 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4553 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Run 4 | Accuracy: 0.8953 | Precision: 0.9532 | Recall: 0.8545 | F1: 0.9011 | LogLoss: 0.3922\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.0014 | Total: 0.7101\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4500 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4573 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4588 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4581 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4582 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4584 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4577 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4593 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Run 5 | Accuracy: 0.8956 | Precision: 0.9672 | Recall: 0.8415 | F1: 0.9000 | LogLoss: 0.4776\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.0014 | Total: 0.7091\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4522 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4566 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4556 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4566 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4566 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4559 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4574 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Run 6 | Accuracy: 0.9115 | Precision: 0.9616 | Recall: 0.8765 | F1: 0.9171 | LogLoss: 0.3615\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.0014 | Total: 0.7123\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4446 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4484 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4497 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4503 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4496 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4511 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4490 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4502 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4501 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4498 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Run 7 | Accuracy: 0.8872 | Precision: 0.9493 | Recall: 0.8430 | F1: 0.8930 | LogLoss: 0.4351\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.0014 | Total: 0.7193\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4367 | λ*Reg: -0.0022 | Total: 0.6910\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4423 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4448 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4446 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4457 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4480 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4454 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4451 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4445 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4469 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Run 8 | Accuracy: 0.9110 | Precision: 0.9435 | Recall: 0.8940 | F1: 0.9181 | LogLoss: 0.3199\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.0014 | Total: 0.7113\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4384 | λ*Reg: -0.0022 | Total: 0.6910\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4475 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4478 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4493 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4474 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4489 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4488 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4468 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4480 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4492 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Run 9 | Accuracy: 0.9118 | Precision: 0.9488 | Recall: 0.8900 | F1: 0.9185 | LogLoss: 0.3164\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.0015 | Total: 0.7099\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4400 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4494 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4503 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4506 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4498 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4495 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4499 | λ*Reg: -0.0022 | Total: 0.6909\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4525 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4514 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4510 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Run 10 | Accuracy: 0.9048 | Precision: 0.9616 | Recall: 0.8640 | F1: 0.9102 | LogLoss: 0.3891\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.005 ---\n",
      "Accuracy : 0.9018 ± 0.0102\n",
      "Precision: 0.9482 ± 0.0156\n",
      "Recall   : 0.8721 ± 0.0191\n",
      "F1 Score : 0.9083 ± 0.0099\n",
      "Log Loss : 0.3719 ± 0.0515\n",
      "\n",
      "================ LAMBDA = 0.009 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.0026 | Total: 0.7150\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4531 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4563 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4573 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4578 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4575 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4570 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4578 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4574 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4578 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Run 1 | Accuracy: 0.9143 | Precision: 0.9476 | Recall: 0.8960 | F1: 0.9211 | LogLoss: 0.3554\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.0026 | Total: 0.7072\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4445 | λ*Reg: -0.0040 | Total: 0.6891\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4531 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4542 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4534 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4543 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4546 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4542 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4536 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4544 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4539 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Run 2 | Accuracy: 0.9135 | Precision: 0.9514 | Recall: 0.8905 | F1: 0.9199 | LogLoss: 0.3408\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.0026 | Total: 0.7101\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4500 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4535 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4544 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4552 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4543 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4551 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4549 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4550 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4547 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4540 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Run 3 | Accuracy: 0.9051 | Precision: 0.9378 | Recall: 0.8890 | F1: 0.9127 | LogLoss: 0.4127\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.0026 | Total: 0.7118\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4563 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4602 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4598 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4595 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4607 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4597 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4607 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4602 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4599 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4603 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Run 4 | Accuracy: 0.9020 | Precision: 0.9558 | Recall: 0.8645 | F1: 0.9078 | LogLoss: 0.4646\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.0026 | Total: 0.7089\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4582 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4620 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4612 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4623 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4617 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 5 | Accuracy: 0.8979 | Precision: 0.9679 | Recall: 0.8450 | F1: 0.9023 | LogLoss: 0.5633\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.0026 | Total: 0.7080\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4577 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4612 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4601 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4613 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4610 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4605 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4603 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4613 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4609 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 6 | Accuracy: 0.9143 | Precision: 0.9598 | Recall: 0.8835 | F1: 0.9201 | LogLoss: 0.4119\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.0026 | Total: 0.7112\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4523 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4549 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4557 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4564 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4557 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4566 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4558 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4564 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4560 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4564 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Run 7 | Accuracy: 0.8942 | Precision: 0.9536 | Recall: 0.8520 | F1: 0.8999 | LogLoss: 0.4915\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.0026 | Total: 0.7181\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4449 | λ*Reg: -0.0040 | Total: 0.6891\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4526 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4544 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4546 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4545 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4564 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4542 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4541 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4538 | λ*Reg: -0.0041 | Total: 0.6891\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4556 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Run 8 | Accuracy: 0.9115 | Precision: 0.9455 | Recall: 0.8930 | F1: 0.9185 | LogLoss: 0.3792\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.0026 | Total: 0.7102\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4494 | λ*Reg: -0.0040 | Total: 0.6891\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4555 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4555 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4557 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4569 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4565 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4555 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4558 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4568 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Run 9 | Accuracy: 0.9149 | Precision: 0.9535 | Recall: 0.8910 | F1: 0.9212 | LogLoss: 0.3665\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.0026 | Total: 0.7087\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4493 | λ*Reg: -0.0040 | Total: 0.6891\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4559 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4565 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4568 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4565 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4557 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4561 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4578 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4574 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4574 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Run 10 | Accuracy: 0.9093 | Precision: 0.9599 | Recall: 0.8740 | F1: 0.9149 | LogLoss: 0.4326\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.009 ---\n",
      "Accuracy : 0.9077 ± 0.0071\n",
      "Precision: 0.9533 ± 0.0080\n",
      "Recall   : 0.8779 ± 0.0173\n",
      "F1 Score : 0.9139 ± 0.0075\n",
      "Log Loss : 0.4218 ± 0.0655\n",
      "\n",
      "================ LAMBDA = 0.01 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.0028 | Total: 0.7147\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4540 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4572 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4578 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4583 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4580 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4576 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4586 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4582 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4584 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4580 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Run 1 | Accuracy: 0.9135 | Precision: 0.9471 | Recall: 0.8950 | F1: 0.9203 | LogLoss: 0.3706\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.0029 | Total: 0.7069\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4457 | λ*Reg: -0.0045 | Total: 0.6887\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4541 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4552 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4544 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4552 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4557 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4551 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4546 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4553 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4549 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Run 2 | Accuracy: 0.9140 | Precision: 0.9514 | Recall: 0.8915 | F1: 0.9205 | LogLoss: 0.3500\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.0028 | Total: 0.7099\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4507 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4541 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4547 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4556 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4547 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4553 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4553 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4552 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4553 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4544 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Run 3 | Accuracy: 0.9051 | Precision: 0.9327 | Recall: 0.8945 | F1: 0.9132 | LogLoss: 0.4282\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.0028 | Total: 0.7115\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4572 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4606 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4603 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4601 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4611 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4603 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4612 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4606 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4605 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4608 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 4 | Accuracy: 0.9032 | Precision: 0.9579 | Recall: 0.8645 | F1: 0.9088 | LogLoss: 0.4731\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.0028 | Total: 0.7086\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4590 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4620 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4620 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4630 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4625 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4617 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 5 | Accuracy: 0.8976 | Precision: 0.9679 | Recall: 0.8445 | F1: 0.9020 | LogLoss: 0.5776\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.0029 | Total: 0.7077\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4587 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4608 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4620 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4616 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4611 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4620 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 6 | Accuracy: 0.9152 | Precision: 0.9604 | Recall: 0.8845 | F1: 0.9209 | LogLoss: 0.4324\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.0029 | Total: 0.7109\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4530 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4557 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4564 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4565 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4573 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4566 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4569 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4567 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Run 7 | Accuracy: 0.8939 | Precision: 0.9530 | Recall: 0.8520 | F1: 0.8997 | LogLoss: 0.5039\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.0029 | Total: 0.7178\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4461 | λ*Reg: -0.0045 | Total: 0.6887\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4540 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4557 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4558 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4556 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4573 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4554 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4552 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4550 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4567 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Run 8 | Accuracy: 0.9118 | Precision: 0.9450 | Recall: 0.8940 | F1: 0.9188 | LogLoss: 0.3914\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.0028 | Total: 0.7099\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4510 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4565 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4565 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4580 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4567 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4579 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4575 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4566 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4568 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4577 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Run 9 | Accuracy: 0.9149 | Precision: 0.9539 | Recall: 0.8905 | F1: 0.9211 | LogLoss: 0.3775\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.0029 | Total: 0.7084\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4508 | λ*Reg: -0.0045 | Total: 0.6886\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4570 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4575 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4580 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4577 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4569 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4587 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4584 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4584 | λ*Reg: -0.0046 | Total: 0.6886\n",
      "Run 10 | Accuracy: 0.9110 | Precision: 0.9600 | Recall: 0.8770 | F1: 0.9166 | LogLoss: 0.4434\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.01 ---\n",
      "Accuracy : 0.9080 ± 0.0073\n",
      "Precision: 0.9529 ± 0.0093\n",
      "Recall   : 0.8788 ± 0.0178\n",
      "F1 Score : 0.9142 ± 0.0077\n",
      "Log Loss : 0.4348 ± 0.0658\n",
      "\n",
      "================ LAMBDA = 0.05 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.0142 | Total: 0.7033\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Run 1 | Accuracy: 0.9157 | Precision: 0.9492 | Recall: 0.8970 | F1: 0.9224 | LogLoss: 0.5645\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.0144 | Total: 0.6954\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4616 | λ*Reg: -0.0231 | Total: 0.6701\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Run 2 | Accuracy: 0.9152 | Precision: 0.9549 | Recall: 0.8900 | F1: 0.9213 | LogLoss: 0.5475\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.0142 | Total: 0.6985\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4625 | λ*Reg: -0.0231 | Total: 0.6700\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Run 3 | Accuracy: 0.9177 | Precision: 0.9438 | Recall: 0.9065 | F1: 0.9248 | LogLoss: 0.5085\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.0142 | Total: 0.7001\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Run 4 | Accuracy: 0.9082 | Precision: 0.9619 | Recall: 0.8700 | F1: 0.9136 | LogLoss: 0.6632\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.0142 | Total: 0.6972\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0231 | Total: 0.6700\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4652 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Run 5 | Accuracy: 0.9048 | Precision: 0.9657 | Recall: 0.8600 | F1: 0.9098 | LogLoss: 0.6390\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.0143 | Total: 0.6963\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0231 | Total: 0.6700\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Run 6 | Accuracy: 0.9152 | Precision: 0.9579 | Recall: 0.8870 | F1: 0.9211 | LogLoss: 0.5187\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.0143 | Total: 0.6995\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Run 7 | Accuracy: 0.9026 | Precision: 0.9609 | Recall: 0.8605 | F1: 0.9079 | LogLoss: 0.6704\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.0143 | Total: 0.7064\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4050 | λ*Reg: -0.0202 | Total: 0.6729\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4608 | λ*Reg: -0.0230 | Total: 0.6701\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0231 | Total: 0.6700\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0231 | Total: 0.6700\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0231 | Total: 0.6700\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0231 | Total: 0.6700\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0231 | Total: 0.6700\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0231 | Total: 0.6700\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4625 | λ*Reg: -0.0231 | Total: 0.6700\n",
      "Run 8 | Accuracy: 0.9054 | Precision: 0.9551 | Recall: 0.8715 | F1: 0.9114 | LogLoss: 0.6267\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.0142 | Total: 0.6986\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Run 9 | Accuracy: 0.9157 | Precision: 0.9574 | Recall: 0.8885 | F1: 0.9217 | LogLoss: 0.5664\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.0147 | Total: 0.6967\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0231 | Total: 0.6701\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4630 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0232 | Total: 0.6700\n",
      "Run 10 | Accuracy: 0.9140 | Precision: 0.9553 | Recall: 0.8875 | F1: 0.9202 | LogLoss: 0.4836\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.05 ---\n",
      "Accuracy : 0.9114 ± 0.0053\n",
      "Precision: 0.9562 ± 0.0060\n",
      "Recall   : 0.8819 ± 0.0148\n",
      "F1 Score : 0.9174 ± 0.0058\n",
      "Log Loss : 0.5789 ± 0.0635\n",
      "\n",
      "================ LAMBDA = 0.09 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.0256 | Total: 0.6919\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0417 | Total: 0.6514\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Run 1 | Accuracy: 0.9146 | Precision: 0.9496 | Recall: 0.8945 | F1: 0.9212 | LogLoss: 0.5456\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.0260 | Total: 0.6838\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0416 | Total: 0.6515\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0418 | Total: 0.6514\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Run 2 | Accuracy: 0.9099 | Precision: 0.9584 | Recall: 0.8765 | F1: 0.9156 | LogLoss: 0.5960\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.0256 | Total: 0.6871\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4606 | λ*Reg: -0.0415 | Total: 0.6517\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0418 | Total: 0.6514\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Run 3 | Accuracy: 0.9174 | Precision: 0.9475 | Recall: 0.9020 | F1: 0.9242 | LogLoss: 0.4531\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.0256 | Total: 0.6887\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 4 | Accuracy: 0.9090 | Precision: 0.9624 | Recall: 0.8710 | F1: 0.9144 | LogLoss: 0.7029\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.0256 | Total: 0.6859\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 5 | Accuracy: 0.9062 | Precision: 0.9658 | Recall: 0.8625 | F1: 0.9113 | LogLoss: 0.6799\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.0257 | Total: 0.6848\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0417 | Total: 0.6515\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4652 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Run 6 | Accuracy: 0.9118 | Precision: 0.9621 | Recall: 0.8765 | F1: 0.9173 | LogLoss: 0.5892\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.0257 | Total: 0.6881\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0417 | Total: 0.6515\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0418 | Total: 0.6514\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0418 | Total: 0.6514\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Run 7 | Accuracy: 0.9040 | Precision: 0.9615 | Recall: 0.8625 | F1: 0.9093 | LogLoss: 0.6435\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.0258 | Total: 0.6949\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4612 | λ*Reg: -0.0415 | Total: 0.6516\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4652 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4652 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Run 8 | Accuracy: 0.9135 | Precision: 0.9548 | Recall: 0.8870 | F1: 0.9196 | LogLoss: 0.6183\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.0255 | Total: 0.6872\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0418 | Total: 0.6514\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4652 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Run 9 | Accuracy: 0.9107 | Precision: 0.9641 | Recall: 0.8725 | F1: 0.9160 | LogLoss: 0.6338\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.0264 | Total: 0.6849\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4623 | λ*Reg: -0.0416 | Total: 0.6515\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Run 10 | Accuracy: 0.9118 | Precision: 0.9581 | Recall: 0.8805 | F1: 0.9177 | LogLoss: 0.5813\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.09 ---\n",
      "Accuracy : 0.9109 ± 0.0037\n",
      "Precision: 0.9584 ± 0.0058\n",
      "Recall   : 0.8786 ± 0.0122\n",
      "F1 Score : 0.9167 ± 0.0042\n",
      "Log Loss : 0.6044 ± 0.0672\n",
      "\n",
      "================ LAMBDA = 0.1 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.0284 | Total: 0.6891\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0463 | Total: 0.6468\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Run 1 | Accuracy: 0.9157 | Precision: 0.9526 | Recall: 0.8935 | F1: 0.9221 | LogLoss: 0.5462\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.0289 | Total: 0.6810\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0464 | Total: 0.6468\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Run 2 | Accuracy: 0.9104 | Precision: 0.9610 | Recall: 0.8750 | F1: 0.9160 | LogLoss: 0.6258\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.0285 | Total: 0.6843\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0462 | Total: 0.6469\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4652 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4652 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4652 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Run 3 | Accuracy: 0.9154 | Precision: 0.9487 | Recall: 0.8970 | F1: 0.9221 | LogLoss: 0.5001\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.0285 | Total: 0.6859\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Run 4 | Accuracy: 0.9073 | Precision: 0.9628 | Recall: 0.8675 | F1: 0.9127 | LogLoss: 0.7151\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.0285 | Total: 0.6830\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Run 5 | Accuracy: 0.9065 | Precision: 0.9653 | Recall: 0.8635 | F1: 0.9116 | LogLoss: 0.6842\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.0286 | Total: 0.6819\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0464 | Total: 0.6468\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Run 6 | Accuracy: 0.9121 | Precision: 0.9611 | Recall: 0.8780 | F1: 0.9177 | LogLoss: 0.5875\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.0285 | Total: 0.6852\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0463 | Total: 0.6468\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0464 | Total: 0.6467\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Run 7 | Accuracy: 0.9037 | Precision: 0.9610 | Recall: 0.8625 | F1: 0.9091 | LogLoss: 0.6688\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.0286 | Total: 0.6921\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0462 | Total: 0.6469\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Run 8 | Accuracy: 0.9154 | Precision: 0.9550 | Recall: 0.8905 | F1: 0.9216 | LogLoss: 0.6204\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.0284 | Total: 0.6844\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0465 | Total: 0.6467\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Run 9 | Accuracy: 0.9118 | Precision: 0.9647 | Recall: 0.8740 | F1: 0.9171 | LogLoss: 0.6464\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.0293 | Total: 0.6820\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0464 | Total: 0.6467\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Run 10 | Accuracy: 0.9118 | Precision: 0.9581 | Recall: 0.8805 | F1: 0.9177 | LogLoss: 0.6064\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.1 ---\n",
      "Accuracy : 0.9110 ± 0.0039\n",
      "Precision: 0.9590 ± 0.0051\n",
      "Recall   : 0.8782 ± 0.0116\n",
      "F1 Score : 0.9168 ± 0.0043\n",
      "Log Loss : 0.6201 ± 0.0611\n",
      "\n",
      "================ LAMBDA = 0.3 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.0853 | Total: 0.6322\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.1398 | Total: 0.5534\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.1399 | Total: 0.5532\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Run 1 | Accuracy: 0.9160 | Precision: 0.9540 | Recall: 0.8925 | F1: 0.9222 | LogLoss: 0.6854\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.0866 | Total: 0.6232\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.1398 | Total: 0.5533\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Run 2 | Accuracy: 0.9018 | Precision: 0.9640 | Recall: 0.8560 | F1: 0.9068 | LogLoss: 0.8152\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.0854 | Total: 0.6273\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.1398 | Total: 0.5533\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Run 3 | Accuracy: 0.9188 | Precision: 0.9533 | Recall: 0.8985 | F1: 0.9251 | LogLoss: 0.6302\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.0855 | Total: 0.6289\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.1399 | Total: 0.5533\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Run 4 | Accuracy: 0.9054 | Precision: 0.9647 | Recall: 0.8620 | F1: 0.9105 | LogLoss: 0.8142\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.0854 | Total: 0.6261\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.1396 | Total: 0.5535\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.1399 | Total: 0.5533\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Run 5 | Accuracy: 0.9071 | Precision: 0.9638 | Recall: 0.8660 | F1: 0.9123 | LogLoss: 0.7159\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.0858 | Total: 0.6247\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4652 | λ*Reg: -0.1395 | Total: 0.5536\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Run 6 | Accuracy: 0.9065 | Precision: 0.9685 | Recall: 0.8605 | F1: 0.9113 | LogLoss: 0.7373\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.0855 | Total: 0.6282\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.1397 | Total: 0.5535\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.1399 | Total: 0.5533\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.1399 | Total: 0.5532\n",
      "Run 7 | Accuracy: 0.9006 | Precision: 0.9681 | Recall: 0.8500 | F1: 0.9052 | LogLoss: 0.8504\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.0859 | Total: 0.6348\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.1396 | Total: 0.5535\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.1399 | Total: 0.5532\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Run 8 | Accuracy: 0.9152 | Precision: 0.9544 | Recall: 0.8905 | F1: 0.9214 | LogLoss: 0.7250\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.0851 | Total: 0.6277\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.1398 | Total: 0.5533\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Run 9 | Accuracy: 0.9101 | Precision: 0.9646 | Recall: 0.8710 | F1: 0.9154 | LogLoss: 0.7221\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.0880 | Total: 0.6233\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Run 10 | Accuracy: 0.9059 | Precision: 0.9648 | Recall: 0.8630 | F1: 0.9111 | LogLoss: 0.8081\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.3 ---\n",
      "Accuracy : 0.9087 ± 0.0058\n",
      "Precision: 0.9620 ± 0.0055\n",
      "Recall   : 0.8710 ± 0.0160\n",
      "F1 Score : 0.9141 ± 0.0064\n",
      "Log Loss : 0.7504 ± 0.0656\n",
      "\n",
      "================ LAMBDA = 0.5 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.1422 | Total: 0.5753\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.2328 | Total: 0.4603\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.2333 | Total: 0.4598\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.2334 | Total: 0.4598\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.2334 | Total: 0.4598\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Run 1 | Accuracy: 0.9163 | Precision: 0.9550 | Recall: 0.8920 | F1: 0.9224 | LogLoss: 0.6746\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.1443 | Total: 0.5655\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.2329 | Total: 0.4603\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.2334 | Total: 0.4598\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.2334 | Total: 0.4598\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Run 2 | Accuracy: 0.9076 | Precision: 0.9670 | Recall: 0.8640 | F1: 0.9126 | LogLoss: 0.7893\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.1423 | Total: 0.5704\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.2330 | Total: 0.4601\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Run 3 | Accuracy: 0.9107 | Precision: 0.9585 | Recall: 0.8780 | F1: 0.9165 | LogLoss: 0.7755\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.1425 | Total: 0.5719\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.2331 | Total: 0.4601\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Run 4 | Accuracy: 0.9045 | Precision: 0.9668 | Recall: 0.8585 | F1: 0.9094 | LogLoss: 0.8280\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.1423 | Total: 0.5692\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.2332 | Total: 0.4600\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Run 5 | Accuracy: 0.9009 | Precision: 0.9692 | Recall: 0.8495 | F1: 0.9054 | LogLoss: 0.8600\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.1430 | Total: 0.5675\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.2330 | Total: 0.4601\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Run 6 | Accuracy: 0.9026 | Precision: 0.9640 | Recall: 0.8575 | F1: 0.9076 | LogLoss: 0.7819\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.1426 | Total: 0.5712\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.2328 | Total: 0.4603\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.2333 | Total: 0.4598\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Run 7 | Accuracy: 0.9048 | Precision: 0.9631 | Recall: 0.8625 | F1: 0.9101 | LogLoss: 0.7897\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.1432 | Total: 0.5776\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.2330 | Total: 0.4602\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Run 8 | Accuracy: 0.9154 | Precision: 0.9569 | Recall: 0.8885 | F1: 0.9214 | LogLoss: 0.7470\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.1418 | Total: 0.5710\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.2328 | Total: 0.4604\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.2333 | Total: 0.4598\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.2334 | Total: 0.4598\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.2333 | Total: 0.4598\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.2334 | Total: 0.4598\n",
      "Run 9 | Accuracy: 0.9085 | Precision: 0.9660 | Recall: 0.8665 | F1: 0.9135 | LogLoss: 0.7227\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.1467 | Total: 0.5646\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.2329 | Total: 0.4603\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Run 10 | Accuracy: 0.9059 | Precision: 0.9632 | Recall: 0.8645 | F1: 0.9112 | LogLoss: 0.7575\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.5 ---\n",
      "Accuracy : 0.9077 ± 0.0049\n",
      "Precision: 0.9630 ± 0.0045\n",
      "Recall   : 0.8681 ± 0.0130\n",
      "F1 Score : 0.9130 ± 0.0053\n",
      "Log Loss : 0.7726 ± 0.0493\n",
      "\n",
      "================ LAMBDA = 0.9 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.2560 | Total: 0.4616\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.4198 | Total: 0.2733\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4204 | Total: 0.2727\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4205 | Total: 0.2727\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4204 | Total: 0.2727\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4205 | Total: 0.2726\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4204 | Total: 0.2727\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4205 | Total: 0.2726\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Run 1 | Accuracy: 0.9146 | Precision: 0.9549 | Recall: 0.8890 | F1: 0.9208 | LogLoss: 0.7097\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.2597 | Total: 0.4501\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.4201 | Total: 0.2731\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Run 2 | Accuracy: 0.9096 | Precision: 0.9645 | Recall: 0.8700 | F1: 0.9148 | LogLoss: 0.8437\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.2561 | Total: 0.4566\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.4200 | Total: 0.2732\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4204 | Total: 0.2727\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4204 | Total: 0.2727\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4205 | Total: 0.2726\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Run 3 | Accuracy: 0.9174 | Precision: 0.9542 | Recall: 0.8950 | F1: 0.9236 | LogLoss: 0.7131\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.2564 | Total: 0.4579\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.4200 | Total: 0.2732\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Run 4 | Accuracy: 0.9054 | Precision: 0.9674 | Recall: 0.8595 | F1: 0.9102 | LogLoss: 0.8910\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.2561 | Total: 0.4554\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.4199 | Total: 0.2733\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4204 | Total: 0.2727\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4205 | Total: 0.2727\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4205 | Total: 0.2726\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Run 5 | Accuracy: 0.8939 | Precision: 0.9688 | Recall: 0.8370 | F1: 0.8981 | LogLoss: 0.9371\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.2575 | Total: 0.4531\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.4199 | Total: 0.2732\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4205 | Total: 0.2726\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Run 6 | Accuracy: 0.9062 | Precision: 0.9633 | Recall: 0.8650 | F1: 0.9115 | LogLoss: 0.8156\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.2566 | Total: 0.4571\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.4197 | Total: 0.2734\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4205 | Total: 0.2727\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4205 | Total: 0.2726\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4205 | Total: 0.2726\n",
      "Run 7 | Accuracy: 0.9065 | Precision: 0.9628 | Recall: 0.8660 | F1: 0.9118 | LogLoss: 0.8295\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.2577 | Total: 0.4630\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.4199 | Total: 0.2732\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Run 8 | Accuracy: 0.9085 | Precision: 0.9578 | Recall: 0.8745 | F1: 0.9143 | LogLoss: 0.8084\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.2552 | Total: 0.4575\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.4201 | Total: 0.2730\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4205 | Total: 0.2727\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2726\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4205 | Total: 0.2726\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4205 | Total: 0.2726\n",
      "Run 9 | Accuracy: 0.9057 | Precision: 0.9658 | Recall: 0.8615 | F1: 0.9107 | LogLoss: 0.8470\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.2641 | Total: 0.4473\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.4201 | Total: 0.2730\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4206 | Total: 0.2725\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Run 10 | Accuracy: 0.9026 | Precision: 0.9599 | Recall: 0.8615 | F1: 0.9080 | LogLoss: 0.8642\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.9 ---\n",
      "Accuracy : 0.9070 ± 0.0061\n",
      "Precision: 0.9619 ± 0.0048\n",
      "Recall   : 0.8679 ± 0.0153\n",
      "F1 Score : 0.9124 ± 0.0066\n",
      "Log Loss : 0.8259 ± 0.0674\n",
      "\n",
      "================ LAMBDA = 1 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.2844 | Total: 0.4331\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.4667 | Total: 0.2264\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4672 | Total: 0.2259\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2259\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2259\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Run 1 | Accuracy: 0.9132 | Precision: 0.9538 | Recall: 0.8875 | F1: 0.9195 | LogLoss: 0.7419\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.2885 | Total: 0.4213\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.4669 | Total: 0.2262\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Run 2 | Accuracy: 0.9110 | Precision: 0.9636 | Recall: 0.8735 | F1: 0.9163 | LogLoss: 0.8471\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.2846 | Total: 0.4281\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.4665 | Total: 0.2267\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4672 | Total: 0.2260\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2259\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4671 | Total: 0.2260\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2259\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2259\n",
      "Run 3 | Accuracy: 0.9199 | Precision: 0.9534 | Recall: 0.9005 | F1: 0.9262 | LogLoss: 0.6786\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.2849 | Total: 0.4294\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.4669 | Total: 0.2263\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Run 4 | Accuracy: 0.9101 | Precision: 0.9630 | Recall: 0.8725 | F1: 0.9155 | LogLoss: 0.8392\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.2846 | Total: 0.4269\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.4668 | Total: 0.2264\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2259\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Run 5 | Accuracy: 0.8906 | Precision: 0.9685 | Recall: 0.8310 | F1: 0.8945 | LogLoss: 0.9751\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.2861 | Total: 0.4245\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.4667 | Total: 0.2264\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2259\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Run 6 | Accuracy: 0.9043 | Precision: 0.9616 | Recall: 0.8630 | F1: 0.9096 | LogLoss: 0.8313\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.2851 | Total: 0.4286\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.4667 | Total: 0.2264\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Run 7 | Accuracy: 0.9068 | Precision: 0.9628 | Recall: 0.8665 | F1: 0.9121 | LogLoss: 0.8562\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.2863 | Total: 0.4344\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.4670 | Total: 0.2261\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Run 8 | Accuracy: 0.9065 | Precision: 0.9587 | Recall: 0.8700 | F1: 0.9122 | LogLoss: 0.8713\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.2836 | Total: 0.4292\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.4667 | Total: 0.2265\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4672 | Total: 0.2259\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2259\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Run 9 | Accuracy: 0.9048 | Precision: 0.9657 | Recall: 0.8600 | F1: 0.9098 | LogLoss: 0.8479\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.2934 | Total: 0.4179\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.4666 | Total: 0.2265\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2257\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Run 10 | Accuracy: 0.9043 | Precision: 0.9600 | Recall: 0.8645 | F1: 0.9098 | LogLoss: 0.8458\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 1 ---\n",
      "Accuracy : 0.9071 ± 0.0072\n",
      "Precision: 0.9611 ± 0.0046\n",
      "Recall   : 0.8689 ± 0.0172\n",
      "F1 Score : 0.9126 ± 0.0078\n",
      "Log Loss : 0.8334 ± 0.0741\n",
      "\n",
      "================ LAMBDA = 2 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -0.5688 | Total: 0.1487\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.9342 | Total: -0.2410\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.9350 | Total: -0.2419\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2421\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9351 | Total: -0.2420\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2423\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2421\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9351 | Total: -0.2420\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2421\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9353 | Total: -0.2422\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2421\n",
      "Run 1 | Accuracy: 0.9152 | Precision: 0.9574 | Recall: 0.8875 | F1: 0.9211 | LogLoss: 0.8266\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -0.5771 | Total: 0.1327\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.9347 | Total: -0.2416\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9358 | Total: -0.2426\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9358 | Total: -0.2426\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9358 | Total: -0.2427\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9358 | Total: -0.2427\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Run 2 | Accuracy: 0.9065 | Precision: 0.9597 | Recall: 0.8690 | F1: 0.9121 | LogLoss: 0.9204\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -0.5691 | Total: 0.1436\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.9345 | Total: -0.2414\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2421\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9353 | Total: -0.2422\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2421\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9353 | Total: -0.2421\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2423\n",
      "Run 3 | Accuracy: 0.9065 | Precision: 0.9587 | Recall: 0.8700 | F1: 0.9122 | LogLoss: 0.8844\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -0.5699 | Total: 0.1445\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.9344 | Total: -0.2413\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9351 | Total: -0.2420\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2421\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9353 | Total: -0.2421\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9353 | Total: -0.2422\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2423\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2423\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2421\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9353 | Total: -0.2422\n",
      "Run 4 | Accuracy: 0.9043 | Precision: 0.9621 | Recall: 0.8625 | F1: 0.9096 | LogLoss: 0.9235\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -0.5691 | Total: 0.1424\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.9341 | Total: -0.2410\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2420\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2421\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9353 | Total: -0.2421\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9353 | Total: -0.2422\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9353 | Total: -0.2421\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2423\n",
      "Run 5 | Accuracy: 0.8992 | Precision: 0.9648 | Recall: 0.8505 | F1: 0.9041 | LogLoss: 0.9608\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -0.5722 | Total: 0.1384\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.9346 | Total: -0.2414\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2423\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Run 6 | Accuracy: 0.8984 | Precision: 0.9642 | Recall: 0.8495 | F1: 0.9032 | LogLoss: 0.9900\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -0.5703 | Total: 0.1435\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.9339 | Total: -0.2408\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2420\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9353 | Total: -0.2421\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9353 | Total: -0.2422\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9353 | Total: -0.2421\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9353 | Total: -0.2421\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2422\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9353 | Total: -0.2421\n",
      "Run 7 | Accuracy: 0.9043 | Precision: 0.9610 | Recall: 0.8635 | F1: 0.9097 | LogLoss: 0.9026\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -0.5726 | Total: 0.1481\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.9349 | Total: -0.2417\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9358 | Total: -0.2426\n",
      "Run 8 | Accuracy: 0.9043 | Precision: 0.9605 | Recall: 0.8640 | F1: 0.9097 | LogLoss: 0.9541\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -0.5672 | Total: 0.1456\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.9350 | Total: -0.2419\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Run 9 | Accuracy: 0.9059 | Precision: 0.9648 | Recall: 0.8630 | F1: 0.9111 | LogLoss: 0.9648\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -0.5868 | Total: 0.1245\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2420\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9359 | Total: -0.2427\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9358 | Total: -0.2427\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -0.9359 | Total: -0.2428\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9359 | Total: -0.2428\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9359 | Total: -0.2427\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -0.9359 | Total: -0.2428\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -0.9360 | Total: -0.2428\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -0.9360 | Total: -0.2428\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -0.9360 | Total: -0.2428\n",
      "Run 10 | Accuracy: 0.9015 | Precision: 0.9598 | Recall: 0.8595 | F1: 0.9069 | LogLoss: 0.9974\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 2 ---\n",
      "Accuracy : 0.9046 ± 0.0044\n",
      "Precision: 0.9613 ± 0.0025\n",
      "Recall   : 0.8639 ± 0.0101\n",
      "F1 Score : 0.9100 ± 0.0047\n",
      "Log Loss : 0.9324 ± 0.0495\n",
      "\n",
      "================ LAMBDA = 5 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -1.4220 | Total: -0.7045\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -2.3382 | Total: -1.6451\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6463\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6466\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6464\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6464\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6466\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Run 1 | Accuracy: 0.9043 | Precision: 0.9580 | Recall: 0.8665 | F1: 0.9100 | LogLoss: 1.0022\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -1.4427 | Total: -0.7329\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3390 | Total: -1.6458\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3404 | Total: -1.6473\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Run 2 | Accuracy: 0.8976 | Precision: 0.9595 | Recall: 0.8525 | F1: 0.9028 | LogLoss: 1.1193\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -1.4228 | Total: -0.7101\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -2.3387 | Total: -1.6456\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6471\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Run 3 | Accuracy: 0.8976 | Precision: 0.9616 | Recall: 0.8505 | F1: 0.9026 | LogLoss: 1.1004\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -1.4247 | Total: -0.7103\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -2.3387 | Total: -1.6456\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Run 4 | Accuracy: 0.8937 | Precision: 0.9618 | Recall: 0.8430 | F1: 0.8985 | LogLoss: 1.1270\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -1.4228 | Total: -0.7113\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -2.3378 | Total: -1.6446\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6467\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6467\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6467\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6467\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Run 5 | Accuracy: 0.8981 | Precision: 0.9611 | Recall: 0.8520 | F1: 0.9033 | LogLoss: 1.0838\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -1.4304 | Total: -0.7199\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -2.3381 | Total: -1.6450\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6463\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6466\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6466\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6467\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6464\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6466\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6465\n",
      "Run 6 | Accuracy: 0.8979 | Precision: 0.9616 | Recall: 0.8510 | F1: 0.9029 | LogLoss: 1.0930\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -1.4257 | Total: -0.7120\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -2.3376 | Total: -1.6444\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6466\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6466\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Run 7 | Accuracy: 0.9029 | Precision: 0.9589 | Recall: 0.8630 | F1: 0.9084 | LogLoss: 1.0515\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -1.4316 | Total: -0.7109\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3389 | Total: -1.6458\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6472\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6471\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3404 | Total: -1.6472\n",
      "Run 8 | Accuracy: 0.8937 | Precision: 0.9623 | Recall: 0.8425 | F1: 0.8984 | LogLoss: 1.1615\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -1.4179 | Total: -0.7052\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3390 | Total: -1.6458\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Run 9 | Accuracy: 0.9029 | Precision: 0.9646 | Recall: 0.8575 | F1: 0.9079 | LogLoss: 1.1037\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -1.4670 | Total: -0.7557\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3391 | Total: -1.6459\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6472\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6472\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3405 | Total: -1.6474\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3404 | Total: -1.6473\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3405 | Total: -1.6474\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3404 | Total: -1.6473\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3404 | Total: -1.6473\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3407 | Total: -1.6475\n",
      "Run 10 | Accuracy: 0.9009 | Precision: 0.9613 | Recall: 0.8570 | F1: 0.9062 | LogLoss: 1.1342\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 5 ---\n",
      "Accuracy : 0.8989 ± 0.0035\n",
      "Precision: 0.9611 ± 0.0018\n",
      "Recall   : 0.8535 ± 0.0073\n",
      "F1 Score : 0.9041 ± 0.0038\n",
      "Log Loss : 1.0977 ± 0.0427\n",
      "\n",
      "================ LAMBDA = 8 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7175 | Reg: -0.2844 | λ*Reg: -2.2752 | Total: -1.5577\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7426 | Total: -3.0495\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7441 | Total: -3.0510\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7442 | Total: -3.0511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0514\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7444 | Total: -3.0513\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Run 1 | Accuracy: 0.8995 | Precision: 0.9602 | Recall: 0.8555 | F1: 0.9048 | LogLoss: 1.1371\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7098 | Reg: -0.2885 | λ*Reg: -2.3084 | Total: -1.5985\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7437 | Total: -3.0506\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0518\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7452 | Total: -3.0520\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4682 | λ*Reg: -3.7455 | Total: -3.0523\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7451 | Total: -3.0519\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4682 | λ*Reg: -3.7453 | Total: -3.0522\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4682 | λ*Reg: -3.7453 | Total: -3.0522\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4682 | λ*Reg: -3.7455 | Total: -3.0524\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7452 | Total: -3.0520\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4682 | λ*Reg: -3.7452 | Total: -3.0521\n",
      "Run 2 | Accuracy: 0.9020 | Precision: 0.9593 | Recall: 0.8610 | F1: 0.9075 | LogLoss: 1.1487\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7127 | Reg: -0.2846 | λ*Reg: -2.2765 | Total: -1.5638\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7428 | Total: -3.0496\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0518\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0518\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Run 3 | Accuracy: 0.8981 | Precision: 0.9611 | Recall: 0.8520 | F1: 0.9033 | LogLoss: 1.1573\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7143 | Reg: -0.2849 | λ*Reg: -2.2795 | Total: -1.5652\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7431 | Total: -3.0499\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7444 | Total: -3.0513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0514\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Run 4 | Accuracy: 0.8959 | Precision: 0.9620 | Recall: 0.8470 | F1: 0.9008 | LogLoss: 1.1977\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7115 | Reg: -0.2846 | λ*Reg: -2.2764 | Total: -1.5650\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7424 | Total: -3.0493\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7444 | Total: -3.0513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0513\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Run 5 | Accuracy: 0.8925 | Precision: 0.9633 | Recall: 0.8395 | F1: 0.8971 | LogLoss: 1.2207\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7106 | Reg: -0.2861 | λ*Reg: -2.2887 | Total: -1.5781\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7422 | Total: -3.0490\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7441 | Total: -3.0509\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7444 | Total: -3.0512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7444 | Total: -3.0512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0514\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7440 | Total: -3.0509\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7442 | Total: -3.0511\n",
      "Run 6 | Accuracy: 0.8951 | Precision: 0.9629 | Recall: 0.8445 | F1: 0.8998 | LogLoss: 1.1738\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7137 | Reg: -0.2851 | λ*Reg: -2.2811 | Total: -1.5674\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7421 | Total: -3.0489\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0511\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0514\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0513\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7444 | Total: -3.0513\n",
      "Run 7 | Accuracy: 0.9018 | Precision: 0.9614 | Recall: 0.8585 | F1: 0.9070 | LogLoss: 1.1368\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7207 | Reg: -0.2863 | λ*Reg: -2.2906 | Total: -1.5699\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7431 | Total: -3.0499\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4682 | λ*Reg: -3.7452 | Total: -3.0521\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Run 8 | Accuracy: 0.8942 | Precision: 0.9613 | Recall: 0.8445 | F1: 0.8991 | LogLoss: 1.2196\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7128 | Reg: -0.2836 | λ*Reg: -2.2687 | Total: -1.5560\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7428 | Total: -3.0497\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Run 9 | Accuracy: 0.8909 | Precision: 0.9642 | Recall: 0.8355 | F1: 0.8953 | LogLoss: 1.2173\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7113 | Reg: -0.2934 | λ*Reg: -2.3472 | Total: -1.6359\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7429 | Total: -3.0498\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0518\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0519\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7452 | Total: -3.0520\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7451 | Total: -3.0519\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4682 | λ*Reg: -3.7452 | Total: -3.0521\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7452 | Total: -3.0520\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7452 | Total: -3.0520\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4682 | λ*Reg: -3.7454 | Total: -3.0523\n",
      "Run 10 | Accuracy: 0.8970 | Precision: 0.9610 | Recall: 0.8500 | F1: 0.9021 | LogLoss: 1.1949\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 8 ---\n",
      "Accuracy : 0.8967 ± 0.0035\n",
      "Precision: 0.9617 ± 0.0014\n",
      "Recall   : 0.8488 ± 0.0078\n",
      "F1 Score : 0.9017 ± 0.0038\n",
      "Log Loss : 1.1804 ± 0.0322\n",
      "\n",
      "================ FINAL SUMMARY FOR ALL LAMBDAS ================\n",
      "\n",
      "  Lambda |           Accuracy |          Precision |             Recall |           F1 Score |           Log Loss\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "   0.001 | 0.8815 ± 0.0283 | 0.9445 ± 0.0180 | 0.8367 ± 0.0439 | 0.8869 ± 0.0294 | 0.3209 ± 0.0904\n",
      "   0.005 | 0.9018 ± 0.0102 | 0.9482 ± 0.0156 | 0.8721 ± 0.0191 | 0.9083 ± 0.0099 | 0.3719 ± 0.0515\n",
      "   0.009 | 0.9077 ± 0.0071 | 0.9533 ± 0.0080 | 0.8779 ± 0.0173 | 0.9139 ± 0.0075 | 0.4218 ± 0.0655\n",
      "    0.01 | 0.9080 ± 0.0073 | 0.9529 ± 0.0093 | 0.8788 ± 0.0178 | 0.9142 ± 0.0077 | 0.4348 ± 0.0658\n",
      "    0.05 | 0.9114 ± 0.0053 | 0.9562 ± 0.0060 | 0.8819 ± 0.0148 | 0.9174 ± 0.0058 | 0.5789 ± 0.0635\n",
      "    0.09 | 0.9109 ± 0.0037 | 0.9584 ± 0.0058 | 0.8786 ± 0.0122 | 0.9167 ± 0.0042 | 0.6044 ± 0.0672\n",
      "     0.1 | 0.9110 ± 0.0039 | 0.9590 ± 0.0051 | 0.8782 ± 0.0116 | 0.9168 ± 0.0043 | 0.6201 ± 0.0611\n",
      "     0.3 | 0.9087 ± 0.0058 | 0.9620 ± 0.0055 | 0.8710 ± 0.0160 | 0.9141 ± 0.0064 | 0.7504 ± 0.0656\n",
      "     0.5 | 0.9077 ± 0.0049 | 0.9630 ± 0.0045 | 0.8681 ± 0.0130 | 0.9130 ± 0.0053 | 0.7726 ± 0.0493\n",
      "     0.9 | 0.9070 ± 0.0061 | 0.9619 ± 0.0048 | 0.8679 ± 0.0153 | 0.9124 ± 0.0066 | 0.8259 ± 0.0674\n",
      "       1 | 0.9071 ± 0.0072 | 0.9611 ± 0.0046 | 0.8689 ± 0.0172 | 0.9126 ± 0.0078 | 0.8334 ± 0.0741\n",
      "       2 | 0.9046 ± 0.0044 | 0.9613 ± 0.0025 | 0.8639 ± 0.0101 | 0.9100 ± 0.0047 | 0.9324 ± 0.0495\n",
      "       5 | 0.8989 ± 0.0035 | 0.9611 ± 0.0018 | 0.8535 ± 0.0073 | 0.9041 ± 0.0038 | 1.0977 ± 0.0427\n",
      "       8 | 0.8967 ± 0.0035 | 0.9617 ± 0.0014 | 0.8488 ± 0.0078 | 0.9017 ± 0.0038 | 1.1804 ± 0.0322\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "hidden_dim   = 256\n",
    "cut          = 0\n",
    "dropout      = 0.25\n",
    "num_runs     = 10\n",
    "heads = 2\n",
    "num_epochs   = 5000\n",
    "lambda_list  = [0.001, 0.005, 0.009, 0.01, 0.05, 0.09, 0.1, 0.3, 0.5, 0.9, 1, 2, 5, 8]\n",
    "base_seed    = 42\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "node_feats = node_feats.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "A = A.to(device)\n",
    "\n",
    "# Use the y_subset created earlier\n",
    "y_subset_np = y_subset.astype(int)\n",
    "\n",
    "N, feats_dim = node_feats.size(0), node_feats.size(1)\n",
    "\n",
    "all_results = []\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for lam in lambda_list:\n",
    "    print(f\"\\n================ LAMBDA = {lam} ================\\n\")\n",
    "\n",
    "    acc_scores, prec_scores, rec_scores, f1_scores, log_losses = [], [], [], [], []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        print(f\"\\n--- Run {run+1}/{num_runs} ---\")\n",
    "\n",
    "        seed = base_seed + run\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "        model = DGI_with_classifier(features.shape[1], hidden_dim, heads=heads, n_classes=2, cut=cut, dropout=dropout).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)\n",
    "        scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n",
    "\n",
    "\n",
    "        for epoch in range(num_epochs + 1):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            perm = torch.randperm(N, device=device)\n",
    "            corrupt_features = node_feats[perm]\n",
    "\n",
    "            logits, embeddings = model(node_feats, corrupt_features, edge_index)\n",
    "\n",
    "            lbl = torch.cat([torch.ones(N, device=device), torch.zeros(N, device=device)])\n",
    "            dgi_loss = bce_loss(logits.squeeze(), lbl)\n",
    "            reg_loss = model.Reg_loss(A, embeddings)\n",
    "\n",
    "            loss = dgi_loss + lam * reg_loss\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                print(f\"Epoch {epoch:4d} | DGI: {dgi_loss.item():.4f} | Reg: {reg_loss.item():.4f} | \"\n",
    "                      f\"λ*Reg: {(lam * reg_loss).item():.4f} | Total: {loss.item():.4f}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            emb = model.get_embeddings(node_feats, edge_index)\n",
    "            logits_cls = model.classifier(emb)                   # [N, 2]\n",
    "            class_probabilities = F.softmax(logits_cls, dim=1).cpu().numpy()\n",
    "            y_pred = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "        acc  = accuracy_score(y_subset_np, y_pred)\n",
    "        acc_inv = accuracy_score(y_subset_np, 1 - y_pred)\n",
    "\n",
    "        if acc_inv > acc:\n",
    "            acc = acc_inv\n",
    "            y_pred = 1 - y_pred\n",
    "            class_probabilities = class_probabilities[:, ::-1]\n",
    "\n",
    "        prec = precision_score(y_subset_np, y_pred, zero_division=0)\n",
    "        rec  = recall_score(y_subset_np, y_pred, zero_division=0)\n",
    "        f1   = f1_score(y_subset_np, y_pred, zero_division=0)\n",
    "        ll   = log_loss(y_subset_np, class_probabilities)\n",
    "\n",
    "        print(f\"Run {run+1} | Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | LogLoss: {ll:.4f}\")\n",
    "\n",
    "        acc_scores.append(acc)\n",
    "        prec_scores.append(prec)\n",
    "        rec_scores.append(rec)\n",
    "        f1_scores.append(f1)\n",
    "        log_losses.append(ll)\n",
    "\n",
    "    lambda_results = {\n",
    "        \"lambda\": lam,\n",
    "        \"accuracy\":  (float(np.mean(acc_scores)), float(np.std(acc_scores))),\n",
    "        \"precision\": (float(np.mean(prec_scores)), float(np.std(prec_scores))),\n",
    "        \"recall\":    (float(np.mean(rec_scores)), float(np.std(rec_scores))),\n",
    "        \"f1\":        (float(np.mean(f1_scores)),  float(np.std(f1_scores))),\n",
    "        \"log_loss\":  (float(np.mean(log_losses)), float(np.std(log_losses))),\n",
    "    }\n",
    "    all_results.append(lambda_results)\n",
    "\n",
    "    print(f\"\\n--- RESULTS FOR LAMBDA = {lam} ---\")\n",
    "    print(f\"Accuracy : {lambda_results['accuracy'][0]:.4f} ± {lambda_results['accuracy'][1]:.4f}\")\n",
    "    print(f\"Precision: {lambda_results['precision'][0]:.4f} ± {lambda_results['precision'][1]:.4f}\")\n",
    "    print(f\"Recall   : {lambda_results['recall'][0]:.4f} ± {lambda_results['recall'][1]:.4f}\")\n",
    "    print(f\"F1 Score : {lambda_results['f1'][0]:.4f} ± {lambda_results['f1'][1]:.4f}\")\n",
    "    print(f\"Log Loss : {lambda_results['log_loss'][0]:.4f} ± {lambda_results['log_loss'][1]:.4f}\")\n",
    "\n",
    "print(\"\\n================ FINAL SUMMARY FOR ALL LAMBDAS ================\\n\")\n",
    "print(f\"{'Lambda':>8} | {'Accuracy':>18} | {'Precision':>18} | {'Recall':>18} | {'F1 Score':>18} | {'Log Loss':>18}\")\n",
    "print(\"-\" * 108)\n",
    "for res in all_results:\n",
    "    print(f\"{res['lambda']:>8} | \"\n",
    "          f\"{res['accuracy'][0]:.4f} ± {res['accuracy'][1]:.4f} | \"\n",
    "          f\"{res['precision'][0]:.4f} ± {res['precision'][1]:.4f} | \"\n",
    "          f\"{res['recall'][0]:.4f} ± {res['recall'][1]:.4f} | \"\n",
    "          f\"{res['f1'][0]:.4f} ± {res['f1'][1]:.4f} | \"\n",
    "          f\"{res['log_loss'][0]:.4f} ± {res['log_loss'][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoZr8SupDBbh",
    "outputId": "bf0c8e2c-ccdf-4256-dbcc-71538cba1dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: -0.001379769830930187\n",
      "Normalized Mutual Information Score: 7.97612442553983e-05\n",
      "Clustering Accuracy (mapped): 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def cluster_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Assigns predicted clusters to true labels\n",
    "    to maximize accuracy using the Jonker-Volgenant algorithm (linear_sum_assignment).\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(-w)\n",
    "    return w[row_ind, col_ind].sum() / y_pred.size\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model.get_embeddings(node_feats.to(device), edge_index.to(device))\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "kmeans.fit(embeddings)\n",
    "y_pred_kmeans = kmeans.labels_\n",
    "\n",
    "ari_score = adjusted_rand_score(y, y_pred_kmeans)\n",
    "nmi_score = normalized_mutual_info_score(y, y_pred_kmeans)\n",
    "\n",
    "print(\"Adjusted Rand Score:\", ari_score)\n",
    "print(\"Normalized Mutual Information Score:\", nmi_score)\n",
    "\n",
    "acc_kmeans = cluster_acc(y, y_pred_kmeans)\n",
    "print(\"Clustering Accuracy (mapped):\", acc_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adGSi9JiEEqO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPfsaXB6_EZp"
   },
   "outputs": [],
   "source": [
    "# class DGI(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim,output_dim, cut=0):\n",
    "#         super().__init__()\n",
    "#         self.encoder = GCNEncoder(input_dim, hidden_dim)\n",
    "#         self.readout = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.cut = cut\n",
    "#         self.output_dim = output_dim\n",
    "\n",
    "#     def forward(self, x, edge_index, corrupt_x, adj=None):\n",
    "#         h = self.encoder(x, edge_index)\n",
    "#         h_corrupt = self.encoder(corrupt_x, edge_index)\n",
    "\n",
    "#         # Summary vector\n",
    "#         s = torch.sigmoid(h.mean(dim=0))\n",
    "\n",
    "#         # Positive & negative scores\n",
    "#         pos = torch.matmul(h, s)\n",
    "#         neg = torch.matmul(h_corrupt, s)\n",
    "\n",
    "#         # DGI loss\n",
    "#         dgi_loss = -torch.log(torch.sigmoid(pos - neg) + 1e-8).mean()\n",
    "\n",
    "#         reg_loss = 0\n",
    "#         if adj is not None:\n",
    "#             A = torch.as_tensor(adj, dtype=torch.float32, device=x.device)\n",
    "#             D = torch.diag(A.sum(dim=1))\n",
    "\n",
    "#             if self.cut == 1:  # Cut loss\n",
    "#                 L = D - A\n",
    "#                 p = self.readout(h)\n",
    "#                 C = F.softmax(p, dim=1)\n",
    "#                 reg_loss = torch.trace(C.T @ L @ C) / (torch.trace(C.T @ D @ C) + 1e-8)\n",
    "\n",
    "#             else:  # Modularity loss\n",
    "#                 m = torch.sum(A)\n",
    "#                 B = A - torch.outer(D.diag(), D.diag()) / (2 * m)\n",
    "#                 p = self.readout(h)\n",
    "#                 C = F.softmax(p, dim=1)\n",
    "#                 k = torch.tensor(self.output_dim, dtype=torch.float32, device=x.device)\n",
    "#                 n = C.shape[0]\n",
    "#                 reg_loss = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n",
    "#                 reg_loss += (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n",
    "\n",
    "\n",
    "#         return h, dgi_loss, reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xzy_llWw_UGN",
    "outputId": "db4fe94b-e693-45af-a7b5-2f4b9bf7342c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | DGI Loss: 0.6922 | Reg Loss: -0.1250 | Total Loss: 0.5672\n",
      "Epoch 500 | DGI Loss: 0.2924 | Reg Loss: -0.1250 | Total Loss: 0.1674\n",
      "Epoch 1000 | DGI Loss: 0.2514 | Reg Loss: -0.1250 | Total Loss: 0.1264\n",
      "Epoch 1500 | DGI Loss: 0.2425 | Reg Loss: -0.1250 | Total Loss: 0.1175\n",
      "Epoch 2000 | DGI Loss: 0.2083 | Reg Loss: -0.1250 | Total Loss: 0.0833\n",
      "Epoch 2500 | DGI Loss: 0.2106 | Reg Loss: -0.1250 | Total Loss: 0.0856\n",
      "Epoch 3000 | DGI Loss: 0.1714 | Reg Loss: -0.1246 | Total Loss: 0.0468\n",
      "Epoch 3500 | DGI Loss: 0.1480 | Reg Loss: -0.1256 | Total Loss: 0.0224\n",
      "Epoch 4000 | DGI Loss: 0.1510 | Reg Loss: -0.1278 | Total Loss: 0.0232\n",
      "Epoch 4500 | DGI Loss: 0.1389 | Reg Loss: -0.1328 | Total Loss: 0.0060\n",
      "Epoch 5000 | DGI Loss: 0.1076 | Reg Loss: -0.1373 | Total Loss: -0.0297\n",
      "Epoch 5500 | DGI Loss: 0.1220 | Reg Loss: -0.1399 | Total Loss: -0.0180\n",
      "Epoch 6000 | DGI Loss: 0.0915 | Reg Loss: -0.1414 | Total Loss: -0.0499\n",
      "Epoch 6500 | DGI Loss: 0.0746 | Reg Loss: -0.1428 | Total Loss: -0.0681\n",
      "Epoch 7000 | DGI Loss: 0.0863 | Reg Loss: -0.1426 | Total Loss: -0.0563\n"
     ]
    }
   ],
   "source": [
    "# hidden_dim = 256\n",
    "# output_dim = 2\n",
    "# cut = 0\n",
    "# model = DGI(features.shape[1], hidden_dim, output_dim, cut=cut).to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# num_epochs = 7000\n",
    "# for epoch in range(num_epochs+1):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     perm = torch.randperm(features.shape[0])\n",
    "#     corrupt_features = node_feats[perm]\n",
    "\n",
    "#     _, dgi_loss, reg_loss = model(\n",
    "#         node_feats.to(device),\n",
    "#         edge_index.to(device),\n",
    "#         corrupt_features.to(device),\n",
    "#         adj=torch.tensor(W0).to(device)\n",
    "#     )\n",
    "\n",
    "#     loss = dgi_loss + reg_loss\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if epoch % 500 == 0:\n",
    "#         print(f\"Epoch {epoch} | DGI Loss: {dgi_loss.item():.4f} | Reg Loss: {reg_loss.item():.4f} | Total Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3sTP63kBAhr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSW7Zhsy_cg6"
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     embeddings, _, _ = model(\n",
    "#         node_feats.to(device),\n",
    "#         edge_index.to(device),\n",
    "#         node_feats.to(device),\n",
    "#         adj=torch.tensor(W0).to(device)\n",
    "#     )\n",
    "\n",
    "# embeddings = embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCN-YL-LXrE5",
    "outputId": "29244971-8ffd-42c0-90df-34d6ed34164a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: 0.00017775231989074027\n",
      "Normalized Mutual Information Score: 0.00035768106511865666\n",
      "Clustering Accuracy (mapped): 0.54\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "# # Use KMeans clustering\n",
    "# kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "# kmeans.fit(embeddings)\n",
    "# y_pred_kmeans = kmeans.labels_\n",
    "\n",
    "# # Evaluate clustering performance\n",
    "# ari_score = adjusted_rand_score(y, y_pred_kmeans)\n",
    "# nmi_score = normalized_mutual_info_score(y, y_pred_kmeans)\n",
    "\n",
    "# print(\"Adjusted Rand Score:\", ari_score)\n",
    "# print(\"Normalized Mutual Information Score:\", nmi_score)\n",
    "\n",
    "# # Note: K-Means is an unsupervised algorithm, so traditional classification metrics like accuracy, precision, recall, and F1 are not directly applicable without mapping clusters to classes.\n",
    "# # However, we can calculate accuracy by mapping the cluster labels to the true labels in the way that maximizes accuracy.\n",
    "# # This is not a standard evaluation for clustering but can give an idea of how well the clusters separate the classes.\n",
    "# from scipy.optimize import linear_sum_assignment\n",
    "# def cluster_acc(y_true, y_pred):\n",
    "#     \"\"\"\n",
    "#     Calculate clustering accuracy. Assigns predicted clusters to true labels\n",
    "#     to maximize accuracy using the Jonker-Volgenant algorithm (linear_sum_assignment).\n",
    "#     \"\"\"\n",
    "#     y_true = y_true.astype(np.int64)\n",
    "#     assert y_pred.size == y_true.size\n",
    "#     D = max(y_pred.max(), y_true.max()) + 1\n",
    "#     w = np.zeros((D, D), dtype=np.int64)\n",
    "#     for i in range(y_pred.size):\n",
    "#         w[y_pred[i], y_true[i]] += 1\n",
    "#     row_ind, col_ind = linear_sum_assignment(-w)\n",
    "#     return w[row_ind, col_ind].sum() / y_pred.size\n",
    "\n",
    "# acc_kmeans = cluster_acc(y, y_pred_kmeans)\n",
    "# print(\"Clustering Accuracy (mapped):\", acc_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WL8xpgMME8sS"
   },
   "source": [
    "1- GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfZdJWjqBSU5"
   },
   "source": [
    "Accuracy: 0.7466666666666667\n",
    "Precision: 0.7263681592039801\n",
    "Recall: 0.874251497005988\n",
    "F1: 0.7934782608695652\n",
    "Log Loss: 0.5786983582841999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWmKFw9cE77L"
   },
   "source": [
    "Accuracy: 0.7533333333333333\n",
    "Precision: 0.7360406091370558\n",
    "Recall: 0.8682634730538922\n",
    "F1: 0.7967032967032966\n",
    "Log Loss: 0.5772490248961657"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

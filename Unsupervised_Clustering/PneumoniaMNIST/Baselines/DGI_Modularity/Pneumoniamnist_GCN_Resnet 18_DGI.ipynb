{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YXFd7Zsz-3XQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "import random\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQ6KiAvW-5rn",
    "outputId": "f92af273-25d0-46ec-c066-4087a27e9083"
   },
   "outputs": [],
   "source": [
    "#data = np.load('pneumoniamnist_224.npz', allow_pickle=True)\n",
    "data = np.load('pneumoniamnist_224.npz', allow_pickle=True)\n",
    "# Combine train, val, and test sets\n",
    "all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n",
    "all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5856, 3, 224, 224]) torch.Size([5856])\n"
     ]
    }
   ],
   "source": [
    "images = all_images.astype(np.float32) / 255.0\n",
    "images = np.repeat(images[:, None, :, :], 3, axis=1)  # Convert to 3 channels (N, 3, 224, 224)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X = torch.tensor(images)\n",
    "y = torch.tensor(all_labels).long()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, y)\n",
    "class0_indices = [i for i in range(len(y)) if y[i] == 0]\n",
    "class1_indices = [i for i in range(len(y)) if y[i] == 1]\n",
    "\n",
    "random.seed(42)\n",
    "sampled_class0 = random.sample(class0_indices, min(2000, len(class0_indices)))\n",
    "sampled_class1 = random.sample(class1_indices, min(2000, len(class1_indices)))\n",
    "\n",
    "combined_indices = sampled_class0 + sampled_class1\n",
    "random.shuffle(combined_indices)\n",
    "\n",
    "# Final subset\n",
    "final_dataset = Subset(dataset, combined_indices)\n",
    "final_loader = DataLoader(final_dataset, batch_size=64, shuffle=False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/va797/tmp_pyg118/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/home/va797/tmp_pyg118/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (3583, 512)\n",
      "Label shape: (3583,)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # Remove final classification layer\n",
    "resnet = resnet.cuda() if torch.cuda.is_available() else resnet\n",
    "resnet.eval()\n",
    "resnet_feats = []\n",
    "y_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in final_loader:\n",
    "        imgs = imgs.cuda() if torch.cuda.is_available() else imgs\n",
    "        features = resnet(imgs)\n",
    "        resnet_feats.append(features.cpu())\n",
    "        y_list.extend(labels.cpu().tolist())\n",
    "F = torch.cat(resnet_feats, dim=0).numpy().astype(np.float32)\n",
    "y_labels = np.array(y_list).astype(np.float32)\n",
    "\n",
    "print(\"Feature shape:\", F.shape)\n",
    "print(\"Label shape:\", y_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MkKdnnzI-7zI"
   },
   "outputs": [],
   "source": [
    "def create_adj(F, alpha=1):\n",
    "    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n",
    "    W = np.dot(F_norm, F_norm.T)\n",
    "    W = (W >= alpha).astype(np.float32)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Qk8neEfFl7kX"
   },
   "outputs": [],
   "source": [
    "def asymmetrize_random(adj_matrix, seed=None):\n",
    "    \"\"\"\n",
    "    Randomly orient each undirected edge from a symmetric adjacency matrix.\n",
    "    \"\"\"\n",
    "    adj = np.array(adj_matrix, dtype=np.float32)\n",
    "    n = adj.shape[0]\n",
    "    asym = np.zeros((n, n), dtype=np.float32)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if adj[i, j]:\n",
    "                if rng.random() < 0.5:\n",
    "                    asym[i, j] = adj[i, j]\n",
    "                else:\n",
    "                    asym[j, i] = adj[i, j]\n",
    "\n",
    "    return asym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "klhn9g9sl-SV"
   },
   "outputs": [],
   "source": [
    "def load_data(adj, node_feats):\n",
    "    node_feats = torch.from_numpy(node_feats).float()\n",
    "    edge_index = torch.from_numpy(np.array(np.nonzero(adj))).long()\n",
    "    return node_feats, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zz160NfE--Tg",
    "outputId": "747750e9-006f-48b7-cf0a-83d772b31669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3583, 512], edge_index=[2, 1642013])\n"
     ]
    }
   ],
   "source": [
    "features = F # Use ResNet embeddings\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "W0 = create_adj(features, alpha=0.9)\n",
    "# W_asym = asymmetrize_random(W0, seed=42)\n",
    "node_feats, edge_index = load_data(W0, features)\n",
    "data = Data(x=node_feats, edge_index=edge_index).to(device)\n",
    "A = torch.from_numpy(W0).to(device)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nhh413xH_Awp"
   },
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, device, activ):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.gcn1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = self.dropout(x)\n",
    "        x = self.batchnorm(x)\n",
    "        logits = self.mlp(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "t1CWUjjG48t_"
   },
   "outputs": [],
   "source": [
    "class AvgReadout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, seq, msk=None):\n",
    "        if msk is None:\n",
    "            return torch.mean(seq, 0)\n",
    "        else:\n",
    "            msk = torch.unsqueeze(msk, -1)\n",
    "            return torch.sum(seq * msk, 0) / torch.sum(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IbNOUPjg42s9"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super().__init__()\n",
    "        self.f_k = nn.Bilinear(n_h, n_h, 1)\n",
    "        nn.init.xavier_uniform_(self.f_k.weight.data)\n",
    "        if self.f_k.bias is not None:\n",
    "            self.f_k.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, c, h_pl, h_mi):\n",
    "        c_x = torch.unsqueeze(c, 0).expand_as(h_pl)\n",
    "        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 1)\n",
    "        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 1)\n",
    "        logits = torch.cat((sc_1, sc_2), 0)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7X7cwk2N8Al2"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, n_in, n_h, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNEncoder(n_in, n_h, device='cuda' if torch.cuda.is_available() else 'cpu', activ=nn.ELU())\n",
    "        self.read = AvgReadout()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        self.disc = Discriminator(n_h)\n",
    "\n",
    "    def forward(self, seq1, seq2, edge_index):\n",
    "        # Create Data objects for the GCNEncoder\n",
    "        data1 = Data(x=seq1, edge_index=edge_index)\n",
    "        data2 = Data(x=seq2, edge_index=edge_index)\n",
    "\n",
    "        h_1 = self.gcn1(data1)\n",
    "        c = self.read(h_1)\n",
    "        c = self.sigm(c)\n",
    "        h_2 = self.gcn1(data2)\n",
    "        logits = self.disc(c, h_1, h_2)\n",
    "        return logits, h_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yVuaMXM1C9T3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class DGI_with_classifier(DGI):\n",
    "    def __init__(self, n_in, n_h, n_classes=2, cut=0, dropout=0.25):\n",
    "        super().__init__(n_in, n_h, dropout=dropout)\n",
    "        self.classifier = nn.Linear(n_h, n_classes)\n",
    "        self.cut = cut\n",
    "\n",
    "    def get_embeddings(self, node_feats, edge_index):\n",
    "        _, embeddings = self.forward(node_feats, node_feats, edge_index)\n",
    "        return embeddings\n",
    "\n",
    "    def cut_loss(self, A, S):\n",
    "        # ensure tensor\n",
    "        if isinstance(A, np.ndarray):\n",
    "            A = torch.from_numpy(A).float().to(S.device)\n",
    "\n",
    "        S = F.softmax(S, dim=1)   # cluster assignment\n",
    "        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n",
    "        num = torch.trace(A_pool)\n",
    "\n",
    "        D = torch.diag(torch.sum(A, dim=-1))\n",
    "        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n",
    "        den = torch.trace(D_pooled)\n",
    "\n",
    "        mincut_loss = -(num / den)\n",
    "\n",
    "        St_S = torch.matmul(S.t(), S)\n",
    "        I_S = torch.eye(S.shape[1], device=A.device)\n",
    "        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n",
    "\n",
    "        return mincut_loss + ortho_loss\n",
    "\n",
    "    def modularity_loss(self, A, S):\n",
    "        # ensure tensor\n",
    "        if isinstance(A, np.ndarray):\n",
    "            A = torch.from_numpy(A).float().to(S.device)\n",
    "\n",
    "        C = F.softmax(S, dim=1)   # cluster assignment\n",
    "        d = torch.sum(A, dim=1)\n",
    "        m = torch.sum(A)\n",
    "\n",
    "        B = A - torch.outer(d, d) / (2 * m)\n",
    "\n",
    "        I_S = torch.eye(C.shape[1], device=A.device)\n",
    "        k = torch.norm(I_S)\n",
    "        n = S.shape[0]\n",
    "\n",
    "        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n",
    "        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n",
    "\n",
    "        return modularity_term + collapse_reg_term\n",
    "\n",
    "    def Reg_loss(self, A, embeddings):\n",
    "        # classifier output used as soft cluster assignment\n",
    "        logits = self.classifier(embeddings)\n",
    "\n",
    "        if self.cut == 1:\n",
    "            return self.cut_loss(A, logits)\n",
    "        else:\n",
    "            return self.modularity_loss(A, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ClSGTZaA_xt",
    "outputId": "5b7f24b6-9012-4c9a-cf1a-73d43fa430ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | DGI Loss: 0.7151 | Reg Loss: -0.2846 | Total: 0.6866\n",
      "Epoch 500 | DGI Loss: 0.6931 | Reg Loss: -0.4657 | Total: 0.6466\n",
      "Epoch 1000 | DGI Loss: 0.6932 | Reg Loss: -0.4657 | Total: 0.6466\n",
      "Epoch 1500 | DGI Loss: 0.6932 | Reg Loss: -0.4663 | Total: 0.6465\n",
      "Epoch 2000 | DGI Loss: 0.6931 | Reg Loss: -0.4672 | Total: 0.6464\n",
      "Epoch 2500 | DGI Loss: 0.6931 | Reg Loss: -0.4669 | Total: 0.6465\n",
      "Epoch 3000 | DGI Loss: 0.6932 | Reg Loss: -0.4666 | Total: 0.6465\n",
      "Epoch 3500 | DGI Loss: 0.6931 | Reg Loss: -0.4673 | Total: 0.6464\n",
      "Epoch 4000 | DGI Loss: 0.6932 | Reg Loss: -0.4668 | Total: 0.6465\n",
      "Epoch 4500 | DGI Loss: 0.6931 | Reg Loss: -0.4676 | Total: 0.6464\n",
      "Epoch 5000 | DGI Loss: 0.6932 | Reg Loss: -0.4672 | Total: 0.6465\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256\n",
    "cut = 0\n",
    "dropout = 0.25\n",
    "\n",
    "# make sure adjacency is a tensor on GPU\n",
    "if isinstance(A, np.ndarray):\n",
    "    A = torch.from_numpy(A).float().to(device)\n",
    "else:\n",
    "    A = A.float().to(device)\n",
    "\n",
    "model = DGI_with_classifier(features.shape[1], hidden_dim, n_classes=2, cut=cut, dropout=dropout).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    perm = torch.randperm(node_feats.size(0))\n",
    "    corrupt_features = node_feats[perm]\n",
    "\n",
    "    logits, embeddings = model(node_feats.to(device), corrupt_features.to(device), edge_index.to(device))\n",
    "\n",
    "    lbl = torch.cat([\n",
    "        torch.ones(node_feats.size(0)),\n",
    "        torch.zeros(node_feats.size(0))\n",
    "    ]).to(device)\n",
    "\n",
    "    dgi_loss = bce_loss(logits.squeeze(), lbl)\n",
    "    reg_loss = model.Reg_loss(A, embeddings)\n",
    "    loss = dgi_loss + 0.1 * reg_loss\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch} | DGI Loss: {dgi_loss.item():.4f} | Reg Loss: {reg_loss.item():.4f} | Total: {loss.item():.4f}\")\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "giN_kiZckBqV"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model.get_embeddings(node_feats.to(device), edge_index.to(device))\n",
    "    class_probabilities = F.softmax(model.classifier(embeddings), dim=1).cpu().numpy()\n",
    "\n",
    "y_pred = np.argmax(class_probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVJYp9cnauDO",
    "outputId": "9481a916-c4d5-4f1b-c711-aace623636b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9137594194808819\n",
      "Accuracy (inverted): 0.08624058051911805\n",
      "Precision: 0.9643053267435475\n",
      "Recall: 0.878\n",
      "F1: 0.9191311175085056\n",
      "Log Loss: 0.6892714422547073\n"
     ]
    }
   ],
   "source": [
    "# Extract the true labels for the subset used for prediction\n",
    "y_subset = y[combined_indices].cpu().numpy()\n",
    "\n",
    "acc_score = accuracy_score(y_subset, y_pred)\n",
    "acc_score_inverted = accuracy_score(y_subset, 1 - y_pred)\n",
    "prec_score = precision_score(y_subset, y_pred)\n",
    "rec_score = recall_score(y_subset, y_pred)\n",
    "f1 = f1_score(y_subset, y_pred)\n",
    "log_loss_value = log_loss(y_subset, class_probabilities)\n",
    "\n",
    "print(\"Accuracy:\", acc_score)\n",
    "print(\"Accuracy (inverted):\", acc_score_inverted)\n",
    "print(\"Precision:\", prec_score)\n",
    "print(\"Recall:\", rec_score)\n",
    "print(\"F1:\", f1)\n",
    "print(\"Log Loss:\", log_loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2TNZi1qljP0",
    "outputId": "f1c43910-61e1-4aec-8cd0-0f5b2ce46fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ LAMBDA = 0.001 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.0003 | Total: 0.7039\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4443 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4484 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4485 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4499 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4489 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4481 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4490 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4497 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4494 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4490 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 1 | Accuracy: 0.9219 | Precision: 0.9649 | Recall: 0.8925 | F1: 0.9273 | LogLoss: 0.2397\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.0003 | Total: 0.7128\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4475 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4509 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4516 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4518 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4514 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4516 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4515 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4523 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4516 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4515 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Run 2 | Accuracy: 0.9107 | Precision: 0.9590 | Recall: 0.8775 | F1: 0.9164 | LogLoss: 0.2712\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.0003 | Total: 0.7202\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4512 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4541 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4540 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4544 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4549 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4551 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4553 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4541 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4547 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4536 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Run 3 | Accuracy: 0.9163 | Precision: 0.9590 | Recall: 0.8880 | F1: 0.9221 | LogLoss: 0.2725\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.0003 | Total: 0.7167\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4330 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4417 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4426 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4427 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4434 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4434 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4427 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4422 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4427 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4429 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 4 | Accuracy: 0.9168 | Precision: 0.9575 | Recall: 0.8905 | F1: 0.9228 | LogLoss: 0.2459\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.0003 | Total: 0.7232\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4504 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4522 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4533 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4534 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4526 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4521 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4531 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4522 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4536 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4524 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Run 5 | Accuracy: 0.9090 | Precision: 0.9574 | Recall: 0.8760 | F1: 0.9149 | LogLoss: 0.2693\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.0003 | Total: 0.7131\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4349 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4406 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4416 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4425 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4421 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4428 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4421 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4411 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4420 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4412 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 6 | Accuracy: 0.9163 | Precision: 0.9620 | Recall: 0.8850 | F1: 0.9219 | LogLoss: 0.2475\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.0003 | Total: 0.7122\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4508 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4520 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4528 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4530 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4529 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4530 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4527 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4530 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4523 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4527 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Run 7 | Accuracy: 0.9076 | Precision: 0.9603 | Recall: 0.8705 | F1: 0.9132 | LogLoss: 0.2753\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.0003 | Total: 0.7168\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4550 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4568 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4572 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4572 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4571 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4574 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4573 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4569 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Run 8 | Accuracy: 0.9099 | Precision: 0.9615 | Recall: 0.8735 | F1: 0.9154 | LogLoss: 0.2933\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.0003 | Total: 0.7059\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4389 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4453 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4454 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4457 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4463 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4463 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4463 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4452 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4460 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4461 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 9 | Accuracy: 0.9166 | Precision: 0.9541 | Recall: 0.8935 | F1: 0.9228 | LogLoss: 0.2534\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.0003 | Total: 0.7070\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4312 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4404 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4450 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4432 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4446 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4451 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4439 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4443 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4442 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4446 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 10 | Accuracy: 0.9138 | Precision: 0.9519 | Recall: 0.8905 | F1: 0.9202 | LogLoss: 0.2585\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.001 ---\n",
      "Accuracy : 0.9139 ± 0.0042\n",
      "Precision: 0.9587 ± 0.0036\n",
      "Recall   : 0.8837 ± 0.0081\n",
      "F1 Score : 0.9197 ± 0.0043\n",
      "Log Loss : 0.2626 ± 0.0157\n",
      "\n",
      "================ LAMBDA = 0.005 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.0014 | Total: 0.7028\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4598 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4616 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 1 | Accuracy: 0.9171 | Precision: 0.9625 | Recall: 0.8860 | F1: 0.9227 | LogLoss: 0.3485\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.0014 | Total: 0.7117\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4610 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4625 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4630 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 2 | Accuracy: 0.9115 | Precision: 0.9611 | Recall: 0.8770 | F1: 0.9171 | LogLoss: 0.3816\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.0014 | Total: 0.7191\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4612 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 3 | Accuracy: 0.9124 | Precision: 0.9612 | Recall: 0.8785 | F1: 0.9180 | LogLoss: 0.3893\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.0014 | Total: 0.7155\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4588 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4609 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4611 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4611 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4612 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4609 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4607 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 4 | Accuracy: 0.9101 | Precision: 0.9600 | Recall: 0.8755 | F1: 0.9158 | LogLoss: 0.3566\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.0015 | Total: 0.7220\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4620 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 5 | Accuracy: 0.9099 | Precision: 0.9595 | Recall: 0.8755 | F1: 0.9156 | LogLoss: 0.3951\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.0015 | Total: 0.7119\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4584 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4598 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4609 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4606 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4607 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4608 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4601 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4603 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4606 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4605 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 6 | Accuracy: 0.9143 | Precision: 0.9618 | Recall: 0.8815 | F1: 0.9199 | LogLoss: 0.3414\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.0014 | Total: 0.7111\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4609 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4618 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4623 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4618 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4623 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 7 | Accuracy: 0.9096 | Precision: 0.9599 | Recall: 0.8745 | F1: 0.9152 | LogLoss: 0.3704\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.0014 | Total: 0.7157\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4620 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 8 | Accuracy: 0.9087 | Precision: 0.9609 | Recall: 0.8720 | F1: 0.9143 | LogLoss: 0.3978\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.0014 | Total: 0.7048\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4601 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4616 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4618 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4618 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4618 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4617 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 9 | Accuracy: 0.9146 | Precision: 0.9603 | Recall: 0.8835 | F1: 0.9203 | LogLoss: 0.3597\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.0014 | Total: 0.7058\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4582 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4610 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4618 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4617 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4618 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4620 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 10 | Accuracy: 0.9104 | Precision: 0.9590 | Recall: 0.8770 | F1: 0.9162 | LogLoss: 0.3789\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.005 ---\n",
      "Accuracy : 0.9119 ± 0.0026\n",
      "Precision: 0.9606 ± 0.0010\n",
      "Recall   : 0.8781 ± 0.0041\n",
      "F1 Score : 0.9175 ± 0.0025\n",
      "Log Loss : 0.3719 ± 0.0188\n",
      "\n",
      "================ LAMBDA = 0.009 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.0026 | Total: 0.7016\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4620 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 1 | Accuracy: 0.9143 | Precision: 0.9623 | Recall: 0.8810 | F1: 0.9199 | LogLoss: 0.3969\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.0026 | Total: 0.7106\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 2 | Accuracy: 0.9118 | Precision: 0.9626 | Recall: 0.8760 | F1: 0.9173 | LogLoss: 0.4340\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.0026 | Total: 0.7179\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 3 | Accuracy: 0.9112 | Precision: 0.9611 | Recall: 0.8765 | F1: 0.9168 | LogLoss: 0.4510\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.0026 | Total: 0.7144\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4618 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 4 | Accuracy: 0.9138 | Precision: 0.9618 | Recall: 0.8805 | F1: 0.9193 | LogLoss: 0.4100\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.0026 | Total: 0.7209\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 5 | Accuracy: 0.9099 | Precision: 0.9610 | Recall: 0.8740 | F1: 0.9154 | LogLoss: 0.4437\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.0026 | Total: 0.7108\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4613 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4630 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 6 | Accuracy: 0.9140 | Precision: 0.9623 | Recall: 0.8805 | F1: 0.9196 | LogLoss: 0.3853\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.0026 | Total: 0.7100\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 7 | Accuracy: 0.9101 | Precision: 0.9640 | Recall: 0.8715 | F1: 0.9154 | LogLoss: 0.4203\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.0026 | Total: 0.7146\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 8 | Accuracy: 0.9099 | Precision: 0.9630 | Recall: 0.8720 | F1: 0.9152 | LogLoss: 0.4518\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.0026 | Total: 0.7036\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 9 | Accuracy: 0.9129 | Precision: 0.9612 | Recall: 0.8795 | F1: 0.9185 | LogLoss: 0.4160\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.0026 | Total: 0.7047\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 10 | Accuracy: 0.9104 | Precision: 0.9605 | Recall: 0.8755 | F1: 0.9160 | LogLoss: 0.4361\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.009 ---\n",
      "Accuracy : 0.9118 ± 0.0017\n",
      "Precision: 0.9620 ± 0.0010\n",
      "Recall   : 0.8767 ± 0.0034\n",
      "F1 Score : 0.9174 ± 0.0017\n",
      "Log Loss : 0.4245 ± 0.0215\n",
      "\n",
      "================ LAMBDA = 0.01 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.0029 | Total: 0.7013\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4620 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 1 | Accuracy: 0.9163 | Precision: 0.9640 | Recall: 0.8830 | F1: 0.9217 | LogLoss: 0.4006\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.0028 | Total: 0.7103\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4630 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 2 | Accuracy: 0.9118 | Precision: 0.9626 | Recall: 0.8760 | F1: 0.9173 | LogLoss: 0.4421\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.0029 | Total: 0.7176\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 3 | Accuracy: 0.9104 | Precision: 0.9610 | Recall: 0.8750 | F1: 0.9160 | LogLoss: 0.4606\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.0029 | Total: 0.7141\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 4 | Accuracy: 0.9138 | Precision: 0.9618 | Recall: 0.8805 | F1: 0.9193 | LogLoss: 0.4190\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.0029 | Total: 0.7206\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4647 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 5 | Accuracy: 0.9101 | Precision: 0.9610 | Recall: 0.8745 | F1: 0.9157 | LogLoss: 0.4529\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.0029 | Total: 0.7105\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 6 | Accuracy: 0.9132 | Precision: 0.9622 | Recall: 0.8790 | F1: 0.9187 | LogLoss: 0.4025\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.0028 | Total: 0.7097\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 7 | Accuracy: 0.9087 | Precision: 0.9624 | Recall: 0.8705 | F1: 0.9142 | LogLoss: 0.4274\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.0028 | Total: 0.7143\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4648 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4652 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4651 | λ*Reg: -0.0047 | Total: 0.6885\n",
      "Run 8 | Accuracy: 0.9093 | Precision: 0.9625 | Recall: 0.8715 | F1: 0.9147 | LogLoss: 0.4612\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.0029 | Total: 0.7033\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 9 | Accuracy: 0.9132 | Precision: 0.9612 | Recall: 0.8800 | F1: 0.9188 | LogLoss: 0.4242\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.0029 | Total: 0.7044\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4646 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 10 | Accuracy: 0.9112 | Precision: 0.9611 | Recall: 0.8765 | F1: 0.9168 | LogLoss: 0.4380\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.01 ---\n",
      "Accuracy : 0.9118 ± 0.0022\n",
      "Precision: 0.9620 ± 0.0009\n",
      "Recall   : 0.8766 ± 0.0038\n",
      "F1 Score : 0.9173 ± 0.0022\n",
      "Log Loss : 0.4328 ± 0.0208\n",
      "\n",
      "================ LAMBDA = 0.05 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.0143 | Total: 0.6899\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 1 | Accuracy: 0.9129 | Precision: 0.9617 | Recall: 0.8790 | F1: 0.9185 | LogLoss: 0.5383\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.0142 | Total: 0.6989\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 2 | Accuracy: 0.9121 | Precision: 0.9627 | Recall: 0.8765 | F1: 0.9176 | LogLoss: 0.5673\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.0144 | Total: 0.7062\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 3 | Accuracy: 0.9118 | Precision: 0.9616 | Recall: 0.8770 | F1: 0.9174 | LogLoss: 0.5691\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.0145 | Total: 0.7025\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 4 | Accuracy: 0.9126 | Precision: 0.9617 | Recall: 0.8785 | F1: 0.9182 | LogLoss: 0.5333\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.0145 | Total: 0.7089\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 5 | Accuracy: 0.9118 | Precision: 0.9621 | Recall: 0.8765 | F1: 0.9173 | LogLoss: 0.5622\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.0146 | Total: 0.6988\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 6 | Accuracy: 0.9143 | Precision: 0.9643 | Recall: 0.8790 | F1: 0.9197 | LogLoss: 0.5271\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.0142 | Total: 0.6983\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 7 | Accuracy: 0.9079 | Precision: 0.9613 | Recall: 0.8700 | F1: 0.9134 | LogLoss: 0.5887\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.0142 | Total: 0.7029\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 8 | Accuracy: 0.9104 | Precision: 0.9615 | Recall: 0.8745 | F1: 0.9159 | LogLoss: 0.5727\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.0144 | Total: 0.6918\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 9 | Accuracy: 0.9140 | Precision: 0.9623 | Recall: 0.8805 | F1: 0.9196 | LogLoss: 0.5518\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.0144 | Total: 0.6929\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 10 | Accuracy: 0.9121 | Precision: 0.9611 | Recall: 0.8780 | F1: 0.9177 | LogLoss: 0.5474\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.05 ---\n",
      "Accuracy : 0.9120 ± 0.0017\n",
      "Precision: 0.9620 ± 0.0009\n",
      "Recall   : 0.8769 ± 0.0028\n",
      "F1 Score : 0.9175 ± 0.0017\n",
      "Log Loss : 0.5558 ± 0.0186\n",
      "\n",
      "================ LAMBDA = 0.09 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.0258 | Total: 0.6784\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 1 | Accuracy: 0.9126 | Precision: 0.9617 | Recall: 0.8785 | F1: 0.9182 | LogLoss: 0.5704\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.0256 | Total: 0.6876\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Run 2 | Accuracy: 0.9112 | Precision: 0.9616 | Recall: 0.8760 | F1: 0.9168 | LogLoss: 0.5952\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.0259 | Total: 0.6947\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 3 | Accuracy: 0.9101 | Precision: 0.9615 | Recall: 0.8740 | F1: 0.9157 | LogLoss: 0.5719\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.0261 | Total: 0.6909\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 4 | Accuracy: 0.9126 | Precision: 0.9617 | Recall: 0.8785 | F1: 0.9182 | LogLoss: 0.5687\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.0262 | Total: 0.6973\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Run 5 | Accuracy: 0.9124 | Precision: 0.9627 | Recall: 0.8770 | F1: 0.9178 | LogLoss: 0.6010\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.0262 | Total: 0.6872\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 6 | Accuracy: 0.9146 | Precision: 0.9633 | Recall: 0.8805 | F1: 0.9201 | LogLoss: 0.5575\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.0256 | Total: 0.6869\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Run 7 | Accuracy: 0.9101 | Precision: 0.9620 | Recall: 0.8735 | F1: 0.9156 | LogLoss: 0.5954\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.0256 | Total: 0.6915\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0419 | Total: 0.6513\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Run 8 | Accuracy: 0.9115 | Precision: 0.9616 | Recall: 0.8765 | F1: 0.9171 | LogLoss: 0.5880\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.0259 | Total: 0.6803\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Run 9 | Accuracy: 0.9138 | Precision: 0.9618 | Recall: 0.8805 | F1: 0.9193 | LogLoss: 0.5751\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.0258 | Total: 0.6814\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 10 | Accuracy: 0.9140 | Precision: 0.9623 | Recall: 0.8805 | F1: 0.9196 | LogLoss: 0.5596\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.09 ---\n",
      "Accuracy : 0.9123 ± 0.0015\n",
      "Precision: 0.9620 ± 0.0006\n",
      "Recall   : 0.8775 ± 0.0025\n",
      "F1 Score : 0.9178 ± 0.0015\n",
      "Log Loss : 0.5783 ± 0.0148\n",
      "\n",
      "================ LAMBDA = 0.1 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.0287 | Total: 0.6755\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 1 | Accuracy: 0.9138 | Precision: 0.9623 | Recall: 0.8800 | F1: 0.9193 | LogLoss: 0.5732\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.0284 | Total: 0.6847\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 2 | Accuracy: 0.9115 | Precision: 0.9611 | Recall: 0.8770 | F1: 0.9171 | LogLoss: 0.5981\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.0287 | Total: 0.6918\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 3 | Accuracy: 0.9112 | Precision: 0.9616 | Recall: 0.8760 | F1: 0.9168 | LogLoss: 0.5935\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.0290 | Total: 0.6880\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Run 4 | Accuracy: 0.9140 | Precision: 0.9623 | Recall: 0.8805 | F1: 0.9196 | LogLoss: 0.5693\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.0291 | Total: 0.6944\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.0467 | Total: 0.6464\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 5 | Accuracy: 0.9124 | Precision: 0.9617 | Recall: 0.8780 | F1: 0.9179 | LogLoss: 0.6145\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.0291 | Total: 0.6843\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Run 6 | Accuracy: 0.9140 | Precision: 0.9628 | Recall: 0.8800 | F1: 0.9195 | LogLoss: 0.5627\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.0285 | Total: 0.6840\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 7 | Accuracy: 0.9093 | Precision: 0.9619 | Recall: 0.8720 | F1: 0.9148 | LogLoss: 0.6046\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.0285 | Total: 0.6886\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 8 | Accuracy: 0.9112 | Precision: 0.9621 | Recall: 0.8755 | F1: 0.9168 | LogLoss: 0.5925\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.0288 | Total: 0.6774\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 9 | Accuracy: 0.9135 | Precision: 0.9617 | Recall: 0.8800 | F1: 0.9191 | LogLoss: 0.5811\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.0287 | Total: 0.6786\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 10 | Accuracy: 0.9135 | Precision: 0.9617 | Recall: 0.8800 | F1: 0.9191 | LogLoss: 0.5834\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.1 ---\n",
      "Accuracy : 0.9124 ± 0.0015\n",
      "Precision: 0.9619 ± 0.0004\n",
      "Recall   : 0.8779 ± 0.0026\n",
      "F1 Score : 0.9180 ± 0.0015\n",
      "Log Loss : 0.5873 ± 0.0155\n",
      "\n",
      "================ LAMBDA = 0.3 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.0860 | Total: 0.6182\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.1399 | Total: 0.5532\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Run 1 | Accuracy: 0.9126 | Precision: 0.9622 | Recall: 0.8780 | F1: 0.9182 | LogLoss: 0.6516\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.0853 | Total: 0.6279\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Run 2 | Accuracy: 0.9112 | Precision: 0.9616 | Recall: 0.8760 | F1: 0.9168 | LogLoss: 0.6834\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.0862 | Total: 0.6343\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Run 3 | Accuracy: 0.9112 | Precision: 0.9621 | Recall: 0.8755 | F1: 0.9168 | LogLoss: 0.6793\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.0869 | Total: 0.6301\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Run 4 | Accuracy: 0.9124 | Precision: 0.9622 | Recall: 0.8775 | F1: 0.9179 | LogLoss: 0.6633\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.0872 | Total: 0.6363\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Run 5 | Accuracy: 0.9126 | Precision: 0.9622 | Recall: 0.8780 | F1: 0.9182 | LogLoss: 0.6920\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.0874 | Total: 0.6260\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Run 6 | Accuracy: 0.9129 | Precision: 0.9627 | Recall: 0.8780 | F1: 0.9184 | LogLoss: 0.6652\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.0855 | Total: 0.6271\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Run 7 | Accuracy: 0.9118 | Precision: 0.9616 | Recall: 0.8770 | F1: 0.9174 | LogLoss: 0.6932\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.0854 | Total: 0.6317\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Run 8 | Accuracy: 0.9112 | Precision: 0.9616 | Recall: 0.8760 | F1: 0.9168 | LogLoss: 0.7098\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.0863 | Total: 0.6199\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.1399 | Total: 0.5532\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Run 9 | Accuracy: 0.9124 | Precision: 0.9622 | Recall: 0.8775 | F1: 0.9179 | LogLoss: 0.6522\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.0861 | Total: 0.6212\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.1399 | Total: 0.5533\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Run 10 | Accuracy: 0.9143 | Precision: 0.9623 | Recall: 0.8810 | F1: 0.9199 | LogLoss: 0.6540\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.3 ---\n",
      "Accuracy : 0.9123 ± 0.0009\n",
      "Precision: 0.9621 ± 0.0003\n",
      "Recall   : 0.8774 ± 0.0015\n",
      "F1 Score : 0.9178 ± 0.0009\n",
      "Log Loss : 0.6744 ± 0.0191\n",
      "\n",
      "================ LAMBDA = 0.5 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.1433 | Total: 0.5609\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.2331 | Total: 0.4600\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Run 1 | Accuracy: 0.9143 | Precision: 0.9623 | Recall: 0.8810 | F1: 0.9199 | LogLoss: 0.6832\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.1421 | Total: 0.5710\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.2334 | Total: 0.4598\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Run 2 | Accuracy: 0.9115 | Precision: 0.9616 | Recall: 0.8765 | F1: 0.9171 | LogLoss: 0.7157\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.1437 | Total: 0.5768\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.2333 | Total: 0.4599\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Run 3 | Accuracy: 0.9118 | Precision: 0.9621 | Recall: 0.8765 | F1: 0.9173 | LogLoss: 0.7147\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.1448 | Total: 0.5722\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Run 4 | Accuracy: 0.9135 | Precision: 0.9628 | Recall: 0.8790 | F1: 0.9190 | LogLoss: 0.6979\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.1453 | Total: 0.5781\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.2332 | Total: 0.4599\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Run 5 | Accuracy: 0.9140 | Precision: 0.9628 | Recall: 0.8800 | F1: 0.9195 | LogLoss: 0.6970\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.1456 | Total: 0.5678\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.2333 | Total: 0.4598\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Run 6 | Accuracy: 0.9135 | Precision: 0.9623 | Recall: 0.8795 | F1: 0.9190 | LogLoss: 0.6905\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.1424 | Total: 0.5701\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.2333 | Total: 0.4598\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Run 7 | Accuracy: 0.9121 | Precision: 0.9627 | Recall: 0.8765 | F1: 0.9176 | LogLoss: 0.7055\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.1423 | Total: 0.5748\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.2333 | Total: 0.4598\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Run 8 | Accuracy: 0.9126 | Precision: 0.9622 | Recall: 0.8780 | F1: 0.9182 | LogLoss: 0.7194\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.1439 | Total: 0.5623\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.2334 | Total: 0.4598\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Run 9 | Accuracy: 0.9138 | Precision: 0.9623 | Recall: 0.8800 | F1: 0.9193 | LogLoss: 0.7010\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.1435 | Total: 0.5638\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.2335 | Total: 0.4597\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Run 10 | Accuracy: 0.9149 | Precision: 0.9624 | Recall: 0.8820 | F1: 0.9204 | LogLoss: 0.7178\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.5 ---\n",
      "Accuracy : 0.9132 ± 0.0011\n",
      "Precision: 0.9623 ± 0.0003\n",
      "Recall   : 0.8789 ± 0.0019\n",
      "F1 Score : 0.9187 ± 0.0011\n",
      "Log Loss : 0.7043 ± 0.0118\n",
      "\n",
      "================ LAMBDA = 0.9 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.2580 | Total: 0.4462\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.4200 | Total: 0.2731\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Run 1 | Accuracy: 0.9143 | Precision: 0.9623 | Recall: 0.8810 | F1: 0.9199 | LogLoss: 0.7469\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.2558 | Total: 0.4573\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.4202 | Total: 0.2729\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Run 2 | Accuracy: 0.9124 | Precision: 0.9622 | Recall: 0.8775 | F1: 0.9179 | LogLoss: 0.7587\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.2586 | Total: 0.4619\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.4202 | Total: 0.2729\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Run 3 | Accuracy: 0.9132 | Precision: 0.9627 | Recall: 0.8785 | F1: 0.9187 | LogLoss: 0.7634\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.2606 | Total: 0.4564\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4204 | Total: 0.2727\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Run 4 | Accuracy: 0.9132 | Precision: 0.9627 | Recall: 0.8785 | F1: 0.9187 | LogLoss: 0.7666\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.2616 | Total: 0.4619\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.4203 | Total: 0.2728\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Run 5 | Accuracy: 0.9135 | Precision: 0.9623 | Recall: 0.8795 | F1: 0.9190 | LogLoss: 0.7669\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.2621 | Total: 0.4513\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.4199 | Total: 0.2732\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Run 6 | Accuracy: 0.9138 | Precision: 0.9628 | Recall: 0.8795 | F1: 0.9193 | LogLoss: 0.7314\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.2564 | Total: 0.4561\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.4203 | Total: 0.2729\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Run 7 | Accuracy: 0.9121 | Precision: 0.9622 | Recall: 0.8770 | F1: 0.9176 | LogLoss: 0.7653\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.2562 | Total: 0.4609\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4205 | Total: 0.2726\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Run 8 | Accuracy: 0.9129 | Precision: 0.9622 | Recall: 0.8785 | F1: 0.9185 | LogLoss: 0.7851\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.2590 | Total: 0.4472\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4205 | Total: 0.2727\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Run 9 | Accuracy: 0.9140 | Precision: 0.9628 | Recall: 0.8800 | F1: 0.9195 | LogLoss: 0.7550\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.2583 | Total: 0.4490\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4204 | Total: 0.2727\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Run 10 | Accuracy: 0.9149 | Precision: 0.9624 | Recall: 0.8820 | F1: 0.9204 | LogLoss: 0.7795\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.9 ---\n",
      "Accuracy : 0.9134 ± 0.0008\n",
      "Precision: 0.9625 ± 0.0003\n",
      "Recall   : 0.8792 ± 0.0015\n",
      "F1 Score : 0.9189 ± 0.0008\n",
      "Log Loss : 0.7619 ± 0.0146\n",
      "\n",
      "================ LAMBDA = 1 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.2866 | Total: 0.4176\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4672 | Total: 0.2259\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Run 1 | Accuracy: 0.9135 | Precision: 0.9623 | Recall: 0.8795 | F1: 0.9190 | LogLoss: 0.7808\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.2842 | Total: 0.4289\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4671 | Total: 0.2260\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Run 2 | Accuracy: 0.9115 | Precision: 0.9616 | Recall: 0.8765 | F1: 0.9171 | LogLoss: 0.7773\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.2874 | Total: 0.4332\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4671 | Total: 0.2260\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Run 3 | Accuracy: 0.9124 | Precision: 0.9627 | Recall: 0.8770 | F1: 0.9178 | LogLoss: 0.7816\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.2895 | Total: 0.4274\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2259\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Run 4 | Accuracy: 0.9124 | Precision: 0.9627 | Recall: 0.8770 | F1: 0.9178 | LogLoss: 0.7740\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.2907 | Total: 0.4328\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4671 | Total: 0.2261\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Run 5 | Accuracy: 0.9132 | Precision: 0.9622 | Recall: 0.8790 | F1: 0.9187 | LogLoss: 0.7755\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.2912 | Total: 0.4222\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.4670 | Total: 0.2261\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Run 6 | Accuracy: 0.9143 | Precision: 0.9633 | Recall: 0.8800 | F1: 0.9198 | LogLoss: 0.7537\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.2849 | Total: 0.4276\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4671 | Total: 0.2261\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Run 7 | Accuracy: 0.9121 | Precision: 0.9622 | Recall: 0.8770 | F1: 0.9176 | LogLoss: 0.7708\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.2847 | Total: 0.4324\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4671 | Total: 0.2261\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Run 8 | Accuracy: 0.9129 | Precision: 0.9622 | Recall: 0.8785 | F1: 0.9185 | LogLoss: 0.7803\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.2878 | Total: 0.4185\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.4670 | Total: 0.2261\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2256\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Run 9 | Accuracy: 0.9143 | Precision: 0.9618 | Recall: 0.8815 | F1: 0.9199 | LogLoss: 0.7557\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.2870 | Total: 0.4203\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4672 | Total: 0.2259\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Run 10 | Accuracy: 0.9143 | Precision: 0.9623 | Recall: 0.8810 | F1: 0.9199 | LogLoss: 0.7974\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 1 ---\n",
      "Accuracy : 0.9131 ± 0.0010\n",
      "Precision: 0.9623 ± 0.0005\n",
      "Recall   : 0.8787 ± 0.0017\n",
      "F1 Score : 0.9186 ± 0.0010\n",
      "Log Loss : 0.7747 ± 0.0121\n",
      "\n",
      "================ LAMBDA = 2 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -0.5733 | Total: 0.1309\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.9350 | Total: -0.2418\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Run 1 | Accuracy: 0.9129 | Precision: 0.9622 | Recall: 0.8785 | F1: 0.9185 | LogLoss: 0.8381\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -0.5684 | Total: 0.1447\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.9348 | Total: -0.2417\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2423\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Run 2 | Accuracy: 0.9112 | Precision: 0.9616 | Recall: 0.8760 | F1: 0.9168 | LogLoss: 0.8448\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -0.5747 | Total: 0.1458\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.9348 | Total: -0.2417\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Run 3 | Accuracy: 0.9110 | Precision: 0.9621 | Recall: 0.8750 | F1: 0.9165 | LogLoss: 0.8506\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -0.5791 | Total: 0.1379\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9352 | Total: -0.2420\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Run 4 | Accuracy: 0.9112 | Precision: 0.9626 | Recall: 0.8750 | F1: 0.9167 | LogLoss: 0.8435\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -0.5813 | Total: 0.1421\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.9350 | Total: -0.2419\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Run 5 | Accuracy: 0.9132 | Precision: 0.9622 | Recall: 0.8790 | F1: 0.9187 | LogLoss: 0.8486\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -0.5824 | Total: 0.1310\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.9348 | Total: -0.2417\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Run 6 | Accuracy: 0.9132 | Precision: 0.9632 | Recall: 0.8780 | F1: 0.9187 | LogLoss: 0.8297\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -0.5698 | Total: 0.1428\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.9347 | Total: -0.2416\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2423\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2423\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Run 7 | Accuracy: 0.9118 | Precision: 0.9621 | Recall: 0.8765 | F1: 0.9173 | LogLoss: 0.8343\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -0.5694 | Total: 0.1478\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.9349 | Total: -0.2417\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Run 8 | Accuracy: 0.9129 | Precision: 0.9622 | Recall: 0.8785 | F1: 0.9185 | LogLoss: 0.8435\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -0.5755 | Total: 0.1307\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.9349 | Total: -0.2417\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Run 9 | Accuracy: 0.9132 | Precision: 0.9627 | Recall: 0.8785 | F1: 0.9187 | LogLoss: 0.8305\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -0.5740 | Total: 0.1333\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.9351 | Total: -0.2419\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Run 10 | Accuracy: 0.9124 | Precision: 0.9617 | Recall: 0.8780 | F1: 0.9179 | LogLoss: 0.8600\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 2 ---\n",
      "Accuracy : 0.9123 ± 0.0009\n",
      "Precision: 0.9623 ± 0.0005\n",
      "Recall   : 0.8773 ± 0.0015\n",
      "F1 Score : 0.9178 ± 0.0009\n",
      "Log Loss : 0.8424 ± 0.0090\n",
      "\n",
      "================ LAMBDA = 5 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -1.4332 | Total: -0.7290\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -2.3384 | Total: -1.6452\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Run 1 | Accuracy: 0.9068 | Precision: 0.9597 | Recall: 0.8695 | F1: 0.9124 | LogLoss: 0.9630\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -1.4210 | Total: -0.7079\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -2.3384 | Total: -1.6453\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6466\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Run 2 | Accuracy: 0.9057 | Precision: 0.9591 | Recall: 0.8680 | F1: 0.9113 | LogLoss: 0.9582\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -1.4368 | Total: -0.7163\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3388 | Total: -1.6456\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6463\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6464\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6466\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6466\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6466\n",
      "Run 3 | Accuracy: 0.9104 | Precision: 0.9615 | Recall: 0.8745 | F1: 0.9159 | LogLoss: 0.9354\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -1.4477 | Total: -0.7307\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3388 | Total: -1.6456\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Run 4 | Accuracy: 0.9071 | Precision: 0.9592 | Recall: 0.8705 | F1: 0.9127 | LogLoss: 0.9521\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -1.4533 | Total: -0.7299\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3388 | Total: -1.6456\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6463\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6464\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6464\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6466\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6465\n",
      "Run 5 | Accuracy: 0.9112 | Precision: 0.9616 | Recall: 0.8760 | F1: 0.9168 | LogLoss: 0.9259\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -1.4561 | Total: -0.7427\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3389 | Total: -1.6458\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Run 6 | Accuracy: 0.9065 | Precision: 0.9582 | Recall: 0.8705 | F1: 0.9122 | LogLoss: 0.9585\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -1.4244 | Total: -0.7119\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -2.3386 | Total: -1.6454\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3394 | Total: -1.6463\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6464\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6464\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6464\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6466\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6464\n",
      "Run 7 | Accuracy: 0.9104 | Precision: 0.9615 | Recall: 0.8745 | F1: 0.9159 | LogLoss: 0.9233\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -1.4234 | Total: -0.7063\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3389 | Total: -1.6458\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Run 8 | Accuracy: 0.9068 | Precision: 0.9592 | Recall: 0.8700 | F1: 0.9124 | LogLoss: 0.9720\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -1.4388 | Total: -0.7326\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -2.3384 | Total: -1.6453\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3394 | Total: -1.6462\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3394 | Total: -1.6463\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6464\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6464\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6464\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6464\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6464\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6464\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6464\n",
      "Run 9 | Accuracy: 0.9107 | Precision: 0.9615 | Recall: 0.8750 | F1: 0.9162 | LogLoss: 0.9116\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -1.4350 | Total: -0.7277\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3388 | Total: -1.6457\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Run 10 | Accuracy: 0.9054 | Precision: 0.9591 | Recall: 0.8675 | F1: 0.9110 | LogLoss: 0.9688\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 5 ---\n",
      "Accuracy : 0.9081 ± 0.0022\n",
      "Precision: 0.9601 ± 0.0013\n",
      "Recall   : 0.8716 ± 0.0029\n",
      "F1 Score : 0.9137 ± 0.0021\n",
      "Log Loss : 0.9469 ± 0.0201\n",
      "\n",
      "================ LAMBDA = 8 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7042 | Reg: -0.2866 | λ*Reg: -2.2931 | Total: -1.5889\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7431 | Total: -3.0499\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7444 | Total: -3.0513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0514\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Run 1 | Accuracy: 0.9037 | Precision: 0.9579 | Recall: 0.8655 | F1: 0.9094 | LogLoss: 1.0250\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2842 | λ*Reg: -2.2736 | Total: -1.5605\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7421 | Total: -3.0490\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7442 | Total: -3.0511\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Run 2 | Accuracy: 0.9059 | Precision: 0.9581 | Recall: 0.8695 | F1: 0.9117 | LogLoss: 1.0216\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7205 | Reg: -0.2874 | λ*Reg: -2.2989 | Total: -1.5783\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7428 | Total: -3.0497\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7437 | Total: -3.0505\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7439 | Total: -3.0508\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7439 | Total: -3.0507\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7438 | Total: -3.0506\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7440 | Total: -3.0508\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7440 | Total: -3.0508\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7439 | Total: -3.0508\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7440 | Total: -3.0509\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7440 | Total: -3.0509\n",
      "Run 3 | Accuracy: 0.9110 | Precision: 0.9616 | Recall: 0.8755 | F1: 0.9165 | LogLoss: 0.9711\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7170 | Reg: -0.2895 | λ*Reg: -2.3163 | Total: -1.5993\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7436 | Total: -3.0505\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Run 4 | Accuracy: 0.9043 | Precision: 0.9580 | Recall: 0.8665 | F1: 0.9100 | LogLoss: 1.0400\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7235 | Reg: -0.2907 | λ*Reg: -2.3253 | Total: -1.6019\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7428 | Total: -3.0496\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7437 | Total: -3.0506\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7438 | Total: -3.0507\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7439 | Total: -3.0507\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7440 | Total: -3.0508\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7440 | Total: -3.0509\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7438 | Total: -3.0507\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7439 | Total: -3.0508\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7438 | Total: -3.0507\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7439 | Total: -3.0508\n",
      "Run 5 | Accuracy: 0.9115 | Precision: 0.9611 | Recall: 0.8770 | F1: 0.9171 | LogLoss: 0.9645\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7134 | Reg: -0.2912 | λ*Reg: -2.3297 | Total: -1.6163\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7430 | Total: -3.0498\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7444 | Total: -3.0513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0514\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Run 6 | Accuracy: 0.9062 | Precision: 0.9581 | Recall: 0.8700 | F1: 0.9119 | LogLoss: 1.0113\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7125 | Reg: -0.2849 | λ*Reg: -2.2791 | Total: -1.5665\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7427 | Total: -3.0496\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7444 | Total: -3.0512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Run 7 | Accuracy: 0.9043 | Precision: 0.9580 | Recall: 0.8665 | F1: 0.9100 | LogLoss: 1.0296\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2847 | λ*Reg: -2.2774 | Total: -1.5603\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7423 | Total: -3.0492\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7439 | Total: -3.0508\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0511\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7442 | Total: -3.0511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0511\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7444 | Total: -3.0512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7444 | Total: -3.0513\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7442 | Total: -3.0511\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0511\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0512\n",
      "Run 8 | Accuracy: 0.9062 | Precision: 0.9592 | Recall: 0.8690 | F1: 0.9119 | LogLoss: 0.9835\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7062 | Reg: -0.2878 | λ*Reg: -2.3020 | Total: -1.5958\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7424 | Total: -3.0492\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7435 | Total: -3.0504\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7435 | Total: -3.0504\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7438 | Total: -3.0506\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7438 | Total: -3.0506\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7438 | Total: -3.0506\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7437 | Total: -3.0505\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7439 | Total: -3.0507\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7438 | Total: -3.0507\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7437 | Total: -3.0505\n",
      "Run 9 | Accuracy: 0.9104 | Precision: 0.9615 | Recall: 0.8745 | F1: 0.9159 | LogLoss: 0.9532\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7073 | Reg: -0.2870 | λ*Reg: -2.2960 | Total: -1.5887\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7428 | Total: -3.0496\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7444 | Total: -3.0513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0514\n",
      "Run 10 | Accuracy: 0.9048 | Precision: 0.9575 | Recall: 0.8680 | F1: 0.9106 | LogLoss: 1.0141\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 8 ---\n",
      "Accuracy : 0.9068 ± 0.0028\n",
      "Precision: 0.9591 ± 0.0015\n",
      "Recall   : 0.8702 ± 0.0039\n",
      "F1 Score : 0.9125 ± 0.0028\n",
      "Log Loss : 1.0014 ± 0.0290\n",
      "\n",
      "================ FINAL SUMMARY FOR ALL LAMBDAS ================\n",
      "\n",
      "  Lambda |           Accuracy |          Precision |             Recall |           F1 Score |           Log Loss\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "   0.001 | 0.9139 ± 0.0042 | 0.9587 ± 0.0036 | 0.8837 ± 0.0081 | 0.9197 ± 0.0043 | 0.2626 ± 0.0157\n",
      "   0.005 | 0.9119 ± 0.0026 | 0.9606 ± 0.0010 | 0.8781 ± 0.0041 | 0.9175 ± 0.0025 | 0.3719 ± 0.0188\n",
      "   0.009 | 0.9118 ± 0.0017 | 0.9620 ± 0.0010 | 0.8767 ± 0.0034 | 0.9174 ± 0.0017 | 0.4245 ± 0.0215\n",
      "    0.01 | 0.9118 ± 0.0022 | 0.9620 ± 0.0009 | 0.8766 ± 0.0038 | 0.9173 ± 0.0022 | 0.4328 ± 0.0208\n",
      "    0.05 | 0.9120 ± 0.0017 | 0.9620 ± 0.0009 | 0.8769 ± 0.0028 | 0.9175 ± 0.0017 | 0.5558 ± 0.0186\n",
      "    0.09 | 0.9123 ± 0.0015 | 0.9620 ± 0.0006 | 0.8775 ± 0.0025 | 0.9178 ± 0.0015 | 0.5783 ± 0.0148\n",
      "     0.1 | 0.9124 ± 0.0015 | 0.9619 ± 0.0004 | 0.8779 ± 0.0026 | 0.9180 ± 0.0015 | 0.5873 ± 0.0155\n",
      "     0.3 | 0.9123 ± 0.0009 | 0.9621 ± 0.0003 | 0.8774 ± 0.0015 | 0.9178 ± 0.0009 | 0.6744 ± 0.0191\n",
      "     0.5 | 0.9132 ± 0.0011 | 0.9623 ± 0.0003 | 0.8789 ± 0.0019 | 0.9187 ± 0.0011 | 0.7043 ± 0.0118\n",
      "     0.9 | 0.9134 ± 0.0008 | 0.9625 ± 0.0003 | 0.8792 ± 0.0015 | 0.9189 ± 0.0008 | 0.7619 ± 0.0146\n",
      "       1 | 0.9131 ± 0.0010 | 0.9623 ± 0.0005 | 0.8787 ± 0.0017 | 0.9186 ± 0.0010 | 0.7747 ± 0.0121\n",
      "       2 | 0.9123 ± 0.0009 | 0.9623 ± 0.0005 | 0.8773 ± 0.0015 | 0.9178 ± 0.0009 | 0.8424 ± 0.0090\n",
      "       5 | 0.9081 ± 0.0022 | 0.9601 ± 0.0013 | 0.8716 ± 0.0029 | 0.9137 ± 0.0021 | 0.9469 ± 0.0201\n",
      "       8 | 0.9068 ± 0.0028 | 0.9591 ± 0.0015 | 0.8702 ± 0.0039 | 0.9125 ± 0.0028 | 1.0014 ± 0.0290\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "hidden_dim   = 256\n",
    "cut          = 0\n",
    "dropout      = 0.25\n",
    "num_runs     = 10\n",
    "num_epochs   = 5000\n",
    "lambda_list  = [0.001, 0.005, 0.009, 0.01, 0.05, 0.09, 0.1, 0.3, 0.5, 0.9, 1, 2, 5, 8]\n",
    "base_seed    = 42\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "node_feats = node_feats.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "A = A.to(device)\n",
    "\n",
    "# Use the y_subset created earlier\n",
    "y_subset_np = y_subset.astype(int)\n",
    "\n",
    "N, feats_dim = node_feats.size(0), node_feats.size(1)\n",
    "\n",
    "all_results = []\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for lam in lambda_list:\n",
    "    print(f\"\\n================ LAMBDA = {lam} ================\\n\")\n",
    "\n",
    "    acc_scores, prec_scores, rec_scores, f1_scores, log_losses = [], [], [], [], []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        print(f\"\\n--- Run {run+1}/{num_runs} ---\")\n",
    "\n",
    "        seed = base_seed + run\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "        model = DGI_with_classifier(feats_dim, hidden_dim, n_classes=2, cut=cut, dropout=dropout).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)\n",
    "        scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n",
    "\n",
    "\n",
    "        for epoch in range(num_epochs + 1):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            perm = torch.randperm(N, device=device)\n",
    "            corrupt_features = node_feats[perm]\n",
    "\n",
    "            logits, embeddings = model(node_feats, corrupt_features, edge_index)\n",
    "\n",
    "            lbl = torch.cat([torch.ones(N, device=device), torch.zeros(N, device=device)])\n",
    "            dgi_loss = bce_loss(logits.squeeze(), lbl)\n",
    "            reg_loss = model.Reg_loss(A, embeddings)\n",
    "\n",
    "            loss = dgi_loss + lam * reg_loss\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                print(f\"Epoch {epoch:4d} | DGI: {dgi_loss.item():.4f} | Reg: {reg_loss.item():.4f} | \"\n",
    "                      f\"λ*Reg: {(lam * reg_loss).item():.4f} | Total: {loss.item():.4f}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            emb = model.get_embeddings(node_feats, edge_index)\n",
    "            logits_cls = model.classifier(emb)                   # [N, 2]\n",
    "            class_probabilities = F.softmax(logits_cls, dim=1).cpu().numpy()\n",
    "            y_pred = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "        acc  = accuracy_score(y_subset_np, y_pred)\n",
    "        acc_inv = accuracy_score(y_subset_np, 1 - y_pred)\n",
    "\n",
    "        if acc_inv > acc:\n",
    "            acc = acc_inv\n",
    "            y_pred = 1 - y_pred\n",
    "            class_probabilities = class_probabilities[:, ::-1]\n",
    "\n",
    "        prec = precision_score(y_subset_np, y_pred, zero_division=0)\n",
    "        rec  = recall_score(y_subset_np, y_pred, zero_division=0)\n",
    "        f1   = f1_score(y_subset_np, y_pred, zero_division=0)\n",
    "        ll   = log_loss(y_subset_np, class_probabilities)\n",
    "\n",
    "        print(f\"Run {run+1} | Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | LogLoss: {ll:.4f}\")\n",
    "\n",
    "        acc_scores.append(acc)\n",
    "        prec_scores.append(prec)\n",
    "        rec_scores.append(rec)\n",
    "        f1_scores.append(f1)\n",
    "        log_losses.append(ll)\n",
    "\n",
    "    lambda_results = {\n",
    "        \"lambda\": lam,\n",
    "        \"accuracy\":  (float(np.mean(acc_scores)), float(np.std(acc_scores))),\n",
    "        \"precision\": (float(np.mean(prec_scores)), float(np.std(prec_scores))),\n",
    "        \"recall\":    (float(np.mean(rec_scores)), float(np.std(rec_scores))),\n",
    "        \"f1\":        (float(np.mean(f1_scores)),  float(np.std(f1_scores))),\n",
    "        \"log_loss\":  (float(np.mean(log_losses)), float(np.std(log_losses))),\n",
    "    }\n",
    "    all_results.append(lambda_results)\n",
    "\n",
    "    print(f\"\\n--- RESULTS FOR LAMBDA = {lam} ---\")\n",
    "    print(f\"Accuracy : {lambda_results['accuracy'][0]:.4f} ± {lambda_results['accuracy'][1]:.4f}\")\n",
    "    print(f\"Precision: {lambda_results['precision'][0]:.4f} ± {lambda_results['precision'][1]:.4f}\")\n",
    "    print(f\"Recall   : {lambda_results['recall'][0]:.4f} ± {lambda_results['recall'][1]:.4f}\")\n",
    "    print(f\"F1 Score : {lambda_results['f1'][0]:.4f} ± {lambda_results['f1'][1]:.4f}\")\n",
    "    print(f\"Log Loss : {lambda_results['log_loss'][0]:.4f} ± {lambda_results['log_loss'][1]:.4f}\")\n",
    "\n",
    "print(\"\\n================ FINAL SUMMARY FOR ALL LAMBDAS ================\\n\")\n",
    "print(f\"{'Lambda':>8} | {'Accuracy':>18} | {'Precision':>18} | {'Recall':>18} | {'F1 Score':>18} | {'Log Loss':>18}\")\n",
    "print(\"-\" * 108)\n",
    "for res in all_results:\n",
    "    print(f\"{res['lambda']:>8} | \"\n",
    "          f\"{res['accuracy'][0]:.4f} ± {res['accuracy'][1]:.4f} | \"\n",
    "          f\"{res['precision'][0]:.4f} ± {res['precision'][1]:.4f} | \"\n",
    "          f\"{res['recall'][0]:.4f} ± {res['recall'][1]:.4f} | \"\n",
    "          f\"{res['f1'][0]:.4f} ± {res['f1'][1]:.4f} | \"\n",
    "          f\"{res['log_loss'][0]:.4f} ± {res['log_loss'][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoZr8SupDBbh",
    "outputId": "bf0c8e2c-ccdf-4256-dbcc-71538cba1dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: -0.001379769830930187\n",
      "Normalized Mutual Information Score: 7.97612442553983e-05\n",
      "Clustering Accuracy (mapped): 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def cluster_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Assigns predicted clusters to true labels\n",
    "    to maximize accuracy using the Jonker-Volgenant algorithm (linear_sum_assignment).\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(-w)\n",
    "    return w[row_ind, col_ind].sum() / y_pred.size\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model.get_embeddings(node_feats.to(device), edge_index.to(device))\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "kmeans.fit(embeddings)\n",
    "y_pred_kmeans = kmeans.labels_\n",
    "\n",
    "ari_score = adjusted_rand_score(y, y_pred_kmeans)\n",
    "nmi_score = normalized_mutual_info_score(y, y_pred_kmeans)\n",
    "\n",
    "print(\"Adjusted Rand Score:\", ari_score)\n",
    "print(\"Normalized Mutual Information Score:\", nmi_score)\n",
    "\n",
    "acc_kmeans = cluster_acc(y, y_pred_kmeans)\n",
    "print(\"Clustering Accuracy (mapped):\", acc_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adGSi9JiEEqO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPfsaXB6_EZp"
   },
   "outputs": [],
   "source": [
    "# class DGI(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim,output_dim, cut=0):\n",
    "#         super().__init__()\n",
    "#         self.encoder = GCNEncoder(input_dim, hidden_dim)\n",
    "#         self.readout = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.cut = cut\n",
    "#         self.output_dim = output_dim\n",
    "\n",
    "#     def forward(self, x, edge_index, corrupt_x, adj=None):\n",
    "#         h = self.encoder(x, edge_index)\n",
    "#         h_corrupt = self.encoder(corrupt_x, edge_index)\n",
    "\n",
    "#         # Summary vector\n",
    "#         s = torch.sigmoid(h.mean(dim=0))\n",
    "\n",
    "#         # Positive & negative scores\n",
    "#         pos = torch.matmul(h, s)\n",
    "#         neg = torch.matmul(h_corrupt, s)\n",
    "\n",
    "#         # DGI loss\n",
    "#         dgi_loss = -torch.log(torch.sigmoid(pos - neg) + 1e-8).mean()\n",
    "\n",
    "#         reg_loss = 0\n",
    "#         if adj is not None:\n",
    "#             A = torch.as_tensor(adj, dtype=torch.float32, device=x.device)\n",
    "#             D = torch.diag(A.sum(dim=1))\n",
    "\n",
    "#             if self.cut == 1:  # Cut loss\n",
    "#                 L = D - A\n",
    "#                 p = self.readout(h)\n",
    "#                 C = F.softmax(p, dim=1)\n",
    "#                 reg_loss = torch.trace(C.T @ L @ C) / (torch.trace(C.T @ D @ C) + 1e-8)\n",
    "\n",
    "#             else:  # Modularity loss\n",
    "#                 m = torch.sum(A)\n",
    "#                 B = A - torch.outer(D.diag(), D.diag()) / (2 * m)\n",
    "#                 p = self.readout(h)\n",
    "#                 C = F.softmax(p, dim=1)\n",
    "#                 k = torch.tensor(self.output_dim, dtype=torch.float32, device=x.device)\n",
    "#                 n = C.shape[0]\n",
    "#                 reg_loss = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n",
    "#                 reg_loss += (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n",
    "\n",
    "\n",
    "#         return h, dgi_loss, reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xzy_llWw_UGN",
    "outputId": "db4fe94b-e693-45af-a7b5-2f4b9bf7342c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | DGI Loss: 0.6922 | Reg Loss: -0.1250 | Total Loss: 0.5672\n",
      "Epoch 500 | DGI Loss: 0.2924 | Reg Loss: -0.1250 | Total Loss: 0.1674\n",
      "Epoch 1000 | DGI Loss: 0.2514 | Reg Loss: -0.1250 | Total Loss: 0.1264\n",
      "Epoch 1500 | DGI Loss: 0.2425 | Reg Loss: -0.1250 | Total Loss: 0.1175\n",
      "Epoch 2000 | DGI Loss: 0.2083 | Reg Loss: -0.1250 | Total Loss: 0.0833\n",
      "Epoch 2500 | DGI Loss: 0.2106 | Reg Loss: -0.1250 | Total Loss: 0.0856\n",
      "Epoch 3000 | DGI Loss: 0.1714 | Reg Loss: -0.1246 | Total Loss: 0.0468\n",
      "Epoch 3500 | DGI Loss: 0.1480 | Reg Loss: -0.1256 | Total Loss: 0.0224\n",
      "Epoch 4000 | DGI Loss: 0.1510 | Reg Loss: -0.1278 | Total Loss: 0.0232\n",
      "Epoch 4500 | DGI Loss: 0.1389 | Reg Loss: -0.1328 | Total Loss: 0.0060\n",
      "Epoch 5000 | DGI Loss: 0.1076 | Reg Loss: -0.1373 | Total Loss: -0.0297\n",
      "Epoch 5500 | DGI Loss: 0.1220 | Reg Loss: -0.1399 | Total Loss: -0.0180\n",
      "Epoch 6000 | DGI Loss: 0.0915 | Reg Loss: -0.1414 | Total Loss: -0.0499\n",
      "Epoch 6500 | DGI Loss: 0.0746 | Reg Loss: -0.1428 | Total Loss: -0.0681\n",
      "Epoch 7000 | DGI Loss: 0.0863 | Reg Loss: -0.1426 | Total Loss: -0.0563\n"
     ]
    }
   ],
   "source": [
    "# hidden_dim = 256\n",
    "# output_dim = 2\n",
    "# cut = 0\n",
    "# model = DGI(features.shape[1], hidden_dim, output_dim, cut=cut).to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# num_epochs = 7000\n",
    "# for epoch in range(num_epochs+1):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     perm = torch.randperm(features.shape[0])\n",
    "#     corrupt_features = node_feats[perm]\n",
    "\n",
    "#     _, dgi_loss, reg_loss = model(\n",
    "#         node_feats.to(device),\n",
    "#         edge_index.to(device),\n",
    "#         corrupt_features.to(device),\n",
    "#         adj=torch.tensor(W0).to(device)\n",
    "#     )\n",
    "\n",
    "#     loss = dgi_loss + reg_loss\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if epoch % 500 == 0:\n",
    "#         print(f\"Epoch {epoch} | DGI Loss: {dgi_loss.item():.4f} | Reg Loss: {reg_loss.item():.4f} | Total Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3sTP63kBAhr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSW7Zhsy_cg6"
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     embeddings, _, _ = model(\n",
    "#         node_feats.to(device),\n",
    "#         edge_index.to(device),\n",
    "#         node_feats.to(device),\n",
    "#         adj=torch.tensor(W0).to(device)\n",
    "#     )\n",
    "\n",
    "# embeddings = embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCN-YL-LXrE5",
    "outputId": "29244971-8ffd-42c0-90df-34d6ed34164a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Score: 0.00017775231989074027\n",
      "Normalized Mutual Information Score: 0.00035768106511865666\n",
      "Clustering Accuracy (mapped): 0.54\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "# # Use KMeans clustering\n",
    "# kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "# kmeans.fit(embeddings)\n",
    "# y_pred_kmeans = kmeans.labels_\n",
    "\n",
    "# # Evaluate clustering performance\n",
    "# ari_score = adjusted_rand_score(y, y_pred_kmeans)\n",
    "# nmi_score = normalized_mutual_info_score(y, y_pred_kmeans)\n",
    "\n",
    "# print(\"Adjusted Rand Score:\", ari_score)\n",
    "# print(\"Normalized Mutual Information Score:\", nmi_score)\n",
    "\n",
    "# # Note: K-Means is an unsupervised algorithm, so traditional classification metrics like accuracy, precision, recall, and F1 are not directly applicable without mapping clusters to classes.\n",
    "# # However, we can calculate accuracy by mapping the cluster labels to the true labels in the way that maximizes accuracy.\n",
    "# # This is not a standard evaluation for clustering but can give an idea of how well the clusters separate the classes.\n",
    "# from scipy.optimize import linear_sum_assignment\n",
    "# def cluster_acc(y_true, y_pred):\n",
    "#     \"\"\"\n",
    "#     Calculate clustering accuracy. Assigns predicted clusters to true labels\n",
    "#     to maximize accuracy using the Jonker-Volgenant algorithm (linear_sum_assignment).\n",
    "#     \"\"\"\n",
    "#     y_true = y_true.astype(np.int64)\n",
    "#     assert y_pred.size == y_true.size\n",
    "#     D = max(y_pred.max(), y_true.max()) + 1\n",
    "#     w = np.zeros((D, D), dtype=np.int64)\n",
    "#     for i in range(y_pred.size):\n",
    "#         w[y_pred[i], y_true[i]] += 1\n",
    "#     row_ind, col_ind = linear_sum_assignment(-w)\n",
    "#     return w[row_ind, col_ind].sum() / y_pred.size\n",
    "\n",
    "# acc_kmeans = cluster_acc(y, y_pred_kmeans)\n",
    "# print(\"Clustering Accuracy (mapped):\", acc_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WL8xpgMME8sS"
   },
   "source": [
    "1- GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfZdJWjqBSU5"
   },
   "source": [
    "Accuracy: 0.7466666666666667\n",
    "Precision: 0.7263681592039801\n",
    "Recall: 0.874251497005988\n",
    "F1: 0.7934782608695652\n",
    "Log Loss: 0.5786983582841999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWmKFw9cE77L"
   },
   "source": [
    "Accuracy: 0.7533333333333333\n",
    "Precision: 0.7360406091370558\n",
    "Recall: 0.8682634730538922\n",
    "F1: 0.7967032967032966\n",
    "Log Loss: 0.5772490248961657"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

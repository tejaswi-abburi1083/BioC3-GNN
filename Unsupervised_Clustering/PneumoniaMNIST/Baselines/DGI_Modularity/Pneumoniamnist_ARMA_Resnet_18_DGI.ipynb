{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YXFd7Zsz-3XQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import ARMAConv\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "import random\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JQ6KiAvW-5rn"
   },
   "outputs": [],
   "source": [
    "#data = np.load('pneumoniamnist_224.npz', allow_pickle=True)\n",
    "data = np.load('pneumoniamnist_224.npz', allow_pickle=True)\n",
    "# Combine train, val, and test sets\n",
    "all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n",
    "all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afjQE2KofZNz",
    "outputId": "43d01d70-cb5c-4642-f747-47e28605ef05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5856, 3, 224, 224]) torch.Size([5856])\n"
     ]
    }
   ],
   "source": [
    "images = all_images.astype(np.float32) / 255.0\n",
    "images = np.repeat(images[:, None, :, :], 3, axis=1)  # Convert to 3 channels (N, 3, 224, 224)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X = torch.tensor(images)\n",
    "y = torch.tensor(all_labels).long()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jBbLbze2fZNz"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, y)\n",
    "class0_indices = [i for i in range(len(y)) if y[i] == 0]\n",
    "class1_indices = [i for i in range(len(y)) if y[i] == 1]\n",
    "\n",
    "random.seed(42)\n",
    "sampled_class0 = random.sample(class0_indices, min(2000, len(class0_indices)))\n",
    "sampled_class1 = random.sample(class1_indices, min(2000, len(class1_indices)))\n",
    "\n",
    "combined_indices = sampled_class0 + sampled_class1\n",
    "random.shuffle(combined_indices)\n",
    "\n",
    "# Final subset\n",
    "final_dataset = Subset(dataset, combined_indices)\n",
    "final_loader = DataLoader(final_dataset, batch_size=64, shuffle=False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bigqt0A5fZN0",
    "outputId": "a359ab8f-edf2-4f8f-f481-7f5d2282f4e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/va797/tmp_pyg118/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/home/va797/tmp_pyg118/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (3583, 512)\n",
      "Label shape: (3583,)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()  # Remove final classification layer\n",
    "resnet = resnet.cuda() if torch.cuda.is_available() else resnet\n",
    "resnet.eval()\n",
    "resnet_feats = []\n",
    "y_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in final_loader:\n",
    "        imgs = imgs.cuda() if torch.cuda.is_available() else imgs\n",
    "        features = resnet(imgs)\n",
    "        resnet_feats.append(features.cpu())\n",
    "        y_list.extend(labels.cpu().tolist())\n",
    "F = torch.cat(resnet_feats, dim=0).numpy().astype(np.float32)\n",
    "y_labels = np.array(y_list).astype(np.float32)\n",
    "\n",
    "print(\"Feature shape:\", F.shape)\n",
    "print(\"Label shape:\", y_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MkKdnnzI-7zI"
   },
   "outputs": [],
   "source": [
    "def create_adj(F, alpha=1):\n",
    "    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n",
    "    W = np.dot(F_norm, F_norm.T)\n",
    "    W = (W >= alpha).astype(np.float32)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Qk8neEfFl7kX"
   },
   "outputs": [],
   "source": [
    "def asymmetrize_random(adj_matrix, seed=None):\n",
    "    \"\"\"\n",
    "    Randomly orient each undirected edge from a symmetric adjacency matrix.\n",
    "    \"\"\"\n",
    "    adj = np.array(adj_matrix, dtype=np.float32)\n",
    "    n = adj.shape[0]\n",
    "    asym = np.zeros((n, n), dtype=np.float32)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if adj[i, j]:\n",
    "                if rng.random() < 0.5:\n",
    "                    asym[i, j] = adj[i, j]\n",
    "                else:\n",
    "                    asym[j, i] = adj[i, j]\n",
    "\n",
    "    return asym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GqvwzvxYgDXF"
   },
   "outputs": [],
   "source": [
    "def load_data(adj, node_feats):\n",
    "    node_feats = torch.from_numpy(node_feats).float()\n",
    "    edge_index = torch.from_numpy(np.array(np.nonzero(adj))).long()\n",
    "    return node_feats, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMvt0-J6fZN1",
    "outputId": "df0f498b-4ab5-4269-b3e2-1bafbe5e46f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3583, 512], edge_index=[2, 1642013])\n"
     ]
    }
   ],
   "source": [
    "features = F # Use ResNet embeddings\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "W0 = create_adj(features, alpha=0.9)\n",
    "# W_asym = asymmetrize_random(W0, seed=42)\n",
    "node_feats, edge_index = load_data(W0, features)\n",
    "data = Data(x=node_feats, edge_index=edge_index).to(device)\n",
    "A = torch.from_numpy(W0).to(device)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Zz160NfE--Tg"
   },
   "outputs": [],
   "source": [
    "# features = F # Use ResNet embeddings\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# W0 = create_adj(features, alpha=0.9)\n",
    "# W_asym = asymmetrize_random(W0, seed=42)\n",
    "# node_feats, edge_index = load_data(W_asym, features) # Use ResNet embeddings here as well\n",
    "# data = Data(x=node_feats, edge_index=edge_index).to(device)\n",
    "# A = torch.from_numpy(W_asym).to(device)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nhh413xH_Awp"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as nnFn\n",
    "\n",
    "class ARMAEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, device, activ=\"ELU\", num_stacks=1, num_layers=1):\n",
    "        super(ARMAEncoder, self).__init__()\n",
    "        self.device = device\n",
    "        # Define all activation functions\n",
    "        activations = {\n",
    "            \"SELU\": nnFn.selu,\n",
    "            \"SiLU\": nnFn.silu,\n",
    "            \"GELU\": nnFn.gelu,\n",
    "            \"ELU\": nnFn.elu,\n",
    "            \"RELU\": nnFn.relu\n",
    "        }\n",
    "        # Get the activation function based on the input string\n",
    "        self.act = activations.get(activ, nnFn.elu)\n",
    "\n",
    "        self.arma = ARMAConv(\n",
    "            in_channels=input_dim,\n",
    "            out_channels=hidden_dim,\n",
    "            num_stacks=num_stacks,   # number of parallel stacks\n",
    "            num_layers=num_layers,   # depth per stack\n",
    "            act=self.act,               # nonlinearity inside ARMA\n",
    "            shared_weights=True,     # weight sharing across layers\n",
    "            dropout=0.25             # ARMA-internal dropout\n",
    "        )\n",
    "        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.arma(x, edge_index)\n",
    "        x = self.dropout(x)\n",
    "        x = self.batchnorm(x)\n",
    "        logits = self.mlp(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t1CWUjjG48t_"
   },
   "outputs": [],
   "source": [
    "class AvgReadout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, seq, msk=None):\n",
    "        if msk is None:\n",
    "            return torch.mean(seq, 0)\n",
    "        else:\n",
    "            msk = torch.unsqueeze(msk, -1)\n",
    "            return torch.sum(seq * msk, 0) / torch.sum(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IbNOUPjg42s9"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super().__init__()\n",
    "        self.f_k = nn.Bilinear(n_h, n_h, 1)\n",
    "        nn.init.xavier_uniform_(self.f_k.weight.data)\n",
    "        if self.f_k.bias is not None:\n",
    "            self.f_k.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, c, h_pl, h_mi):\n",
    "        c_x = torch.unsqueeze(c, 0).expand_as(h_pl)\n",
    "        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 1)\n",
    "        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 1)\n",
    "        logits = torch.cat((sc_1, sc_2), 0)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7X7cwk2N8Al2"
   },
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, n_in, n_h, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.arma1 = ARMAEncoder(n_in, n_h, device='cuda' if torch.cuda.is_available() else 'cpu', activ=nn.ELU())\n",
    "        self.read = AvgReadout()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        self.disc = Discriminator(n_h)\n",
    "\n",
    "    def forward(self, seq1, seq2, edge_index):\n",
    "        # Create Data objects for the ARMAEncoder\n",
    "        data1 = Data(x=seq1, edge_index=edge_index)\n",
    "        data2 = Data(x=seq2, edge_index=edge_index)\n",
    "\n",
    "        h_1 = self.arma1(data1)\n",
    "        c = self.read(h_1)\n",
    "        c = self.sigm(c)\n",
    "        h_2 = self.arma1(data2)\n",
    "        logits = self.disc(c, h_1, h_2)\n",
    "        return logits, h_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yVuaMXM1C9T3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class DGI_with_classifier(DGI):\n",
    "    def __init__(self, n_in, n_h, n_classes=2, cut=0, dropout=0.25):\n",
    "        super().__init__(n_in, n_h, dropout=dropout)\n",
    "        self.classifier = nn.Linear(n_h, n_classes)\n",
    "        self.cut = cut\n",
    "\n",
    "    def get_embeddings(self, node_feats, edge_index):\n",
    "        _, embeddings = self.forward(node_feats, node_feats, edge_index)\n",
    "        return embeddings\n",
    "\n",
    "    def cut_loss(self, A, S):\n",
    "        # ensure tensor\n",
    "        if isinstance(A, np.ndarray):\n",
    "            A = torch.from_numpy(A).float().to(S.device)\n",
    "\n",
    "        S = F.softmax(S, dim=1)   # cluster assignment\n",
    "        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n",
    "        num = torch.trace(A_pool)\n",
    "\n",
    "        D = torch.diag(torch.sum(A, dim=-1))\n",
    "        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n",
    "        den = torch.trace(D_pooled)\n",
    "\n",
    "        mincut_loss = -(num / den)\n",
    "\n",
    "        St_S = torch.matmul(S.t(), S)\n",
    "        I_S = torch.eye(S.shape[1], device=A.device)\n",
    "        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n",
    "\n",
    "        return mincut_loss + ortho_loss\n",
    "\n",
    "    def modularity_loss(self, A, S):\n",
    "        # ensure tensor\n",
    "        if isinstance(A, np.ndarray):\n",
    "            A = torch.from_numpy(A).float().to(S.device)\n",
    "\n",
    "        C = F.softmax(S, dim=1)   # cluster assignment\n",
    "        d = torch.sum(A, dim=1)\n",
    "        m = torch.sum(A)\n",
    "\n",
    "        B = A - torch.outer(d, d) / (2 * m)\n",
    "\n",
    "        I_S = torch.eye(C.shape[1], device=A.device)\n",
    "        k = torch.norm(I_S)\n",
    "        n = S.shape[0]\n",
    "\n",
    "        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n",
    "        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n",
    "\n",
    "        return modularity_term + collapse_reg_term\n",
    "\n",
    "    def Reg_loss(self, A, embeddings):\n",
    "        # classifier output used as soft cluster assignment\n",
    "        logits = self.classifier(embeddings)\n",
    "\n",
    "        if self.cut == 1:\n",
    "            return self.cut_loss(A, logits)\n",
    "        else:\n",
    "            return self.modularity_loss(A, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4ClSGTZaA_xt",
    "outputId": "54ae907f-84c8-4682-88fe-cab2be9db5cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | DGI Loss: 0.7143 | Reg Loss: -0.2844 | Total: 0.5721\n",
      "Epoch 500 | DGI Loss: 0.6932 | Reg Loss: -0.4670 | Total: 0.4596\n",
      "Epoch 1000 | DGI Loss: 0.6987 | Reg Loss: -0.4655 | Total: 0.4660\n",
      "Epoch 1500 | DGI Loss: 0.6932 | Reg Loss: -0.4676 | Total: 0.4593\n",
      "Epoch 2000 | DGI Loss: 0.6931 | Reg Loss: -0.4679 | Total: 0.4592\n",
      "Epoch 2500 | DGI Loss: 0.6933 | Reg Loss: -0.4671 | Total: 0.4597\n",
      "Epoch 3000 | DGI Loss: 0.6933 | Reg Loss: -0.4673 | Total: 0.4596\n",
      "Epoch 3500 | DGI Loss: 0.6932 | Reg Loss: -0.4679 | Total: 0.4592\n",
      "Epoch 4000 | DGI Loss: 0.6932 | Reg Loss: -0.4679 | Total: 0.4592\n",
      "Epoch 4500 | DGI Loss: 0.6931 | Reg Loss: -0.4680 | Total: 0.4591\n",
      "Epoch 5000 | DGI Loss: 0.6932 | Reg Loss: -0.4679 | Total: 0.4593\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256\n",
    "cut = 0\n",
    "dropout = 0.25\n",
    "heads = 2\n",
    "# make sure adjacency is a tensor on GPU\n",
    "if isinstance(A, np.ndarray):\n",
    "    A = torch.from_numpy(A).float().to(device)\n",
    "else:\n",
    "    A = A.float().to(device)\n",
    "\n",
    "model = DGI_with_classifier(features.shape[1], hidden_dim, n_classes=2, cut=cut, dropout=dropout).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    perm = torch.randperm(node_feats.size(0))\n",
    "    corrupt_features = node_feats[perm]\n",
    "\n",
    "    logits, embeddings = model(node_feats.to(device), corrupt_features.to(device), edge_index.to(device))\n",
    "\n",
    "    lbl = torch.cat([\n",
    "        torch.ones(node_feats.size(0)),\n",
    "        torch.zeros(node_feats.size(0))\n",
    "    ]).to(device)\n",
    "\n",
    "    dgi_loss = bce_loss(logits.squeeze(), lbl)\n",
    "    reg_loss = model.Reg_loss(A, embeddings)\n",
    "    loss = dgi_loss + 0.5 * reg_loss\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch} | DGI Loss: {dgi_loss.item():.4f} | Reg Loss: {reg_loss.item():.4f} | Total: {loss.item():.4f}\")\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "giN_kiZckBqV"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model.get_embeddings(node_feats.to(device), edge_index.to(device))\n",
    "    class_probabilities = F.softmax(model.classifier(embeddings), dim=1).cpu().numpy()\n",
    "\n",
    "y_pred = np.argmax(class_probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVJYp9cnauDO",
    "outputId": "9481a916-c4d5-4f1b-c711-aace623636b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.08875244208763607\n",
      "Accuracy (inverted): 0.9112475579123639\n",
      "Precision: 0.13711990820424555\n",
      "Recall: 0.1195\n",
      "F1: 0.12770504942559444\n",
      "Log Loss: 12.86645688544938\n"
     ]
    }
   ],
   "source": [
    "# Extract the true labels for the subset used for prediction\n",
    "y_subset = y[combined_indices].cpu().numpy()\n",
    "\n",
    "acc_score = accuracy_score(y_subset, y_pred)\n",
    "acc_score_inverted = accuracy_score(y_subset, 1 - y_pred)\n",
    "prec_score = precision_score(y_subset, y_pred)\n",
    "rec_score = recall_score(y_subset, y_pred)\n",
    "f1 = f1_score(y_subset, y_pred)\n",
    "log_loss_value = log_loss(y_subset, class_probabilities)\n",
    "\n",
    "print(\"Accuracy:\", acc_score)\n",
    "print(\"Accuracy (inverted):\", acc_score_inverted)\n",
    "print(\"Precision:\", prec_score)\n",
    "print(\"Recall:\", rec_score)\n",
    "print(\"F1:\", f1)\n",
    "print(\"Log Loss:\", log_loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2TNZi1qljP0",
    "outputId": "f1c43910-61e1-4aec-8cd0-0f5b2ce46fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ LAMBDA = 0.001 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.0003 | Total: 0.7164\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4360 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4407 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4422 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4402 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4415 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4421 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4414 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4432 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4441 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4429 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 1 | Accuracy: 0.9079 | Precision: 0.9563 | Recall: 0.8750 | F1: 0.9138 | LogLoss: 0.2658\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.0003 | Total: 0.7108\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4465 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4499 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4500 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4502 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4500 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4507 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4510 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4507 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4512 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4505 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Run 2 | Accuracy: 0.9051 | Precision: 0.9596 | Recall: 0.8665 | F1: 0.9107 | LogLoss: 0.2718\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.0003 | Total: 0.7092\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4423 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4494 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4496 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4502 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4504 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4508 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4500 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4509 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4502 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4498 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 3 | Accuracy: 0.9124 | Precision: 0.9622 | Recall: 0.8775 | F1: 0.9179 | LogLoss: 0.2587\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.0003 | Total: 0.7128\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4346 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4419 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4449 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4436 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4436 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4445 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4445 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4434 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4447 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4443 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 4 | Accuracy: 0.9096 | Precision: 0.9520 | Recall: 0.8825 | F1: 0.9159 | LogLoss: 0.2587\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.0003 | Total: 0.7168\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4446 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4488 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4483 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4489 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4488 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4487 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4483 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4486 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4490 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4484 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 5 | Accuracy: 0.9110 | Precision: 0.9646 | Recall: 0.8725 | F1: 0.9163 | LogLoss: 0.2603\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.0003 | Total: 0.7147\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4477 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4498 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4501 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4512 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4503 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4508 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4498 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4507 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4500 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4509 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Run 6 | Accuracy: 0.9149 | Precision: 0.9589 | Recall: 0.8855 | F1: 0.9207 | LogLoss: 0.2596\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.0003 | Total: 0.7114\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4339 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4390 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4410 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4401 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4419 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4411 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4402 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4406 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4400 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4416 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 7 | Accuracy: 0.9196 | Precision: 0.9617 | Recall: 0.8915 | F1: 0.9253 | LogLoss: 0.2300\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.0003 | Total: 0.7155\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4454 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4503 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4510 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4511 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4512 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4505 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4524 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4510 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4520 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4506 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Run 8 | Accuracy: 0.9143 | Precision: 0.9608 | Recall: 0.8825 | F1: 0.9200 | LogLoss: 0.2512\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.0003 | Total: 0.7181\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4392 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4440 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4440 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4452 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4450 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4448 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4452 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4467 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4444 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4453 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Run 9 | Accuracy: 0.9146 | Precision: 0.9649 | Recall: 0.8790 | F1: 0.9199 | LogLoss: 0.2372\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.0003 | Total: 0.7137\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4466 | λ*Reg: -0.0004 | Total: 0.6927\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4505 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4514 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4511 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4518 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4516 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4511 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4514 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4507 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4504 | λ*Reg: -0.0005 | Total: 0.6927\n",
      "Run 10 | Accuracy: 0.9191 | Precision: 0.9612 | Recall: 0.8910 | F1: 0.9248 | LogLoss: 0.2457\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.001 ---\n",
      "Accuracy : 0.9128 ± 0.0044\n",
      "Precision: 0.9602 ± 0.0037\n",
      "Recall   : 0.8803 ± 0.0075\n",
      "F1 Score : 0.9185 ± 0.0044\n",
      "Log Loss : 0.2539 ± 0.0123\n",
      "\n",
      "================ LAMBDA = 0.005 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.0014 | Total: 0.7152\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4576 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4597 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4606 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4592 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4600 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4597 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4601 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4609 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4603 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4608 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 1 | Accuracy: 0.9107 | Precision: 0.9590 | Recall: 0.8775 | F1: 0.9164 | LogLoss: 0.3599\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.0014 | Total: 0.7097\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4584 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4613 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4617 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4613 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4616 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4613 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4613 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 2 | Accuracy: 0.9093 | Precision: 0.9625 | Recall: 0.8715 | F1: 0.9147 | LogLoss: 0.3608\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.0014 | Total: 0.7080\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4602 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4625 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4623 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 3 | Accuracy: 0.9132 | Precision: 0.9643 | Recall: 0.8770 | F1: 0.9186 | LogLoss: 0.3764\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.0014 | Total: 0.7117\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4575 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4604 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4611 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4608 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4609 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4616 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4608 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4611 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4608 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 4 | Accuracy: 0.9090 | Precision: 0.9609 | Recall: 0.8725 | F1: 0.9146 | LogLoss: 0.3541\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.0014 | Total: 0.7157\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4579 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4605 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4609 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4612 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4610 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4611 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4604 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4607 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4613 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4610 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 5 | Accuracy: 0.9115 | Precision: 0.9667 | Recall: 0.8715 | F1: 0.9166 | LogLoss: 0.3461\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.0014 | Total: 0.7135\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4575 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4603 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4602 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4612 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4610 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4609 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4612 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4604 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4610 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 6 | Accuracy: 0.9124 | Precision: 0.9632 | Recall: 0.8765 | F1: 0.9178 | LogLoss: 0.3471\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.0014 | Total: 0.7102\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4572 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4587 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4599 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4594 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4599 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4593 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4594 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4600 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4591 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4602 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 7 | Accuracy: 0.9143 | Precision: 0.9603 | Recall: 0.8830 | F1: 0.9200 | LogLoss: 0.3309\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.0014 | Total: 0.7144\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4593 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4617 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4617 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4623 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4616 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4617 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 8 | Accuracy: 0.9112 | Precision: 0.9626 | Recall: 0.8750 | F1: 0.9167 | LogLoss: 0.3553\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.0014 | Total: 0.7170\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4589 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4602 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4604 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4606 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4604 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4600 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4607 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4613 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4599 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4607 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 9 | Accuracy: 0.9126 | Precision: 0.9658 | Recall: 0.8745 | F1: 0.9179 | LogLoss: 0.3388\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.0014 | Total: 0.7125\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4579 | λ*Reg: -0.0023 | Total: 0.6909\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4611 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4620 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4611 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4614 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4616 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4616 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4611 | λ*Reg: -0.0023 | Total: 0.6908\n",
      "Run 10 | Accuracy: 0.9152 | Precision: 0.9609 | Recall: 0.8840 | F1: 0.9208 | LogLoss: 0.3496\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.005 ---\n",
      "Accuracy : 0.9119 ± 0.0019\n",
      "Precision: 0.9626 ± 0.0023\n",
      "Recall   : 0.8763 ± 0.0041\n",
      "F1 Score : 0.9174 ± 0.0019\n",
      "Log Loss : 0.3519 ± 0.0120\n",
      "\n",
      "================ LAMBDA = 0.009 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.0026 | Total: 0.7141\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4610 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 1 | Accuracy: 0.9107 | Precision: 0.9615 | Recall: 0.8750 | F1: 0.9162 | LogLoss: 0.4124\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.0026 | Total: 0.7085\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4617 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 2 | Accuracy: 0.9118 | Precision: 0.9611 | Recall: 0.8775 | F1: 0.9174 | LogLoss: 0.4000\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.0026 | Total: 0.7069\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4612 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 3 | Accuracy: 0.9115 | Precision: 0.9652 | Recall: 0.8730 | F1: 0.9168 | LogLoss: 0.4001\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.0026 | Total: 0.7105\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4610 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4630 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4630 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 4 | Accuracy: 0.9093 | Precision: 0.9625 | Recall: 0.8715 | F1: 0.9147 | LogLoss: 0.4100\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.0026 | Total: 0.7145\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4612 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4630 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 5 | Accuracy: 0.9112 | Precision: 0.9672 | Recall: 0.8705 | F1: 0.9163 | LogLoss: 0.4005\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.0026 | Total: 0.7124\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 6 | Accuracy: 0.9124 | Precision: 0.9637 | Recall: 0.8760 | F1: 0.9178 | LogLoss: 0.4092\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.0026 | Total: 0.7091\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4606 | λ*Reg: -0.0041 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4617 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4625 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4618 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 7 | Accuracy: 0.9135 | Precision: 0.9607 | Recall: 0.8810 | F1: 0.9191 | LogLoss: 0.3900\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.0026 | Total: 0.7132\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 8 | Accuracy: 0.9124 | Precision: 0.9627 | Recall: 0.8770 | F1: 0.9178 | LogLoss: 0.4128\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.0026 | Total: 0.7158\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4617 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4625 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4630 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 9 | Accuracy: 0.9126 | Precision: 0.9653 | Recall: 0.8750 | F1: 0.9179 | LogLoss: 0.3915\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.0026 | Total: 0.7114\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4616 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0042 | Total: 0.6890\n",
      "Run 10 | Accuracy: 0.9138 | Precision: 0.9633 | Recall: 0.8790 | F1: 0.9192 | LogLoss: 0.4021\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.009 ---\n",
      "Accuracy : 0.9119 ± 0.0013\n",
      "Precision: 0.9633 ± 0.0020\n",
      "Recall   : 0.8755 ± 0.0031\n",
      "F1 Score : 0.9173 ± 0.0013\n",
      "Log Loss : 0.4029 ± 0.0077\n",
      "\n",
      "================ LAMBDA = 0.01 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.0028 | Total: 0.7138\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4623 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4630 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 1 | Accuracy: 0.9112 | Precision: 0.9621 | Recall: 0.8755 | F1: 0.9168 | LogLoss: 0.4225\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.0028 | Total: 0.7083\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 2 | Accuracy: 0.9124 | Precision: 0.9612 | Recall: 0.8785 | F1: 0.9180 | LogLoss: 0.4105\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.0029 | Total: 0.7066\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 3 | Accuracy: 0.9129 | Precision: 0.9653 | Recall: 0.8755 | F1: 0.9182 | LogLoss: 0.4067\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.0028 | Total: 0.7102\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4618 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 4 | Accuracy: 0.9087 | Precision: 0.9599 | Recall: 0.8730 | F1: 0.9144 | LogLoss: 0.4320\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.0028 | Total: 0.7143\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4615 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4632 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 5 | Accuracy: 0.9104 | Precision: 0.9666 | Recall: 0.8695 | F1: 0.9155 | LogLoss: 0.4075\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.0029 | Total: 0.7121\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4623 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4634 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4642 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 6 | Accuracy: 0.9143 | Precision: 0.9654 | Recall: 0.8780 | F1: 0.9196 | LogLoss: 0.4183\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.0028 | Total: 0.7088\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4611 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4623 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4624 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4627 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4622 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4629 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 7 | Accuracy: 0.9140 | Precision: 0.9613 | Recall: 0.8815 | F1: 0.9197 | LogLoss: 0.4010\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.0029 | Total: 0.7130\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4623 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4644 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4639 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 8 | Accuracy: 0.9115 | Precision: 0.9621 | Recall: 0.8760 | F1: 0.9170 | LogLoss: 0.4092\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.0028 | Total: 0.7156\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4621 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4628 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4625 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4631 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4635 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4626 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4633 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 9 | Accuracy: 0.9121 | Precision: 0.9642 | Recall: 0.8750 | F1: 0.9174 | LogLoss: 0.4015\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.0028 | Total: 0.7111\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4619 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4636 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4640 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4641 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4638 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4637 | λ*Reg: -0.0046 | Total: 0.6885\n",
      "Run 10 | Accuracy: 0.9135 | Precision: 0.9623 | Recall: 0.8795 | F1: 0.9190 | LogLoss: 0.4163\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.01 ---\n",
      "Accuracy : 0.9121 ± 0.0016\n",
      "Precision: 0.9630 ± 0.0021\n",
      "Recall   : 0.8762 ± 0.0032\n",
      "F1 Score : 0.9176 ± 0.0016\n",
      "Log Loss : 0.4125 ± 0.0092\n",
      "\n",
      "================ LAMBDA = 0.05 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.0142 | Total: 0.7024\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4653 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 1 | Accuracy: 0.9143 | Precision: 0.9628 | Recall: 0.8805 | F1: 0.9198 | LogLoss: 0.5364\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.0142 | Total: 0.6969\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4650 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Run 2 | Accuracy: 0.9121 | Precision: 0.9611 | Recall: 0.8780 | F1: 0.9177 | LogLoss: 0.5344\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.0143 | Total: 0.6952\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 3 | Accuracy: 0.9121 | Precision: 0.9642 | Recall: 0.8750 | F1: 0.9174 | LogLoss: 0.5583\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.0142 | Total: 0.6989\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 4 | Accuracy: 0.9129 | Precision: 0.9617 | Recall: 0.8790 | F1: 0.9185 | LogLoss: 0.5603\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.0142 | Total: 0.7029\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4656 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Run 5 | Accuracy: 0.9126 | Precision: 0.9627 | Recall: 0.8775 | F1: 0.9181 | LogLoss: 0.5174\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.0143 | Total: 0.7007\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 6 | Accuracy: 0.9157 | Precision: 0.9644 | Recall: 0.8815 | F1: 0.9211 | LogLoss: 0.5347\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.0142 | Total: 0.6975\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4645 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Run 7 | Accuracy: 0.9121 | Precision: 0.9601 | Recall: 0.8790 | F1: 0.9178 | LogLoss: 0.5287\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.0143 | Total: 0.7015\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4643 | λ*Reg: -0.0232 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 8 | Accuracy: 0.9157 | Precision: 0.9639 | Recall: 0.8820 | F1: 0.9211 | LogLoss: 0.5122\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.0142 | Total: 0.7042\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 9 | Accuracy: 0.9135 | Precision: 0.9643 | Recall: 0.8775 | F1: 0.9188 | LogLoss: 0.5315\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.0142 | Total: 0.6997\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4655 | λ*Reg: -0.0233 | Total: 0.6699\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0233 | Total: 0.6698\n",
      "Run 10 | Accuracy: 0.9138 | Precision: 0.9623 | Recall: 0.8800 | F1: 0.9193 | LogLoss: 0.5645\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.05 ---\n",
      "Accuracy : 0.9135 ± 0.0013\n",
      "Precision: 0.9628 ± 0.0014\n",
      "Recall   : 0.8790 ± 0.0020\n",
      "F1 Score : 0.9190 ± 0.0013\n",
      "Log Loss : 0.5378 ± 0.0169\n",
      "\n",
      "================ LAMBDA = 0.09 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.0256 | Total: 0.6911\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 1 | Accuracy: 0.9129 | Precision: 0.9627 | Recall: 0.8780 | F1: 0.9184 | LogLoss: 0.5521\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.0255 | Total: 0.6856\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 2 | Accuracy: 0.9115 | Precision: 0.9611 | Recall: 0.8770 | F1: 0.9171 | LogLoss: 0.5857\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.0257 | Total: 0.6838\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Run 3 | Accuracy: 0.9143 | Precision: 0.9638 | Recall: 0.8795 | F1: 0.9197 | LogLoss: 0.5956\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.0256 | Total: 0.6875\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 4 | Accuracy: 0.9126 | Precision: 0.9612 | Recall: 0.8790 | F1: 0.9183 | LogLoss: 0.6242\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.0255 | Total: 0.6916\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4657 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 5 | Accuracy: 0.9126 | Precision: 0.9632 | Recall: 0.8770 | F1: 0.9181 | LogLoss: 0.5834\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.0257 | Total: 0.6892\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Run 6 | Accuracy: 0.9143 | Precision: 0.9623 | Recall: 0.8810 | F1: 0.9199 | LogLoss: 0.5961\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.0256 | Total: 0.6861\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4649 | λ*Reg: -0.0418 | Total: 0.6513\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4660 | λ*Reg: -0.0419 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Run 7 | Accuracy: 0.9143 | Precision: 0.9618 | Recall: 0.8815 | F1: 0.9199 | LogLoss: 0.5479\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.0257 | Total: 0.6901\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Run 8 | Accuracy: 0.9140 | Precision: 0.9638 | Recall: 0.8790 | F1: 0.9195 | LogLoss: 0.6064\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.0256 | Total: 0.6928\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Run 9 | Accuracy: 0.9132 | Precision: 0.9632 | Recall: 0.8780 | F1: 0.9187 | LogLoss: 0.6038\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.0256 | Total: 0.6884\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0420 | Total: 0.6512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0420 | Total: 0.6511\n",
      "Run 10 | Accuracy: 0.9138 | Precision: 0.9638 | Recall: 0.8785 | F1: 0.9192 | LogLoss: 0.6246\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.09 ---\n",
      "Accuracy : 0.9134 ± 0.0009\n",
      "Precision: 0.9627 ± 0.0010\n",
      "Recall   : 0.8789 ± 0.0014\n",
      "F1 Score : 0.9189 ± 0.0009\n",
      "Log Loss : 0.5920 ± 0.0248\n",
      "\n",
      "================ LAMBDA = 0.1 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.0284 | Total: 0.6882\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 1 | Accuracy: 0.9138 | Precision: 0.9638 | Recall: 0.8785 | F1: 0.9192 | LogLoss: 0.5654\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.0284 | Total: 0.6827\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4659 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Run 2 | Accuracy: 0.9112 | Precision: 0.9611 | Recall: 0.8765 | F1: 0.9168 | LogLoss: 0.6107\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.0285 | Total: 0.6809\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 3 | Accuracy: 0.9140 | Precision: 0.9638 | Recall: 0.8790 | F1: 0.9195 | LogLoss: 0.6054\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.0284 | Total: 0.6846\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 4 | Accuracy: 0.9126 | Precision: 0.9612 | Recall: 0.8790 | F1: 0.9183 | LogLoss: 0.6357\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.0284 | Total: 0.6887\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4658 | λ*Reg: -0.0466 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Run 5 | Accuracy: 0.9121 | Precision: 0.9627 | Recall: 0.8765 | F1: 0.9176 | LogLoss: 0.5885\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.0286 | Total: 0.6864\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 6 | Accuracy: 0.9140 | Precision: 0.9623 | Recall: 0.8805 | F1: 0.9196 | LogLoss: 0.6167\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.0284 | Total: 0.6833\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4654 | λ*Reg: -0.0465 | Total: 0.6466\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4662 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Run 7 | Accuracy: 0.9140 | Precision: 0.9618 | Recall: 0.8810 | F1: 0.9196 | LogLoss: 0.5703\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.0285 | Total: 0.6873\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.0467 | Total: 0.6464\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.0467 | Total: 0.6464\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 8 | Accuracy: 0.9140 | Precision: 0.9638 | Recall: 0.8790 | F1: 0.9195 | LogLoss: 0.6187\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.0285 | Total: 0.6899\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4665 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 9 | Accuracy: 0.9138 | Precision: 0.9633 | Recall: 0.8790 | F1: 0.9192 | LogLoss: 0.5794\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.0284 | Total: 0.6855\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4664 | λ*Reg: -0.0466 | Total: 0.6465\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.0467 | Total: 0.6464\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.0467 | Total: 0.6464\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.0467 | Total: 0.6465\n",
      "Run 10 | Accuracy: 0.9138 | Precision: 0.9643 | Recall: 0.8780 | F1: 0.9191 | LogLoss: 0.6352\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.1 ---\n",
      "Accuracy : 0.9133 ± 0.0009\n",
      "Precision: 0.9628 ± 0.0011\n",
      "Recall   : 0.8787 ± 0.0014\n",
      "F1 Score : 0.9188 ± 0.0009\n",
      "Log Loss : 0.6026 ± 0.0242\n",
      "\n",
      "================ LAMBDA = 0.3 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.0852 | Total: 0.6315\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4663 | λ*Reg: -0.1399 | Total: 0.5533\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Run 1 | Accuracy: 0.9138 | Precision: 0.9633 | Recall: 0.8790 | F1: 0.9192 | LogLoss: 0.6350\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.0851 | Total: 0.6260\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4661 | λ*Reg: -0.1398 | Total: 0.5533\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Run 2 | Accuracy: 0.9135 | Precision: 0.9638 | Recall: 0.8780 | F1: 0.9189 | LogLoss: 0.6518\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.0856 | Total: 0.6239\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Run 3 | Accuracy: 0.9149 | Precision: 0.9639 | Recall: 0.8805 | F1: 0.9203 | LogLoss: 0.7158\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.0853 | Total: 0.6278\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4670 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Run 4 | Accuracy: 0.9135 | Precision: 0.9638 | Recall: 0.8780 | F1: 0.9189 | LogLoss: 0.7156\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.0851 | Total: 0.6320\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Run 5 | Accuracy: 0.9135 | Precision: 0.9633 | Recall: 0.8785 | F1: 0.9189 | LogLoss: 0.6992\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.0858 | Total: 0.6292\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Run 6 | Accuracy: 0.9135 | Precision: 0.9633 | Recall: 0.8785 | F1: 0.9189 | LogLoss: 0.7243\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.0852 | Total: 0.6265\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4667 | λ*Reg: -0.1400 | Total: 0.5531\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Run 7 | Accuracy: 0.9135 | Precision: 0.9628 | Recall: 0.8790 | F1: 0.9190 | LogLoss: 0.6900\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.0856 | Total: 0.6302\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.1400 | Total: 0.5532\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Run 8 | Accuracy: 0.9146 | Precision: 0.9628 | Recall: 0.8810 | F1: 0.9201 | LogLoss: 0.6814\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.0854 | Total: 0.6330\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4669 | λ*Reg: -0.1401 | Total: 0.5531\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Run 9 | Accuracy: 0.9138 | Precision: 0.9633 | Recall: 0.8790 | F1: 0.9192 | LogLoss: 0.6903\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.0853 | Total: 0.6287\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.1401 | Total: 0.5530\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.1402 | Total: 0.5530\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.1402 | Total: 0.5529\n",
      "Run 10 | Accuracy: 0.9140 | Precision: 0.9638 | Recall: 0.8790 | F1: 0.9195 | LogLoss: 0.7197\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.3 ---\n",
      "Accuracy : 0.9138 ± 0.0005\n",
      "Precision: 0.9634 ± 0.0004\n",
      "Recall   : 0.8790 ± 0.0009\n",
      "F1 Score : 0.9193 ± 0.0005\n",
      "Log Loss : 0.6923 ± 0.0282\n",
      "\n",
      "================ LAMBDA = 0.5 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.1420 | Total: 0.5747\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.2334 | Total: 0.4598\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Run 1 | Accuracy: 0.9138 | Precision: 0.9633 | Recall: 0.8790 | F1: 0.9192 | LogLoss: 0.6909\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.1419 | Total: 0.5692\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4668 | λ*Reg: -0.2334 | Total: 0.4597\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Run 2 | Accuracy: 0.9143 | Precision: 0.9638 | Recall: 0.8795 | F1: 0.9197 | LogLoss: 0.7140\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.1427 | Total: 0.5668\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Run 3 | Accuracy: 0.9135 | Precision: 0.9633 | Recall: 0.8785 | F1: 0.9189 | LogLoss: 0.7671\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.1421 | Total: 0.5709\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.2333 | Total: 0.4598\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Run 4 | Accuracy: 0.9132 | Precision: 0.9632 | Recall: 0.8780 | F1: 0.9187 | LogLoss: 0.6960\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.1418 | Total: 0.5753\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4596\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Run 5 | Accuracy: 0.9129 | Precision: 0.9637 | Recall: 0.8770 | F1: 0.9183 | LogLoss: 0.7495\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.1430 | Total: 0.5720\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Run 6 | Accuracy: 0.9129 | Precision: 0.9622 | Recall: 0.8785 | F1: 0.9185 | LogLoss: 0.7711\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.1420 | Total: 0.5697\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4666 | λ*Reg: -0.2333 | Total: 0.4599\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Run 7 | Accuracy: 0.9146 | Precision: 0.9633 | Recall: 0.8805 | F1: 0.9201 | LogLoss: 0.6978\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.1427 | Total: 0.5731\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Run 8 | Accuracy: 0.9129 | Precision: 0.9622 | Recall: 0.8785 | F1: 0.9185 | LogLoss: 0.7582\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.1423 | Total: 0.5761\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.2335 | Total: 0.4596\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Run 9 | Accuracy: 0.9135 | Precision: 0.9633 | Recall: 0.8785 | F1: 0.9189 | LogLoss: 0.7382\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.1422 | Total: 0.5718\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.2336 | Total: 0.4595\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4595\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.2338 | Total: 0.4594\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.2338 | Total: 0.4593\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.2337 | Total: 0.4594\n",
      "Run 10 | Accuracy: 0.9140 | Precision: 0.9638 | Recall: 0.8790 | F1: 0.9195 | LogLoss: 0.7488\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.5 ---\n",
      "Accuracy : 0.9136 ± 0.0006\n",
      "Precision: 0.9632 ± 0.0006\n",
      "Recall   : 0.8787 ± 0.0009\n",
      "F1 Score : 0.9190 ± 0.0006\n",
      "Log Loss : 0.7332 ± 0.0292\n",
      "\n",
      "================ LAMBDA = 0.9 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.2555 | Total: 0.4611\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4204 | Total: 0.2728\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Run 1 | Accuracy: 0.9132 | Precision: 0.9632 | Recall: 0.8780 | F1: 0.9187 | LogLoss: 0.7501\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.2554 | Total: 0.4557\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Run 2 | Accuracy: 0.9135 | Precision: 0.9633 | Recall: 0.8785 | F1: 0.9189 | LogLoss: 0.8107\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.2568 | Total: 0.4527\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4210 | Total: 0.2721\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Run 3 | Accuracy: 0.9138 | Precision: 0.9633 | Recall: 0.8790 | F1: 0.9192 | LogLoss: 0.8232\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.2559 | Total: 0.4572\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Run 4 | Accuracy: 0.9132 | Precision: 0.9632 | Recall: 0.8780 | F1: 0.9187 | LogLoss: 0.8015\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.2553 | Total: 0.4618\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4204 | Total: 0.2728\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Run 5 | Accuracy: 0.9132 | Precision: 0.9632 | Recall: 0.8780 | F1: 0.9187 | LogLoss: 0.7443\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.2574 | Total: 0.4576\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4204 | Total: 0.2727\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Run 6 | Accuracy: 0.9132 | Precision: 0.9622 | Recall: 0.8790 | F1: 0.9187 | LogLoss: 0.7790\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.2556 | Total: 0.4560\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4204 | Total: 0.2728\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Run 7 | Accuracy: 0.9135 | Precision: 0.9628 | Recall: 0.8790 | F1: 0.9190 | LogLoss: 0.7571\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.2568 | Total: 0.4590\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2725\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4210 | Total: 0.2721\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4210 | Total: 0.2721\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Run 8 | Accuracy: 0.9132 | Precision: 0.9617 | Recall: 0.8795 | F1: 0.9188 | LogLoss: 0.8174\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.2561 | Total: 0.4623\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4671 | λ*Reg: -0.4204 | Total: 0.2728\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4207 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4208 | Total: 0.2723\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Run 9 | Accuracy: 0.9140 | Precision: 0.9633 | Recall: 0.8795 | F1: 0.9195 | LogLoss: 0.7605\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.2559 | Total: 0.4581\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4205 | Total: 0.2726\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4208 | Total: 0.2724\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4209 | Total: 0.2722\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4210 | Total: 0.2722\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4209 | Total: 0.2723\n",
      "Run 10 | Accuracy: 0.9138 | Precision: 0.9633 | Recall: 0.8790 | F1: 0.9192 | LogLoss: 0.7864\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 0.9 ---\n",
      "Accuracy : 0.9135 ± 0.0003\n",
      "Precision: 0.9630 ± 0.0005\n",
      "Recall   : 0.8787 ± 0.0006\n",
      "F1 Score : 0.9189 ± 0.0003\n",
      "Log Loss : 0.7830 ± 0.0277\n",
      "\n",
      "================ LAMBDA = 1 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.2839 | Total: 0.4327\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4678 | Total: 0.2254\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Run 1 | Accuracy: 0.9132 | Precision: 0.9632 | Recall: 0.8780 | F1: 0.9187 | LogLoss: 0.8029\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.2837 | Total: 0.4274\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4678 | Total: 0.2254\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4678 | Total: 0.2254\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Run 2 | Accuracy: 0.9135 | Precision: 0.9633 | Recall: 0.8785 | F1: 0.9189 | LogLoss: 0.8263\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.2853 | Total: 0.4241\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4678 | Total: 0.2254\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4678 | Total: 0.2254\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Run 3 | Accuracy: 0.9138 | Precision: 0.9628 | Recall: 0.8795 | F1: 0.9193 | LogLoss: 0.8169\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.2843 | Total: 0.4288\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Run 4 | Accuracy: 0.9129 | Precision: 0.9632 | Recall: 0.8775 | F1: 0.9184 | LogLoss: 0.8122\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.2837 | Total: 0.4334\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4672 | Total: 0.2259\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Run 5 | Accuracy: 0.9138 | Precision: 0.9638 | Recall: 0.8785 | F1: 0.9192 | LogLoss: 0.7814\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.2860 | Total: 0.4290\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4672 | Total: 0.2259\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Run 6 | Accuracy: 0.9129 | Precision: 0.9622 | Recall: 0.8785 | F1: 0.9185 | LogLoss: 0.7861\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.2840 | Total: 0.4276\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.4674 | Total: 0.2258\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Run 7 | Accuracy: 0.9129 | Precision: 0.9627 | Recall: 0.8780 | F1: 0.9184 | LogLoss: 0.7999\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.2853 | Total: 0.4305\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4672 | Total: 0.2259\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4678 | Total: 0.2254\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4678 | Total: 0.2254\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2254\n",
      "Run 8 | Accuracy: 0.9138 | Precision: 0.9623 | Recall: 0.8800 | F1: 0.9193 | LogLoss: 0.7911\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.2845 | Total: 0.4339\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4672 | λ*Reg: -0.4672 | Total: 0.2259\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.4675 | Total: 0.2257\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Run 9 | Accuracy: 0.9140 | Precision: 0.9628 | Recall: 0.8800 | F1: 0.9195 | LogLoss: 0.7741\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.2843 | Total: 0.4296\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.4673 | Total: 0.2258\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2256\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.4676 | Total: 0.2255\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.4678 | Total: 0.2254\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.4677 | Total: 0.2255\n",
      "Run 10 | Accuracy: 0.9138 | Precision: 0.9633 | Recall: 0.8790 | F1: 0.9192 | LogLoss: 0.7936\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 1 ---\n",
      "Accuracy : 0.9135 ± 0.0004\n",
      "Precision: 0.9630 ± 0.0005\n",
      "Recall   : 0.8787 ± 0.0008\n",
      "F1 Score : 0.9189 ± 0.0004\n",
      "Log Loss : 0.7985 ± 0.0156\n",
      "\n",
      "================ LAMBDA = 2 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -0.5678 | Total: 0.1488\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.9350 | Total: -0.2419\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Run 1 | Accuracy: 0.9138 | Precision: 0.9623 | Recall: 0.8800 | F1: 0.9193 | LogLoss: 0.8331\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -0.5675 | Total: 0.1436\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9358 | Total: -0.2426\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9358 | Total: -0.2427\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9358 | Total: -0.2426\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Run 2 | Accuracy: 0.9129 | Precision: 0.9622 | Recall: 0.8785 | F1: 0.9185 | LogLoss: 0.8874\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -0.5707 | Total: 0.1388\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.9350 | Total: -0.2419\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2423\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Run 3 | Accuracy: 0.9118 | Precision: 0.9616 | Recall: 0.8770 | F1: 0.9174 | LogLoss: 0.8524\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -0.5686 | Total: 0.1445\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9353 | Total: -0.2421\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Run 4 | Accuracy: 0.9124 | Precision: 0.9622 | Recall: 0.8775 | F1: 0.9179 | LogLoss: 0.8717\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -0.5673 | Total: 0.1498\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.9350 | Total: -0.2418\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9358 | Total: -0.2426\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Run 5 | Accuracy: 0.9126 | Precision: 0.9622 | Recall: 0.8780 | F1: 0.9182 | LogLoss: 0.8521\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -0.5719 | Total: 0.1431\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4675 | λ*Reg: -0.9350 | Total: -0.2419\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Run 6 | Accuracy: 0.9104 | Precision: 0.9595 | Recall: 0.8765 | F1: 0.9161 | LogLoss: 0.8388\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -0.5680 | Total: 0.1436\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4674 | λ*Reg: -0.9347 | Total: -0.2416\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Run 7 | Accuracy: 0.9132 | Precision: 0.9622 | Recall: 0.8790 | F1: 0.9187 | LogLoss: 0.8219\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -0.5707 | Total: 0.1452\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4673 | λ*Reg: -0.9347 | Total: -0.2415\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9355 | Total: -0.2423\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Run 8 | Accuracy: 0.9132 | Precision: 0.9617 | Recall: 0.8795 | F1: 0.9188 | LogLoss: 0.8303\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -0.5691 | Total: 0.1493\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9353 | Total: -0.2421\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -0.9354 | Total: -0.2423\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2424\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2426\n",
      "Run 9 | Accuracy: 0.9135 | Precision: 0.9617 | Recall: 0.8800 | F1: 0.9191 | LogLoss: 0.8650\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -0.5686 | Total: 0.1453\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4676 | λ*Reg: -0.9353 | Total: -0.2421\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9355 | Total: -0.2424\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9357 | Total: -0.2425\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -0.9358 | Total: -0.2427\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -0.9356 | Total: -0.2425\n",
      "Run 10 | Accuracy: 0.9126 | Precision: 0.9622 | Recall: 0.8780 | F1: 0.9182 | LogLoss: 0.8674\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 2 ---\n",
      "Accuracy : 0.9126 ± 0.0009\n",
      "Precision: 0.9618 ± 0.0008\n",
      "Recall   : 0.8784 ± 0.0012\n",
      "F1 Score : 0.9182 ± 0.0009\n",
      "Log Loss : 0.8520 ± 0.0199\n",
      "\n",
      "================ LAMBDA = 5 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -1.4195 | Total: -0.7029\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3391 | Total: -1.6460\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6467\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Run 1 | Accuracy: 0.9099 | Precision: 0.9600 | Recall: 0.8750 | F1: 0.9155 | LogLoss: 0.9170\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -1.4187 | Total: -0.7076\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3391 | Total: -1.6459\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6466\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6466\n",
      "Run 2 | Accuracy: 0.9099 | Precision: 0.9600 | Recall: 0.8750 | F1: 0.9155 | LogLoss: 0.9178\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -1.4266 | Total: -0.7172\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3392 | Total: -1.6460\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6466\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6471\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6471\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3404 | Total: -1.6472\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6471\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6472\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6472\n",
      "Run 3 | Accuracy: 0.9068 | Precision: 0.9577 | Recall: 0.8715 | F1: 0.9126 | LogLoss: 0.9521\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -1.4214 | Total: -0.7083\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3389 | Total: -1.6457\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6466\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6471\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6471\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Run 4 | Accuracy: 0.9068 | Precision: 0.9582 | Recall: 0.8710 | F1: 0.9125 | LogLoss: 0.9304\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -1.4183 | Total: -0.7012\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3388 | Total: -1.6456\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6464\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6467\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6466\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6466\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3396 | Total: -1.6465\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6467\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6467\n",
      "Run 5 | Accuracy: 0.9129 | Precision: 0.9622 | Recall: 0.8785 | F1: 0.9185 | LogLoss: 0.9296\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -1.4298 | Total: -0.7148\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -2.3386 | Total: -1.6454\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Run 6 | Accuracy: 0.9076 | Precision: 0.9578 | Recall: 0.8730 | F1: 0.9134 | LogLoss: 0.9299\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -1.4201 | Total: -0.7084\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4677 | λ*Reg: -2.3386 | Total: -1.6454\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6467\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6468\n",
      "Run 7 | Accuracy: 0.9073 | Precision: 0.9582 | Recall: 0.8720 | F1: 0.9131 | LogLoss: 0.9219\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -1.4266 | Total: -0.7108\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3389 | Total: -1.6458\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6466\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3399 | Total: -1.6467\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3397 | Total: -1.6466\n",
      "Run 8 | Accuracy: 0.9101 | Precision: 0.9595 | Recall: 0.8760 | F1: 0.9158 | LogLoss: 0.9332\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -1.4227 | Total: -0.7043\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -2.3388 | Total: -1.6457\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3395 | Total: -1.6464\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6469\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6472\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Run 9 | Accuracy: 0.9087 | Precision: 0.9584 | Recall: 0.8745 | F1: 0.9145 | LogLoss: 0.9253\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -1.4216 | Total: -0.7077\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -2.3393 | Total: -1.6461\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3398 | Total: -1.6466\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6470\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6470\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3401 | Total: -1.6469\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3402 | Total: -1.6471\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -2.3403 | Total: -1.6471\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -2.3400 | Total: -1.6468\n",
      "Run 10 | Accuracy: 0.9073 | Precision: 0.9577 | Recall: 0.8725 | F1: 0.9131 | LogLoss: 0.9354\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 5 ---\n",
      "Accuracy : 0.9087 ± 0.0019\n",
      "Precision: 0.9590 ± 0.0014\n",
      "Recall   : 0.8739 ± 0.0022\n",
      "F1 Score : 0.9145 ± 0.0018\n",
      "Log Loss : 0.9293 ± 0.0096\n",
      "\n",
      "================ LAMBDA = 8 ================\n",
      "\n",
      "\n",
      "--- Run 1/10 ---\n",
      "Epoch    0 | DGI: 0.7166 | Reg: -0.2839 | λ*Reg: -2.2713 | Total: -1.5546\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7434 | Total: -3.0502\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7442 | Total: -3.0511\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7444 | Total: -3.0513\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0511\n",
      "Run 1 | Accuracy: 0.9090 | Precision: 0.9589 | Recall: 0.8745 | F1: 0.9147 | LogLoss: 0.9596\n",
      "\n",
      "--- Run 2/10 ---\n",
      "Epoch    0 | DGI: 0.7111 | Reg: -0.2837 | λ*Reg: -2.2699 | Total: -1.5588\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7434 | Total: -3.0503\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7442 | Total: -3.0510\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0513\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0512\n",
      "Run 2 | Accuracy: 0.9079 | Precision: 0.9583 | Recall: 0.8730 | F1: 0.9137 | LogLoss: 0.9670\n",
      "\n",
      "--- Run 3/10 ---\n",
      "Epoch    0 | DGI: 0.7095 | Reg: -0.2853 | λ*Reg: -2.2826 | Total: -1.5731\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7438 | Total: -3.0507\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7442 | Total: -3.0510\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0518\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0519\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0519\n",
      "Run 3 | Accuracy: 0.9065 | Precision: 0.9577 | Recall: 0.8710 | F1: 0.9123 | LogLoss: 0.9976\n",
      "\n",
      "--- Run 4/10 ---\n",
      "Epoch    0 | DGI: 0.7131 | Reg: -0.2843 | λ*Reg: -2.2743 | Total: -1.5612\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7434 | Total: -3.0503\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7444 | Total: -3.0512\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7444 | Total: -3.0512\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7451 | Total: -3.0519\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0518\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Run 4 | Accuracy: 0.9062 | Precision: 0.9576 | Recall: 0.8705 | F1: 0.9120 | LogLoss: 0.9916\n",
      "\n",
      "--- Run 5/10 ---\n",
      "Epoch    0 | DGI: 0.7171 | Reg: -0.2837 | λ*Reg: -2.2692 | Total: -1.5521\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4678 | λ*Reg: -3.7427 | Total: -3.0496\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7437 | Total: -3.0506\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0513\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7440 | Total: -3.0509\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7440 | Total: -3.0509\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7441 | Total: -3.0509\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0512\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7439 | Total: -3.0507\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7442 | Total: -3.0510\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7442 | Total: -3.0510\n",
      "Run 5 | Accuracy: 0.9112 | Precision: 0.9601 | Recall: 0.8775 | F1: 0.9169 | LogLoss: 0.9584\n",
      "\n",
      "--- Run 6/10 ---\n",
      "Epoch    0 | DGI: 0.7150 | Reg: -0.2860 | λ*Reg: -2.2877 | Total: -1.5727\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7429 | Total: -3.0497\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0513\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Run 6 | Accuracy: 0.9068 | Precision: 0.9577 | Recall: 0.8715 | F1: 0.9126 | LogLoss: 0.9865\n",
      "\n",
      "--- Run 7/10 ---\n",
      "Epoch    0 | DGI: 0.7117 | Reg: -0.2840 | λ*Reg: -2.2722 | Total: -1.5605\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7431 | Total: -3.0500\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0514\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0515\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0517\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0518\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0514\n",
      "Run 7 | Accuracy: 0.9057 | Precision: 0.9576 | Recall: 0.8695 | F1: 0.9114 | LogLoss: 0.9911\n",
      "\n",
      "--- Run 8/10 ---\n",
      "Epoch    0 | DGI: 0.7158 | Reg: -0.2853 | λ*Reg: -2.2826 | Total: -1.5668\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7429 | Total: -3.0497\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0511\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0519\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7451 | Total: -3.0520\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0511\n",
      "Run 8 | Accuracy: 0.9065 | Precision: 0.9577 | Recall: 0.8710 | F1: 0.9123 | LogLoss: 0.9791\n",
      "\n",
      "--- Run 9/10 ---\n",
      "Epoch    0 | DGI: 0.7184 | Reg: -0.2845 | λ*Reg: -2.2764 | Total: -1.5580\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7433 | Total: -3.0501\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7441 | Total: -3.0509\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7449 | Total: -3.0517\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0518\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7448 | Total: -3.0516\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7450 | Total: -3.0519\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Run 9 | Accuracy: 0.9062 | Precision: 0.9576 | Recall: 0.8705 | F1: 0.9120 | LogLoss: 0.9863\n",
      "\n",
      "--- Run 10/10 ---\n",
      "Epoch    0 | DGI: 0.7139 | Reg: -0.2843 | λ*Reg: -2.2746 | Total: -1.5607\n",
      "Epoch  500 | DGI: 0.6931 | Reg: -0.4679 | λ*Reg: -3.7431 | Total: -3.0500\n",
      "Epoch 1000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7439 | Total: -3.0508\n",
      "Epoch 1500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0512\n",
      "Epoch 2000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7444 | Total: -3.0513\n",
      "Epoch 2500 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7444 | Total: -3.0512\n",
      "Epoch 3000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0514\n",
      "Epoch 3500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7445 | Total: -3.0513\n",
      "Epoch 4000 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7446 | Total: -3.0515\n",
      "Epoch 4500 | DGI: 0.6931 | Reg: -0.4681 | λ*Reg: -3.7447 | Total: -3.0516\n",
      "Epoch 5000 | DGI: 0.6931 | Reg: -0.4680 | λ*Reg: -3.7443 | Total: -3.0511\n",
      "Run 10 | Accuracy: 0.9068 | Precision: 0.9577 | Recall: 0.8715 | F1: 0.9126 | LogLoss: 0.9665\n",
      "\n",
      "--- RESULTS FOR LAMBDA = 8 ---\n",
      "Accuracy : 0.9073 ± 0.0016\n",
      "Precision: 0.9581 ± 0.0008\n",
      "Recall   : 0.8720 ± 0.0023\n",
      "F1 Score : 0.9130 ± 0.0016\n",
      "Log Loss : 0.9784 ± 0.0136\n",
      "\n",
      "================ FINAL SUMMARY FOR ALL LAMBDAS ================\n",
      "\n",
      "  Lambda |           Accuracy |          Precision |             Recall |           F1 Score |           Log Loss\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "   0.001 | 0.9128 ± 0.0044 | 0.9602 ± 0.0037 | 0.8803 ± 0.0075 | 0.9185 ± 0.0044 | 0.2539 ± 0.0123\n",
      "   0.005 | 0.9119 ± 0.0019 | 0.9626 ± 0.0023 | 0.8763 ± 0.0041 | 0.9174 ± 0.0019 | 0.3519 ± 0.0120\n",
      "   0.009 | 0.9119 ± 0.0013 | 0.9633 ± 0.0020 | 0.8755 ± 0.0031 | 0.9173 ± 0.0013 | 0.4029 ± 0.0077\n",
      "    0.01 | 0.9121 ± 0.0016 | 0.9630 ± 0.0021 | 0.8762 ± 0.0032 | 0.9176 ± 0.0016 | 0.4125 ± 0.0092\n",
      "    0.05 | 0.9135 ± 0.0013 | 0.9628 ± 0.0014 | 0.8790 ± 0.0020 | 0.9190 ± 0.0013 | 0.5378 ± 0.0169\n",
      "    0.09 | 0.9134 ± 0.0009 | 0.9627 ± 0.0010 | 0.8789 ± 0.0014 | 0.9189 ± 0.0009 | 0.5920 ± 0.0248\n",
      "     0.1 | 0.9133 ± 0.0009 | 0.9628 ± 0.0011 | 0.8787 ± 0.0014 | 0.9188 ± 0.0009 | 0.6026 ± 0.0242\n",
      "     0.3 | 0.9138 ± 0.0005 | 0.9634 ± 0.0004 | 0.8790 ± 0.0009 | 0.9193 ± 0.0005 | 0.6923 ± 0.0282\n",
      "     0.5 | 0.9136 ± 0.0006 | 0.9632 ± 0.0006 | 0.8787 ± 0.0009 | 0.9190 ± 0.0006 | 0.7332 ± 0.0292\n",
      "     0.9 | 0.9135 ± 0.0003 | 0.9630 ± 0.0005 | 0.8787 ± 0.0006 | 0.9189 ± 0.0003 | 0.7830 ± 0.0277\n",
      "       1 | 0.9135 ± 0.0004 | 0.9630 ± 0.0005 | 0.8787 ± 0.0008 | 0.9189 ± 0.0004 | 0.7985 ± 0.0156\n",
      "       2 | 0.9126 ± 0.0009 | 0.9618 ± 0.0008 | 0.8784 ± 0.0012 | 0.9182 ± 0.0009 | 0.8520 ± 0.0199\n",
      "       5 | 0.9087 ± 0.0019 | 0.9590 ± 0.0014 | 0.8739 ± 0.0022 | 0.9145 ± 0.0018 | 0.9293 ± 0.0096\n",
      "       8 | 0.9073 ± 0.0016 | 0.9581 ± 0.0008 | 0.8720 ± 0.0023 | 0.9130 ± 0.0016 | 0.9784 ± 0.0136\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "hidden_dim   = 256\n",
    "cut          = 0\n",
    "dropout      = 0.25\n",
    "num_runs     = 10\n",
    "heads = 2\n",
    "num_epochs   = 5000\n",
    "lambda_list  = [0.001, 0.005, 0.009, 0.01, 0.05, 0.09, 0.1, 0.3, 0.5, 0.9, 1, 2, 5, 8]\n",
    "base_seed    = 42\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "node_feats = node_feats.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "A = A.to(device)\n",
    "\n",
    "# Use the y_subset created earlier\n",
    "y_subset_np = y_subset.astype(int)\n",
    "\n",
    "N, feats_dim = node_feats.size(0), node_feats.size(1)\n",
    "\n",
    "all_results = []\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for lam in lambda_list:\n",
    "    print(f\"\\n================ LAMBDA = {lam} ================\\n\")\n",
    "\n",
    "    acc_scores, prec_scores, rec_scores, f1_scores, log_losses = [], [], [], [], []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        print(f\"\\n--- Run {run+1}/{num_runs} ---\")\n",
    "\n",
    "        seed = base_seed + run\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "        model = DGI_with_classifier(features.shape[1], hidden_dim, n_classes=2, cut=cut, dropout=dropout).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)\n",
    "        scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n",
    "\n",
    "\n",
    "        for epoch in range(num_epochs + 1):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            perm = torch.randperm(N, device=device)\n",
    "            corrupt_features = node_feats[perm]\n",
    "\n",
    "            logits, embeddings = model(node_feats, corrupt_features, edge_index)\n",
    "\n",
    "            lbl = torch.cat([torch.ones(N, device=device), torch.zeros(N, device=device)])\n",
    "            dgi_loss = bce_loss(logits.squeeze(), lbl)\n",
    "            reg_loss = model.Reg_loss(A, embeddings)\n",
    "\n",
    "            loss = dgi_loss + lam * reg_loss\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                print(f\"Epoch {epoch:4d} | DGI: {dgi_loss.item():.4f} | Reg: {reg_loss.item():.4f} | \"\n",
    "                      f\"λ*Reg: {(lam * reg_loss).item():.4f} | Total: {loss.item():.4f}\")\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            emb = model.get_embeddings(node_feats, edge_index)\n",
    "            logits_cls = model.classifier(emb)                   # [N, 2]\n",
    "            class_probabilities = F.softmax(logits_cls, dim=1).cpu().numpy()\n",
    "            y_pred = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "        acc  = accuracy_score(y_subset_np, y_pred)\n",
    "        acc_inv = accuracy_score(y_subset_np, 1 - y_pred)\n",
    "\n",
    "        if acc_inv > acc:\n",
    "            acc = acc_inv\n",
    "            y_pred = 1 - y_pred\n",
    "            class_probabilities = class_probabilities[:, ::-1]\n",
    "\n",
    "        prec = precision_score(y_subset_np, y_pred, zero_division=0)\n",
    "        rec  = recall_score(y_subset_np, y_pred, zero_division=0)\n",
    "        f1   = f1_score(y_subset_np, y_pred, zero_division=0)\n",
    "        ll   = log_loss(y_subset_np, class_probabilities)\n",
    "\n",
    "        print(f\"Run {run+1} | Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | LogLoss: {ll:.4f}\")\n",
    "\n",
    "        acc_scores.append(acc)\n",
    "        prec_scores.append(prec)\n",
    "        rec_scores.append(rec)\n",
    "        f1_scores.append(f1)\n",
    "        log_losses.append(ll)\n",
    "\n",
    "    lambda_results = {\n",
    "        \"lambda\": lam,\n",
    "        \"accuracy\":  (float(np.mean(acc_scores)), float(np.std(acc_scores))),\n",
    "        \"precision\": (float(np.mean(prec_scores)), float(np.std(prec_scores))),\n",
    "        \"recall\":    (float(np.mean(rec_scores)), float(np.std(rec_scores))),\n",
    "        \"f1\":        (float(np.mean(f1_scores)),  float(np.std(f1_scores))),\n",
    "        \"log_loss\":  (float(np.mean(log_losses)), float(np.std(log_losses))),\n",
    "    }\n",
    "    all_results.append(lambda_results)\n",
    "\n",
    "    print(f\"\\n--- RESULTS FOR LAMBDA = {lam} ---\")\n",
    "    print(f\"Accuracy : {lambda_results['accuracy'][0]:.4f} ± {lambda_results['accuracy'][1]:.4f}\")\n",
    "    print(f\"Precision: {lambda_results['precision'][0]:.4f} ± {lambda_results['precision'][1]:.4f}\")\n",
    "    print(f\"Recall   : {lambda_results['recall'][0]:.4f} ± {lambda_results['recall'][1]:.4f}\")\n",
    "    print(f\"F1 Score : {lambda_results['f1'][0]:.4f} ± {lambda_results['f1'][1]:.4f}\")\n",
    "    print(f\"Log Loss : {lambda_results['log_loss'][0]:.4f} ± {lambda_results['log_loss'][1]:.4f}\")\n",
    "\n",
    "print(\"\\n================ FINAL SUMMARY FOR ALL LAMBDAS ================\\n\")\n",
    "print(f\"{'Lambda':>8} | {'Accuracy':>18} | {'Precision':>18} | {'Recall':>18} | {'F1 Score':>18} | {'Log Loss':>18}\")\n",
    "print(\"-\" * 108)\n",
    "for res in all_results:\n",
    "    print(f\"{res['lambda']:>8} | \"\n",
    "          f\"{res['accuracy'][0]:.4f} ± {res['accuracy'][1]:.4f} | \"\n",
    "          f\"{res['precision'][0]:.4f} ± {res['precision'][1]:.4f} | \"\n",
    "          f\"{res['recall'][0]:.4f} ± {res['recall'][1]:.4f} | \"\n",
    "          f\"{res['f1'][0]:.4f} ± {res['f1'][1]:.4f} | \"\n",
    "          f\"{res['log_loss'][0]:.4f} ± {res['log_loss'][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoZr8SupDBbh",
    "outputId": "bf0c8e2c-ccdf-4256-dbcc-71538cba1dae"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def cluster_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Assigns predicted clusters to true labels\n",
    "    to maximize accuracy using the Jonker-Volgenant algorithm (linear_sum_assignment).\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(-w)\n",
    "    return w[row_ind, col_ind].sum() / y_pred.size\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model.get_embeddings(node_feats.to(device), edge_index.to(device))\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "kmeans.fit(embeddings)\n",
    "y_pred_kmeans = kmeans.labels_\n",
    "\n",
    "ari_score = adjusted_rand_score(y, y_pred_kmeans)\n",
    "nmi_score = normalized_mutual_info_score(y, y_pred_kmeans)\n",
    "\n",
    "print(\"Adjusted Rand Score:\", ari_score)\n",
    "print(\"Normalized Mutual Information Score:\", nmi_score)\n",
    "\n",
    "acc_kmeans = cluster_acc(y, y_pred_kmeans)\n",
    "print(\"Clustering Accuracy (mapped):\", acc_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adGSi9JiEEqO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPfsaXB6_EZp"
   },
   "outputs": [],
   "source": [
    "# class DGI(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim,output_dim, cut=0):\n",
    "#         super().__init__()\n",
    "#         self.encoder = GCNEncoder(input_dim, hidden_dim)\n",
    "#         self.readout = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.cut = cut\n",
    "#         self.output_dim = output_dim\n",
    "\n",
    "#     def forward(self, x, edge_index, corrupt_x, adj=None):\n",
    "#         h = self.encoder(x, edge_index)\n",
    "#         h_corrupt = self.encoder(corrupt_x, edge_index)\n",
    "\n",
    "#         # Summary vector\n",
    "#         s = torch.sigmoid(h.mean(dim=0))\n",
    "\n",
    "#         # Positive & negative scores\n",
    "#         pos = torch.matmul(h, s)\n",
    "#         neg = torch.matmul(h_corrupt, s)\n",
    "\n",
    "#         # DGI loss\n",
    "#         dgi_loss = -torch.log(torch.sigmoid(pos - neg) + 1e-8).mean()\n",
    "\n",
    "#         reg_loss = 0\n",
    "#         if adj is not None:\n",
    "#             A = torch.as_tensor(adj, dtype=torch.float32, device=x.device)\n",
    "#             D = torch.diag(A.sum(dim=1))\n",
    "\n",
    "#             if self.cut == 1:  # Cut loss\n",
    "#                 L = D - A\n",
    "#                 p = self.readout(h)\n",
    "#                 C = F.softmax(p, dim=1)\n",
    "#                 reg_loss = torch.trace(C.T @ L @ C) / (torch.trace(C.T @ D @ C) + 1e-8)\n",
    "\n",
    "#             else:  # Modularity loss\n",
    "#                 m = torch.sum(A)\n",
    "#                 B = A - torch.outer(D.diag(), D.diag()) / (2 * m)\n",
    "#                 p = self.readout(h)\n",
    "#                 C = F.softmax(p, dim=1)\n",
    "#                 k = torch.tensor(self.output_dim, dtype=torch.float32, device=x.device)\n",
    "#                 n = C.shape[0]\n",
    "#                 reg_loss = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n",
    "#                 reg_loss += (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n",
    "\n",
    "\n",
    "#         return h, dgi_loss, reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xzy_llWw_UGN",
    "outputId": "db4fe94b-e693-45af-a7b5-2f4b9bf7342c"
   },
   "outputs": [],
   "source": [
    "# hidden_dim = 256\n",
    "# output_dim = 2\n",
    "# cut = 0\n",
    "# model = DGI(features.shape[1], hidden_dim, output_dim, cut=cut).to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# num_epochs = 7000\n",
    "# for epoch in range(num_epochs+1):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     perm = torch.randperm(features.shape[0])\n",
    "#     corrupt_features = node_feats[perm]\n",
    "\n",
    "#     _, dgi_loss, reg_loss = model(\n",
    "#         node_feats.to(device),\n",
    "#         edge_index.to(device),\n",
    "#         corrupt_features.to(device),\n",
    "#         adj=torch.tensor(W0).to(device)\n",
    "#     )\n",
    "\n",
    "#     loss = dgi_loss + reg_loss\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if epoch % 500 == 0:\n",
    "#         print(f\"Epoch {epoch} | DGI Loss: {dgi_loss.item():.4f} | Reg Loss: {reg_loss.item():.4f} | Total Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3sTP63kBAhr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSW7Zhsy_cg6"
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     embeddings, _, _ = model(\n",
    "#         node_feats.to(device),\n",
    "#         edge_index.to(device),\n",
    "#         node_feats.to(device),\n",
    "#         adj=torch.tensor(W0).to(device)\n",
    "#     )\n",
    "\n",
    "# embeddings = embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCN-YL-LXrE5",
    "outputId": "29244971-8ffd-42c0-90df-34d6ed34164a"
   },
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "# # Use KMeans clustering\n",
    "# kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "# kmeans.fit(embeddings)\n",
    "# y_pred_kmeans = kmeans.labels_\n",
    "\n",
    "# # Evaluate clustering performance\n",
    "# ari_score = adjusted_rand_score(y, y_pred_kmeans)\n",
    "# nmi_score = normalized_mutual_info_score(y, y_pred_kmeans)\n",
    "\n",
    "# print(\"Adjusted Rand Score:\", ari_score)\n",
    "# print(\"Normalized Mutual Information Score:\", nmi_score)\n",
    "\n",
    "# # Note: K-Means is an unsupervised algorithm, so traditional classification metrics like accuracy, precision, recall, and F1 are not directly applicable without mapping clusters to classes.\n",
    "# # However, we can calculate accuracy by mapping the cluster labels to the true labels in the way that maximizes accuracy.\n",
    "# # This is not a standard evaluation for clustering but can give an idea of how well the clusters separate the classes.\n",
    "# from scipy.optimize import linear_sum_assignment\n",
    "# def cluster_acc(y_true, y_pred):\n",
    "#     \"\"\"\n",
    "#     Calculate clustering accuracy. Assigns predicted clusters to true labels\n",
    "#     to maximize accuracy using the Jonker-Volgenant algorithm (linear_sum_assignment).\n",
    "#     \"\"\"\n",
    "#     y_true = y_true.astype(np.int64)\n",
    "#     assert y_pred.size == y_true.size\n",
    "#     D = max(y_pred.max(), y_true.max()) + 1\n",
    "#     w = np.zeros((D, D), dtype=np.int64)\n",
    "#     for i in range(y_pred.size):\n",
    "#         w[y_pred[i], y_true[i]] += 1\n",
    "#     row_ind, col_ind = linear_sum_assignment(-w)\n",
    "#     return w[row_ind, col_ind].sum() / y_pred.size\n",
    "\n",
    "# acc_kmeans = cluster_acc(y, y_pred_kmeans)\n",
    "# print(\"Clustering Accuracy (mapped):\", acc_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WL8xpgMME8sS"
   },
   "source": [
    "1- GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfZdJWjqBSU5"
   },
   "source": [
    "Accuracy: 0.7466666666666667\n",
    "Precision: 0.7263681592039801\n",
    "Recall: 0.874251497005988\n",
    "F1: 0.7934782608695652\n",
    "Log Loss: 0.5786983582841999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWmKFw9cE77L"
   },
   "source": [
    "Accuracy: 0.7533333333333333\n",
    "Precision: 0.7360406091370558\n",
    "Recall: 0.8682634730538922\n",
    "F1: 0.7967032967032966\n",
    "Log Loss: 0.5772490248961657"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"LZUOPMDkneAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q torch_geometric\n","!pip install -q class_resolver\n","!pip3 install pymatting\n"],"metadata":{"id":"KW4uc3ICnhZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VSYEATM8HJ2u","executionInfo":{"status":"ok","timestamp":1766986824586,"user_tz":-330,"elapsed":4574,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import random\n","import copy\n","import scipy.sparse as sp\n","\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","from torchvision import models\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","\n","# torch-geometric imports\n","from torch_geometric.nn import ARMAConv\n","from torch_geometric.data import Data"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"wf0XTltjflwk","outputId":"6cdca100-bae2-4636-9872-6f38c6944a17","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766986825252,"user_tz":-330,"elapsed":26,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available: True\n","GPU Name: NVIDIA A100-SXM4-40GB\n"]}],"source":["import torch\n","print(\"CUDA available:\", torch.cuda.is_available())\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"JinL9v8LHM8o","executionInfo":{"status":"ok","timestamp":1766986842956,"user_tz":-330,"elapsed":4366,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["data = np.load('/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/Medmnist_data/pneumoniamnist_224.npz', allow_pickle=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":18296,"status":"ok","timestamp":1766986861314,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"wiHdTxQpHbWL","outputId":"433835d7-9898-4dda-c6a8-a5cd867f2f5d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Images, labels shapes: torch.Size([5856, 3, 224, 224]) torch.Size([5856])\n"]}],"source":["all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","images = all_images.astype(np.float32) / 255.0\n","images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N,3,224,224)\n","\n","X = torch.tensor(images)\n","y = torch.tensor(all_labels).long()\n","print(\"Images, labels shapes:\", X.shape, y.shape)\n","\n","dataset = TensorDataset(X, y)\n","class0_indices = [i for i in range(len(y)) if y[i] == 0]\n","class1_indices = [i for i in range(len(y)) if y[i] == 1]\n","\n","random.seed(42)\n","sampled_class0 = random.sample(class0_indices, min(2000, len(class0_indices)))\n","sampled_class1 = random.sample(class1_indices, min(2000, len(class1_indices)))\n","\n","combined_indices = sampled_class0 + sampled_class1\n","random.shuffle(combined_indices)\n","\n","final_dataset = Subset(dataset, combined_indices)\n","final_loader = DataLoader(final_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3071,"status":"ok","timestamp":1766986864387,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"egLJ3D9jHmdP","outputId":"ad53c14a-cbb2-45e9-f097-5da6e8a8ff25","scrolled":true},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 44.7M/44.7M [00:00<00:00, 95.8MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Feature shape: (3583, 512) Label shape: (3583,)\n"]}],"source":["resnet = models.resnet18(pretrained=True)\n","resnet.fc = nn.Identity()\n","resnet = resnet.to(device)\n","resnet.eval()\n","\n","resnet_feats = []\n","y_list = []\n","with torch.no_grad():\n","    for imgs, labels in final_loader:\n","        imgs = imgs.to(device)\n","        feats = resnet(imgs)\n","        resnet_feats.append(feats.cpu())\n","        y_list.extend(labels.cpu().tolist())\n","\n","features = torch.cat(resnet_feats, dim=0).numpy().astype(np.float32)  # shape (N, feat_dim)\n","y_labels = np.array(y_list).astype(np.float32)\n","print(\"Feature shape:\", features.shape, \"Label shape:\", y_labels.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Wpcmbg6mflwm","executionInfo":{"status":"ok","timestamp":1766986864443,"user_tz":-330,"elapsed":19,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def sim(h1, h2, tau=0.2):\n","    z1 = nnFn.normalize(h1, dim=-1, p=2)\n","    z2 = nnFn.normalize(h2, dim=-1, p=2)\n","    return torch.mm(z1, z2.t()) / tau\n","\n","def contrastive_loss_wo_cross_network(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    intra_sim = f(sim(h1, h1))\n","    inter_sim = f(sim(h1, h2))\n","    return -torch.log(inter_sim.diag() /\n","                     (intra_sim.sum(dim=-1) + inter_sim.sum(dim=-1) - intra_sim.diag()))\n","\n","def contrastive_loss_wo_cross_view(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    cross_sim = f(sim(h1, z))\n","    return -torch.log(cross_sim.diag() / cross_sim.sum(dim=-1))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"FQhjb1oDflwm","executionInfo":{"status":"ok","timestamp":1766986864461,"user_tz":-330,"elapsed":15,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.PReLU(), # nn.ELU()\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"q4Qnnhf7flwm","executionInfo":{"status":"ok","timestamp":1766986864500,"user_tz":-330,"elapsed":20,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class ARMAEncoder(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ=\"ELU\", num_stacks=1, num_layers=3):\n","        super(ARMAEncoder, self).__init__()\n","        self.device = device\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"ELU\": nnFn.elu,\n","            \"RELU\": nnFn.relu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","        self.arma = ARMAConv(\n","            in_channels=input_dim,\n","            out_channels=hidden_dim,\n","            num_stacks=num_stacks,\n","            num_layers=num_layers,\n","            act=self.act,\n","            shared_weights=True,\n","            dropout=0.25\n","        )\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(0.25)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.arma(x, edge_index)\n","        x = self.dropout(x)\n","        x = self.batchnorm(x)\n","        logits = self.mlp(x)\n","        return logits"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"7RIXmtobflwm","executionInfo":{"status":"ok","timestamp":1766986864534,"user_tz":-330,"elapsed":10,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class EMA():  # Moving Average update\n","    def __init__(self, beta):\n","        super().__init__()\n","        self.beta = beta\n","\n","    def update_average(self, old, new):\n","        if old is None:\n","            return new\n","        return old * self.beta + (1 - self.beta) * new\n","\n","def update_moving_average(ema_updater, ma_model, current_model):\n","    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n","        old_weight, up_weight = ma_params.data, current_params.data\n","        ma_params.data = ema_updater.update_average(old_weight, up_weight)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"9Br5pO-vflwn","executionInfo":{"status":"ok","timestamp":1766986864703,"user_tz":-330,"elapsed":165,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["class ARMA(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ, moving_average_decay=0.5, cut=True):\n","        super(ARMA, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","        self.cut = cut\n","        self.beta = 0.6\n","\n","        self.online_encoder = ARMAEncoder(input_dim, hidden_dim, device, activ)\n","        self.target_encoder = copy.deepcopy(self.online_encoder)\n","\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_dim)\n","        self.loss = self.cut_loss if cut else self.modularity_loss\n","        self.target_ema_updater = EMA(moving_average_decay)\n","\n","    def reset_moving_average(self):\n","        del self.target_encoder\n","        self.target_encoder = None\n","\n","    def update_ma(self):\n","        assert self.target_encoder is not None, 'target encoder has not been created yet'\n","        update_moving_average(self.target_ema_updater, self.target_encoder, self.online_encoder)\n","\n","    def forward(self, data1, data2):\n","        x1 = self.online_encoder(data1)\n","        logits1 = self.online_predictor(x1)\n","        S1 = nnFn.softmax(logits1, dim=1)\n","\n","        x2 = self.online_encoder(data2)\n","        logits2 = self.online_predictor(x2)\n","        S2 = nnFn.softmax(logits2, dim=1)\n","\n","        with torch.no_grad():\n","            target_proj_one = self.target_encoder(data1).detach()\n","            target_proj_two = self.target_encoder(data2).detach()\n","\n","        l1 = self.beta * contrastive_loss_wo_cross_network(x1, x2, target_proj_two) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x1, x2, target_proj_two)\n","\n","        l2 = self.beta * contrastive_loss_wo_cross_network(x2, x1, target_proj_one) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x2, x1, target_proj_one)\n","\n","        return S1, S2, logits1, logits2, l1, l2\n","\n","    def modularity_loss(self, A, S):\n","        C = nnFn.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A)\n","        B = A - torch.ger(d, d) / (2 * m)\n","\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        k = torch.tensor(self.num_clusters, dtype=torch.float32, device=self.device)\n","        n = S.shape[0]\n","\n","        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n","\n","        return modularity_term + collapse_reg_term\n","\n","    def cut_loss(self, A, S):\n","        S = nnFn.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / den)\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n","\n","        return mincut_loss + ortho_loss"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"TLz2kJBNflwn","executionInfo":{"status":"ok","timestamp":1766986864707,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def create_adj(features, cut, alpha=1.0):\n","    \"\"\"Return a dense W0 matrix (only once), as you originally used for A1 / unsup loss.\n","       We still create the dense matrix once, but all augmentations below work with edge_index.\n","    \"\"\"\n","    F_norm = features / np.linalg.norm(features, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = (W * (W >= alpha)).astype(np.float32)\n","    return W"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"vGe2NfWYflwn","executionInfo":{"status":"ok","timestamp":1766986864710,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def edge_index_from_dense(W):\n","    \"\"\"Return edge_index as numpy array shape (2, E) and edge_weight vector.\"\"\"\n","    rows, cols = np.nonzero(W > 0)\n","    edge_index = np.vstack([rows, cols]).astype(np.int64)\n","    edge_weight = W[rows, cols].astype(np.float32)\n","    return edge_index, edge_weight"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"byEBQ3yIflwn","executionInfo":{"status":"ok","timestamp":1766986864713,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def build_adj_list(edge_index_np, num_nodes):\n","    \"\"\"Build adjacency list: list of neighbor arrays for each node (numpy).\"\"\"\n","    adj = [[] for _ in range(num_nodes)]\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    for s, d in zip(src, dst):\n","        adj[s].append(d)\n","    # convert to numpy arrays for speed\n","    adj = [np.array(neis, dtype=np.int64) if len(neis) > 0 else np.array([], dtype=np.int64) for neis in adj]\n","    return adj"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"31MF3NKaflwn","executionInfo":{"status":"ok","timestamp":1766986864716,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=None):\n","    \"\"\"Randomly drop edges from edge_index. Returns new edge_index (2 x E') and edge_weight placeholder.\"\"\"\n","    rng = np.random.default_rng(seed)\n","    E = edge_index_np.shape[1]\n","    keep_mask = rng.random(E) >= drop_percent\n","    new_edge_index = edge_index_np[:, keep_mask]\n","    return new_edge_index"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"eogmQlX9flwn","executionInfo":{"status":"ok","timestamp":1766986864735,"user_tz":-330,"elapsed":18,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def aug_subgraph_edge_index(features_np, edge_index_np, adj_list, drop_percent=0.2, seed=None):\n","    \"\"\"\n","    Sample a subgraph by selecting s_node_num nodes via neighbor expansion (BFS-like),\n","    then return (sub_features, sub_edge_index) with node ids remapped to [0..s-1].\n","    \"\"\"\n","    rng = np.random.default_rng(seed)\n","    num_nodes = features_np.shape[0]\n","    s_node_num = int(num_nodes * (1 - drop_percent))\n","    if s_node_num < 1:\n","        s_node_num = 1\n","\n","    # choose a random center node\n","    center_node = int(rng.integers(0, num_nodes))\n","    sub_nodes = [center_node]\n","    front_idx = 0\n","\n","    # BFS-like expansion using adjacency list until we reach s_node_num\n","    while len(sub_nodes) < s_node_num and front_idx < len(sub_nodes):\n","        cur = sub_nodes[front_idx]\n","        neighbors = adj_list[cur]\n","        if neighbors.size > 0:\n","            # shuffle neighbors and try to add new ones\n","            nbrs_shuffled = neighbors.copy()\n","            rng.shuffle(nbrs_shuffled)\n","            for nb in nbrs_shuffled:\n","                if nb not in sub_nodes:\n","                    sub_nodes.append(int(nb))\n","                    if len(sub_nodes) >= s_node_num:\n","                        break\n","        front_idx += 1\n","        # if BFS stalls (no new neighbors), add random nodes\n","        if front_idx >= len(sub_nodes) and len(sub_nodes) < s_node_num:\n","            remaining = [n for n in range(num_nodes) if n not in sub_nodes]\n","            if not remaining:\n","                break\n","            add = int(rng.choice(remaining))\n","            sub_nodes.append(add)\n","\n","    sub_nodes = sorted(set(sub_nodes))\n","    node_map = {old: new for new, old in enumerate(sub_nodes)}\n","\n","    # induce edges that have both ends in sub_nodes\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    mask_src_in = np.isin(src, sub_nodes)\n","    mask_dst_in = np.isin(dst, sub_nodes)\n","    mask = mask_src_in & mask_dst_in\n","    sel_src = src[mask]\n","    sel_dst = dst[mask]\n","    # remap\n","    remapped_src = np.array([node_map[int(s)] for s in sel_src], dtype=np.int64)\n","    remapped_dst = np.array([node_map[int(d)] for d in sel_dst], dtype=np.int64)\n","    new_edge_index = np.vstack([remapped_src, remapped_dst])\n","    # sub features\n","    sub_features = features_np[sub_nodes, :].astype(np.float32)\n","    return sub_features, new_edge_index"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"ugSKKunsflwo","executionInfo":{"status":"ok","timestamp":1766986869914,"user_tz":-330,"elapsed":11,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["def load_data_from_edge_index(node_feats_np, edge_index_np, device):\n","    \"\"\"Return PyG Data with torch tensors. edge_index_np is (2, E) numpy.\"\"\"\n","    node_feats = torch.from_numpy(node_feats_np).float()\n","    edge_index = torch.from_numpy(edge_index_np.astype(np.int64)).long()\n","    return node_feats, edge_index"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"_hBfbNCzDXtq","executionInfo":{"status":"ok","timestamp":1766986873910,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["# Required Parameters\n","cut = 1 # Consider n-cut loss OR Modularity loss (by default cut = 0)\n","alpha = 0.9 # Edge creation Threshold\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","K = 2  # Number of clusters\n","np.random.seed(42)\n","# Define all activation functions to test\n","define_activations = [\"SELU\", \"SiLU\", \"GELU\", \"ELU\", \"RELU\"]\n","activ = \"ELU\"\n","num_epochs = 5000\n","base_seed = 42\n","lambda_contrastive = 0.005\n","feats_dim = features.shape[1]"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":684,"status":"ok","timestamp":1766986876193,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"XEKC0_x4Da-3","outputId":"b2ccfe5b-f36b-49f5-944d-58dfe1c64b32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data0: Data(x=[3583, 512], edge_index=[2, 1642249])\n"]}],"source":["W0 = create_adj(features, cut, alpha)  # shape (N, N) dense\n","A1 = torch.from_numpy(W0).float().to(device)\n","\n","edge_index_np, edge_weight_np = edge_index_from_dense(W0)  # numpy edge_index (2, E)\n","num_nodes = features.shape[0]\n","adj_list = build_adj_list(edge_index_np, num_nodes)  # adjacency list for fast subgraph sampling\n","\n","# convert features to numpy (we'll slice them in augmentations)\n","features_np = features.copy()\n","\n","# Build initial Data object (full graph)\n","node_feats_full, edge_index_full = load_data_from_edge_index(features_np, edge_index_np, device)\n","data0 = Data(x=node_feats_full.to(device), edge_index=edge_index_full.to(device))\n","print(\"Data0:\", data0)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1024765,"status":"ok","timestamp":1766987906687,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"sGbMVrM5Dcbk","outputId":"c9954799-7698-4101-cad7-05fd6f648e34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 | Total: -0.2038 | Unsup: -0.2428 | Cont: 7.8066\n","Epoch 100 | Total: -0.8452 | Unsup: -0.8838 | Cont: 7.7214\n","Epoch 200 | Total: -0.8604 | Unsup: -0.8986 | Cont: 7.6523\n","Epoch 300 | Total: -0.8635 | Unsup: -0.9016 | Cont: 7.6286\n","Epoch 400 | Total: -0.8663 | Unsup: -0.9042 | Cont: 7.5849\n","Epoch 500 | Total: -0.8684 | Unsup: -0.9063 | Cont: 7.5647\n","Epoch 600 | Total: -0.8690 | Unsup: -0.9068 | Cont: 7.5478\n","Epoch 700 | Total: -0.8694 | Unsup: -0.9071 | Cont: 7.5372\n","Epoch 800 | Total: -0.8701 | Unsup: -0.9078 | Cont: 7.5244\n","Epoch 900 | Total: -0.8713 | Unsup: -0.9089 | Cont: 7.5180\n","Epoch 1000 | Total: -0.8707 | Unsup: -0.9083 | Cont: 7.5110\n","Epoch 1100 | Total: -0.8712 | Unsup: -0.9088 | Cont: 7.5137\n","Epoch 1200 | Total: -0.8712 | Unsup: -0.9087 | Cont: 7.5127\n","Epoch 1300 | Total: -0.8714 | Unsup: -0.9089 | Cont: 7.5028\n","Epoch 1400 | Total: -0.8721 | Unsup: -0.9096 | Cont: 7.5011\n","Epoch 1500 | Total: -0.8715 | Unsup: -0.9090 | Cont: 7.5030\n","Epoch 1600 | Total: -0.8710 | Unsup: -0.9085 | Cont: 7.5009\n","Epoch 1700 | Total: -0.8715 | Unsup: -0.9089 | Cont: 7.4980\n","Epoch 1800 | Total: -0.8716 | Unsup: -0.9091 | Cont: 7.5001\n","Epoch 1900 | Total: -0.8715 | Unsup: -0.9089 | Cont: 7.4974\n","Epoch 2000 | Total: -0.8720 | Unsup: -0.9095 | Cont: 7.5025\n","Epoch 2100 | Total: -0.8716 | Unsup: -0.9091 | Cont: 7.4990\n","Epoch 2200 | Total: -0.8720 | Unsup: -0.9095 | Cont: 7.4994\n","Epoch 2300 | Total: -0.8710 | Unsup: -0.9085 | Cont: 7.4994\n","Epoch 2400 | Total: -0.8718 | Unsup: -0.9093 | Cont: 7.5007\n","Epoch 2500 | Total: -0.8706 | Unsup: -0.9081 | Cont: 7.4982\n","Epoch 2600 | Total: -0.8710 | Unsup: -0.9085 | Cont: 7.4989\n","Epoch 2700 | Total: -0.8715 | Unsup: -0.9090 | Cont: 7.5000\n","Epoch 2800 | Total: -0.8725 | Unsup: -0.9100 | Cont: 7.4979\n","Epoch 2900 | Total: -0.8718 | Unsup: -0.9093 | Cont: 7.4958\n","Epoch 3000 | Total: -0.8719 | Unsup: -0.9093 | Cont: 7.4997\n","Epoch 3100 | Total: -0.8714 | Unsup: -0.9089 | Cont: 7.4929\n","Epoch 3200 | Total: -0.8706 | Unsup: -0.9081 | Cont: 7.4992\n","Epoch 3300 | Total: -0.8715 | Unsup: -0.9090 | Cont: 7.4960\n","Epoch 3400 | Total: -0.8717 | Unsup: -0.9091 | Cont: 7.4965\n","Epoch 3500 | Total: -0.8716 | Unsup: -0.9091 | Cont: 7.4960\n","Epoch 3600 | Total: -0.8715 | Unsup: -0.9090 | Cont: 7.4987\n","Epoch 3700 | Total: -0.8717 | Unsup: -0.9092 | Cont: 7.4959\n","Epoch 3800 | Total: -0.8712 | Unsup: -0.9087 | Cont: 7.5003\n","Epoch 3900 | Total: -0.8719 | Unsup: -0.9094 | Cont: 7.4939\n","Epoch 4000 | Total: -0.8714 | Unsup: -0.9088 | Cont: 7.4946\n","Epoch 4100 | Total: -0.8709 | Unsup: -0.9084 | Cont: 7.4934\n","Epoch 4200 | Total: -0.8712 | Unsup: -0.9087 | Cont: 7.4965\n","Epoch 4300 | Total: -0.8707 | Unsup: -0.9082 | Cont: 7.4967\n","Epoch 4400 | Total: -0.8719 | Unsup: -0.9094 | Cont: 7.4970\n","Epoch 4500 | Total: -0.8712 | Unsup: -0.9086 | Cont: 7.4977\n","Epoch 4600 | Total: -0.8715 | Unsup: -0.9090 | Cont: 7.5020\n","Epoch 4700 | Total: -0.8712 | Unsup: -0.9087 | Cont: 7.4985\n","Epoch 4800 | Total: -0.8712 | Unsup: -0.9087 | Cont: 7.4976\n","Epoch 4900 | Total: -0.8717 | Unsup: -0.9092 | Cont: 7.4951\n"]}],"source":["from torch.optim.lr_scheduler import StepLR\n","from torch.optim import AdamW\n","\n","feats_dim = features.shape[1]\n","model = ARMA(feats_dim, 256, K, device, activ, cut).to(device)\n","optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","# Seeds\n","np.random.seed(42)\n","random.seed(42)\n","torch.manual_seed(42)\n","\n","# Training hyperparams (you can reduce num_epochs for debugging)\n","num_epochs = 5000\n","lambda_contrastive = 0.005\n","\n","for epoch in range(num_epochs):\n","    # --- Augmentations using edge_index or adjacency list (fast, sparse) ---\n","    # 1) Random edge drop on edge_index\n","    W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","\n","    # 2) Subgraph via adjacency list (returns sub_features and sub_edge_index)\n","    W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","    features_aug2 = features_np.copy()\n","\n","    # 3) Feature augmentations (keep these as numpy operations)\n","    # Feature dropout (column-wise)\n","    rng = np.random.default_rng(epoch)\n","    mask = rng.random(features_np.shape) >= 0.2\n","    features_aug1 = (features_np * mask.astype(np.float32))\n","\n","    # Feature cell dropout (random cell zeroing)\n","    aug_feat2 = features_np.copy()\n","    num_nodes_local, feat_dim = aug_feat2.shape\n","    drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","    # random positions to zero\n","    flat_idx = rng.choice(num_nodes_local * feat_dim, size=drop_feat_num, replace=False)\n","    rows = (flat_idx // feat_dim)\n","    cols = (flat_idx % feat_dim)\n","    aug_feat2[rows, cols] = 0.0\n","    features_aug2_feat = aug_feat2.astype(np.float32)\n","\n","    # --- Build PyG Data objects for the two views ---\n","    # view1: features_aug1 with W_aug1_edge_index\n","    node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","    data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","\n","    # view2: features_aug2 (from subgraph) and its edge_index\n","    node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, W_aug2_edge_index, device)\n","    data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","    # --- Training step ---\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","\n","    unsup_loss = model.loss(A1, logits1)\n","    cont_loss = ((l1 + l2) / 2).mean()\n","    total_loss = unsup_loss + lambda_contrastive * cont_loss\n","\n","    total_loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","    model.update_ma()\n","\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} | Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"jpYmDT0aDeG3","executionInfo":{"status":"ok","timestamp":1766987906769,"user_tz":-330,"elapsed":75,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["model.eval()\n","with torch.no_grad():\n","    S1, _, logits1, _, _, _ = model(data0, data0)\n","    y_pred_proba = nnFn.softmax(logits1, dim=1).cpu().numpy()\n","    y_pred = np.argmax(y_pred_proba, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1752741680035,"user":{"displayName":"CSE AIML Lab","userId":"00030888881271621426"},"user_tz":-330},"id":"NbofKb5oDhyj","outputId":"b81291e8-974d-40bd-cd44-5e687399bee8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1]\n","[0.9999994  0.9999323  0.9999832  0.99999905 0.9995409  0.9999615\n"," 0.9996792  0.9979074  0.9997521  0.99984396 0.9999212  0.99999654\n"," 0.99987507 0.9998702  0.99461526 0.9993561  0.99999917 0.99211407\n"," 0.999426   0.99997294]\n"]}],"source":["print(y_pred[:20])\n","print(y_pred_proba.max(axis=-1)[:20])"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":786,"status":"ok","timestamp":1766987907559,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"},"user_tz":-330},"id":"n1HmfThBDifY","outputId":"6c07d9f0-048a-44be-eb1a-38052863b3ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Score: 0.9031537817471392\n","Precision Score: 0.9635445877734156\n","Recall Score: 0.859\n","F1 Score: 0.908273856727465\n","Log Loss: 0.6143861689992804\n"]}],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n","acc_score = accuracy_score(y_labels, y_pred)\n","acc_score_inverted = accuracy_score(y_labels, 1 - y_pred)\n","if acc_score_inverted > acc_score:\n","    acc_score = acc_score_inverted\n","    y_pred = 1 - y_pred\n","\n","prec_score = precision_score(y_labels, y_pred)\n","rec_score = recall_score(y_labels, y_pred)\n","f1 = f1_score(y_labels, y_pred)\n","log_loss_value = log_loss(y_labels, y_pred_proba)\n","\n","print(\"Accuracy Score:\", acc_score)\n","print(\"Precision Score:\", prec_score)\n","print(\"Recall Score:\", rec_score)\n","print(\"F1 Score:\", f1)\n","print(\"Log Loss:\", log_loss_value)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"PoEzLL3uflwo","outputId":"edd3c87c-66f6-4177-ba34-b562b536ae92","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766998262247,"user_tz":-330,"elapsed":5104626,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================ LAMBDA = 0.005 ================\n","\n","\n","--- Run 1/10 ---\n","Epoch 0 | Total: -0.1922 | Unsup: -0.2323 | Cont: 8.0109\n","Epoch 500 | Total: -0.8671 | Unsup: -0.9054 | Cont: 7.6570\n","Epoch 1000 | Total: -0.8708 | Unsup: -0.9089 | Cont: 7.6059\n","Epoch 1500 | Total: -0.8711 | Unsup: -0.9091 | Cont: 7.5954\n","Epoch 2000 | Total: -0.8719 | Unsup: -0.9099 | Cont: 7.5967\n","Epoch 2500 | Total: -0.8714 | Unsup: -0.9093 | Cont: 7.5926\n","Epoch 3000 | Total: -0.8718 | Unsup: -0.9097 | Cont: 7.5919\n","Epoch 3500 | Total: -0.8714 | Unsup: -0.9093 | Cont: 7.5930\n","Epoch 4000 | Total: -0.8711 | Unsup: -0.9091 | Cont: 7.5918\n","Epoch 4500 | Total: -0.8707 | Unsup: -0.9087 | Cont: 7.6017\n","Run 1 Accuracy: 0.9040, F1: 0.9092\n","\n","--- Run 2/10 ---\n","Epoch 0 | Total: -0.1930 | Unsup: -0.2327 | Cont: 7.9541\n","Epoch 500 | Total: -0.8676 | Unsup: -0.9057 | Cont: 7.6193\n","Epoch 1000 | Total: -0.8705 | Unsup: -0.9083 | Cont: 7.5637\n","Epoch 1500 | Total: -0.8712 | Unsup: -0.9090 | Cont: 7.5589\n","Epoch 2000 | Total: -0.8706 | Unsup: -0.9083 | Cont: 7.5452\n","Epoch 2500 | Total: -0.8719 | Unsup: -0.9096 | Cont: 7.5529\n","Epoch 3000 | Total: -0.8716 | Unsup: -0.9094 | Cont: 7.5519\n","Epoch 3500 | Total: -0.8706 | Unsup: -0.9084 | Cont: 7.5547\n","Epoch 4000 | Total: -0.8706 | Unsup: -0.9084 | Cont: 7.5518\n","Epoch 4500 | Total: -0.8715 | Unsup: -0.9092 | Cont: 7.5465\n","Run 2 Accuracy: 0.9057, F1: 0.9108\n","\n","--- Run 3/10 ---\n","Epoch 0 | Total: -0.1876 | Unsup: -0.2274 | Cont: 7.9703\n","Epoch 500 | Total: -0.8674 | Unsup: -0.9057 | Cont: 7.6680\n","Epoch 1000 | Total: -0.8701 | Unsup: -0.9082 | Cont: 7.6177\n","Epoch 1500 | Total: -0.8716 | Unsup: -0.9097 | Cont: 7.6069\n","Epoch 2000 | Total: -0.8718 | Unsup: -0.9098 | Cont: 7.6089\n","Epoch 2500 | Total: -0.8710 | Unsup: -0.9090 | Cont: 7.6036\n","Epoch 3000 | Total: -0.8708 | Unsup: -0.9089 | Cont: 7.6037\n","Epoch 3500 | Total: -0.8713 | Unsup: -0.9094 | Cont: 7.6075\n","Epoch 4000 | Total: -0.8704 | Unsup: -0.9084 | Cont: 7.6066\n","Epoch 4500 | Total: -0.8713 | Unsup: -0.9094 | Cont: 7.6111\n","Run 3 Accuracy: 0.9051, F1: 0.9103\n","\n","--- Run 4/10 ---\n","Epoch 0 | Total: -0.1938 | Unsup: -0.2337 | Cont: 7.9767\n","Epoch 500 | Total: -0.8674 | Unsup: -0.9055 | Cont: 7.6248\n","Epoch 1000 | Total: -0.8703 | Unsup: -0.9081 | Cont: 7.5656\n","Epoch 1500 | Total: -0.8714 | Unsup: -0.9092 | Cont: 7.5563\n","Epoch 2000 | Total: -0.8712 | Unsup: -0.9090 | Cont: 7.5568\n","Epoch 2500 | Total: -0.8712 | Unsup: -0.9090 | Cont: 7.5571\n","Epoch 3000 | Total: -0.8719 | Unsup: -0.9097 | Cont: 7.5532\n","Epoch 3500 | Total: -0.8705 | Unsup: -0.9083 | Cont: 7.5557\n","Epoch 4000 | Total: -0.8710 | Unsup: -0.9087 | Cont: 7.5508\n","Epoch 4500 | Total: -0.8714 | Unsup: -0.9092 | Cont: 7.5604\n","Run 4 Accuracy: 0.9048, F1: 0.9100\n","\n","--- Run 5/10 ---\n","Epoch 0 | Total: -0.2007 | Unsup: -0.2403 | Cont: 7.9173\n","Epoch 500 | Total: -0.8686 | Unsup: -0.9067 | Cont: 7.6049\n","Epoch 1000 | Total: -0.8705 | Unsup: -0.9082 | Cont: 7.5460\n","Epoch 1500 | Total: -0.8708 | Unsup: -0.9085 | Cont: 7.5366\n","Epoch 2000 | Total: -0.8707 | Unsup: -0.9084 | Cont: 7.5381\n","Epoch 2500 | Total: -0.8722 | Unsup: -0.9098 | Cont: 7.5280\n","Epoch 3000 | Total: -0.8710 | Unsup: -0.9086 | Cont: 7.5312\n","Epoch 3500 | Total: -0.8705 | Unsup: -0.9082 | Cont: 7.5301\n","Epoch 4000 | Total: -0.8713 | Unsup: -0.9089 | Cont: 7.5303\n","Epoch 4500 | Total: -0.8714 | Unsup: -0.9090 | Cont: 7.5320\n","Run 5 Accuracy: 0.9034, F1: 0.9086\n","\n","--- Run 6/10 ---\n","Epoch 0 | Total: -0.1957 | Unsup: -0.2355 | Cont: 7.9705\n","Epoch 500 | Total: -0.8679 | Unsup: -0.9062 | Cont: 7.6662\n","Epoch 1000 | Total: -0.8704 | Unsup: -0.9085 | Cont: 7.6098\n","Epoch 1500 | Total: -0.8699 | Unsup: -0.9080 | Cont: 7.6100\n","Epoch 2000 | Total: -0.8712 | Unsup: -0.9093 | Cont: 7.6024\n","Epoch 2500 | Total: -0.8713 | Unsup: -0.9093 | Cont: 7.5986\n","Epoch 3000 | Total: -0.8716 | Unsup: -0.9096 | Cont: 7.5967\n","Epoch 3500 | Total: -0.8703 | Unsup: -0.9083 | Cont: 7.5991\n","Epoch 4000 | Total: -0.8702 | Unsup: -0.9082 | Cont: 7.5992\n","Epoch 4500 | Total: -0.8716 | Unsup: -0.9096 | Cont: 7.6044\n","Run 6 Accuracy: 0.9051, F1: 0.9101\n","\n","--- Run 7/10 ---\n","Epoch 0 | Total: -0.1920 | Unsup: -0.2318 | Cont: 7.9523\n","Epoch 500 | Total: -0.8685 | Unsup: -0.9067 | Cont: 7.6310\n","Epoch 1000 | Total: -0.8704 | Unsup: -0.9083 | Cont: 7.5852\n","Epoch 1500 | Total: -0.8706 | Unsup: -0.9084 | Cont: 7.5718\n","Epoch 2000 | Total: -0.8711 | Unsup: -0.9090 | Cont: 7.5719\n","Epoch 2500 | Total: -0.8716 | Unsup: -0.9094 | Cont: 7.5647\n","Epoch 3000 | Total: -0.8702 | Unsup: -0.9080 | Cont: 7.5629\n","Epoch 3500 | Total: -0.8711 | Unsup: -0.9089 | Cont: 7.5676\n","Epoch 4000 | Total: -0.8704 | Unsup: -0.9082 | Cont: 7.5630\n","Epoch 4500 | Total: -0.8714 | Unsup: -0.9092 | Cont: 7.5670\n","Run 7 Accuracy: 0.9054, F1: 0.9104\n","\n","--- Run 8/10 ---\n","Epoch 0 | Total: -0.1932 | Unsup: -0.2329 | Cont: 7.9458\n","Epoch 500 | Total: -0.8679 | Unsup: -0.9059 | Cont: 7.5912\n","Epoch 1000 | Total: -0.8704 | Unsup: -0.9081 | Cont: 7.5321\n","Epoch 1500 | Total: -0.8715 | Unsup: -0.9092 | Cont: 7.5297\n","Epoch 2000 | Total: -0.8713 | Unsup: -0.9090 | Cont: 7.5243\n","Epoch 2500 | Total: -0.8715 | Unsup: -0.9091 | Cont: 7.5168\n","Epoch 3000 | Total: -0.8724 | Unsup: -0.9100 | Cont: 7.5216\n","Epoch 3500 | Total: -0.8715 | Unsup: -0.9091 | Cont: 7.5228\n","Epoch 4000 | Total: -0.8711 | Unsup: -0.9087 | Cont: 7.5205\n","Epoch 4500 | Total: -0.8705 | Unsup: -0.9082 | Cont: 7.5269\n","Run 8 Accuracy: 0.9034, F1: 0.9084\n","\n","--- Run 9/10 ---\n","Epoch 0 | Total: -0.1914 | Unsup: -0.2312 | Cont: 7.9437\n","Epoch 500 | Total: -0.8671 | Unsup: -0.9052 | Cont: 7.6103\n","Epoch 1000 | Total: -0.8718 | Unsup: -0.9096 | Cont: 7.5559\n","Epoch 1500 | Total: -0.8705 | Unsup: -0.9082 | Cont: 7.5525\n","Epoch 2000 | Total: -0.8713 | Unsup: -0.9090 | Cont: 7.5511\n","Epoch 2500 | Total: -0.8719 | Unsup: -0.9096 | Cont: 7.5431\n","Epoch 3000 | Total: -0.8716 | Unsup: -0.9094 | Cont: 7.5458\n","Epoch 3500 | Total: -0.8711 | Unsup: -0.9088 | Cont: 7.5469\n","Epoch 4000 | Total: -0.8716 | Unsup: -0.9093 | Cont: 7.5428\n","Epoch 4500 | Total: -0.8723 | Unsup: -0.9100 | Cont: 7.5442\n","Run 9 Accuracy: 0.9054, F1: 0.9104\n","\n","--- Run 10/10 ---\n","Epoch 0 | Total: -0.1892 | Unsup: -0.2289 | Cont: 7.9434\n","Epoch 500 | Total: -0.8678 | Unsup: -0.9059 | Cont: 7.6301\n","Epoch 1000 | Total: -0.8706 | Unsup: -0.9085 | Cont: 7.5846\n","Epoch 1500 | Total: -0.8708 | Unsup: -0.9087 | Cont: 7.5710\n","Epoch 2000 | Total: -0.8713 | Unsup: -0.9091 | Cont: 7.5670\n","Epoch 2500 | Total: -0.8710 | Unsup: -0.9088 | Cont: 7.5638\n","Epoch 3000 | Total: -0.8712 | Unsup: -0.9090 | Cont: 7.5675\n","Epoch 3500 | Total: -0.8706 | Unsup: -0.9084 | Cont: 7.5649\n","Epoch 4000 | Total: -0.8716 | Unsup: -0.9094 | Cont: 7.5656\n","Epoch 4500 | Total: -0.8711 | Unsup: -0.9089 | Cont: 7.5681\n","Run 10 Accuracy: 0.9043, F1: 0.9094\n","\n","--- RESULTS FOR LAMBDA = 0.005 ---\n","Accuracy: 0.9047 ± 0.0008\n","Precision: 0.9645 ± 0.0010\n","Recall: 0.8608 ± 0.0015\n","F1 Score: 0.9097 ± 0.0008\n","Log Loss: 6.7843 ± 4.0367\n","\n","================ FINAL SUMMARY FOR ALL LAMBDAS ================\n","\n","  Lambda |           Accuracy |          Precision |             Recall |           F1 Score |           Log Loss\n","------------------------------------------------------------------------------------------------------------\n","   0.005 | 0.9047 ± 0.0008 | 0.9645 ± 0.0010 | 0.8608 ± 0.0015 | 0.9097 ± 0.0008 | 6.7843 ± 4.0367\n"]}],"source":["num_runs = 10\n","num_epochs = 5000\n","lr = 1e-4\n","weight_decay = 1e-4\n","lambda_list = [0.005]\n","base_seed = 42\n","\n","all_results = []\n","\n","for lam in lambda_list:\n","    print(f\"\\n================ LAMBDA = {lam} ================\\n\")\n","\n","    acc_scores, prec_scores, rec_scores, f1_scores, log_losses = [], [], [], [], []\n","\n","    for run in range(num_runs):\n","        print(f\"\\n--- Run {run + 1}/{num_runs} ---\")\n","        torch.manual_seed(base_seed + run)\n","        np.random.seed(base_seed + run)\n","        random.seed(base_seed + run)\n","\n","        # --- Model Setup ---\n","        model = ARMA(feats_dim, 256, K, device, activ, cut).to(device)\n","        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","        scheduler = StepLR(optimizer, step_size=200, gamma=0.5)\n","\n","        for epoch in range(num_epochs):\n","            # 1) Two random edge augmentations\n","            W_aug1_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch)\n","            W_aug2_edge_index = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=epoch + 999)\n","\n","            # 2) Feature augmentations\n","            rng = np.random.default_rng(epoch)\n","            mask = rng.random(features_np.shape) >= 0.2\n","            features_aug1 = (features_np * mask.astype(np.float32))\n","            features_aug2 = features_np.copy()\n","            num_nodes_local, feat_dim = features_aug2.shape\n","            drop_feat_num = int(num_nodes_local * feat_dim * 0.2)\n","            flat_idx = rng.choice(num_nodes_local * feat_dim, size=drop_feat_num, replace=False)\n","            rows = (flat_idx // feat_dim)\n","            cols = (flat_idx % feat_dim)\n","            features_aug2[rows, cols] = 0.0\n","            features_aug2_feat = features_aug2.astype(np.float32)\n","\n","            # 3) Build Data views\n","            node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, W_aug1_edge_index, device)\n","            data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","            node_feats2, edge_index2 = load_data_from_edge_index(features_aug2_feat, W_aug2_edge_index, device)\n","            data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","            # --- Training step ---\n","            model.train()\n","            optimizer.zero_grad()\n","\n","            S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","            unsup_loss = model.loss(A1, logits1)\n","            cont_loss = ((l1 + l2) / 2).mean()\n","            total_loss = unsup_loss + lam * cont_loss\n","\n","            total_loss.backward()\n","            optimizer.step()\n","            scheduler.step()\n","            model.update_ma()\n","\n","            if epoch % 500 == 0:\n","                print(f\"Epoch {epoch} | Total: {total_loss.item():.4f} | Unsup: {unsup_loss.item():.4f} | Cont: {cont_loss.item():.4f}\")\n","\n","        # --- Evaluation ---\n","        model.eval()\n","        with torch.no_grad():\n","            S1, _, logits1, _, _, _ = model(data0, data0)\n","            y_pred_proba = nnFn.softmax(logits1, dim=1).cpu().numpy()\n","            y_pred = np.argmax(y_pred_proba, axis=1)\n","\n","        acc = accuracy_score(y_labels, y_pred)\n","        acc_inv = accuracy_score(y_labels, 1 - y_pred)\n","        if acc_inv > acc:\n","            acc = acc_inv\n","            y_pred = 1 - y_pred\n","\n","        prec = precision_score(y_labels, y_pred)\n","        rec = recall_score(y_labels, y_pred)\n","        f1 = f1_score(y_labels, y_pred)\n","        ll = log_loss(y_labels, y_pred_proba)\n","\n","        acc_scores.append(acc)\n","        prec_scores.append(prec)\n","        rec_scores.append(rec)\n","        f1_scores.append(f1)\n","        log_losses.append(ll)\n","\n","        print(f\"Run {run + 1} Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n","\n","    # --- Aggregate Results ---\n","    lambda_results = {\n","        \"lambda\": lam,\n","        \"accuracy\": (np.mean(acc_scores), np.std(acc_scores)),\n","        \"precision\": (np.mean(prec_scores), np.std(prec_scores)),\n","        \"recall\": (np.mean(rec_scores), np.std(rec_scores)),\n","        \"f1\": (np.mean(f1_scores), np.std(f1_scores)),\n","        \"log_loss\": (np.mean(log_losses), np.std(log_losses))\n","    }\n","    all_results.append(lambda_results)\n","\n","    print(f\"\\n--- RESULTS FOR LAMBDA = {lam} ---\")\n","    print(f\"Accuracy: {lambda_results['accuracy'][0]:.4f} ± {lambda_results['accuracy'][1]:.4f}\")\n","    print(f\"Precision: {lambda_results['precision'][0]:.4f} ± {lambda_results['precision'][1]:.4f}\")\n","    print(f\"Recall: {lambda_results['recall'][0]:.4f} ± {lambda_results['recall'][1]:.4f}\")\n","    print(f\"F1 Score: {lambda_results['f1'][0]:.4f} ± {lambda_results['f1'][1]:.4f}\")\n","    print(f\"Log Loss: {lambda_results['log_loss'][0]:.4f} ± {lambda_results['log_loss'][1]:.4f}\")\n","\n","# ==========================================================\n","# === Final Summary ===\n","# ==========================================================\n","print(\"\\n================ FINAL SUMMARY FOR ALL LAMBDAS ================\\n\")\n","print(f\"{'Lambda':>8} | {'Accuracy':>18} | {'Precision':>18} | {'Recall':>18} | {'F1 Score':>18} | {'Log Loss':>18}\")\n","print(\"-\" * 108)\n","for res in all_results:\n","    print(f\"{res['lambda']:>8} | \"\n","          f\"{res['accuracy'][0]:.4f} ± {res['accuracy'][1]:.4f} | \"\n","          f\"{res['precision'][0]:.4f} ± {res['precision'][1]:.4f} | \"\n","          f\"{res['recall'][0]:.4f} ± {res['recall'][1]:.4f} | \"\n","          f\"{res['f1'][0]:.4f} ± {res['f1'][1]:.4f} | \"\n","          f\"{res['log_loss'][0]:.4f} ± {res['log_loss'][1]:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wRt0Yzzfflwp"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"Python (tmp_pyg118)","language":"python","name":"tmp_pyg118"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"}},"nbformat":4,"nbformat_minor":0}
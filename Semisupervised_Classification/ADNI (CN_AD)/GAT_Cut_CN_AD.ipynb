{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1BHr1JkPk832kbYKQYDohItySgMEM_b-k","timestamp":1761983080532}],"authorship_tag":"ABX9TyNviVj6ykFNw8Mg4SE3Cl7a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"id":"ZhoWIduU0285","executionInfo":{"status":"ok","timestamp":1767500933834,"user_tz":-330,"elapsed":5,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","import torch.optim as optim\n","import numpy as np\n","import random\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GATConv\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score,\n","    f1_score, roc_auc_score, log_loss\n",")"]},{"cell_type":"code","source":["fa_feature_path = \"/home/snu/Downloads/Histogram_CN_FA_20bin_updated.npy\"\n","Histogram_feature_CN_FA_array = np.load(fa_feature_path, allow_pickle=True)\n","\n","fa_feature_path = \"/home/snu/Downloads/Histogram_AD_FA_20bin_updated.npy\" # Assuming this is the AD data based on the request.\n","Histogram_feature_AD_FA_array = np.load(fa_feature_path, allow_pickle=True)\n","\n","X = np.vstack([Histogram_feature_CN_FA_array, Histogram_feature_AD_FA_array])\n","y = np.hstack([\n","    np.zeros(Histogram_feature_CN_FA_array.shape[0], dtype=np.int64),\n","    np.ones(Histogram_feature_AD_FA_array.shape[0], dtype=np.int64)\n","])\n","\n","num_nodes, num_feats = X.shape\n","print(f\"Features: {X.shape}, Labels: {y.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgv5wIW403rR","executionInfo":{"status":"ok","timestamp":1767500933839,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"6835cdb2-7e1b-420e-e28d-1288995d85f6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Features: (223, 180), Labels: (223,)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","from torch_geometric.nn import GATConv\n","\n","\n","class GAT_SemiSupervised(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, device, heads=2, activ=\"SELU\", dropout=0.25):\n","        super(GAT_SemiSupervised, self).__init__()\n","        self.device = device\n","\n","        # GAT layer\n","        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True, dropout=dropout)\n","        self.bn1 = nn.BatchNorm1d(hidden_dim * heads)  # heads multiply feature dimension if concat=True\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hidden_dim * heads, output_dim)\n","        self.num_clusters = output_dim\n","\n","        # Activation mapping\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu,\n","            \"ELU\": nnFn.elu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","\n","        # GAT layer\n","        x = self.conv1(x, edge_index)\n","        x = self.bn1(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","\n","        logits = self.fc(x)\n","        return logits\n","\n","    def cut_loss(self, A, S):\n","        S = nnFn.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / den)\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n","\n","        return mincut_loss + ortho_loss"],"metadata":{"id":"rfbVT3Yp05dB","executionInfo":{"status":"ok","timestamp":1767500933885,"user_tz":-330,"elapsed":45,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def create_adj(F, alpha=1):\n","    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","    W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","    W = W / W.max()\n","    return W\n","\n","def load_data(adj, node_feats):\n","    node_feats = torch.from_numpy(node_feats).float()\n","    edge_index = torch.from_numpy(np.array(np.nonzero((adj > 0))))\n","    return Data(x=node_feats, edge_index=edge_index)"],"metadata":{"id":"8AUYk2fh0_iR","executionInfo":{"status":"ok","timestamp":1767500933888,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","alpha = 0.8\n","feats_dim = num_feats\n","hidden_dim = 512\n","num_classes = 2\n","num_epochs = 2000\n","lr = 0.0001\n","weight_decay = 1e-4\n","batch_print_freq = 100\n","lambda_mod = 0.1 #0.01  # weight for modularity loss\n","# lambda_sup = 5"],"metadata":{"id":"5xD2P7ic1B65","executionInfo":{"status":"ok","timestamp":1767500933943,"user_tz":-330,"elapsed":54,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["W = create_adj(X, alpha)\n","data = load_data(W, X).to(device)\n","A_tensor = torch.from_numpy(W).float().to(device)\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-mfsholh1Erx","executionInfo":{"status":"ok","timestamp":1767500934002,"user_tz":-330,"elapsed":55,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"e32cc938-0f3f-4245-b318-c1bf2376b229"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Data(x=[223, 180], edge_index=[2, 41689])\n"]}]},{"cell_type":"code","source":["sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=42)\n","\n","accuracies, precisions, recalls, f1_scores, aucs, ce_losses = [], [], [], [], [], []\n","\n","for fold, (train_val_idx, test_idx_global) in enumerate(sss.split(X, y), start=1):\n","    print(f\"\\n=== Fold {fold} ===\")\n","\n","\n","    cn_idx = np.where(y == 0)[0]\n","    ad_idx = np.where(y == 1)[0]\n","\n","    sss_class = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=fold)\n","    cn_train_idx, _ = next(sss_class.split(X[cn_idx], y[cn_idx]))\n","    ad_train_idx, _ = next(sss_class.split(X[ad_idx], y[ad_idx]))\n","\n","    cn_train = cn_idx[cn_train_idx]\n","    ad_train = ad_idx[ad_train_idx]\n","    train_idx_final = np.concatenate([cn_train, ad_train])\n","    np.random.shuffle(train_idx_final)\n","\n","    print(f\"Train CN: {len(cn_train)}, Train AD: {len(ad_train)}\")\n","\n","    train_idx_t = torch.from_numpy(train_idx_final).long().to(device)\n","    y_train_tensor = torch.from_numpy(y[train_idx_final]).long().to(device)\n","\n","\n","    model = GAT_SemiSupervised(feats_dim, hidden_dim, num_classes, device, activ=\"SELU\").to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","\n","    for epoch in range(1, num_epochs + 1):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        logits = model(data)\n","        loss_sup = ce_loss(logits[train_idx_t], y_train_tensor)\n","        loss_unsup = model.cut_loss(A_tensor, logits)\n","        total_loss = loss_sup + lambda_mod * loss_unsup\n","\n","        total_loss.backward()\n","        optimizer.step()\n","\n","        if epoch % batch_print_freq == 0 or epoch == 1:\n","            model.eval()\n","            with torch.no_grad():\n","                preds_train = logits[train_idx_t].argmax(dim=1)\n","                acc_train = accuracy_score(y_train_tensor.cpu(), preds_train.cpu())\n","            print(f\"Fold {fold} Epoch {epoch}: \"\n","                  f\"TotalLoss={total_loss.item():.6f} | Sup={loss_sup.item():.6f} | \"\n","                  f\"Unsup={loss_unsup.item():.6f} | TrainAcc={acc_train:.4f}\")\n","\n","\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data)\n","        preds = out.argmax(dim=1).cpu().numpy()\n","        probs = torch.softmax(out, dim=1)[:, 1].cpu().numpy()  # Probability for class 1\n","\n","    y_test = y[test_idx_global]\n","    y_pred_test = preds[test_idx_global]\n","    y_prob_test = probs[test_idx_global]\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","    auc = roc_auc_score(y_test, y_prob_test)\n","    ce = log_loss(y_test, y_prob_test)\n","\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    aucs.append(auc)\n","    ce_losses.append(ce)\n","\n","    print(f\"Fold {fold} → \"\n","          f\"Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | \"\n","          f\"F1={f1:.4f} | AUC={auc:.4f} | CE Loss={ce:.4f}\")\n","\n","\n","print(\"\\n=== Average Results Across 20 Folds ===\")\n","print(f\"Accuracy:  {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n","print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n","print(f\"Recall:    {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n","print(f\"F1-score:  {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n","print(f\"AUC:       {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n","print(f\"CE Loss:   {np.mean(ce_losses):.4f} ± {np.std(ce_losses):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBy-hReA1Hqa","outputId":"a7fe84c1-ce36-4c42-f1d2-5cf5c1da75e7","executionInfo":{"status":"ok","timestamp":1767501770806,"user_tz":-330,"elapsed":836805,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Fold 1 ===\n","Train CN: 13, Train AD: 9\n","Fold 1 Epoch 1: TotalLoss=0.603871 | Sup=0.631085 | Unsup=-0.272139 | TrainAcc=0.5909\n","Fold 1 Epoch 100: TotalLoss=0.397064 | Sup=0.430847 | Unsup=-0.337832 | TrainAcc=0.8182\n","Fold 1 Epoch 200: TotalLoss=0.180369 | Sup=0.215563 | Unsup=-0.351935 | TrainAcc=0.9545\n","Fold 1 Epoch 300: TotalLoss=0.051737 | Sup=0.087697 | Unsup=-0.359595 | TrainAcc=0.9545\n","Fold 1 Epoch 400: TotalLoss=-0.014620 | Sup=0.023333 | Unsup=-0.379529 | TrainAcc=1.0000\n","Fold 1 Epoch 500: TotalLoss=-0.035800 | Sup=0.005555 | Unsup=-0.413545 | TrainAcc=1.0000\n","Fold 1 Epoch 600: TotalLoss=-0.030989 | Sup=0.009825 | Unsup=-0.408138 | TrainAcc=1.0000\n","Fold 1 Epoch 700: TotalLoss=-0.038181 | Sup=0.002192 | Unsup=-0.403726 | TrainAcc=1.0000\n","Fold 1 Epoch 800: TotalLoss=-0.041689 | Sup=0.004661 | Unsup=-0.463496 | TrainAcc=1.0000\n","Fold 1 Epoch 900: TotalLoss=-0.044588 | Sup=0.003183 | Unsup=-0.477716 | TrainAcc=1.0000\n","Fold 1 Epoch 1000: TotalLoss=-0.049319 | Sup=0.000740 | Unsup=-0.500595 | TrainAcc=1.0000\n","Fold 1 Epoch 1100: TotalLoss=-0.042958 | Sup=0.006425 | Unsup=-0.493823 | TrainAcc=1.0000\n","Fold 1 Epoch 1200: TotalLoss=-0.050721 | Sup=0.000295 | Unsup=-0.510166 | TrainAcc=1.0000\n","Fold 1 Epoch 1300: TotalLoss=-0.049348 | Sup=0.001421 | Unsup=-0.507683 | TrainAcc=1.0000\n","Fold 1 Epoch 1400: TotalLoss=-0.050230 | Sup=0.001595 | Unsup=-0.518248 | TrainAcc=1.0000\n","Fold 1 Epoch 1500: TotalLoss=-0.050649 | Sup=0.000195 | Unsup=-0.508438 | TrainAcc=1.0000\n","Fold 1 Epoch 1600: TotalLoss=-0.050841 | Sup=0.001695 | Unsup=-0.525362 | TrainAcc=1.0000\n","Fold 1 Epoch 1700: TotalLoss=-0.050642 | Sup=0.001557 | Unsup=-0.521986 | TrainAcc=1.0000\n","Fold 1 Epoch 1800: TotalLoss=-0.049850 | Sup=0.002044 | Unsup=-0.518945 | TrainAcc=1.0000\n","Fold 1 Epoch 1900: TotalLoss=-0.052121 | Sup=0.000253 | Unsup=-0.523744 | TrainAcc=1.0000\n","Fold 1 Epoch 2000: TotalLoss=-0.048255 | Sup=0.002552 | Unsup=-0.508070 | TrainAcc=1.0000\n","Fold 1 → Acc=0.8060 | Prec=0.7234 | Rec=0.8395 | F1=0.7771 | AUC=0.8526 | CE Loss=1.5114\n","\n","=== Fold 2 ===\n","Train CN: 13, Train AD: 9\n","Fold 2 Epoch 1: TotalLoss=0.688731 | Sup=0.713200 | Unsup=-0.244691 | TrainAcc=0.5000\n","Fold 2 Epoch 100: TotalLoss=0.535586 | Sup=0.571206 | Unsup=-0.356193 | TrainAcc=0.6818\n","Fold 2 Epoch 200: TotalLoss=0.415531 | Sup=0.452387 | Unsup=-0.368554 | TrainAcc=0.8182\n","Fold 2 Epoch 300: TotalLoss=0.248178 | Sup=0.285394 | Unsup=-0.372159 | TrainAcc=0.9091\n","Fold 2 Epoch 400: TotalLoss=0.059238 | Sup=0.101622 | Unsup=-0.423840 | TrainAcc=1.0000\n","Fold 2 Epoch 500: TotalLoss=0.028165 | Sup=0.070361 | Unsup=-0.421961 | TrainAcc=1.0000\n","Fold 2 Epoch 600: TotalLoss=-0.034464 | Sup=0.010087 | Unsup=-0.445512 | TrainAcc=1.0000\n","Fold 2 Epoch 700: TotalLoss=-0.045214 | Sup=0.002588 | Unsup=-0.478025 | TrainAcc=1.0000\n","Fold 2 Epoch 800: TotalLoss=-0.046784 | Sup=0.001981 | Unsup=-0.487649 | TrainAcc=1.0000\n","Fold 2 Epoch 900: TotalLoss=-0.044158 | Sup=0.003935 | Unsup=-0.480930 | TrainAcc=1.0000\n","Fold 2 Epoch 1000: TotalLoss=-0.039358 | Sup=0.010748 | Unsup=-0.501062 | TrainAcc=1.0000\n","Fold 2 Epoch 1100: TotalLoss=-0.047306 | Sup=0.000969 | Unsup=-0.482744 | TrainAcc=1.0000\n","Fold 2 Epoch 1200: TotalLoss=-0.042568 | Sup=0.007471 | Unsup=-0.500394 | TrainAcc=1.0000\n","Fold 2 Epoch 1300: TotalLoss=-0.049766 | Sup=0.000236 | Unsup=-0.500021 | TrainAcc=1.0000\n","Fold 2 Epoch 1400: TotalLoss=-0.037034 | Sup=0.012587 | Unsup=-0.496212 | TrainAcc=1.0000\n","Fold 2 Epoch 1500: TotalLoss=-0.050216 | Sup=0.000227 | Unsup=-0.504432 | TrainAcc=1.0000\n","Fold 2 Epoch 1600: TotalLoss=-0.048299 | Sup=0.001492 | Unsup=-0.497912 | TrainAcc=1.0000\n","Fold 2 Epoch 1700: TotalLoss=-0.049181 | Sup=0.000825 | Unsup=-0.500069 | TrainAcc=1.0000\n","Fold 2 Epoch 1800: TotalLoss=-0.050318 | Sup=0.000468 | Unsup=-0.507857 | TrainAcc=1.0000\n","Fold 2 Epoch 1900: TotalLoss=-0.050619 | Sup=0.000093 | Unsup=-0.507127 | TrainAcc=1.0000\n","Fold 2 Epoch 2000: TotalLoss=-0.051289 | Sup=0.000102 | Unsup=-0.513914 | TrainAcc=1.0000\n","Fold 2 → Acc=0.7711 | Prec=0.6699 | Rec=0.8519 | F1=0.7500 | AUC=0.8499 | CE Loss=1.6862\n","\n","=== Fold 3 ===\n","Train CN: 13, Train AD: 9\n","Fold 3 Epoch 1: TotalLoss=0.809689 | Sup=0.836938 | Unsup=-0.272496 | TrainAcc=0.3636\n","Fold 3 Epoch 100: TotalLoss=0.487561 | Sup=0.520932 | Unsup=-0.333706 | TrainAcc=0.6818\n","Fold 3 Epoch 200: TotalLoss=0.315793 | Sup=0.350073 | Unsup=-0.342791 | TrainAcc=0.7727\n","Fold 3 Epoch 300: TotalLoss=0.131211 | Sup=0.164847 | Unsup=-0.336363 | TrainAcc=0.9545\n","Fold 3 Epoch 400: TotalLoss=0.006601 | Sup=0.038222 | Unsup=-0.316208 | TrainAcc=1.0000\n","Fold 3 Epoch 500: TotalLoss=-0.025784 | Sup=0.007051 | Unsup=-0.328352 | TrainAcc=1.0000\n","Fold 3 Epoch 600: TotalLoss=-0.029174 | Sup=0.007615 | Unsup=-0.367898 | TrainAcc=1.0000\n","Fold 3 Epoch 700: TotalLoss=-0.031880 | Sup=0.003174 | Unsup=-0.350537 | TrainAcc=1.0000\n","Fold 3 Epoch 800: TotalLoss=-0.030055 | Sup=0.006546 | Unsup=-0.366016 | TrainAcc=1.0000\n","Fold 3 Epoch 900: TotalLoss=-0.038023 | Sup=0.003104 | Unsup=-0.411278 | TrainAcc=1.0000\n","Fold 3 Epoch 1000: TotalLoss=-0.030400 | Sup=0.012705 | Unsup=-0.431050 | TrainAcc=1.0000\n","Fold 3 Epoch 1100: TotalLoss=-0.035601 | Sup=0.008533 | Unsup=-0.441341 | TrainAcc=1.0000\n","Fold 3 Epoch 1200: TotalLoss=-0.043252 | Sup=0.000782 | Unsup=-0.440348 | TrainAcc=1.0000\n","Fold 3 Epoch 1300: TotalLoss=-0.044256 | Sup=0.000644 | Unsup=-0.448993 | TrainAcc=1.0000\n","Fold 3 Epoch 1400: TotalLoss=-0.049260 | Sup=0.000227 | Unsup=-0.494870 | TrainAcc=1.0000\n","Fold 3 Epoch 1500: TotalLoss=-0.048649 | Sup=0.000295 | Unsup=-0.489437 | TrainAcc=1.0000\n","Fold 3 Epoch 1600: TotalLoss=-0.049415 | Sup=0.000248 | Unsup=-0.496637 | TrainAcc=1.0000\n","Fold 3 Epoch 1700: TotalLoss=-0.049663 | Sup=0.000846 | Unsup=-0.505088 | TrainAcc=1.0000\n","Fold 3 Epoch 1800: TotalLoss=-0.046298 | Sup=0.003112 | Unsup=-0.494095 | TrainAcc=1.0000\n","Fold 3 Epoch 1900: TotalLoss=-0.051434 | Sup=0.000036 | Unsup=-0.514696 | TrainAcc=1.0000\n","Fold 3 Epoch 2000: TotalLoss=-0.051162 | Sup=0.000176 | Unsup=-0.513375 | TrainAcc=1.0000\n","Fold 3 → Acc=0.7065 | Prec=0.6078 | Rec=0.7654 | F1=0.6776 | AUC=0.8086 | CE Loss=2.0761\n","\n","=== Fold 4 ===\n","Train CN: 13, Train AD: 9\n","Fold 4 Epoch 1: TotalLoss=0.746339 | Sup=0.770270 | Unsup=-0.239310 | TrainAcc=0.3182\n","Fold 4 Epoch 100: TotalLoss=0.557014 | Sup=0.592545 | Unsup=-0.355313 | TrainAcc=0.6818\n","Fold 4 Epoch 200: TotalLoss=0.363682 | Sup=0.399279 | Unsup=-0.355972 | TrainAcc=0.8636\n","Fold 4 Epoch 300: TotalLoss=0.074302 | Sup=0.111179 | Unsup=-0.368763 | TrainAcc=1.0000\n","Fold 4 Epoch 400: TotalLoss=-0.001151 | Sup=0.032945 | Unsup=-0.340958 | TrainAcc=1.0000\n","Fold 4 Epoch 500: TotalLoss=-0.012097 | Sup=0.024424 | Unsup=-0.365207 | TrainAcc=1.0000\n","Fold 4 Epoch 600: TotalLoss=-0.009816 | Sup=0.028623 | Unsup=-0.384387 | TrainAcc=1.0000\n","Fold 4 Epoch 700: TotalLoss=-0.040144 | Sup=0.003301 | Unsup=-0.434459 | TrainAcc=1.0000\n","Fold 4 Epoch 800: TotalLoss=-0.038309 | Sup=0.002704 | Unsup=-0.410123 | TrainAcc=1.0000\n","Fold 4 Epoch 900: TotalLoss=-0.039078 | Sup=0.006146 | Unsup=-0.452241 | TrainAcc=1.0000\n","Fold 4 Epoch 1000: TotalLoss=-0.044258 | Sup=0.002178 | Unsup=-0.464355 | TrainAcc=1.0000\n","Fold 4 Epoch 1100: TotalLoss=-0.048626 | Sup=0.000697 | Unsup=-0.493231 | TrainAcc=1.0000\n","Fold 4 Epoch 1200: TotalLoss=-0.047660 | Sup=0.001797 | Unsup=-0.494570 | TrainAcc=1.0000\n","Fold 4 Epoch 1300: TotalLoss=-0.049179 | Sup=0.000876 | Unsup=-0.500549 | TrainAcc=1.0000\n","Fold 4 Epoch 1400: TotalLoss=-0.049309 | Sup=0.000406 | Unsup=-0.497148 | TrainAcc=1.0000\n","Fold 4 Epoch 1500: TotalLoss=-0.049491 | Sup=0.000793 | Unsup=-0.502847 | TrainAcc=1.0000\n","Fold 4 Epoch 1600: TotalLoss=-0.048558 | Sup=0.001077 | Unsup=-0.496351 | TrainAcc=1.0000\n","Fold 4 Epoch 1700: TotalLoss=-0.049603 | Sup=0.000208 | Unsup=-0.498119 | TrainAcc=1.0000\n","Fold 4 Epoch 1800: TotalLoss=-0.050384 | Sup=0.000090 | Unsup=-0.504733 | TrainAcc=1.0000\n","Fold 4 Epoch 1900: TotalLoss=-0.049659 | Sup=0.000463 | Unsup=-0.501219 | TrainAcc=1.0000\n","Fold 4 Epoch 2000: TotalLoss=-0.049398 | Sup=0.000162 | Unsup=-0.495608 | TrainAcc=1.0000\n","Fold 4 → Acc=0.7761 | Prec=0.8103 | Rec=0.5802 | F1=0.6763 | AUC=0.8384 | CE Loss=1.4431\n","\n","=== Fold 5 ===\n","Train CN: 13, Train AD: 9\n","Fold 5 Epoch 1: TotalLoss=0.708895 | Sup=0.732930 | Unsup=-0.240351 | TrainAcc=0.5000\n","Fold 5 Epoch 100: TotalLoss=0.369686 | Sup=0.403157 | Unsup=-0.334709 | TrainAcc=0.8182\n","Fold 5 Epoch 200: TotalLoss=0.256389 | Sup=0.291194 | Unsup=-0.348050 | TrainAcc=0.8636\n","Fold 5 Epoch 300: TotalLoss=0.068886 | Sup=0.105694 | Unsup=-0.368088 | TrainAcc=0.9545\n","Fold 5 Epoch 400: TotalLoss=-0.022150 | Sup=0.015865 | Unsup=-0.380149 | TrainAcc=1.0000\n","Fold 5 Epoch 500: TotalLoss=-0.034607 | Sup=0.008566 | Unsup=-0.431732 | TrainAcc=1.0000\n","Fold 5 Epoch 600: TotalLoss=-0.029993 | Sup=0.015176 | Unsup=-0.451687 | TrainAcc=1.0000\n","Fold 5 Epoch 700: TotalLoss=-0.043367 | Sup=0.002558 | Unsup=-0.459250 | TrainAcc=1.0000\n","Fold 5 Epoch 800: TotalLoss=-0.046509 | Sup=0.000667 | Unsup=-0.471762 | TrainAcc=1.0000\n","Fold 5 Epoch 900: TotalLoss=-0.044141 | Sup=0.003145 | Unsup=-0.472866 | TrainAcc=1.0000\n","Fold 5 Epoch 1000: TotalLoss=-0.037655 | Sup=0.010610 | Unsup=-0.482646 | TrainAcc=1.0000\n","Fold 5 Epoch 1100: TotalLoss=-0.048775 | Sup=0.000186 | Unsup=-0.489609 | TrainAcc=1.0000\n","Fold 5 Epoch 1200: TotalLoss=-0.048113 | Sup=0.000319 | Unsup=-0.484328 | TrainAcc=1.0000\n","Fold 5 Epoch 1300: TotalLoss=-0.048189 | Sup=0.000782 | Unsup=-0.489709 | TrainAcc=1.0000\n","Fold 5 Epoch 1400: TotalLoss=-0.049056 | Sup=0.000740 | Unsup=-0.497966 | TrainAcc=1.0000\n","Fold 5 Epoch 1500: TotalLoss=-0.049301 | Sup=0.000759 | Unsup=-0.500606 | TrainAcc=1.0000\n","Fold 5 Epoch 1600: TotalLoss=-0.049315 | Sup=0.000127 | Unsup=-0.494417 | TrainAcc=1.0000\n","Fold 5 Epoch 1700: TotalLoss=-0.050167 | Sup=0.000291 | Unsup=-0.504577 | TrainAcc=1.0000\n","Fold 5 Epoch 1800: TotalLoss=-0.050750 | Sup=0.000181 | Unsup=-0.509308 | TrainAcc=1.0000\n","Fold 5 Epoch 1900: TotalLoss=-0.050558 | Sup=0.000106 | Unsup=-0.506635 | TrainAcc=1.0000\n","Fold 5 Epoch 2000: TotalLoss=-0.051462 | Sup=0.000007 | Unsup=-0.514686 | TrainAcc=1.0000\n","Fold 5 → Acc=0.8159 | Prec=0.7245 | Rec=0.8765 | F1=0.7933 | AUC=0.9123 | CE Loss=1.0546\n","\n","=== Fold 6 ===\n","Train CN: 13, Train AD: 9\n","Fold 6 Epoch 1: TotalLoss=0.816033 | Sup=0.842203 | Unsup=-0.261698 | TrainAcc=0.4545\n","Fold 6 Epoch 100: TotalLoss=0.380767 | Sup=0.412783 | Unsup=-0.320156 | TrainAcc=0.8182\n","Fold 6 Epoch 200: TotalLoss=0.316117 | Sup=0.347760 | Unsup=-0.316427 | TrainAcc=0.8182\n","Fold 6 Epoch 300: TotalLoss=0.101870 | Sup=0.134536 | Unsup=-0.326666 | TrainAcc=0.9545\n","Fold 6 Epoch 400: TotalLoss=0.045263 | Sup=0.074229 | Unsup=-0.289661 | TrainAcc=1.0000\n","Fold 6 Epoch 500: TotalLoss=-0.024632 | Sup=0.006404 | Unsup=-0.310361 | TrainAcc=1.0000\n","Fold 6 Epoch 600: TotalLoss=-0.009196 | Sup=0.025360 | Unsup=-0.345563 | TrainAcc=1.0000\n","Fold 6 Epoch 700: TotalLoss=-0.031269 | Sup=0.003813 | Unsup=-0.350814 | TrainAcc=1.0000\n","Fold 6 Epoch 800: TotalLoss=-0.033598 | Sup=0.001498 | Unsup=-0.350961 | TrainAcc=1.0000\n","Fold 6 Epoch 900: TotalLoss=-0.018976 | Sup=0.019484 | Unsup=-0.384597 | TrainAcc=1.0000\n","Fold 6 Epoch 1000: TotalLoss=-0.028229 | Sup=0.012336 | Unsup=-0.405650 | TrainAcc=1.0000\n","Fold 6 Epoch 1100: TotalLoss=-0.041537 | Sup=0.001153 | Unsup=-0.426899 | TrainAcc=1.0000\n","Fold 6 Epoch 1200: TotalLoss=-0.042980 | Sup=0.000949 | Unsup=-0.439297 | TrainAcc=1.0000\n","Fold 6 Epoch 1300: TotalLoss=-0.045594 | Sup=0.002896 | Unsup=-0.484897 | TrainAcc=1.0000\n","Fold 6 Epoch 1400: TotalLoss=-0.048360 | Sup=0.000119 | Unsup=-0.484788 | TrainAcc=1.0000\n","Fold 6 Epoch 1500: TotalLoss=-0.047027 | Sup=0.001357 | Unsup=-0.483841 | TrainAcc=1.0000\n","Fold 6 Epoch 1600: TotalLoss=-0.048279 | Sup=0.000575 | Unsup=-0.488538 | TrainAcc=1.0000\n","Fold 6 Epoch 1700: TotalLoss=-0.047679 | Sup=0.001973 | Unsup=-0.496518 | TrainAcc=1.0000\n","Fold 6 Epoch 1800: TotalLoss=-0.048896 | Sup=0.000836 | Unsup=-0.497316 | TrainAcc=1.0000\n","Fold 6 Epoch 1900: TotalLoss=-0.049663 | Sup=0.000164 | Unsup=-0.498270 | TrainAcc=1.0000\n","Fold 6 Epoch 2000: TotalLoss=-0.048013 | Sup=0.000809 | Unsup=-0.488215 | TrainAcc=1.0000\n","Fold 6 → Acc=0.7512 | Prec=0.6598 | Rec=0.7901 | F1=0.7191 | AUC=0.8451 | CE Loss=1.3771\n","\n","=== Fold 7 ===\n","Train CN: 13, Train AD: 9\n","Fold 7 Epoch 1: TotalLoss=0.732714 | Sup=0.758115 | Unsup=-0.254016 | TrainAcc=0.4545\n","Fold 7 Epoch 100: TotalLoss=0.382866 | Sup=0.419650 | Unsup=-0.367834 | TrainAcc=0.7273\n","Fold 7 Epoch 200: TotalLoss=0.232383 | Sup=0.271233 | Unsup=-0.388506 | TrainAcc=0.8636\n","Fold 7 Epoch 300: TotalLoss=0.087628 | Sup=0.131083 | Unsup=-0.434544 | TrainAcc=0.9091\n","Fold 7 Epoch 400: TotalLoss=-0.013231 | Sup=0.031727 | Unsup=-0.449579 | TrainAcc=1.0000\n","Fold 7 Epoch 500: TotalLoss=-0.027443 | Sup=0.019579 | Unsup=-0.470217 | TrainAcc=1.0000\n","Fold 7 Epoch 600: TotalLoss=-0.035545 | Sup=0.012727 | Unsup=-0.482717 | TrainAcc=1.0000\n","Fold 7 Epoch 700: TotalLoss=-0.043497 | Sup=0.006313 | Unsup=-0.498094 | TrainAcc=1.0000\n","Fold 7 Epoch 800: TotalLoss=-0.048324 | Sup=0.001106 | Unsup=-0.494297 | TrainAcc=1.0000\n","Fold 7 Epoch 900: TotalLoss=-0.049572 | Sup=0.001147 | Unsup=-0.507199 | TrainAcc=1.0000\n","Fold 7 Epoch 1000: TotalLoss=-0.051001 | Sup=0.000369 | Unsup=-0.513701 | TrainAcc=1.0000\n","Fold 7 Epoch 1100: TotalLoss=-0.050917 | Sup=0.000413 | Unsup=-0.513303 | TrainAcc=1.0000\n","Fold 7 Epoch 1200: TotalLoss=-0.048858 | Sup=0.001585 | Unsup=-0.504432 | TrainAcc=1.0000\n","Fold 7 Epoch 1300: TotalLoss=-0.049536 | Sup=0.000558 | Unsup=-0.500947 | TrainAcc=1.0000\n","Fold 7 Epoch 1400: TotalLoss=-0.050941 | Sup=0.000717 | Unsup=-0.516583 | TrainAcc=1.0000\n","Fold 7 Epoch 1500: TotalLoss=-0.051310 | Sup=0.000266 | Unsup=-0.515766 | TrainAcc=1.0000\n","Fold 7 Epoch 1600: TotalLoss=-0.049553 | Sup=0.002394 | Unsup=-0.519476 | TrainAcc=1.0000\n","Fold 7 Epoch 1700: TotalLoss=-0.051030 | Sup=0.000115 | Unsup=-0.511445 | TrainAcc=1.0000\n","Fold 7 Epoch 1800: TotalLoss=-0.048963 | Sup=0.001619 | Unsup=-0.505820 | TrainAcc=1.0000\n","Fold 7 Epoch 1900: TotalLoss=-0.052038 | Sup=0.000121 | Unsup=-0.521587 | TrainAcc=1.0000\n","Fold 7 Epoch 2000: TotalLoss=-0.052277 | Sup=0.000228 | Unsup=-0.525057 | TrainAcc=1.0000\n","Fold 7 → Acc=0.7960 | Prec=0.7083 | Rec=0.8395 | F1=0.7684 | AUC=0.8661 | CE Loss=1.3982\n","\n","=== Fold 8 ===\n","Train CN: 13, Train AD: 9\n","Fold 8 Epoch 1: TotalLoss=0.671575 | Sup=0.695552 | Unsup=-0.239767 | TrainAcc=0.4545\n","Fold 8 Epoch 100: TotalLoss=0.411429 | Sup=0.444677 | Unsup=-0.332472 | TrainAcc=0.8182\n","Fold 8 Epoch 200: TotalLoss=0.219089 | Sup=0.254627 | Unsup=-0.355377 | TrainAcc=0.9091\n","Fold 8 Epoch 300: TotalLoss=0.015235 | Sup=0.051989 | Unsup=-0.367543 | TrainAcc=1.0000\n","Fold 8 Epoch 400: TotalLoss=0.031011 | Sup=0.068742 | Unsup=-0.377302 | TrainAcc=1.0000\n","Fold 8 Epoch 500: TotalLoss=-0.034439 | Sup=0.004559 | Unsup=-0.389983 | TrainAcc=1.0000\n","Fold 8 Epoch 600: TotalLoss=-0.027820 | Sup=0.012968 | Unsup=-0.407879 | TrainAcc=1.0000\n","Fold 8 Epoch 700: TotalLoss=-0.037406 | Sup=0.006952 | Unsup=-0.443580 | TrainAcc=1.0000\n","Fold 8 Epoch 800: TotalLoss=-0.040451 | Sup=0.001195 | Unsup=-0.416458 | TrainAcc=1.0000\n","Fold 8 Epoch 900: TotalLoss=-0.044907 | Sup=0.003033 | Unsup=-0.479400 | TrainAcc=1.0000\n","Fold 8 Epoch 1000: TotalLoss=-0.037939 | Sup=0.010897 | Unsup=-0.488352 | TrainAcc=1.0000\n","Fold 8 Epoch 1100: TotalLoss=-0.049599 | Sup=0.001333 | Unsup=-0.509321 | TrainAcc=1.0000\n","Fold 8 Epoch 1200: TotalLoss=-0.050751 | Sup=0.000788 | Unsup=-0.515396 | TrainAcc=1.0000\n","Fold 8 Epoch 1300: TotalLoss=-0.048654 | Sup=0.001116 | Unsup=-0.497700 | TrainAcc=1.0000\n","Fold 8 Epoch 1400: TotalLoss=-0.045080 | Sup=0.005141 | Unsup=-0.502215 | TrainAcc=1.0000\n","Fold 8 Epoch 1500: TotalLoss=-0.051266 | Sup=0.000058 | Unsup=-0.513239 | TrainAcc=1.0000\n","Fold 8 Epoch 1600: TotalLoss=-0.051311 | Sup=0.000763 | Unsup=-0.520741 | TrainAcc=1.0000\n","Fold 8 Epoch 1700: TotalLoss=-0.050117 | Sup=0.000706 | Unsup=-0.508233 | TrainAcc=1.0000\n","Fold 8 Epoch 1800: TotalLoss=-0.051311 | Sup=0.000245 | Unsup=-0.515560 | TrainAcc=1.0000\n","Fold 8 Epoch 1900: TotalLoss=-0.051876 | Sup=0.000033 | Unsup=-0.519093 | TrainAcc=1.0000\n","Fold 8 Epoch 2000: TotalLoss=-0.051713 | Sup=0.000145 | Unsup=-0.518581 | TrainAcc=1.0000\n","Fold 8 → Acc=0.7861 | Prec=0.6827 | Rec=0.8765 | F1=0.7676 | AUC=0.8808 | CE Loss=1.4956\n","\n","=== Fold 9 ===\n","Train CN: 13, Train AD: 9\n","Fold 9 Epoch 1: TotalLoss=0.748147 | Sup=0.773102 | Unsup=-0.249548 | TrainAcc=0.5000\n","Fold 9 Epoch 100: TotalLoss=0.330729 | Sup=0.363422 | Unsup=-0.326926 | TrainAcc=0.9091\n","Fold 9 Epoch 200: TotalLoss=0.091236 | Sup=0.126381 | Unsup=-0.351452 | TrainAcc=1.0000\n","Fold 9 Epoch 300: TotalLoss=0.011646 | Sup=0.046419 | Unsup=-0.347733 | TrainAcc=1.0000\n","Fold 9 Epoch 400: TotalLoss=-0.012772 | Sup=0.025038 | Unsup=-0.378095 | TrainAcc=1.0000\n","Fold 9 Epoch 500: TotalLoss=-0.013448 | Sup=0.024477 | Unsup=-0.379256 | TrainAcc=1.0000\n","Fold 9 Epoch 600: TotalLoss=-0.035407 | Sup=0.006119 | Unsup=-0.415263 | TrainAcc=1.0000\n","Fold 9 Epoch 700: TotalLoss=-0.039982 | Sup=0.002250 | Unsup=-0.422315 | TrainAcc=1.0000\n","Fold 9 Epoch 800: TotalLoss=-0.041222 | Sup=0.006303 | Unsup=-0.475244 | TrainAcc=1.0000\n","Fold 9 Epoch 900: TotalLoss=-0.045026 | Sup=0.001196 | Unsup=-0.462222 | TrainAcc=1.0000\n","Fold 9 Epoch 1000: TotalLoss=-0.040975 | Sup=0.007627 | Unsup=-0.486015 | TrainAcc=1.0000\n","Fold 9 Epoch 1100: TotalLoss=-0.044065 | Sup=0.005601 | Unsup=-0.496658 | TrainAcc=1.0000\n","Fold 9 Epoch 1200: TotalLoss=-0.049299 | Sup=0.000489 | Unsup=-0.497884 | TrainAcc=1.0000\n","Fold 9 Epoch 1300: TotalLoss=-0.048442 | Sup=0.000306 | Unsup=-0.487481 | TrainAcc=1.0000\n","Fold 9 Epoch 1400: TotalLoss=-0.050461 | Sup=0.000224 | Unsup=-0.506850 | TrainAcc=1.0000\n","Fold 9 Epoch 1500: TotalLoss=-0.049706 | Sup=0.000519 | Unsup=-0.502251 | TrainAcc=1.0000\n","Fold 9 Epoch 1600: TotalLoss=-0.048519 | Sup=0.000138 | Unsup=-0.486563 | TrainAcc=1.0000\n","Fold 9 Epoch 1700: TotalLoss=-0.049665 | Sup=0.000306 | Unsup=-0.499709 | TrainAcc=1.0000\n","Fold 9 Epoch 1800: TotalLoss=-0.049211 | Sup=0.000240 | Unsup=-0.494515 | TrainAcc=1.0000\n","Fold 9 Epoch 1900: TotalLoss=-0.049925 | Sup=0.000086 | Unsup=-0.500116 | TrainAcc=1.0000\n","Fold 9 Epoch 2000: TotalLoss=-0.050661 | Sup=0.000018 | Unsup=-0.506784 | TrainAcc=1.0000\n","Fold 9 → Acc=0.8507 | Prec=0.7931 | Rec=0.8519 | F1=0.8214 | AUC=0.8903 | CE Loss=1.0813\n","\n","=== Fold 10 ===\n","Train CN: 13, Train AD: 9\n","Fold 10 Epoch 1: TotalLoss=0.617987 | Sup=0.643744 | Unsup=-0.257571 | TrainAcc=0.5455\n","Fold 10 Epoch 100: TotalLoss=0.413874 | Sup=0.450263 | Unsup=-0.363891 | TrainAcc=0.7273\n","Fold 10 Epoch 200: TotalLoss=0.304860 | Sup=0.343343 | Unsup=-0.384826 | TrainAcc=0.8182\n","Fold 10 Epoch 300: TotalLoss=0.101383 | Sup=0.142196 | Unsup=-0.408124 | TrainAcc=0.9545\n","Fold 10 Epoch 400: TotalLoss=-0.007254 | Sup=0.033386 | Unsup=-0.406398 | TrainAcc=1.0000\n","Fold 10 Epoch 500: TotalLoss=-0.040775 | Sup=0.005551 | Unsup=-0.463263 | TrainAcc=1.0000\n","Fold 10 Epoch 600: TotalLoss=-0.036847 | Sup=0.008810 | Unsup=-0.456577 | TrainAcc=1.0000\n","Fold 10 Epoch 700: TotalLoss=-0.045253 | Sup=0.002415 | Unsup=-0.476672 | TrainAcc=1.0000\n","Fold 10 Epoch 800: TotalLoss=-0.049009 | Sup=0.001108 | Unsup=-0.501173 | TrainAcc=1.0000\n","Fold 10 Epoch 900: TotalLoss=-0.049779 | Sup=0.000633 | Unsup=-0.504123 | TrainAcc=1.0000\n","Fold 10 Epoch 1000: TotalLoss=-0.049669 | Sup=0.001030 | Unsup=-0.506984 | TrainAcc=1.0000\n","Fold 10 Epoch 1100: TotalLoss=-0.050624 | Sup=0.000206 | Unsup=-0.508292 | TrainAcc=1.0000\n","Fold 10 Epoch 1200: TotalLoss=-0.049937 | Sup=0.000085 | Unsup=-0.500223 | TrainAcc=1.0000\n","Fold 10 Epoch 1300: TotalLoss=-0.049516 | Sup=0.001485 | Unsup=-0.510009 | TrainAcc=1.0000\n","Fold 10 Epoch 1400: TotalLoss=-0.050829 | Sup=0.000173 | Unsup=-0.510019 | TrainAcc=1.0000\n","Fold 10 Epoch 1500: TotalLoss=-0.052066 | Sup=0.000146 | Unsup=-0.522123 | TrainAcc=1.0000\n","Fold 10 Epoch 1600: TotalLoss=-0.050896 | Sup=0.000306 | Unsup=-0.512021 | TrainAcc=1.0000\n","Fold 10 Epoch 1700: TotalLoss=-0.050674 | Sup=0.000045 | Unsup=-0.507190 | TrainAcc=1.0000\n","Fold 10 Epoch 1800: TotalLoss=-0.051630 | Sup=0.000162 | Unsup=-0.517919 | TrainAcc=1.0000\n","Fold 10 Epoch 1900: TotalLoss=-0.051198 | Sup=0.000276 | Unsup=-0.514731 | TrainAcc=1.0000\n","Fold 10 Epoch 2000: TotalLoss=-0.051575 | Sup=0.000264 | Unsup=-0.518388 | TrainAcc=1.0000\n","Fold 10 → Acc=0.7811 | Prec=0.6796 | Rec=0.8642 | F1=0.7609 | AUC=0.9094 | CE Loss=1.1357\n","\n","=== Fold 11 ===\n","Train CN: 13, Train AD: 9\n","Fold 11 Epoch 1: TotalLoss=0.782718 | Sup=0.807751 | Unsup=-0.250331 | TrainAcc=0.3182\n","Fold 11 Epoch 100: TotalLoss=0.278443 | Sup=0.312155 | Unsup=-0.337122 | TrainAcc=0.9091\n","Fold 11 Epoch 200: TotalLoss=0.127994 | Sup=0.164416 | Unsup=-0.364216 | TrainAcc=0.9545\n","Fold 11 Epoch 300: TotalLoss=-0.013369 | Sup=0.026050 | Unsup=-0.394196 | TrainAcc=1.0000\n","Fold 11 Epoch 400: TotalLoss=-0.029522 | Sup=0.012644 | Unsup=-0.421658 | TrainAcc=1.0000\n","Fold 11 Epoch 500: TotalLoss=-0.037681 | Sup=0.006379 | Unsup=-0.440603 | TrainAcc=1.0000\n","Fold 11 Epoch 600: TotalLoss=-0.010377 | Sup=0.036531 | Unsup=-0.469078 | TrainAcc=0.9545\n","Fold 11 Epoch 700: TotalLoss=-0.038256 | Sup=0.009467 | Unsup=-0.477222 | TrainAcc=1.0000\n","Fold 11 Epoch 800: TotalLoss=-0.046803 | Sup=0.000926 | Unsup=-0.477288 | TrainAcc=1.0000\n","Fold 11 Epoch 900: TotalLoss=-0.047549 | Sup=0.000558 | Unsup=-0.481071 | TrainAcc=1.0000\n","Fold 11 Epoch 1000: TotalLoss=-0.048331 | Sup=0.000430 | Unsup=-0.487617 | TrainAcc=1.0000\n","Fold 11 Epoch 1100: TotalLoss=-0.048706 | Sup=0.000371 | Unsup=-0.490768 | TrainAcc=1.0000\n","Fold 11 Epoch 1200: TotalLoss=-0.048185 | Sup=0.000182 | Unsup=-0.483665 | TrainAcc=1.0000\n","Fold 11 Epoch 1300: TotalLoss=-0.048323 | Sup=0.002114 | Unsup=-0.504365 | TrainAcc=1.0000\n","Fold 11 Epoch 1400: TotalLoss=-0.048943 | Sup=0.002110 | Unsup=-0.510531 | TrainAcc=1.0000\n","Fold 11 Epoch 1500: TotalLoss=-0.050109 | Sup=0.000452 | Unsup=-0.505607 | TrainAcc=1.0000\n","Fold 11 Epoch 1600: TotalLoss=-0.050252 | Sup=0.000567 | Unsup=-0.508196 | TrainAcc=1.0000\n","Fold 11 Epoch 1700: TotalLoss=-0.050069 | Sup=0.000656 | Unsup=-0.507245 | TrainAcc=1.0000\n","Fold 11 Epoch 1800: TotalLoss=-0.039752 | Sup=0.010572 | Unsup=-0.503238 | TrainAcc=1.0000\n","Fold 11 Epoch 1900: TotalLoss=-0.049413 | Sup=0.001111 | Unsup=-0.505243 | TrainAcc=1.0000\n","Fold 11 Epoch 2000: TotalLoss=-0.050740 | Sup=0.000174 | Unsup=-0.509141 | TrainAcc=1.0000\n","Fold 11 → Acc=0.7562 | Prec=0.6633 | Rec=0.8025 | F1=0.7263 | AUC=0.8440 | CE Loss=1.5808\n","\n","=== Fold 12 ===\n","Train CN: 13, Train AD: 9\n","Fold 12 Epoch 1: TotalLoss=0.725163 | Sup=0.749114 | Unsup=-0.239504 | TrainAcc=0.3636\n","Fold 12 Epoch 100: TotalLoss=0.289064 | Sup=0.324989 | Unsup=-0.359249 | TrainAcc=0.9091\n","Fold 12 Epoch 200: TotalLoss=0.153608 | Sup=0.192127 | Unsup=-0.385188 | TrainAcc=0.9091\n","Fold 12 Epoch 300: TotalLoss=-0.002187 | Sup=0.036176 | Unsup=-0.383628 | TrainAcc=1.0000\n","Fold 12 Epoch 400: TotalLoss=-0.030915 | Sup=0.011966 | Unsup=-0.428808 | TrainAcc=1.0000\n","Fold 12 Epoch 500: TotalLoss=-0.033051 | Sup=0.011544 | Unsup=-0.445947 | TrainAcc=1.0000\n","Fold 12 Epoch 600: TotalLoss=-0.039831 | Sup=0.005827 | Unsup=-0.456587 | TrainAcc=1.0000\n","Fold 12 Epoch 700: TotalLoss=-0.042242 | Sup=0.006280 | Unsup=-0.485214 | TrainAcc=1.0000\n","Fold 12 Epoch 800: TotalLoss=-0.049273 | Sup=0.001480 | Unsup=-0.507530 | TrainAcc=1.0000\n","Fold 12 Epoch 900: TotalLoss=-0.049820 | Sup=0.001080 | Unsup=-0.509003 | TrainAcc=1.0000\n","Fold 12 Epoch 1000: TotalLoss=-0.046824 | Sup=0.003284 | Unsup=-0.501078 | TrainAcc=1.0000\n","Fold 12 Epoch 1100: TotalLoss=-0.049811 | Sup=0.000696 | Unsup=-0.505064 | TrainAcc=1.0000\n","Fold 12 Epoch 1200: TotalLoss=-0.050858 | Sup=0.000408 | Unsup=-0.512661 | TrainAcc=1.0000\n","Fold 12 Epoch 1300: TotalLoss=-0.051191 | Sup=0.000185 | Unsup=-0.513751 | TrainAcc=1.0000\n","Fold 12 Epoch 1400: TotalLoss=-0.051286 | Sup=0.001012 | Unsup=-0.522974 | TrainAcc=1.0000\n","Fold 12 Epoch 1500: TotalLoss=-0.052075 | Sup=0.000059 | Unsup=-0.521344 | TrainAcc=1.0000\n","Fold 12 Epoch 1600: TotalLoss=-0.051450 | Sup=0.000064 | Unsup=-0.515142 | TrainAcc=1.0000\n","Fold 12 Epoch 1700: TotalLoss=-0.051935 | Sup=0.000262 | Unsup=-0.521966 | TrainAcc=1.0000\n","Fold 12 Epoch 1800: TotalLoss=-0.051873 | Sup=0.000351 | Unsup=-0.522247 | TrainAcc=1.0000\n","Fold 12 Epoch 1900: TotalLoss=-0.050905 | Sup=0.001526 | Unsup=-0.524309 | TrainAcc=1.0000\n","Fold 12 Epoch 2000: TotalLoss=-0.052185 | Sup=0.000020 | Unsup=-0.522048 | TrainAcc=1.0000\n","Fold 12 → Acc=0.7861 | Prec=0.6727 | Rec=0.9136 | F1=0.7749 | AUC=0.8843 | CE Loss=1.6706\n","\n","=== Fold 13 ===\n","Train CN: 13, Train AD: 9\n","Fold 13 Epoch 1: TotalLoss=0.562754 | Sup=0.587732 | Unsup=-0.249777 | TrainAcc=0.7727\n","Fold 13 Epoch 100: TotalLoss=0.293697 | Sup=0.332807 | Unsup=-0.391101 | TrainAcc=0.8636\n","Fold 13 Epoch 200: TotalLoss=0.136268 | Sup=0.178399 | Unsup=-0.421310 | TrainAcc=0.9545\n","Fold 13 Epoch 300: TotalLoss=0.030740 | Sup=0.074276 | Unsup=-0.435357 | TrainAcc=0.9545\n","Fold 13 Epoch 400: TotalLoss=-0.016247 | Sup=0.027896 | Unsup=-0.441428 | TrainAcc=1.0000\n","Fold 13 Epoch 500: TotalLoss=-0.041342 | Sup=0.004691 | Unsup=-0.460336 | TrainAcc=1.0000\n","Fold 13 Epoch 600: TotalLoss=-0.042980 | Sup=0.004758 | Unsup=-0.477376 | TrainAcc=1.0000\n","Fold 13 Epoch 700: TotalLoss=-0.043524 | Sup=0.004870 | Unsup=-0.483937 | TrainAcc=1.0000\n","Fold 13 Epoch 800: TotalLoss=-0.041971 | Sup=0.009753 | Unsup=-0.517244 | TrainAcc=1.0000\n","Fold 13 Epoch 900: TotalLoss=-0.048364 | Sup=0.001711 | Unsup=-0.500754 | TrainAcc=1.0000\n","Fold 13 Epoch 1000: TotalLoss=-0.048584 | Sup=0.003563 | Unsup=-0.521474 | TrainAcc=1.0000\n","Fold 13 Epoch 1100: TotalLoss=-0.050205 | Sup=0.000985 | Unsup=-0.511905 | TrainAcc=1.0000\n","Fold 13 Epoch 1200: TotalLoss=-0.051217 | Sup=0.000647 | Unsup=-0.518634 | TrainAcc=1.0000\n","Fold 13 Epoch 1300: TotalLoss=-0.051482 | Sup=0.000269 | Unsup=-0.517514 | TrainAcc=1.0000\n","Fold 13 Epoch 1400: TotalLoss=-0.051565 | Sup=0.000524 | Unsup=-0.520886 | TrainAcc=1.0000\n","Fold 13 Epoch 1500: TotalLoss=-0.043641 | Sup=0.008017 | Unsup=-0.516577 | TrainAcc=1.0000\n","Fold 13 Epoch 1600: TotalLoss=-0.052298 | Sup=0.000344 | Unsup=-0.526419 | TrainAcc=1.0000\n","Fold 13 Epoch 1700: TotalLoss=-0.050354 | Sup=0.000067 | Unsup=-0.504201 | TrainAcc=1.0000\n","Fold 13 Epoch 1800: TotalLoss=-0.051772 | Sup=0.000285 | Unsup=-0.520576 | TrainAcc=1.0000\n","Fold 13 Epoch 1900: TotalLoss=-0.052604 | Sup=0.000074 | Unsup=-0.526780 | TrainAcc=1.0000\n","Fold 13 Epoch 2000: TotalLoss=-0.052727 | Sup=0.000028 | Unsup=-0.527555 | TrainAcc=1.0000\n","Fold 13 → Acc=0.7960 | Prec=0.7000 | Rec=0.8642 | F1=0.7735 | AUC=0.8551 | CE Loss=1.7521\n","\n","=== Fold 14 ===\n","Train CN: 13, Train AD: 9\n","Fold 14 Epoch 1: TotalLoss=0.642013 | Sup=0.666803 | Unsup=-0.247896 | TrainAcc=0.6364\n","Fold 14 Epoch 100: TotalLoss=0.325254 | Sup=0.360081 | Unsup=-0.348276 | TrainAcc=0.9091\n","Fold 14 Epoch 200: TotalLoss=0.084108 | Sup=0.119045 | Unsup=-0.349371 | TrainAcc=0.9545\n","Fold 14 Epoch 300: TotalLoss=-0.008594 | Sup=0.026520 | Unsup=-0.351146 | TrainAcc=1.0000\n","Fold 14 Epoch 400: TotalLoss=-0.015782 | Sup=0.019954 | Unsup=-0.357355 | TrainAcc=1.0000\n","Fold 14 Epoch 500: TotalLoss=-0.023131 | Sup=0.013769 | Unsup=-0.369002 | TrainAcc=1.0000\n","Fold 14 Epoch 600: TotalLoss=-0.030082 | Sup=0.006359 | Unsup=-0.364411 | TrainAcc=1.0000\n","Fold 14 Epoch 700: TotalLoss=-0.034898 | Sup=0.002758 | Unsup=-0.376560 | TrainAcc=1.0000\n","Fold 14 Epoch 800: TotalLoss=-0.039942 | Sup=0.000612 | Unsup=-0.405540 | TrainAcc=1.0000\n","Fold 14 Epoch 900: TotalLoss=-0.043230 | Sup=0.000919 | Unsup=-0.441487 | TrainAcc=1.0000\n","Fold 14 Epoch 1000: TotalLoss=-0.042547 | Sup=0.001287 | Unsup=-0.438339 | TrainAcc=1.0000\n","Fold 14 Epoch 1100: TotalLoss=-0.044840 | Sup=0.000674 | Unsup=-0.455140 | TrainAcc=1.0000\n","Fold 14 Epoch 1200: TotalLoss=-0.046732 | Sup=0.000280 | Unsup=-0.470126 | TrainAcc=1.0000\n","Fold 14 Epoch 1300: TotalLoss=-0.047860 | Sup=0.001106 | Unsup=-0.489661 | TrainAcc=1.0000\n","Fold 14 Epoch 1400: TotalLoss=-0.046930 | Sup=0.003348 | Unsup=-0.502774 | TrainAcc=1.0000\n","Fold 14 Epoch 1500: TotalLoss=-0.049852 | Sup=0.001419 | Unsup=-0.512718 | TrainAcc=1.0000\n","Fold 14 Epoch 1600: TotalLoss=-0.051234 | Sup=0.000279 | Unsup=-0.515127 | TrainAcc=1.0000\n","Fold 14 Epoch 1700: TotalLoss=-0.051066 | Sup=0.000399 | Unsup=-0.514656 | TrainAcc=1.0000\n","Fold 14 Epoch 1800: TotalLoss=-0.051934 | Sup=0.000231 | Unsup=-0.521655 | TrainAcc=1.0000\n","Fold 14 Epoch 1900: TotalLoss=-0.049754 | Sup=0.000062 | Unsup=-0.498161 | TrainAcc=1.0000\n","Fold 14 Epoch 2000: TotalLoss=-0.051774 | Sup=0.000022 | Unsup=-0.517967 | TrainAcc=1.0000\n","Fold 14 → Acc=0.7811 | Prec=0.6832 | Rec=0.8519 | F1=0.7582 | AUC=0.8763 | CE Loss=1.3948\n","\n","=== Fold 15 ===\n","Train CN: 13, Train AD: 9\n","Fold 15 Epoch 1: TotalLoss=0.552134 | Sup=0.577451 | Unsup=-0.253168 | TrainAcc=0.8182\n","Fold 15 Epoch 100: TotalLoss=0.345107 | Sup=0.384337 | Unsup=-0.392306 | TrainAcc=0.8182\n","Fold 15 Epoch 200: TotalLoss=0.256443 | Sup=0.298239 | Unsup=-0.417957 | TrainAcc=0.9091\n","Fold 15 Epoch 300: TotalLoss=0.031208 | Sup=0.074385 | Unsup=-0.431765 | TrainAcc=1.0000\n","Fold 15 Epoch 400: TotalLoss=-0.015479 | Sup=0.027360 | Unsup=-0.428385 | TrainAcc=1.0000\n","Fold 15 Epoch 500: TotalLoss=-0.031614 | Sup=0.012281 | Unsup=-0.438951 | TrainAcc=1.0000\n","Fold 15 Epoch 600: TotalLoss=-0.041215 | Sup=0.007446 | Unsup=-0.486604 | TrainAcc=1.0000\n","Fold 15 Epoch 700: TotalLoss=-0.046282 | Sup=0.001950 | Unsup=-0.482321 | TrainAcc=1.0000\n","Fold 15 Epoch 800: TotalLoss=-0.035648 | Sup=0.011975 | Unsup=-0.476234 | TrainAcc=1.0000\n","Fold 15 Epoch 900: TotalLoss=-0.046509 | Sup=0.001813 | Unsup=-0.483218 | TrainAcc=1.0000\n","Fold 15 Epoch 1000: TotalLoss=-0.045099 | Sup=0.005990 | Unsup=-0.510893 | TrainAcc=1.0000\n","Fold 15 Epoch 1100: TotalLoss=-0.051390 | Sup=0.000658 | Unsup=-0.520479 | TrainAcc=1.0000\n","Fold 15 Epoch 1200: TotalLoss=-0.050673 | Sup=0.000808 | Unsup=-0.514810 | TrainAcc=1.0000\n","Fold 15 Epoch 1300: TotalLoss=-0.051350 | Sup=0.000968 | Unsup=-0.523174 | TrainAcc=1.0000\n","Fold 15 Epoch 1400: TotalLoss=-0.050699 | Sup=0.001159 | Unsup=-0.518584 | TrainAcc=1.0000\n","Fold 15 Epoch 1500: TotalLoss=-0.052158 | Sup=0.000149 | Unsup=-0.523071 | TrainAcc=1.0000\n","Fold 15 Epoch 1600: TotalLoss=-0.051711 | Sup=0.000239 | Unsup=-0.519499 | TrainAcc=1.0000\n","Fold 15 Epoch 1700: TotalLoss=-0.051889 | Sup=0.000414 | Unsup=-0.523036 | TrainAcc=1.0000\n","Fold 15 Epoch 1800: TotalLoss=-0.051215 | Sup=0.000257 | Unsup=-0.514720 | TrainAcc=1.0000\n","Fold 15 Epoch 1900: TotalLoss=-0.051430 | Sup=0.000430 | Unsup=-0.518597 | TrainAcc=1.0000\n","Fold 15 Epoch 2000: TotalLoss=-0.043670 | Sup=0.008862 | Unsup=-0.525320 | TrainAcc=1.0000\n","Fold 15 → Acc=0.7363 | Prec=0.6458 | Rec=0.7654 | F1=0.7006 | AUC=0.8200 | CE Loss=1.9294\n","\n","=== Fold 16 ===\n","Train CN: 13, Train AD: 9\n","Fold 16 Epoch 1: TotalLoss=1.054699 | Sup=1.082050 | Unsup=-0.273512 | TrainAcc=0.1818\n","Fold 16 Epoch 100: TotalLoss=0.247787 | Sup=0.285522 | Unsup=-0.377355 | TrainAcc=0.8636\n","Fold 16 Epoch 200: TotalLoss=0.096601 | Sup=0.133968 | Unsup=-0.373664 | TrainAcc=1.0000\n","Fold 16 Epoch 300: TotalLoss=0.011150 | Sup=0.047438 | Unsup=-0.362882 | TrainAcc=1.0000\n","Fold 16 Epoch 400: TotalLoss=-0.023542 | Sup=0.015828 | Unsup=-0.393702 | TrainAcc=1.0000\n","Fold 16 Epoch 500: TotalLoss=-0.021597 | Sup=0.016748 | Unsup=-0.383457 | TrainAcc=1.0000\n","Fold 16 Epoch 600: TotalLoss=-0.039457 | Sup=0.004413 | Unsup=-0.438704 | TrainAcc=1.0000\n","Fold 16 Epoch 700: TotalLoss=-0.041577 | Sup=0.002047 | Unsup=-0.436243 | TrainAcc=1.0000\n","Fold 16 Epoch 800: TotalLoss=-0.044261 | Sup=0.003614 | Unsup=-0.478748 | TrainAcc=1.0000\n","Fold 16 Epoch 900: TotalLoss=-0.044105 | Sup=0.005352 | Unsup=-0.494570 | TrainAcc=1.0000\n","Fold 16 Epoch 1000: TotalLoss=-0.049084 | Sup=0.000428 | Unsup=-0.495124 | TrainAcc=1.0000\n","Fold 16 Epoch 1100: TotalLoss=-0.047422 | Sup=0.002517 | Unsup=-0.499386 | TrainAcc=1.0000\n","Fold 16 Epoch 1200: TotalLoss=-0.048310 | Sup=0.001707 | Unsup=-0.500169 | TrainAcc=1.0000\n","Fold 16 Epoch 1300: TotalLoss=-0.049006 | Sup=0.001913 | Unsup=-0.509182 | TrainAcc=1.0000\n","Fold 16 Epoch 1400: TotalLoss=-0.049281 | Sup=0.000060 | Unsup=-0.493409 | TrainAcc=1.0000\n","Fold 16 Epoch 1500: TotalLoss=-0.043577 | Sup=0.006902 | Unsup=-0.504788 | TrainAcc=1.0000\n","Fold 16 Epoch 1600: TotalLoss=-0.050010 | Sup=0.000153 | Unsup=-0.501625 | TrainAcc=1.0000\n","Fold 16 Epoch 1700: TotalLoss=-0.051157 | Sup=0.000078 | Unsup=-0.512349 | TrainAcc=1.0000\n","Fold 16 Epoch 1800: TotalLoss=-0.049734 | Sup=0.000054 | Unsup=-0.497881 | TrainAcc=1.0000\n","Fold 16 Epoch 1900: TotalLoss=-0.050211 | Sup=0.000027 | Unsup=-0.502380 | TrainAcc=1.0000\n","Fold 16 Epoch 2000: TotalLoss=-0.050545 | Sup=0.000111 | Unsup=-0.506558 | TrainAcc=1.0000\n","Fold 16 → Acc=0.7114 | Prec=0.6264 | Rec=0.7037 | F1=0.6628 | AUC=0.7989 | CE Loss=1.9851\n","\n","=== Fold 17 ===\n","Train CN: 13, Train AD: 9\n","Fold 17 Epoch 1: TotalLoss=0.761204 | Sup=0.786459 | Unsup=-0.252547 | TrainAcc=0.2273\n","Fold 17 Epoch 100: TotalLoss=0.364882 | Sup=0.401319 | Unsup=-0.364364 | TrainAcc=0.8182\n","Fold 17 Epoch 200: TotalLoss=0.158227 | Sup=0.197056 | Unsup=-0.388285 | TrainAcc=0.9091\n","Fold 17 Epoch 300: TotalLoss=0.035713 | Sup=0.076706 | Unsup=-0.409931 | TrainAcc=1.0000\n","Fold 17 Epoch 400: TotalLoss=0.040365 | Sup=0.082857 | Unsup=-0.424922 | TrainAcc=0.9545\n","Fold 17 Epoch 500: TotalLoss=-0.041777 | Sup=0.002662 | Unsup=-0.444385 | TrainAcc=1.0000\n","Fold 17 Epoch 600: TotalLoss=-0.036503 | Sup=0.009940 | Unsup=-0.464430 | TrainAcc=1.0000\n","Fold 17 Epoch 700: TotalLoss=-0.045183 | Sup=0.001427 | Unsup=-0.466093 | TrainAcc=1.0000\n","Fold 17 Epoch 800: TotalLoss=-0.031487 | Sup=0.019534 | Unsup=-0.510203 | TrainAcc=1.0000\n","Fold 17 Epoch 900: TotalLoss=-0.048424 | Sup=0.002433 | Unsup=-0.508571 | TrainAcc=1.0000\n","Fold 17 Epoch 1000: TotalLoss=-0.050540 | Sup=0.000579 | Unsup=-0.511185 | TrainAcc=1.0000\n","Fold 17 Epoch 1100: TotalLoss=-0.049095 | Sup=0.001693 | Unsup=-0.507885 | TrainAcc=1.0000\n","Fold 17 Epoch 1200: TotalLoss=-0.048997 | Sup=0.001895 | Unsup=-0.508928 | TrainAcc=1.0000\n","Fold 17 Epoch 1300: TotalLoss=-0.051626 | Sup=0.000225 | Unsup=-0.518515 | TrainAcc=1.0000\n","Fold 17 Epoch 1400: TotalLoss=-0.051487 | Sup=0.000437 | Unsup=-0.519233 | TrainAcc=1.0000\n","Fold 17 Epoch 1500: TotalLoss=-0.051357 | Sup=0.000743 | Unsup=-0.521000 | TrainAcc=1.0000\n","Fold 17 Epoch 1600: TotalLoss=-0.051258 | Sup=0.000371 | Unsup=-0.516289 | TrainAcc=1.0000\n","Fold 17 Epoch 1700: TotalLoss=-0.049962 | Sup=0.001436 | Unsup=-0.513984 | TrainAcc=1.0000\n","Fold 17 Epoch 1800: TotalLoss=-0.050951 | Sup=0.000863 | Unsup=-0.518135 | TrainAcc=1.0000\n","Fold 17 Epoch 1900: TotalLoss=-0.049866 | Sup=0.002426 | Unsup=-0.522922 | TrainAcc=1.0000\n","Fold 17 Epoch 2000: TotalLoss=-0.051996 | Sup=0.000087 | Unsup=-0.520824 | TrainAcc=1.0000\n","Fold 17 → Acc=0.7612 | Prec=0.6667 | Rec=0.8148 | F1=0.7333 | AUC=0.8624 | CE Loss=1.6197\n","\n","=== Fold 18 ===\n","Train CN: 13, Train AD: 9\n","Fold 18 Epoch 1: TotalLoss=0.694119 | Sup=0.718288 | Unsup=-0.241693 | TrainAcc=0.5455\n","Fold 18 Epoch 100: TotalLoss=0.412062 | Sup=0.447784 | Unsup=-0.357227 | TrainAcc=0.7727\n","Fold 18 Epoch 200: TotalLoss=0.340465 | Sup=0.376600 | Unsup=-0.361347 | TrainAcc=0.8182\n","Fold 18 Epoch 300: TotalLoss=0.131735 | Sup=0.167508 | Unsup=-0.357731 | TrainAcc=1.0000\n","Fold 18 Epoch 400: TotalLoss=0.044610 | Sup=0.081220 | Unsup=-0.366101 | TrainAcc=1.0000\n","Fold 18 Epoch 500: TotalLoss=-0.025001 | Sup=0.011966 | Unsup=-0.369667 | TrainAcc=1.0000\n","Fold 18 Epoch 600: TotalLoss=-0.024720 | Sup=0.011033 | Unsup=-0.357534 | TrainAcc=1.0000\n","Fold 18 Epoch 700: TotalLoss=-0.036406 | Sup=0.001968 | Unsup=-0.383742 | TrainAcc=1.0000\n","Fold 18 Epoch 800: TotalLoss=-0.036893 | Sup=0.002374 | Unsup=-0.392661 | TrainAcc=1.0000\n","Fold 18 Epoch 900: TotalLoss=-0.039513 | Sup=0.003861 | Unsup=-0.433735 | TrainAcc=1.0000\n","Fold 18 Epoch 1000: TotalLoss=-0.045447 | Sup=0.001466 | Unsup=-0.469139 | TrainAcc=1.0000\n","Fold 18 Epoch 1100: TotalLoss=-0.024667 | Sup=0.020889 | Unsup=-0.455556 | TrainAcc=1.0000\n","Fold 18 Epoch 1200: TotalLoss=-0.044590 | Sup=0.004946 | Unsup=-0.495356 | TrainAcc=1.0000\n","Fold 18 Epoch 1300: TotalLoss=-0.046006 | Sup=0.002290 | Unsup=-0.482953 | TrainAcc=1.0000\n","Fold 18 Epoch 1400: TotalLoss=-0.049319 | Sup=0.000337 | Unsup=-0.496557 | TrainAcc=1.0000\n","Fold 18 Epoch 1500: TotalLoss=-0.046404 | Sup=0.003173 | Unsup=-0.495764 | TrainAcc=1.0000\n","Fold 18 Epoch 1600: TotalLoss=-0.050426 | Sup=0.000950 | Unsup=-0.513760 | TrainAcc=1.0000\n","Fold 18 Epoch 1700: TotalLoss=-0.050049 | Sup=0.000445 | Unsup=-0.504939 | TrainAcc=1.0000\n","Fold 18 Epoch 1800: TotalLoss=-0.050390 | Sup=0.001146 | Unsup=-0.515355 | TrainAcc=1.0000\n","Fold 18 Epoch 1900: TotalLoss=-0.051514 | Sup=0.000335 | Unsup=-0.518490 | TrainAcc=1.0000\n","Fold 18 Epoch 2000: TotalLoss=-0.051313 | Sup=0.000117 | Unsup=-0.514297 | TrainAcc=1.0000\n","Fold 18 → Acc=0.8159 | Prec=0.7245 | Rec=0.8765 | F1=0.7933 | AUC=0.9037 | CE Loss=0.9719\n","\n","=== Fold 19 ===\n","Train CN: 13, Train AD: 9\n","Fold 19 Epoch 1: TotalLoss=0.719948 | Sup=0.744440 | Unsup=-0.244925 | TrainAcc=0.4091\n","Fold 19 Epoch 100: TotalLoss=0.362690 | Sup=0.397033 | Unsup=-0.343432 | TrainAcc=0.8182\n","Fold 19 Epoch 200: TotalLoss=0.242547 | Sup=0.279978 | Unsup=-0.374313 | TrainAcc=0.8636\n","Fold 19 Epoch 300: TotalLoss=0.158408 | Sup=0.199177 | Unsup=-0.407690 | TrainAcc=0.8636\n","Fold 19 Epoch 400: TotalLoss=0.107281 | Sup=0.150078 | Unsup=-0.427969 | TrainAcc=0.9545\n","Fold 19 Epoch 500: TotalLoss=-0.009318 | Sup=0.037308 | Unsup=-0.466255 | TrainAcc=1.0000\n","Fold 19 Epoch 600: TotalLoss=-0.042188 | Sup=0.004116 | Unsup=-0.463045 | TrainAcc=1.0000\n","Fold 19 Epoch 700: TotalLoss=-0.043003 | Sup=0.004632 | Unsup=-0.476351 | TrainAcc=1.0000\n","Fold 19 Epoch 800: TotalLoss=-0.047501 | Sup=0.002024 | Unsup=-0.495250 | TrainAcc=1.0000\n","Fold 19 Epoch 900: TotalLoss=-0.044791 | Sup=0.001488 | Unsup=-0.462794 | TrainAcc=1.0000\n","Fold 19 Epoch 1000: TotalLoss=-0.046080 | Sup=0.003945 | Unsup=-0.500247 | TrainAcc=1.0000\n","Fold 19 Epoch 1100: TotalLoss=-0.047488 | Sup=0.003217 | Unsup=-0.507055 | TrainAcc=1.0000\n","Fold 19 Epoch 1200: TotalLoss=-0.046950 | Sup=0.003687 | Unsup=-0.506371 | TrainAcc=1.0000\n","Fold 19 Epoch 1300: TotalLoss=-0.049706 | Sup=0.001997 | Unsup=-0.517031 | TrainAcc=1.0000\n","Fold 19 Epoch 1400: TotalLoss=-0.050906 | Sup=0.000785 | Unsup=-0.516911 | TrainAcc=1.0000\n","Fold 19 Epoch 1500: TotalLoss=-0.050890 | Sup=0.000344 | Unsup=-0.512340 | TrainAcc=1.0000\n","Fold 19 Epoch 1600: TotalLoss=-0.050821 | Sup=0.000465 | Unsup=-0.512863 | TrainAcc=1.0000\n","Fold 19 Epoch 1700: TotalLoss=-0.051649 | Sup=0.000280 | Unsup=-0.519292 | TrainAcc=1.0000\n","Fold 19 Epoch 1800: TotalLoss=-0.050690 | Sup=0.000302 | Unsup=-0.509923 | TrainAcc=1.0000\n","Fold 19 Epoch 1900: TotalLoss=-0.052135 | Sup=0.000118 | Unsup=-0.522528 | TrainAcc=1.0000\n","Fold 19 Epoch 2000: TotalLoss=-0.052176 | Sup=0.000053 | Unsup=-0.522293 | TrainAcc=1.0000\n","Fold 19 → Acc=0.8109 | Prec=0.7129 | Rec=0.8889 | F1=0.7912 | AUC=0.8913 | CE Loss=1.2295\n","\n","=== Fold 20 ===\n","Train CN: 13, Train AD: 9\n","Fold 20 Epoch 1: TotalLoss=0.646058 | Sup=0.671026 | Unsup=-0.249681 | TrainAcc=0.4545\n","Fold 20 Epoch 100: TotalLoss=0.380261 | Sup=0.414820 | Unsup=-0.345582 | TrainAcc=0.7727\n","Fold 20 Epoch 200: TotalLoss=0.342755 | Sup=0.376865 | Unsup=-0.341105 | TrainAcc=0.7727\n","Fold 20 Epoch 300: TotalLoss=0.332186 | Sup=0.367408 | Unsup=-0.352224 | TrainAcc=0.7727\n","Fold 20 Epoch 400: TotalLoss=0.078551 | Sup=0.117462 | Unsup=-0.389104 | TrainAcc=1.0000\n","Fold 20 Epoch 500: TotalLoss=-0.017675 | Sup=0.020182 | Unsup=-0.378572 | TrainAcc=1.0000\n","Fold 20 Epoch 600: TotalLoss=-0.035180 | Sup=0.007740 | Unsup=-0.429200 | TrainAcc=1.0000\n","Fold 20 Epoch 700: TotalLoss=-0.039191 | Sup=0.004783 | Unsup=-0.439734 | TrainAcc=1.0000\n","Fold 20 Epoch 800: TotalLoss=-0.039506 | Sup=0.005086 | Unsup=-0.445917 | TrainAcc=1.0000\n","Fold 20 Epoch 900: TotalLoss=-0.044646 | Sup=0.003655 | Unsup=-0.483004 | TrainAcc=1.0000\n","Fold 20 Epoch 1000: TotalLoss=-0.046044 | Sup=0.000451 | Unsup=-0.464943 | TrainAcc=1.0000\n","Fold 20 Epoch 1100: TotalLoss=-0.048408 | Sup=0.001913 | Unsup=-0.503212 | TrainAcc=1.0000\n","Fold 20 Epoch 1200: TotalLoss=-0.049079 | Sup=0.001257 | Unsup=-0.503356 | TrainAcc=1.0000\n","Fold 20 Epoch 1300: TotalLoss=-0.050017 | Sup=0.000868 | Unsup=-0.508850 | TrainAcc=1.0000\n","Fold 20 Epoch 1400: TotalLoss=-0.050906 | Sup=0.000640 | Unsup=-0.515457 | TrainAcc=1.0000\n","Fold 20 Epoch 1500: TotalLoss=-0.050663 | Sup=0.001212 | Unsup=-0.518750 | TrainAcc=1.0000\n","Fold 20 Epoch 1600: TotalLoss=-0.051449 | Sup=0.000685 | Unsup=-0.521337 | TrainAcc=1.0000\n","Fold 20 Epoch 1700: TotalLoss=-0.045355 | Sup=0.005601 | Unsup=-0.509562 | TrainAcc=1.0000\n","Fold 20 Epoch 1800: TotalLoss=-0.051447 | Sup=0.000092 | Unsup=-0.515389 | TrainAcc=1.0000\n","Fold 20 Epoch 1900: TotalLoss=-0.050224 | Sup=0.001341 | Unsup=-0.515648 | TrainAcc=1.0000\n","Fold 20 Epoch 2000: TotalLoss=-0.052507 | Sup=0.000067 | Unsup=-0.525740 | TrainAcc=1.0000\n","Fold 20 → Acc=0.7662 | Prec=0.6635 | Rec=0.8519 | F1=0.7459 | AUC=0.8501 | CE Loss=1.5221\n","\n","=== Average Results Across 20 Folds ===\n","Accuracy:  0.7781 ± 0.0345\n","Precision: 0.6909 ± 0.0480\n","Recall:    0.8235 ± 0.0741\n","F1-score:  0.7486 ± 0.0423\n","AUC:       0.8620 ± 0.0312\n","CE Loss:   1.4958 ± 0.2999\n"]}]},{"cell_type":"code","source":["# import torch\n","# import torch.nn as nn\n","# import torch.optim as optim\n","# import numpy as np\n","# import pandas as pd\n","# from sklearn.model_selection import StratifiedShuffleSplit\n","# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n","\n","# # ==========================================\n","# # CONFIG\n","# # ==========================================\n","# SEED = 42\n","# np.random.seed(SEED)\n","# torch.manual_seed(SEED)\n","# if torch.cuda.is_available():\n","#     torch.cuda.manual_seed_all(SEED)\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# hidden_dim = 512\n","# num_epochs = 2000\n","# lr = 1e-4\n","# weight_decay = 1e-4\n","# batch_print_freq = 500  # print every 500 epochs\n","\n","# # Use same λ list as before\n","# lambda_mod_list = [0.001, 0.005, 0.009, 0.01, 0.05, 0.09, 0.1, 0.3, 0.5, 0.9, 1, 2, 5, 8]\n","\n","\n","\n","# results_summary = []\n","\n","\n","# for lambda_mod in lambda_mod_list:\n","#     print(f\"\\n==============================\")\n","#     print(f\" Running with λ_mod = {lambda_mod}\")\n","#     print(f\"==============================\")\n","\n","#     accuracies, precisions, recalls, f1_scores, aucs, ce_losses = [], [], [], [], [], []\n","\n","#     sss = StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=SEED)\n","\n","#     for fold, (train_val_idx, test_idx_global) in enumerate(sss.split(X, y), start=1):\n","#         print(f\"\\n=== Fold {fold} ===\")\n","\n","#         cn_idx = np.where(y == 0)[0]\n","#         ad_idx = np.where(y == 1)[0]\n","\n","#         sss_class = StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=fold)\n","#         cn_train_idx, _ = next(sss_class.split(X[cn_idx], y[cn_idx]))\n","#         ad_train_idx, _ = next(sss_class.split(X[ad_idx], y[ad_idx]))\n","\n","#         cn_train = cn_idx[cn_train_idx]\n","#         ad_train = ad_idx[ad_train_idx]\n","#         train_idx_final = np.concatenate([cn_train, ad_train])\n","#         np.random.shuffle(train_idx_final)\n","\n","#         print(f\"Train CN: {len(cn_train)}, Train AD: {len(ad_train)}\")\n","\n","#         train_idx_t = torch.from_numpy(train_idx_final).long().to(device)\n","#         y_train_tensor = torch.from_numpy(y[train_idx_final]).long().to(device)\n","\n","#         # Initialize model\n","#         model = GCN_SemiSupervised(feats_dim, hidden_dim, num_classes, device, activ=\"RELU\").to(device)\n","#         optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","#         ce_loss = nn.CrossEntropyLoss()\n","\n","#         # Training loop\n","#         for epoch in range(1, num_epochs + 1):\n","#             model.train()\n","#             optimizer.zero_grad()\n","\n","#             logits = model(data)\n","#             loss_sup = ce_loss(logits[train_idx_t], y_train_tensor)\n","#             loss_unsup = model.modularity_loss(A_tensor, logits)\n","#             total_loss = loss_sup + lambda_mod * loss_unsup\n","\n","#             total_loss.backward()\n","#             optimizer.step()\n","\n","#             if epoch % batch_print_freq == 0 or epoch == 1:\n","#                 model.eval()\n","#                 with torch.no_grad():\n","#                     preds_train = logits[train_idx_t].argmax(dim=1)\n","#                     acc_train = accuracy_score(y_train_tensor.cpu(), preds_train.cpu())\n","#                 print(f\"Fold {fold} Epoch {epoch}: \"\n","#                       f\"TotalLoss={total_loss.item():.6f} | Sup={loss_sup.item():.6f} | \"\n","#                       f\"Unsup={loss_unsup.item():.6f} | TrainAcc={acc_train:.4f}\")\n","\n","#         # Evaluation\n","#         model.eval()\n","#         with torch.no_grad():\n","#             out = model(data)\n","#             preds = out.argmax(dim=1).cpu().numpy()\n","#             probs = torch.softmax(out, dim=1)[:, 1].cpu().numpy()  # probability for \"AD\"\n","\n","#         y_test = y[test_idx_global]\n","#         y_pred_test = preds[test_idx_global]\n","#         y_prob_test = probs[test_idx_global]\n","\n","#         acc = accuracy_score(y_test, y_pred_test)\n","#         prec = precision_score(y_test, y_pred_test, zero_division=0)\n","#         rec = recall_score(y_test, y_pred_test, zero_division=0)\n","#         f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","#         auc = roc_auc_score(y_test, y_prob_test)\n","#         ce = log_loss(y_test, y_prob_test)\n","\n","#         accuracies.append(acc)\n","#         precisions.append(prec)\n","#         recalls.append(rec)\n","#         f1_scores.append(f1)\n","#         aucs.append(auc)\n","#         ce_losses.append(ce)\n","\n","#         print(f\"Fold {fold} → \"\n","#               f\"Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | \"\n","#               f\"F1={f1:.4f} | AUC={auc:.4f} | CE Loss={ce:.4f}\")\n","\n","#     # Average results per λ_mod\n","#     mean_acc, std_acc = np.mean(accuracies), np.std(accuracies)\n","#     mean_prec, std_prec = np.mean(precisions), np.std(precisions)\n","#     mean_rec, std_rec = np.mean(recalls), np.std(recalls)\n","#     mean_f1, std_f1 = np.mean(f1_scores), np.std(f1_scores)\n","#     mean_auc, std_auc = np.mean(aucs), np.std(aucs)\n","#     mean_ce, std_ce = np.mean(ce_losses), np.std(ce_losses)\n","\n","#     results_summary.append({\n","#         \"λ_mod\": lambda_mod,\n","#         \"Accuracy\": f\"{mean_acc:.4f} ± {std_acc:.4f}\",\n","#         \"Precision\": f\"{mean_prec:.4f} ± {std_prec:.4f}\",\n","#         \"Recall\": f\"{mean_rec:.4f} ± {std_rec:.4f}\",\n","#         \"F1\": f\"{mean_f1:.4f} ± {std_f1:.4f}\",\n","#         \"AUC\": f\"{mean_auc:.4f} ± {std_auc:.4f}\",\n","#         \"CE Loss\": f\"{mean_ce:.4f} ± {std_ce:.4f}\",\n","#     })\n","\n","#     print(f\"\\n=== λ_mod = {lambda_mod} → Average Results ===\")\n","#     print(f\"Accuracy:  {mean_acc:.4f} ± {std_acc:.4f}\")\n","#     print(f\"Precision: {mean_prec:.4f} ± {std_prec:.4f}\")\n","#     print(f\"Recall:    {mean_rec:.4f} ± {std_rec:.4f}\")\n","#     print(f\"F1-score:  {mean_f1:.4f} ± {std_f1:.4f}\")\n","#     print(f\"AUC:       {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n","#     print(f\"CE Loss:   {np.mean(ce_losses):.4f} ± {np.std(ce_losses):.4f}\")\n","\n","# # ==========================================\n","# # Final summary table for all λ_mod values\n","# # ==========================================\n","# print(\"\\n\\n========== FINAL SUMMARY TABLE (CN vs AD) ==========\")\n","# results_df = pd.DataFrame(results_summary)\n","# print(results_df.to_string(index=False))"],"metadata":{"id":"MvcImaSfR83Z","executionInfo":{"status":"ok","timestamp":1767501770810,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# import torch\n","# import torch.nn as nn\n","# import torch.optim as optim\n","# import numpy as np\n","# import pandas as pd\n","# from sklearn.model_selection import StratifiedShuffleSplit\n","# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n","\n","# # ==========================================\n","# # CONFIG\n","# # ==========================================\n","# SEED = 42\n","# np.random.seed(SEED)\n","# torch.manual_seed(SEED)\n","# if torch.cuda.is_available():\n","#     torch.cuda.manual_seed_all(SEED)\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# hidden_dim = 512\n","# num_epochs = 2000\n","# lr = 1e-4\n","# weight_decay = 1e-4\n","# batch_print_freq = 500  # print every 500 epochs\n","\n","# # Use same λ list as before\n","# lambda_mod_list = [0.001, 0.005, 0.009, 0.01, 0.05, 0.09, 0.1, 0.3, 0.5, 0.9, 1, 2, 5, 8]\n","\n","\n","\n","# results_summary = []\n","\n","\n","# for lambda_mod in lambda_mod_list:\n","#     print(f\"\\n==============================\")\n","#     print(f\" Running with λ_mod = {lambda_mod}\")\n","#     print(f\"==============================\")\n","\n","#     accuracies, precisions, recalls, f1_scores, aucs, ce_losses = [], [], [], [], [], []\n","\n","#     sss = StratifiedShuffleSplit(n_splits=20, test_size=0.1, random_state=SEED)\n","\n","#     for fold, (train_val_idx, test_idx_global) in enumerate(sss.split(X, y), start=1):\n","#         print(f\"\\n=== Fold {fold} ===\")\n","\n","#         cn_idx = np.where(y == 0)[0]\n","#         ad_idx = np.where(y == 1)[0]\n","\n","#         sss_class = StratifiedShuffleSplit(n_splits=20, test_size=0.1, random_state=fold)\n","#         cn_train_idx, _ = next(sss_class.split(X[cn_idx], y[cn_idx]))\n","#         ad_train_idx, _ = next(sss_class.split(X[ad_idx], y[ad_idx]))\n","\n","#         cn_train = cn_idx[cn_train_idx]\n","#         ad_train = ad_idx[ad_train_idx]\n","#         train_idx_final = np.concatenate([cn_train, ad_train])\n","#         np.random.shuffle(train_idx_final)\n","\n","#         print(f\"Train CN: {len(cn_train)}, Train AD: {len(ad_train)}\")\n","\n","#         train_idx_t = torch.from_numpy(train_idx_final).long().to(device)\n","#         y_train_tensor = torch.from_numpy(y[train_idx_final]).long().to(device)\n","\n","#         # Initialize model\n","#         model = GCN_SemiSupervised(feats_dim, hidden_dim, num_classes, device, activ=\"RELU\").to(device)\n","#         optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","#         ce_loss = nn.CrossEntropyLoss()\n","\n","#         # Training loop\n","#         for epoch in range(1, num_epochs + 1):\n","#             model.train()\n","#             optimizer.zero_grad()\n","\n","#             logits = model(data)\n","#             loss_sup = ce_loss(logits[train_idx_t], y_train_tensor)\n","#             loss_unsup = model.modularity_loss(A_tensor, logits)\n","#             total_loss = loss_sup + lambda_mod * loss_unsup\n","\n","#             total_loss.backward()\n","#             optimizer.step()\n","\n","#             if epoch % batch_print_freq == 0 or epoch == 1:\n","#                 model.eval()\n","#                 with torch.no_grad():\n","#                     preds_train = logits[train_idx_t].argmax(dim=1)\n","#                     acc_train = accuracy_score(y_train_tensor.cpu(), preds_train.cpu())\n","#                 print(f\"Fold {fold} Epoch {epoch}: \"\n","#                       f\"TotalLoss={total_loss.item():.6f} | Sup={loss_sup.item():.6f} | \"\n","#                       f\"Unsup={loss_unsup.item():.6f} | TrainAcc={acc_train:.4f}\")\n","\n","#         # Evaluation\n","#         model.eval()\n","#         with torch.no_grad():\n","#             out = model(data)\n","#             preds = out.argmax(dim=1).cpu().numpy()\n","#             probs = torch.softmax(out, dim=1)[:, 1].cpu().numpy()  # probability for \"AD\"\n","\n","#         y_test = y[test_idx_global]\n","#         y_pred_test = preds[test_idx_global]\n","#         y_prob_test = probs[test_idx_global]\n","\n","#         acc = accuracy_score(y_test, y_pred_test)\n","#         prec = precision_score(y_test, y_pred_test, zero_division=0)\n","#         rec = recall_score(y_test, y_pred_test, zero_division=0)\n","#         f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","#         auc = roc_auc_score(y_test, y_prob_test)\n","#         ce = log_loss(y_test, y_prob_test)\n","\n","#         accuracies.append(acc)\n","#         precisions.append(prec)\n","#         recalls.append(rec)\n","#         f1_scores.append(f1)\n","#         aucs.append(auc)\n","#         ce_losses.append(ce)\n","\n","#         print(f\"Fold {fold} → \"\n","#               f\"Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | \"\n","#               f\"F1={f1:.4f} | AUC={auc:.4f} | CE Loss={ce:.4f}\")\n","\n","#     # Average results per λ_mod\n","#     mean_acc, std_acc = np.mean(accuracies), np.std(accuracies)\n","#     mean_prec, std_prec = np.mean(precisions), np.std(precisions)\n","#     mean_rec, std_rec = np.mean(recalls), np.std(recalls)\n","#     mean_f1, std_f1 = np.mean(f1_scores), np.std(f1_scores)\n","#     mean_auc, std_auc = np.mean(aucs), np.std(aucs)\n","#     mean_ce, std_ce = np.mean(ce_losses), np.std(ce_losses)\n","\n","#     results_summary.append({\n","#         \"λ_mod\": lambda_mod,\n","#         \"Accuracy\": f\"{mean_acc:.4f} ± {std_acc:.4f}\",\n","#         \"Precision\": f\"{mean_prec:.4f} ± {std_prec:.4f}\",\n","#         \"Recall\": f\"{mean_rec:.4f} ± {std_rec:.4f}\",\n","#         \"F1\": f\"{mean_f1:.4f} ± {std_f1:.4f}\",\n","#         \"AUC\": f\"{mean_auc:.4f} ± {std_auc:.4f}\",\n","#         \"CE Loss\": f\"{mean_ce:.4f} ± {std_ce:.4f}\",\n","#     })\n","\n","#     print(f\"\\n=== λ_mod = {lambda_mod} → Average Results ===\")\n","#     print(f\"Accuracy:  {mean_acc:.4f} ± {std_acc:.4f}\")\n","#     print(f\"Precision: {mean_prec:.4f} ± {std_prec:.4f}\")\n","#     print(f\"Recall:    {mean_rec:.4f} ± {std_rec:.4f}\")\n","#     print(f\"F1-score:  {mean_f1:.4f} ± {std_f1:.4f}\")\n","#     print(f\"AUC:       {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n","#     print(f\"CE Loss:   {np.mean(ce_losses):.4f} ± {np.std(ce_losses):.4f}\")\n","\n","# # ==========================================\n","# # Final summary table for all λ_mod values\n","# # ==========================================\n","# print(\"\\n\\n========== FINAL SUMMARY TABLE (CN vs AD) ==========\")\n","# results_df = pd.DataFrame(results_summary)\n","# print(results_df.to_string(index=False))"],"metadata":{"id":"3UECXZ_gBjXE","executionInfo":{"status":"ok","timestamp":1767501770851,"user_tz":-330,"elapsed":40,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":16,"outputs":[]}]}
{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7qmgiP7WLaO","executionInfo":{"status":"ok","timestamp":1764334474375,"user_tz":-330,"elapsed":2751954,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"69fc7985-1c3a-49a0-c3c4-cb8c14ad4ff5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","/home/snu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"output_type":"stream","name":"stdout","text":["Dataset: nodes=300, feats=180\n","W0: (300, 300)\n","Number of edges: 13604\n","Using device: cuda\n","\n","=== Fold 1 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7409 | DGI=0.7102 | Reg=-0.2455 | Total=1.4266 | TrainAcc=0.4483\n","Epoch 500: Sup=0.0818 | DGI=0.6971 | Reg=-0.6040 | Total=0.7185 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0029 | DGI=0.6932 | Reg=-0.6312 | Total=0.6329 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0015 | DGI=0.6985 | Reg=-0.6471 | Total=0.6353 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.1265 | DGI=0.6975 | Reg=-0.6580 | Total=0.7582 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0789 | DGI=0.6932 | Reg=-0.6538 | Total=0.7067 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0004 | DGI=0.6956 | Reg=-0.6455 | Total=0.6315 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0002 | DGI=0.7021 | Reg=-0.6757 | Total=0.6347 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0251 | DGI=0.6932 | Reg=-0.6676 | Total=0.6515 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0280 | DGI=0.6947 | Reg=-0.6965 | Total=0.6530 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0073 | DGI=0.6932 | Reg=-0.6818 | Total=0.6323 | TrainAcc=1.0000\n","Fold 1 → Acc=0.7823 Prec=0.8485 Rec=0.7417 F1=0.7915 AUC=0.8748\n","\n","=== Fold 2 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7086 | DGI=0.7064 | Reg=-0.2378 | Total=1.3912 | TrainAcc=0.4483\n","Epoch 500: Sup=0.0527 | DGI=0.6941 | Reg=-0.6435 | Total=0.6825 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0110 | DGI=0.7102 | Reg=-0.6768 | Total=0.6535 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0552 | DGI=0.7019 | Reg=-0.7051 | Total=0.6866 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0056 | DGI=0.6932 | Reg=-0.6897 | Total=0.6298 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0328 | DGI=0.6938 | Reg=-0.6950 | Total=0.6571 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0009 | DGI=0.6931 | Reg=-0.6934 | Total=0.6247 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0010 | DGI=0.6939 | Reg=-0.6889 | Total=0.6260 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0001 | DGI=0.6935 | Reg=-0.6993 | Total=0.6237 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0014 | DGI=0.6931 | Reg=-0.7181 | Total=0.6227 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.1207 | DGI=0.6933 | Reg=-0.6754 | Total=0.7464 | TrainAcc=1.0000\n","Fold 2 → Acc=0.8081 Prec=0.8511 Rec=0.7947 F1=0.8219 AUC=0.8753\n","\n","=== Fold 3 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7400 | DGI=0.7126 | Reg=-0.2425 | Total=1.4284 | TrainAcc=0.5517\n","Epoch 500: Sup=0.0026 | DGI=0.6932 | Reg=-0.6869 | Total=0.6271 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0080 | DGI=0.6935 | Reg=-0.7586 | Total=0.6256 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0020 | DGI=0.6932 | Reg=-0.7739 | Total=0.6179 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0026 | DGI=0.6935 | Reg=-0.7524 | Total=0.6209 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0007 | DGI=0.6955 | Reg=-0.7392 | Total=0.6222 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0002 | DGI=0.6931 | Reg=-0.7764 | Total=0.6157 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0035 | DGI=0.7043 | Reg=-0.7644 | Total=0.6314 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0004 | DGI=0.6988 | Reg=-0.7799 | Total=0.6212 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0002 | DGI=0.6932 | Reg=-0.7839 | Total=0.6150 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0001 | DGI=0.6934 | Reg=-0.7893 | Total=0.6146 | TrainAcc=1.0000\n","Fold 3 → Acc=0.7897 Prec=0.8852 Rec=0.7152 F1=0.7912 AUC=0.8493\n","\n","=== Fold 4 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.6429 | DGI=0.7154 | Reg=-0.2391 | Total=1.3344 | TrainAcc=0.6552\n","Epoch 500: Sup=0.0114 | DGI=0.6963 | Reg=-0.6507 | Total=0.6427 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0019 | DGI=0.6959 | Reg=-0.6643 | Total=0.6313 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0008 | DGI=0.6932 | Reg=-0.6628 | Total=0.6277 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0093 | DGI=0.6936 | Reg=-0.6778 | Total=0.6352 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0003 | DGI=0.7030 | Reg=-0.7034 | Total=0.6329 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0001 | DGI=0.7052 | Reg=-0.7079 | Total=0.6344 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0027 | DGI=0.6966 | Reg=-0.7023 | Total=0.6291 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0009 | DGI=0.6939 | Reg=-0.7055 | Total=0.6243 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0005 | DGI=0.6931 | Reg=-0.7102 | Total=0.6226 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0011 | DGI=0.6936 | Reg=-0.7101 | Total=0.6237 | TrainAcc=1.0000\n","Fold 4 → Acc=0.7601 Prec=0.7722 Rec=0.8079 F1=0.7896 AUC=0.7658\n","\n","=== Fold 5 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.6663 | DGI=0.7161 | Reg=-0.2350 | Total=1.3588 | TrainAcc=0.6897\n","Epoch 500: Sup=0.0640 | DGI=0.6933 | Reg=-0.6291 | Total=0.6944 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0088 | DGI=0.6935 | Reg=-0.6202 | Total=0.6402 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0005 | DGI=0.6932 | Reg=-0.6311 | Total=0.6306 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0007 | DGI=0.6932 | Reg=-0.6633 | Total=0.6275 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0003 | DGI=0.6944 | Reg=-0.6663 | Total=0.6280 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0002 | DGI=0.6936 | Reg=-0.6632 | Total=0.6274 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0001 | DGI=0.6932 | Reg=-0.7001 | Total=0.6233 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0007 | DGI=0.6932 | Reg=-0.7163 | Total=0.6223 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0018 | DGI=0.6932 | Reg=-0.7099 | Total=0.6241 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0088 | DGI=0.6932 | Reg=-0.6659 | Total=0.6354 | TrainAcc=1.0000\n","Fold 5 → Acc=0.7860 Prec=0.7925 Rec=0.8344 F1=0.8129 AUC=0.8383\n","\n","=== Fold 6 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7518 | DGI=0.7138 | Reg=-0.2389 | Total=1.4418 | TrainAcc=0.5517\n","Epoch 500: Sup=0.0222 | DGI=0.6941 | Reg=-0.6781 | Total=0.6485 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0024 | DGI=0.6970 | Reg=-0.6927 | Total=0.6301 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0266 | DGI=0.6932 | Reg=-0.6893 | Total=0.6509 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0055 | DGI=0.6937 | Reg=-0.6977 | Total=0.6295 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0527 | DGI=0.6949 | Reg=-0.7090 | Total=0.6766 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0027 | DGI=0.6936 | Reg=-0.7182 | Total=0.6244 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0081 | DGI=0.6932 | Reg=-0.7373 | Total=0.6276 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0004 | DGI=0.6940 | Reg=-0.6900 | Total=0.6253 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0002 | DGI=0.6932 | Reg=-0.7372 | Total=0.6196 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0001 | DGI=0.6937 | Reg=-0.7390 | Total=0.6199 | TrainAcc=1.0000\n","Fold 6 → Acc=0.8192 Prec=0.8750 Rec=0.7881 F1=0.8293 AUC=0.8769\n","\n","=== Fold 7 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7331 | DGI=0.7126 | Reg=-0.2348 | Total=1.4223 | TrainAcc=0.4483\n","Epoch 500: Sup=0.0462 | DGI=0.6939 | Reg=-0.6619 | Total=0.6739 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.1299 | DGI=0.6932 | Reg=-0.6725 | Total=0.7559 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0036 | DGI=0.6932 | Reg=-0.6951 | Total=0.6273 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0108 | DGI=0.6981 | Reg=-0.7065 | Total=0.6382 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0002 | DGI=0.6969 | Reg=-0.6858 | Total=0.6285 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0013 | DGI=0.6933 | Reg=-0.6964 | Total=0.6249 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0027 | DGI=0.6932 | Reg=-0.7093 | Total=0.6250 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0010 | DGI=0.6931 | Reg=-0.7094 | Total=0.6232 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0003 | DGI=0.6931 | Reg=-0.6959 | Total=0.6238 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0015 | DGI=0.6934 | Reg=-0.7006 | Total=0.6249 | TrainAcc=1.0000\n","Fold 7 → Acc=0.7860 Prec=0.8496 Rec=0.7483 F1=0.7958 AUC=0.8424\n","\n","=== Fold 8 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7676 | DGI=0.7132 | Reg=-0.2372 | Total=1.4571 | TrainAcc=0.5517\n","Epoch 500: Sup=0.0559 | DGI=0.6932 | Reg=-0.6251 | Total=0.6866 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0250 | DGI=0.6933 | Reg=-0.6253 | Total=0.6557 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0045 | DGI=0.7072 | Reg=-0.6405 | Total=0.6476 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0356 | DGI=0.6933 | Reg=-0.6073 | Total=0.6682 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0078 | DGI=0.6932 | Reg=-0.6406 | Total=0.6369 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0034 | DGI=0.6931 | Reg=-0.6648 | Total=0.6301 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0093 | DGI=0.6983 | Reg=-0.6618 | Total=0.6414 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0004 | DGI=0.6934 | Reg=-0.6578 | Total=0.6281 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0225 | DGI=0.6932 | Reg=-0.6548 | Total=0.6502 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0008 | DGI=0.6933 | Reg=-0.6469 | Total=0.6294 | TrainAcc=1.0000\n","Fold 8 → Acc=0.7712 Prec=0.7871 Rec=0.8079 F1=0.7974 AUC=0.8420\n","\n","=== Fold 9 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7054 | DGI=0.7191 | Reg=-0.2369 | Total=1.4007 | TrainAcc=0.5517\n","Epoch 500: Sup=0.0474 | DGI=0.6943 | Reg=-0.6263 | Total=0.6791 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0036 | DGI=0.6952 | Reg=-0.6413 | Total=0.6347 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0014 | DGI=0.6969 | Reg=-0.6481 | Total=0.6335 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0291 | DGI=0.6936 | Reg=-0.6886 | Total=0.6538 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0029 | DGI=0.6934 | Reg=-0.6873 | Total=0.6276 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0058 | DGI=0.6972 | Reg=-0.6875 | Total=0.6342 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0003 | DGI=0.6966 | Reg=-0.7088 | Total=0.6260 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0002 | DGI=0.6932 | Reg=-0.7059 | Total=0.6228 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0019 | DGI=0.6935 | Reg=-0.6963 | Total=0.6259 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0001 | DGI=0.6932 | Reg=-0.6957 | Total=0.6236 | TrainAcc=1.0000\n","Fold 9 → Acc=0.7159 Prec=0.7681 Rec=0.7020 F1=0.7336 AUC=0.8118\n","\n","=== Fold 10 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7477 | DGI=0.7104 | Reg=-0.2372 | Total=1.4344 | TrainAcc=0.5517\n","Epoch 500: Sup=0.0388 | DGI=0.6936 | Reg=-0.6778 | Total=0.6646 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0078 | DGI=0.7000 | Reg=-0.6871 | Total=0.6391 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0440 | DGI=0.6944 | Reg=-0.7056 | Total=0.6679 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0076 | DGI=0.6933 | Reg=-0.7235 | Total=0.6285 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0402 | DGI=0.6943 | Reg=-0.7177 | Total=0.6627 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0252 | DGI=0.6941 | Reg=-0.7320 | Total=0.6461 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.1510 | DGI=0.6936 | Reg=-0.7315 | Total=0.7714 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0004 | DGI=0.6967 | Reg=-0.7251 | Total=0.6246 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0019 | DGI=0.6942 | Reg=-0.7202 | Total=0.6240 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0004 | DGI=0.6942 | Reg=-0.7010 | Total=0.6245 | TrainAcc=1.0000\n","Fold 10 → Acc=0.8044 Prec=0.8451 Rec=0.7947 F1=0.8191 AUC=0.8359\n","\n","=== Fold 11 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7168 | DGI=0.7170 | Reg=-0.2347 | Total=1.4104 | TrainAcc=0.5517\n","Epoch 500: Sup=0.0680 | DGI=0.6932 | Reg=-0.6459 | Total=0.6966 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0363 | DGI=0.6932 | Reg=-0.6603 | Total=0.6635 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0458 | DGI=0.6943 | Reg=-0.6610 | Total=0.6740 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0055 | DGI=0.6936 | Reg=-0.7039 | Total=0.6287 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0066 | DGI=0.6932 | Reg=-0.6951 | Total=0.6303 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0019 | DGI=0.6948 | Reg=-0.6969 | Total=0.6269 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0611 | DGI=0.6932 | Reg=-0.6950 | Total=0.6848 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0001 | DGI=0.6933 | Reg=-0.7071 | Total=0.6227 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0163 | DGI=0.6932 | Reg=-0.7162 | Total=0.6379 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0002 | DGI=0.6951 | Reg=-0.7331 | Total=0.6220 | TrainAcc=1.0000\n","Fold 11 → Acc=0.7048 Prec=0.7415 Rec=0.7219 F1=0.7315 AUC=0.7212\n","\n","=== Fold 12 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.6657 | DGI=0.7087 | Reg=-0.2401 | Total=1.3504 | TrainAcc=0.5517\n","Epoch 500: Sup=0.0248 | DGI=0.6943 | Reg=-0.7150 | Total=0.6477 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0420 | DGI=0.6937 | Reg=-0.7072 | Total=0.6649 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0103 | DGI=0.6932 | Reg=-0.7283 | Total=0.6307 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0027 | DGI=0.6935 | Reg=-0.7250 | Total=0.6237 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0024 | DGI=0.6932 | Reg=-0.7286 | Total=0.6227 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0013 | DGI=0.6940 | Reg=-0.7555 | Total=0.6198 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.1108 | DGI=0.6934 | Reg=-0.7166 | Total=0.7326 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0120 | DGI=0.6963 | Reg=-0.7241 | Total=0.6359 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0028 | DGI=0.6931 | Reg=-0.7300 | Total=0.6230 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0266 | DGI=0.6935 | Reg=-0.7370 | Total=0.6464 | TrainAcc=1.0000\n","Fold 12 → Acc=0.7934 Prec=0.8740 Rec=0.7351 F1=0.7986 AUC=0.8731\n","\n","=== Fold 13 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7773 | DGI=0.7152 | Reg=-0.2340 | Total=1.4691 | TrainAcc=0.5517\n","Epoch 500: Sup=0.0340 | DGI=0.6933 | Reg=-0.6628 | Total=0.6610 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0285 | DGI=0.6956 | Reg=-0.7173 | Total=0.6523 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0141 | DGI=0.6947 | Reg=-0.7176 | Total=0.6370 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0067 | DGI=0.6932 | Reg=-0.7190 | Total=0.6280 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0114 | DGI=0.6932 | Reg=-0.7143 | Total=0.6332 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0030 | DGI=0.6935 | Reg=-0.7413 | Total=0.6224 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0084 | DGI=0.6975 | Reg=-0.7262 | Total=0.6333 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0578 | DGI=0.7009 | Reg=-0.7092 | Total=0.6878 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0015 | DGI=0.6932 | Reg=-0.7470 | Total=0.6200 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0035 | DGI=0.6952 | Reg=-0.7391 | Total=0.6248 | TrainAcc=1.0000\n","Fold 13 → Acc=0.8155 Prec=0.8582 Rec=0.8013 F1=0.8288 AUC=0.8993\n","\n","=== Fold 14 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7059 | DGI=0.7080 | Reg=-0.2372 | Total=1.3902 | TrainAcc=0.7241\n","Epoch 500: Sup=0.0858 | DGI=0.6943 | Reg=-0.6261 | Total=0.7175 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0091 | DGI=0.6948 | Reg=-0.6718 | Total=0.6367 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0177 | DGI=0.6932 | Reg=-0.6645 | Total=0.6444 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0090 | DGI=0.6978 | Reg=-0.6670 | Total=0.6401 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.2526 | DGI=0.6932 | Reg=-0.6850 | Total=0.8773 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0178 | DGI=0.6951 | Reg=-0.6621 | Total=0.6468 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0005 | DGI=0.7031 | Reg=-0.6767 | Total=0.6359 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0005 | DGI=0.6937 | Reg=-0.6582 | Total=0.6284 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0027 | DGI=0.6967 | Reg=-0.6626 | Total=0.6331 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0210 | DGI=0.7328 | Reg=-0.6728 | Total=0.6865 | TrainAcc=1.0000\n","Fold 14 → Acc=0.7897 Prec=0.8176 Rec=0.8013 F1=0.8094 AUC=0.8673\n","\n","=== Fold 15 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7383 | DGI=0.7098 | Reg=-0.2361 | Total=1.4245 | TrainAcc=0.4483\n","Epoch 500: Sup=0.0331 | DGI=0.6988 | Reg=-0.6593 | Total=0.6660 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0287 | DGI=0.6949 | Reg=-0.7060 | Total=0.6530 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0040 | DGI=0.6953 | Reg=-0.7122 | Total=0.6281 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0073 | DGI=0.6934 | Reg=-0.7275 | Total=0.6280 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0008 | DGI=0.6932 | Reg=-0.7224 | Total=0.6218 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0003 | DGI=0.6938 | Reg=-0.7227 | Total=0.6218 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.1086 | DGI=0.7008 | Reg=-0.7277 | Total=0.7366 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0051 | DGI=0.6932 | Reg=-0.6930 | Total=0.6290 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0010 | DGI=0.6932 | Reg=-0.7245 | Total=0.6218 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0003 | DGI=0.6989 | Reg=-0.7412 | Total=0.6250 | TrainAcc=1.0000\n","Fold 15 → Acc=0.8007 Prec=0.9008 Rec=0.7219 F1=0.8015 AUC=0.8593\n","\n","=== Fold 16 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7569 | DGI=0.7131 | Reg=-0.2437 | Total=1.4456 | TrainAcc=0.5172\n","Epoch 500: Sup=0.0617 | DGI=0.6964 | Reg=-0.6114 | Total=0.6969 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0841 | DGI=0.6932 | Reg=-0.6908 | Total=0.7081 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0372 | DGI=0.6932 | Reg=-0.6710 | Total=0.6634 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0791 | DGI=0.6972 | Reg=-0.6985 | Total=0.7064 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0810 | DGI=0.6944 | Reg=-0.7549 | Total=0.7000 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0440 | DGI=0.6937 | Reg=-0.7084 | Total=0.6668 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0036 | DGI=0.6934 | Reg=-0.7147 | Total=0.6256 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0157 | DGI=0.6932 | Reg=-0.7189 | Total=0.6370 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0014 | DGI=0.6932 | Reg=-0.7444 | Total=0.6201 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0997 | DGI=0.6937 | Reg=-0.7219 | Total=0.7212 | TrainAcc=1.0000\n","Fold 16 → Acc=0.7860 Prec=0.8394 Rec=0.7616 F1=0.7986 AUC=0.8550\n","\n","=== Fold 17 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.6988 | DGI=0.7145 | Reg=-0.2393 | Total=1.3893 | TrainAcc=0.4483\n","Epoch 500: Sup=0.0189 | DGI=0.6932 | Reg=-0.5563 | Total=0.6565 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0739 | DGI=0.7144 | Reg=-0.5841 | Total=0.7298 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0230 | DGI=0.6945 | Reg=-0.5896 | Total=0.6586 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0078 | DGI=0.6989 | Reg=-0.6328 | Total=0.6434 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0041 | DGI=0.6948 | Reg=-0.5934 | Total=0.6396 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0003 | DGI=0.6960 | Reg=-0.6560 | Total=0.6308 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0046 | DGI=0.6934 | Reg=-0.6275 | Total=0.6352 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.2249 | DGI=0.6936 | Reg=-0.6438 | Total=0.8541 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0002 | DGI=0.6931 | Reg=-0.6315 | Total=0.6302 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0011 | DGI=0.6966 | Reg=-0.6104 | Total=0.6366 | TrainAcc=1.0000\n","Fold 17 → Acc=0.7970 Prec=0.8934 Rec=0.7219 F1=0.7985 AUC=0.8777\n","\n","=== Fold 18 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7113 | DGI=0.7147 | Reg=-0.2395 | Total=1.4021 | TrainAcc=0.5517\n","Epoch 500: Sup=0.1066 | DGI=0.6939 | Reg=-0.6221 | Total=0.7383 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0124 | DGI=0.6933 | Reg=-0.6222 | Total=0.6435 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0455 | DGI=0.6933 | Reg=-0.6509 | Total=0.6737 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0216 | DGI=0.6934 | Reg=-0.6399 | Total=0.6510 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0068 | DGI=0.6933 | Reg=-0.6630 | Total=0.6338 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.1327 | DGI=0.6932 | Reg=-0.6973 | Total=0.7562 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0072 | DGI=0.6991 | Reg=-0.7062 | Total=0.6356 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0051 | DGI=0.6934 | Reg=-0.7021 | Total=0.6284 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0006 | DGI=0.7020 | Reg=-0.7022 | Total=0.6323 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0002 | DGI=0.6965 | Reg=-0.7043 | Total=0.6263 | TrainAcc=1.0000\n","Fold 18 → Acc=0.7491 Prec=0.7943 Rec=0.7417 F1=0.7671 AUC=0.8393\n","\n","=== Fold 19 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.6582 | DGI=0.7121 | Reg=-0.2397 | Total=1.3463 | TrainAcc=0.5517\n","Epoch 500: Sup=0.0700 | DGI=0.7003 | Reg=-0.6763 | Total=0.7028 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.1076 | DGI=0.7415 | Reg=-0.7407 | Total=0.7750 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.1040 | DGI=0.6932 | Reg=-0.7441 | Total=0.7228 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0002 | DGI=0.7001 | Reg=-0.7444 | Total=0.6258 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0060 | DGI=0.7012 | Reg=-0.7551 | Total=0.6317 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0527 | DGI=0.6932 | Reg=-0.7352 | Total=0.6724 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0002 | DGI=0.6932 | Reg=-0.7507 | Total=0.6183 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0123 | DGI=0.6957 | Reg=-0.7527 | Total=0.6327 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0082 | DGI=0.6933 | Reg=-0.7684 | Total=0.6246 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0002 | DGI=0.6955 | Reg=-0.7512 | Total=0.6206 | TrainAcc=1.0000\n","Fold 19 → Acc=0.8155 Prec=0.8915 Rec=0.7616 F1=0.8214 AUC=0.8558\n","\n","=== Fold 20 ===\n","Train CN: 13, Train MCI: 16\n","Test CN: 120, Test MCI: 151\n","Epoch 1: Sup=0.7047 | DGI=0.7121 | Reg=-0.2388 | Total=1.3930 | TrainAcc=0.5517\n","Epoch 500: Sup=0.0738 | DGI=0.6932 | Reg=-0.7797 | Total=0.6890 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0091 | DGI=0.6932 | Reg=-0.7783 | Total=0.6245 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0002 | DGI=0.6932 | Reg=-0.7860 | Total=0.6147 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0013 | DGI=0.6931 | Reg=-0.7942 | Total=0.6151 | TrainAcc=1.0000\n","Epoch 2500: Sup=0.0002 | DGI=0.6932 | Reg=-0.7848 | Total=0.6149 | TrainAcc=1.0000\n","Epoch 3000: Sup=0.0000 | DGI=0.6932 | Reg=-0.7915 | Total=0.6140 | TrainAcc=1.0000\n","Epoch 3500: Sup=0.0072 | DGI=0.6942 | Reg=-0.7967 | Total=0.6217 | TrainAcc=1.0000\n","Epoch 4000: Sup=0.0024 | DGI=0.6932 | Reg=-0.7968 | Total=0.6159 | TrainAcc=1.0000\n","Epoch 4500: Sup=0.0000 | DGI=0.7095 | Reg=-0.8022 | Total=0.6292 | TrainAcc=1.0000\n","Epoch 5000: Sup=0.0006 | DGI=0.6934 | Reg=-0.8167 | Total=0.6123 | TrainAcc=1.0000\n","Fold 20 → Acc=0.7675 Prec=0.8284 Rec=0.7351 F1=0.7789 AUC=0.8045\n","\n","=== Average Results ===\n","Accuracy: 0.7821 ± 0.0299\n","Precision: 0.8357 ± 0.0454\n","Recall: 0.7619 ± 0.0377\n","F1: 0.7958 ± 0.0263\n","LogLoss: 1.6878 ± 0.4758\n","AUC: 0.8432 ± 0.0406\n"]}],"source":["# combined_dgi_arma_cutloss.py\n","import os\n","import sys\n","import numpy as np\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.data import Data\n","from torch_geometric.nn import ARMAConv\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_auc_score\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# ------------------------\n","# Reproducibility / seeds\n","# ------------------------\n","SEED = 42\n","np.random.seed(SEED)\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","torch.set_num_threads(4)\n","\n","# ------------------------\n","# Paths to your data\n","# ------------------------\n","fa_cn = \"/home/snu/Downloads/Histogram_CN_FA_20bin_updated.npy\"\n","fa_mci = \"/home/snu/Downloads/Histogram_MCI_FA_20bin_updated.npy\"\n","# ------------------------\n","# Load features & labels\n","# ------------------------\n","X_cn = np.load(fa_cn, allow_pickle=True)\n","X_mci = np.load(fa_mci, allow_pickle=True)\n","\n","X = np.vstack([X_cn, X_mci]).astype(np.float32)\n","y = np.hstack([\n","    np.zeros(X_cn.shape[0], dtype=np.int64),\n","    np.ones(X_mci.shape[0], dtype=np.int64)\n","])\n","\n","# shuffle dataset\n","perm = np.random.RandomState(SEED).permutation(len(X))\n","X = X[perm]\n","y = y[perm]\n","\n","num_nodes, num_feats = X.shape\n","print(f\"Dataset: nodes={num_nodes}, feats={num_feats}\")\n","\n","# ------------------------\n","# adjacency building\n","# ------------------------\n","def create_adj(F, alpha=1.0):\n","    norms = np.linalg.norm(F, axis=1, keepdims=True)\n","    norms[norms == 0] = 1.0\n","    F_norm = F / norms\n","    W = np.dot(F_norm, F_norm.T)\n","    W = (W >= alpha).astype(np.float32)\n","    return W\n","\n","W0 = create_adj(X, alpha=0.92)\n","print(f\"W0: {W0.shape}\")\n","\n","def load_graph_torch(adj, node_feats):\n","    node_feats_t = torch.from_numpy(node_feats).float()\n","    edge_idx = np.array(np.nonzero(adj))\n","    edge_index = torch.from_numpy(edge_idx).long()\n","    return node_feats_t, edge_index\n","\n","node_feats_all, edge_index_all = load_graph_torch(W0, X)\n","print(f\"Number of edges: {edge_index_all.size(1)}\")\n","\n","# ------------------------\n","# model components\n","# ------------------------\n","class ARMAEncoder(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_stacks=1, num_layers=1, activ=\"RELU\"):\n","        super(ARMAEncoder, self).__init__()\n","        activations = {\n","            \"SELU\": F.selu,\n","            \"SiLU\": F.silu,\n","            \"GELU\": F.gelu,\n","            \"ELU\": F.elu,\n","            \"RELU\": F.relu\n","        }\n","        self.act = activations.get(activ, F.elu)\n","        self.arma = ARMAConv(\n","            input_dim, hidden_dim,\n","            num_stacks=num_stacks,\n","            num_layers=num_layers,\n","            shared_weights=True,\n","            dropout=0.3\n","        )\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.arma(x, edge_index)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        x = self.batchnorm(x)\n","        logits = self.mlp(x)\n","        return logits\n","\n","class AvgReadout(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, seq, msk=None):\n","        if msk is None:\n","            return torch.mean(seq, 0)\n","        else:\n","            msk = torch.unsqueeze(msk, -1)\n","            return torch.sum(seq * msk, 0) / torch.sum(msk)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, n_h):\n","        super().__init__()\n","        self.f_k = nn.Bilinear(n_h, n_h, 1)\n","        nn.init.xavier_uniform_(self.f_k.weight.data)\n","        if self.f_k.bias is not None:\n","            self.f_k.bias.data.fill_(0.0)\n","\n","    def forward(self, c, h_pl, h_mi):\n","        c_x = torch.unsqueeze(c, 0).expand_as(h_pl)\n","        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 1)\n","        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 1)\n","        logits = torch.cat((sc_1, sc_2), 0)\n","        return logits\n","\n","class DGI(nn.Module):\n","    def __init__(self, n_in, n_h, num_stacks=2, num_layers=1):\n","        super().__init__()\n","        self.gcn1 = ARMAEncoder(n_in, n_h, num_stacks=num_stacks, num_layers=num_layers)\n","        self.read = AvgReadout()\n","        self.sigm = nn.Sigmoid()\n","        self.disc = Discriminator(n_h)\n","\n","    def forward(self, seq1, seq2, edge_index):\n","        data1 = Data(x=seq1, edge_index=edge_index)\n","        data2 = Data(x=seq2, edge_index=edge_index)\n","        h_1 = self.gcn1(data1)\n","        c = self.read(h_1)\n","        c = self.sigm(c)\n","        h_2 = self.gcn1(data2)\n","        logits = self.disc(c, h_1, h_2)\n","        return logits, h_1\n","\n","class DGI_with_classifier(DGI):\n","    def __init__(self, n_in, n_h, n_classes=2, cut=0, device='cpu', num_stacks=2, num_layers=1):\n","        super().__init__(n_in, n_h, num_stacks=num_stacks, num_layers=num_layers)\n","        self.classifier = nn.Linear(n_h, n_classes)\n","        self.cut = cut\n","        self.device = device\n","        self.n_clusters = n_classes\n","\n","    def get_embeddings(self, node_feats, edge_index):\n","        _, embeddings = self.forward(node_feats, node_feats, edge_index)\n","        return embeddings\n","\n","    def cut_loss(self, A, S):\n","        C = F.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, C).t(), C)\n","        num = torch.trace(A_pool)\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, C).t(), C)\n","        den = torch.trace(D_pooled) + 1e-9\n","        mincut_loss = -(num / den)\n","        St_S = torch.matmul(C.t(), C)\n","        I_S = torch.eye(C.shape[1], device=A.device)\n","        ortho_loss = torch.norm(St_S / (torch.norm(St_S) + 1e-9) - I_S / (torch.norm(I_S) + 1e-9))\n","        return mincut_loss + ortho_loss\n","\n","    def modularity_loss(self, A, S):\n","        C = F.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A) + 1e-9\n","        B = A - torch.outer(d, d) / (2 * m)\n","        I_S = torch.eye(C.shape[1], device=A.device)\n","        k = torch.norm(I_S)\n","        n = S.shape[0]\n","        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n","        return modularity_term + collapse_reg_term\n","\n","    def Reg_loss(self, A, embeddings):\n","        logits = self.classifier(embeddings)\n","        if self.cut == 1:\n","            return self.cut_loss(A, logits)\n","        else:\n","            return self.modularity_loss(A, logits)\n","\n","# ------------------------\n","# Prepare cross-validation\n","# ------------------------\n","sss = StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=SEED)\n","accuracies, precisions, recalls, f1_scores, losses = [], [], [], [], []\n","all_auc = []\n","\n","def get_device():\n","    try:\n","        if torch.cuda.is_available():\n","            dev = torch.device(\"cuda\")\n","            torch.tensor([1.0], device=dev) + 1.0\n","            return dev\n","    except Exception as e:\n","        print(\"CUDA not usable, falling back to CPU:\", e)\n","        try:\n","            torch.cuda.empty_cache()\n","        except:\n","            pass\n","    return torch.device(\"cpu\")\n","\n","device = get_device()\n","print(\"Using device:\", device)\n","\n","A_tensor = torch.from_numpy(W0).float().to(device)\n","hidden_dim = 512\n","cut = 1\n","num_epochs = 5000\n","lr = 1e-4\n","weight_decay = 1e-4\n","reg_weight = 0.1\n","num_stacks = 2\n","num_layers = 1\n","\n","node_feats = node_feats_all.to(device)\n","edge_index = edge_index_all.to(device)\n","\n","N = node_feats.size(0)\n","lbl = torch.cat([torch.ones(N, device=device), torch.zeros(N, device=device)]).float()\n","\n","for fold, (train_idx, test_idx) in enumerate(sss.split(X, y), start=1):\n","    print(f\"\\n=== Fold {fold} ===\")\n","\n","    cn_idx = np.where(y == 0)[0]\n","    mci_idx = np.where(y == 1)[0]\n","\n","    sss_class = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=fold)\n","    cn_train_idx, cn_test_idx = next(sss_class.split(X[cn_idx], y[cn_idx]))\n","    mci_train_idx, mci_test_idx = next(sss_class.split(X[mci_idx], y[mci_idx]))\n","\n","    cn_train = cn_idx[cn_train_idx]\n","    mci_train = mci_idx[mci_train_idx]\n","    cn_test = cn_idx[cn_test_idx]\n","    mci_test = mci_idx[mci_test_idx]\n","\n","    balanced_train_idx = np.concatenate([cn_train, mci_train])\n","    test_idx_final = np.concatenate([cn_test, mci_test])\n","    np.random.shuffle(balanced_train_idx)\n","    np.random.shuffle(test_idx_final)\n","\n","    print(f\"Train CN: {len(cn_train)}, Train MCI: {len(mci_train)}\")\n","    print(f\"Test CN: {len(cn_test)}, Test MCI: {len(mci_test)}\")\n","\n","    y_tensor = torch.from_numpy(y).long().to(device)\n","    train_idx_t = torch.from_numpy(balanced_train_idx).long().to(device)\n","    test_idx_t = torch.from_numpy(test_idx_final).long().to(device)\n","\n","    model = DGI_with_classifier(num_feats, hidden_dim, n_classes=2, cut=cut, device=device, num_stacks=num_stacks, num_layers=num_layers).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    bce_loss = nn.BCEWithLogitsLoss()\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","    for epoch in range(1, num_epochs + 1):\n","        model.train()\n","        optimizer.zero_grad()\n","        perm = torch.randperm(N, device=device)\n","        corrupt = node_feats[perm]\n","        logits_dgi, embeddings = model(node_feats, corrupt, edge_index)\n","        dgi_loss = bce_loss(logits_dgi.squeeze(), lbl)\n","        logits_cls = model.classifier(embeddings)\n","        train_logits = logits_cls[train_idx_t]\n","        train_labels = y_tensor[train_idx_t]\n","        supervised_loss = ce_loss(train_logits, train_labels)\n","        reg_loss_val = model.Reg_loss(A_tensor, embeddings)\n","        total_loss = supervised_loss + dgi_loss + reg_weight * reg_loss_val\n","        total_loss.backward()\n","        optimizer.step()\n","\n","        if epoch % 500 == 0 or epoch == 1:\n","            model.eval()\n","            with torch.no_grad():\n","                logits_eval = model.classifier(model.get_embeddings(node_feats, edge_index))\n","                preds_train = torch.argmax(logits_eval[train_idx_t], dim=1).cpu().numpy()\n","                acc = accuracy_score(train_labels.cpu().numpy(), preds_train)\n","            print(f\"Epoch {epoch}: Sup={supervised_loss.item():.4f} | DGI={dgi_loss.item():.4f} | Reg={reg_loss_val.item():.4f} | Total={total_loss.item():.4f} | TrainAcc={acc:.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        emb_final = model.get_embeddings(node_feats, edge_index)\n","        logits_final = model.classifier(emb_final)\n","        probs = F.softmax(logits_final, dim=1).cpu().numpy()\n","        y_pred = np.argmax(probs, axis=1)\n","\n","    y_test = y[test_idx_final]\n","    y_pred_test = y_pred[test_idx_final]\n","    y_proba_test = probs[test_idx_final, 1]\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","    loss_val = log_loss(y_test, y_proba_test)\n","    auc_score = roc_auc_score(y_test, y_proba_test)\n","\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    losses.append(loss_val)\n","    all_auc.append(auc_score)\n","\n","    print(f\"Fold {fold} → Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} F1={f1:.4f} AUC={auc_score:.4f}\")\n","\n","print(\"\\n=== Average Results ===\")\n","print(f\"Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n","print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n","print(f\"Recall: {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n","print(f\"F1: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n","print(f\"LogLoss: {np.mean(losses):.4f} ± {np.std(losses):.4f}\")\n","print(f\"AUC: {np.mean(all_auc):.4f} ± {np.std(all_auc):.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WypTtPKFWLaT"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"}},"nbformat":4,"nbformat_minor":0}
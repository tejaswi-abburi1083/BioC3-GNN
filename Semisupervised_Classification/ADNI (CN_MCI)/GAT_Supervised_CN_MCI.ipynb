{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqDwVNkZjstI+UUpkt+rjd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ZhoWIduU0285","executionInfo":{"status":"ok","timestamp":1767072751829,"user_tz":-330,"elapsed":1825,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a3b3903-d392-4aac-fd37-3aee1d55c52b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","/home/snu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","import torch.optim as optim\n","import numpy as np\n","import random\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GATConv\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score,\n","    f1_score, roc_auc_score, log_loss\n",")"]},{"cell_type":"code","source":["fa_feature_path = \"/home/snu/Downloads/Histogram_CN_FA_20bin_updated.npy\"\n","Histogram_feature_CN_FA_array = np.load(fa_feature_path, allow_pickle=True)\n","\n","fa_feature_path = \"/home/snu/Downloads/Histogram_MCI_FA_20bin_updated.npy\"\n","Histogram_feature_MCI_FA_array = np.load(fa_feature_path, allow_pickle=True)\n","\n","X = np.vstack([Histogram_feature_CN_FA_array, Histogram_feature_MCI_FA_array])\n","y = np.hstack([\n","    np.zeros(Histogram_feature_CN_FA_array.shape[0], dtype=np.int64),\n","    np.ones(Histogram_feature_MCI_FA_array.shape[0], dtype=np.int64)\n","])\n","\n","num_nodes, num_feats = X.shape\n","print(f\"Features: {X.shape}, Labels: {y.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgv5wIW403rR","executionInfo":{"status":"ok","timestamp":1767072751884,"user_tz":-330,"elapsed":53,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"a04d24ea-cbad-4740-bbaf-8b6457ecc534"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Features: (300, 180), Labels: (300,)\n"]}]},{"cell_type":"code","source":["class GAT_Supervised(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, heads=4, activ=\"RELU\", dropout=0.2):\n","        super(GAT_Supervised, self).__init__()\n","        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True, dropout=dropout)\n","        self.bn1 = nn.BatchNorm1d(hidden_dim * heads)\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hidden_dim * heads, output_dim)\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu,\n","            \"ELU\": nnFn.elu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = self.bn1(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        logits = self.fc(x)\n","        return logits"],"metadata":{"id":"rfbVT3Yp05dB","executionInfo":{"status":"ok","timestamp":1767072751888,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def create_adj(F, alpha=1):\n","    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","    W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","    W = W / W.max()\n","    return W\n","\n","def load_data(adj, node_feats):\n","    node_feats = torch.from_numpy(node_feats).float()\n","    edge_index = torch.from_numpy(np.array(np.nonzero((adj > 0))))\n","    return Data(x=node_feats, edge_index=edge_index)"],"metadata":{"id":"8AUYk2fh0_iR","executionInfo":{"status":"ok","timestamp":1767072751892,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","alpha = 0.92\n","feats_dim = num_feats\n","hidden_dim = 512\n","num_classes = 2\n","num_epochs = 2000\n","lr = 0.0001\n","weight_decay = 1e-4\n","batch_print_freq = 100"],"metadata":{"id":"5xD2P7ic1B65","executionInfo":{"status":"ok","timestamp":1767072751949,"user_tz":-330,"elapsed":54,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["W = create_adj(X, alpha)\n","data = load_data(W, X).to(device)\n","A_tensor = torch.from_numpy(W).float().to(device)\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-mfsholh1Erx","executionInfo":{"status":"ok","timestamp":1767072752090,"user_tz":-330,"elapsed":138,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"c26e1ef5-03b1-41f4-a235-bc947e2496f7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Data(x=[300, 180], edge_index=[2, 13604])\n"]}]},{"cell_type":"code","source":["sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=42)\n","\n","accuracies, precisions, recalls, f1_scores, aucs, ce_losses = [], [], [], [], [], []\n","\n","for fold, (train_idx, test_idx) in enumerate(sss.split(X, y), start=1):\n","    print(f\"\\n=== Fold {fold} ===\")\n","\n","    train_idx_t = torch.from_numpy(train_idx).long().to(device)\n","    y_train_tensor = torch.from_numpy(y[train_idx]).long().to(device)\n","\n","    model = GAT_Supervised(feats_dim, hidden_dim, num_classes).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","\n","    for epoch in range(1, num_epochs + 1):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        logits = model(data)\n","        loss = ce_loss(logits[train_idx_t], y_train_tensor)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if epoch % batch_print_freq == 0 or epoch == 1:\n","            model.eval()\n","            with torch.no_grad():\n","                preds_train = logits[train_idx_t].argmax(dim=1)\n","                acc_train = accuracy_score(y_train_tensor.cpu(), preds_train.cpu())\n","            print(f\"Fold {fold} Epoch {epoch}: \"\n","                  f\"Loss={loss.item():.6f} | TrainAcc={acc_train:.4f}\")\n","\n","\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data)\n","        preds = out.argmax(dim=1).cpu().numpy()\n","        probs = torch.softmax(out, dim=1)[:, 1].cpu().numpy()  # Probability for class 1\n","\n","    y_test = y[test_idx]\n","    y_pred_test = preds[test_idx]\n","    y_prob_test = probs[test_idx]\n","\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","    auc = roc_auc_score(y_test, y_prob_test)\n","    ce = log_loss(y_test, y_prob_test)\n","\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    aucs.append(auc)\n","    ce_losses.append(ce)\n","\n","    print(f\"Fold {fold} → \"\n","          f\"Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | \"\n","          f\"F1={f1:.4f} | AUC={auc:.4f} | CE Loss={ce:.4f}\")\n","\n","\n","print(\"\\n=== Average Results Across 20 Folds ===\")\n","print(f\"Accuracy:  {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n","print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n","print(f\"Recall:    {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n","print(f\"F1-score:  {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n","print(f\"CE Loss:   {np.mean(ce_losses):.4f} ± {np.std(ce_losses):.4f}\")\n","print(f\"AUC:       {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBy-hReA1Hqa","executionInfo":{"status":"ok","timestamp":1767072965031,"user_tz":-330,"elapsed":212935,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"a075fb08-158e-4365-c208-a2c4c1e6cdbe"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Fold 1 ===\n","Fold 1 Epoch 1: Loss=0.983016 | TrainAcc=0.2667\n","Fold 1 Epoch 100: Loss=0.156264 | TrainAcc=0.9000\n","Fold 1 Epoch 200: Loss=0.097616 | TrainAcc=0.9667\n","Fold 1 Epoch 300: Loss=0.059547 | TrainAcc=1.0000\n","Fold 1 Epoch 400: Loss=0.039748 | TrainAcc=1.0000\n","Fold 1 Epoch 500: Loss=0.020396 | TrainAcc=1.0000\n","Fold 1 Epoch 600: Loss=0.007938 | TrainAcc=1.0000\n","Fold 1 Epoch 700: Loss=0.005601 | TrainAcc=1.0000\n","Fold 1 Epoch 800: Loss=0.005070 | TrainAcc=1.0000\n","Fold 1 Epoch 900: Loss=0.004880 | TrainAcc=1.0000\n","Fold 1 Epoch 1000: Loss=0.003691 | TrainAcc=1.0000\n","Fold 1 Epoch 1100: Loss=0.004786 | TrainAcc=1.0000\n","Fold 1 Epoch 1200: Loss=0.002614 | TrainAcc=1.0000\n","Fold 1 Epoch 1300: Loss=0.002215 | TrainAcc=1.0000\n","Fold 1 Epoch 1400: Loss=0.003009 | TrainAcc=1.0000\n","Fold 1 Epoch 1500: Loss=0.001075 | TrainAcc=1.0000\n","Fold 1 Epoch 1600: Loss=0.002446 | TrainAcc=1.0000\n","Fold 1 Epoch 1700: Loss=0.004079 | TrainAcc=1.0000\n","Fold 1 Epoch 1800: Loss=0.001536 | TrainAcc=1.0000\n","Fold 1 Epoch 1900: Loss=0.001679 | TrainAcc=1.0000\n","Fold 1 Epoch 2000: Loss=0.000934 | TrainAcc=1.0000\n","Fold 1 → Acc=0.7741 | Prec=0.7665 | Rec=0.8533 | F1=0.8076 | AUC=0.8504 | CE Loss=1.4626\n","\n","=== Fold 2 ===\n","Fold 2 Epoch 1: Loss=0.702951 | TrainAcc=0.4667\n","Fold 2 Epoch 100: Loss=0.166470 | TrainAcc=0.9000\n","Fold 2 Epoch 200: Loss=0.127146 | TrainAcc=0.9667\n","Fold 2 Epoch 300: Loss=0.089678 | TrainAcc=0.9667\n","Fold 2 Epoch 400: Loss=0.053084 | TrainAcc=1.0000\n","Fold 2 Epoch 500: Loss=0.030576 | TrainAcc=1.0000\n","Fold 2 Epoch 600: Loss=0.025250 | TrainAcc=1.0000\n","Fold 2 Epoch 700: Loss=0.008835 | TrainAcc=1.0000\n","Fold 2 Epoch 800: Loss=0.007563 | TrainAcc=1.0000\n","Fold 2 Epoch 900: Loss=0.003109 | TrainAcc=1.0000\n","Fold 2 Epoch 1000: Loss=0.002828 | TrainAcc=1.0000\n","Fold 2 Epoch 1100: Loss=0.003223 | TrainAcc=1.0000\n","Fold 2 Epoch 1200: Loss=0.002693 | TrainAcc=1.0000\n","Fold 2 Epoch 1300: Loss=0.002175 | TrainAcc=1.0000\n","Fold 2 Epoch 1400: Loss=0.001669 | TrainAcc=1.0000\n","Fold 2 Epoch 1500: Loss=0.002788 | TrainAcc=1.0000\n","Fold 2 Epoch 1600: Loss=0.001159 | TrainAcc=1.0000\n","Fold 2 Epoch 1700: Loss=0.001214 | TrainAcc=1.0000\n","Fold 2 Epoch 1800: Loss=0.000674 | TrainAcc=1.0000\n","Fold 2 Epoch 1900: Loss=0.000883 | TrainAcc=1.0000\n","Fold 2 Epoch 2000: Loss=0.000822 | TrainAcc=1.0000\n","Fold 2 → Acc=0.7815 | Prec=0.8138 | Rec=0.7867 | F1=0.8000 | AUC=0.8502 | CE Loss=1.4739\n","\n","=== Fold 3 ===\n","Fold 3 Epoch 1: Loss=0.718276 | TrainAcc=0.5000\n","Fold 3 Epoch 100: Loss=0.217244 | TrainAcc=0.9667\n","Fold 3 Epoch 200: Loss=0.134934 | TrainAcc=0.9667\n","Fold 3 Epoch 300: Loss=0.077100 | TrainAcc=0.9667\n","Fold 3 Epoch 400: Loss=0.046808 | TrainAcc=1.0000\n","Fold 3 Epoch 500: Loss=0.028526 | TrainAcc=1.0000\n","Fold 3 Epoch 600: Loss=0.022375 | TrainAcc=1.0000\n","Fold 3 Epoch 700: Loss=0.023270 | TrainAcc=1.0000\n","Fold 3 Epoch 800: Loss=0.016913 | TrainAcc=1.0000\n","Fold 3 Epoch 900: Loss=0.011362 | TrainAcc=1.0000\n","Fold 3 Epoch 1000: Loss=0.018294 | TrainAcc=1.0000\n","Fold 3 Epoch 1100: Loss=0.016964 | TrainAcc=1.0000\n","Fold 3 Epoch 1200: Loss=0.005091 | TrainAcc=1.0000\n","Fold 3 Epoch 1300: Loss=0.002803 | TrainAcc=1.0000\n","Fold 3 Epoch 1400: Loss=0.004844 | TrainAcc=1.0000\n","Fold 3 Epoch 1500: Loss=0.006294 | TrainAcc=1.0000\n","Fold 3 Epoch 1600: Loss=0.001490 | TrainAcc=1.0000\n","Fold 3 Epoch 1700: Loss=0.003252 | TrainAcc=1.0000\n","Fold 3 Epoch 1800: Loss=0.001298 | TrainAcc=1.0000\n","Fold 3 Epoch 1900: Loss=0.006099 | TrainAcc=1.0000\n","Fold 3 Epoch 2000: Loss=0.000888 | TrainAcc=1.0000\n","Fold 3 → Acc=0.6815 | Prec=0.6778 | Rec=0.8133 | F1=0.7394 | AUC=0.6900 | CE Loss=2.4554\n","\n","=== Fold 4 ===\n","Fold 4 Epoch 1: Loss=0.708053 | TrainAcc=0.4667\n","Fold 4 Epoch 100: Loss=0.275075 | TrainAcc=0.9333\n","Fold 4 Epoch 200: Loss=0.163143 | TrainAcc=0.9333\n","Fold 4 Epoch 300: Loss=0.103388 | TrainAcc=1.0000\n","Fold 4 Epoch 400: Loss=0.075483 | TrainAcc=1.0000\n","Fold 4 Epoch 500: Loss=0.034423 | TrainAcc=1.0000\n","Fold 4 Epoch 600: Loss=0.017895 | TrainAcc=1.0000\n","Fold 4 Epoch 700: Loss=0.009254 | TrainAcc=1.0000\n","Fold 4 Epoch 800: Loss=0.020581 | TrainAcc=1.0000\n","Fold 4 Epoch 900: Loss=0.005990 | TrainAcc=1.0000\n","Fold 4 Epoch 1000: Loss=0.012752 | TrainAcc=1.0000\n","Fold 4 Epoch 1100: Loss=0.004008 | TrainAcc=1.0000\n","Fold 4 Epoch 1200: Loss=0.003517 | TrainAcc=1.0000\n","Fold 4 Epoch 1300: Loss=0.012680 | TrainAcc=1.0000\n","Fold 4 Epoch 1400: Loss=0.002181 | TrainAcc=1.0000\n","Fold 4 Epoch 1500: Loss=0.005906 | TrainAcc=1.0000\n","Fold 4 Epoch 1600: Loss=0.002138 | TrainAcc=1.0000\n","Fold 4 Epoch 1700: Loss=0.003400 | TrainAcc=1.0000\n","Fold 4 Epoch 1800: Loss=0.002353 | TrainAcc=1.0000\n","Fold 4 Epoch 1900: Loss=0.003524 | TrainAcc=1.0000\n","Fold 4 Epoch 2000: Loss=0.001426 | TrainAcc=1.0000\n","Fold 4 → Acc=0.6889 | Prec=0.6833 | Rec=0.8200 | F1=0.7455 | AUC=0.7306 | CE Loss=1.9363\n","\n","=== Fold 5 ===\n","Fold 5 Epoch 1: Loss=0.690489 | TrainAcc=0.5333\n","Fold 5 Epoch 100: Loss=0.122695 | TrainAcc=0.9333\n","Fold 5 Epoch 200: Loss=0.070620 | TrainAcc=1.0000\n","Fold 5 Epoch 300: Loss=0.038552 | TrainAcc=1.0000\n","Fold 5 Epoch 400: Loss=0.018568 | TrainAcc=1.0000\n","Fold 5 Epoch 500: Loss=0.011172 | TrainAcc=1.0000\n","Fold 5 Epoch 600: Loss=0.009168 | TrainAcc=1.0000\n","Fold 5 Epoch 700: Loss=0.004818 | TrainAcc=1.0000\n","Fold 5 Epoch 800: Loss=0.002261 | TrainAcc=1.0000\n","Fold 5 Epoch 900: Loss=0.002774 | TrainAcc=1.0000\n","Fold 5 Epoch 1000: Loss=0.003831 | TrainAcc=1.0000\n","Fold 5 Epoch 1100: Loss=0.003690 | TrainAcc=1.0000\n","Fold 5 Epoch 1200: Loss=0.001414 | TrainAcc=1.0000\n","Fold 5 Epoch 1300: Loss=0.002403 | TrainAcc=1.0000\n","Fold 5 Epoch 1400: Loss=0.001012 | TrainAcc=1.0000\n","Fold 5 Epoch 1500: Loss=0.000947 | TrainAcc=1.0000\n","Fold 5 Epoch 1600: Loss=0.001610 | TrainAcc=1.0000\n","Fold 5 Epoch 1700: Loss=0.001115 | TrainAcc=1.0000\n","Fold 5 Epoch 1800: Loss=0.005159 | TrainAcc=1.0000\n","Fold 5 Epoch 1900: Loss=0.000796 | TrainAcc=1.0000\n","Fold 5 Epoch 2000: Loss=0.001603 | TrainAcc=1.0000\n","Fold 5 → Acc=0.7222 | Prec=0.7049 | Rec=0.8600 | F1=0.7748 | AUC=0.8283 | CE Loss=1.4582\n","\n","=== Fold 6 ===\n","Fold 6 Epoch 1: Loss=0.700964 | TrainAcc=0.6000\n","Fold 6 Epoch 100: Loss=0.114106 | TrainAcc=1.0000\n","Fold 6 Epoch 200: Loss=0.045353 | TrainAcc=1.0000\n","Fold 6 Epoch 300: Loss=0.019500 | TrainAcc=1.0000\n","Fold 6 Epoch 400: Loss=0.011127 | TrainAcc=1.0000\n","Fold 6 Epoch 500: Loss=0.007470 | TrainAcc=1.0000\n","Fold 6 Epoch 600: Loss=0.004582 | TrainAcc=1.0000\n","Fold 6 Epoch 700: Loss=0.004215 | TrainAcc=1.0000\n","Fold 6 Epoch 800: Loss=0.002780 | TrainAcc=1.0000\n","Fold 6 Epoch 900: Loss=0.002468 | TrainAcc=1.0000\n","Fold 6 Epoch 1000: Loss=0.001727 | TrainAcc=1.0000\n","Fold 6 Epoch 1100: Loss=0.001650 | TrainAcc=1.0000\n","Fold 6 Epoch 1200: Loss=0.002817 | TrainAcc=1.0000\n","Fold 6 Epoch 1300: Loss=0.001809 | TrainAcc=1.0000\n","Fold 6 Epoch 1400: Loss=0.001125 | TrainAcc=1.0000\n","Fold 6 Epoch 1500: Loss=0.001406 | TrainAcc=1.0000\n","Fold 6 Epoch 1600: Loss=0.001158 | TrainAcc=1.0000\n","Fold 6 Epoch 1700: Loss=0.000722 | TrainAcc=1.0000\n","Fold 6 Epoch 1800: Loss=0.000586 | TrainAcc=1.0000\n","Fold 6 Epoch 1900: Loss=0.001062 | TrainAcc=1.0000\n","Fold 6 Epoch 2000: Loss=0.000706 | TrainAcc=1.0000\n","Fold 6 → Acc=0.7333 | Prec=0.7294 | Rec=0.8267 | F1=0.7750 | AUC=0.7736 | CE Loss=1.8451\n","\n","=== Fold 7 ===\n","Fold 7 Epoch 1: Loss=0.752355 | TrainAcc=0.4667\n","Fold 7 Epoch 100: Loss=0.195583 | TrainAcc=0.9333\n","Fold 7 Epoch 200: Loss=0.137548 | TrainAcc=0.9667\n","Fold 7 Epoch 300: Loss=0.099901 | TrainAcc=0.9667\n","Fold 7 Epoch 400: Loss=0.061794 | TrainAcc=1.0000\n","Fold 7 Epoch 500: Loss=0.035539 | TrainAcc=1.0000\n","Fold 7 Epoch 600: Loss=0.023556 | TrainAcc=1.0000\n","Fold 7 Epoch 700: Loss=0.018955 | TrainAcc=1.0000\n","Fold 7 Epoch 800: Loss=0.016379 | TrainAcc=1.0000\n","Fold 7 Epoch 900: Loss=0.010119 | TrainAcc=1.0000\n","Fold 7 Epoch 1000: Loss=0.004393 | TrainAcc=1.0000\n","Fold 7 Epoch 1100: Loss=0.002864 | TrainAcc=1.0000\n","Fold 7 Epoch 1200: Loss=0.002417 | TrainAcc=1.0000\n","Fold 7 Epoch 1300: Loss=0.002913 | TrainAcc=1.0000\n","Fold 7 Epoch 1400: Loss=0.003158 | TrainAcc=1.0000\n","Fold 7 Epoch 1500: Loss=0.002510 | TrainAcc=1.0000\n","Fold 7 Epoch 1600: Loss=0.002701 | TrainAcc=1.0000\n","Fold 7 Epoch 1700: Loss=0.001271 | TrainAcc=1.0000\n","Fold 7 Epoch 1800: Loss=0.001320 | TrainAcc=1.0000\n","Fold 7 Epoch 1900: Loss=0.002167 | TrainAcc=1.0000\n","Fold 7 Epoch 2000: Loss=0.003260 | TrainAcc=1.0000\n","Fold 7 → Acc=0.6481 | Prec=0.6846 | Rec=0.6800 | F1=0.6823 | AUC=0.7264 | CE Loss=2.3629\n","\n","=== Fold 8 ===\n","Fold 8 Epoch 1: Loss=0.742269 | TrainAcc=0.4667\n","Fold 8 Epoch 100: Loss=0.197655 | TrainAcc=0.9333\n","Fold 8 Epoch 200: Loss=0.089123 | TrainAcc=1.0000\n","Fold 8 Epoch 300: Loss=0.059021 | TrainAcc=1.0000\n","Fold 8 Epoch 400: Loss=0.031932 | TrainAcc=1.0000\n","Fold 8 Epoch 500: Loss=0.019271 | TrainAcc=1.0000\n","Fold 8 Epoch 600: Loss=0.010974 | TrainAcc=1.0000\n","Fold 8 Epoch 700: Loss=0.009108 | TrainAcc=1.0000\n","Fold 8 Epoch 800: Loss=0.009547 | TrainAcc=1.0000\n","Fold 8 Epoch 900: Loss=0.006185 | TrainAcc=1.0000\n","Fold 8 Epoch 1000: Loss=0.002312 | TrainAcc=1.0000\n","Fold 8 Epoch 1100: Loss=0.003323 | TrainAcc=1.0000\n","Fold 8 Epoch 1200: Loss=0.002600 | TrainAcc=1.0000\n","Fold 8 Epoch 1300: Loss=0.001936 | TrainAcc=1.0000\n","Fold 8 Epoch 1400: Loss=0.001144 | TrainAcc=1.0000\n","Fold 8 Epoch 1500: Loss=0.001383 | TrainAcc=1.0000\n","Fold 8 Epoch 1600: Loss=0.001468 | TrainAcc=1.0000\n","Fold 8 Epoch 1700: Loss=0.000867 | TrainAcc=1.0000\n","Fold 8 Epoch 1800: Loss=0.001235 | TrainAcc=1.0000\n","Fold 8 Epoch 1900: Loss=0.002082 | TrainAcc=1.0000\n","Fold 8 Epoch 2000: Loss=0.000785 | TrainAcc=1.0000\n","Fold 8 → Acc=0.7444 | Prec=0.7485 | Rec=0.8133 | F1=0.7796 | AUC=0.7853 | CE Loss=1.8063\n","\n","=== Fold 9 ===\n","Fold 9 Epoch 1: Loss=0.755765 | TrainAcc=0.5000\n","Fold 9 Epoch 100: Loss=0.106474 | TrainAcc=0.9667\n","Fold 9 Epoch 200: Loss=0.043026 | TrainAcc=1.0000\n","Fold 9 Epoch 300: Loss=0.020385 | TrainAcc=1.0000\n","Fold 9 Epoch 400: Loss=0.011800 | TrainAcc=1.0000\n","Fold 9 Epoch 500: Loss=0.006669 | TrainAcc=1.0000\n","Fold 9 Epoch 600: Loss=0.003992 | TrainAcc=1.0000\n","Fold 9 Epoch 700: Loss=0.003605 | TrainAcc=1.0000\n","Fold 9 Epoch 800: Loss=0.003441 | TrainAcc=1.0000\n","Fold 9 Epoch 900: Loss=0.002144 | TrainAcc=1.0000\n","Fold 9 Epoch 1000: Loss=0.001148 | TrainAcc=1.0000\n","Fold 9 Epoch 1100: Loss=0.001952 | TrainAcc=1.0000\n","Fold 9 Epoch 1200: Loss=0.000987 | TrainAcc=1.0000\n","Fold 9 Epoch 1300: Loss=0.000937 | TrainAcc=1.0000\n","Fold 9 Epoch 1400: Loss=0.001033 | TrainAcc=1.0000\n","Fold 9 Epoch 1500: Loss=0.000869 | TrainAcc=1.0000\n","Fold 9 Epoch 1600: Loss=0.000762 | TrainAcc=1.0000\n","Fold 9 Epoch 1700: Loss=0.000959 | TrainAcc=1.0000\n","Fold 9 Epoch 1800: Loss=0.000660 | TrainAcc=1.0000\n","Fold 9 Epoch 1900: Loss=0.000706 | TrainAcc=1.0000\n","Fold 9 Epoch 2000: Loss=0.000804 | TrainAcc=1.0000\n","Fold 9 → Acc=0.6963 | Prec=0.7267 | Rec=0.7267 | F1=0.7267 | AUC=0.7642 | CE Loss=1.9228\n","\n","=== Fold 10 ===\n","Fold 10 Epoch 1: Loss=0.798170 | TrainAcc=0.2667\n","Fold 10 Epoch 100: Loss=0.283229 | TrainAcc=0.9000\n","Fold 10 Epoch 200: Loss=0.190293 | TrainAcc=0.9333\n","Fold 10 Epoch 300: Loss=0.108671 | TrainAcc=0.9667\n","Fold 10 Epoch 400: Loss=0.065727 | TrainAcc=1.0000\n","Fold 10 Epoch 500: Loss=0.053506 | TrainAcc=1.0000\n","Fold 10 Epoch 600: Loss=0.023610 | TrainAcc=1.0000\n","Fold 10 Epoch 700: Loss=0.030151 | TrainAcc=1.0000\n","Fold 10 Epoch 800: Loss=0.013930 | TrainAcc=1.0000\n","Fold 10 Epoch 900: Loss=0.011329 | TrainAcc=1.0000\n","Fold 10 Epoch 1000: Loss=0.012752 | TrainAcc=1.0000\n","Fold 10 Epoch 1100: Loss=0.006512 | TrainAcc=1.0000\n","Fold 10 Epoch 1200: Loss=0.004753 | TrainAcc=1.0000\n","Fold 10 Epoch 1300: Loss=0.004344 | TrainAcc=1.0000\n","Fold 10 Epoch 1400: Loss=0.003908 | TrainAcc=1.0000\n","Fold 10 Epoch 1500: Loss=0.004439 | TrainAcc=1.0000\n","Fold 10 Epoch 1600: Loss=0.003168 | TrainAcc=1.0000\n","Fold 10 Epoch 1700: Loss=0.003530 | TrainAcc=1.0000\n","Fold 10 Epoch 1800: Loss=0.002861 | TrainAcc=1.0000\n","Fold 10 Epoch 1900: Loss=0.002320 | TrainAcc=1.0000\n","Fold 10 Epoch 2000: Loss=0.003336 | TrainAcc=1.0000\n","Fold 10 → Acc=0.5630 | Prec=0.6111 | Rec=0.5867 | F1=0.5986 | AUC=0.5902 | CE Loss=2.2829\n","\n","=== Fold 11 ===\n","Fold 11 Epoch 1: Loss=0.763893 | TrainAcc=0.3667\n","Fold 11 Epoch 100: Loss=0.158207 | TrainAcc=0.9000\n","Fold 11 Epoch 200: Loss=0.129993 | TrainAcc=0.9333\n","Fold 11 Epoch 300: Loss=0.087856 | TrainAcc=0.9667\n","Fold 11 Epoch 400: Loss=0.055388 | TrainAcc=1.0000\n","Fold 11 Epoch 500: Loss=0.036336 | TrainAcc=1.0000\n","Fold 11 Epoch 600: Loss=0.029386 | TrainAcc=1.0000\n","Fold 11 Epoch 700: Loss=0.022517 | TrainAcc=1.0000\n","Fold 11 Epoch 800: Loss=0.021502 | TrainAcc=1.0000\n","Fold 11 Epoch 900: Loss=0.008905 | TrainAcc=1.0000\n","Fold 11 Epoch 1000: Loss=0.012578 | TrainAcc=1.0000\n","Fold 11 Epoch 1100: Loss=0.004031 | TrainAcc=1.0000\n","Fold 11 Epoch 1200: Loss=0.005636 | TrainAcc=1.0000\n","Fold 11 Epoch 1300: Loss=0.004251 | TrainAcc=1.0000\n","Fold 11 Epoch 1400: Loss=0.003922 | TrainAcc=1.0000\n","Fold 11 Epoch 1500: Loss=0.002820 | TrainAcc=1.0000\n","Fold 11 Epoch 1600: Loss=0.001684 | TrainAcc=1.0000\n","Fold 11 Epoch 1700: Loss=0.002747 | TrainAcc=1.0000\n","Fold 11 Epoch 1800: Loss=0.001139 | TrainAcc=1.0000\n","Fold 11 Epoch 1900: Loss=0.001642 | TrainAcc=1.0000\n","Fold 11 Epoch 2000: Loss=0.001314 | TrainAcc=1.0000\n","Fold 11 → Acc=0.7407 | Prec=0.7299 | Rec=0.8467 | F1=0.7840 | AUC=0.8585 | CE Loss=1.1787\n","\n","=== Fold 12 ===\n","Fold 12 Epoch 1: Loss=0.739876 | TrainAcc=0.3667\n","Fold 12 Epoch 100: Loss=0.160235 | TrainAcc=0.9333\n","Fold 12 Epoch 200: Loss=0.090292 | TrainAcc=0.9667\n","Fold 12 Epoch 300: Loss=0.054090 | TrainAcc=1.0000\n","Fold 12 Epoch 400: Loss=0.049071 | TrainAcc=1.0000\n","Fold 12 Epoch 500: Loss=0.032638 | TrainAcc=1.0000\n","Fold 12 Epoch 600: Loss=0.016124 | TrainAcc=1.0000\n","Fold 12 Epoch 700: Loss=0.028607 | TrainAcc=1.0000\n","Fold 12 Epoch 800: Loss=0.008317 | TrainAcc=1.0000\n","Fold 12 Epoch 900: Loss=0.004750 | TrainAcc=1.0000\n","Fold 12 Epoch 1000: Loss=0.005969 | TrainAcc=1.0000\n","Fold 12 Epoch 1100: Loss=0.001704 | TrainAcc=1.0000\n","Fold 12 Epoch 1200: Loss=0.002303 | TrainAcc=1.0000\n","Fold 12 Epoch 1300: Loss=0.003464 | TrainAcc=1.0000\n","Fold 12 Epoch 1400: Loss=0.001180 | TrainAcc=1.0000\n","Fold 12 Epoch 1500: Loss=0.002402 | TrainAcc=1.0000\n","Fold 12 Epoch 1600: Loss=0.001788 | TrainAcc=1.0000\n","Fold 12 Epoch 1700: Loss=0.002541 | TrainAcc=1.0000\n","Fold 12 Epoch 1800: Loss=0.001564 | TrainAcc=1.0000\n","Fold 12 Epoch 1900: Loss=0.000904 | TrainAcc=1.0000\n","Fold 12 Epoch 2000: Loss=0.004021 | TrainAcc=1.0000\n","Fold 12 → Acc=0.6630 | Prec=0.6855 | Rec=0.7267 | F1=0.7055 | AUC=0.6807 | CE Loss=2.7677\n","\n","=== Fold 13 ===\n","Fold 13 Epoch 1: Loss=0.929514 | TrainAcc=0.3000\n","Fold 13 Epoch 100: Loss=0.207118 | TrainAcc=0.9333\n","Fold 13 Epoch 200: Loss=0.072972 | TrainAcc=1.0000\n","Fold 13 Epoch 300: Loss=0.031209 | TrainAcc=1.0000\n","Fold 13 Epoch 400: Loss=0.019295 | TrainAcc=1.0000\n","Fold 13 Epoch 500: Loss=0.012089 | TrainAcc=1.0000\n","Fold 13 Epoch 600: Loss=0.005919 | TrainAcc=1.0000\n","Fold 13 Epoch 700: Loss=0.005086 | TrainAcc=1.0000\n","Fold 13 Epoch 800: Loss=0.004364 | TrainAcc=1.0000\n","Fold 13 Epoch 900: Loss=0.004219 | TrainAcc=1.0000\n","Fold 13 Epoch 1000: Loss=0.001970 | TrainAcc=1.0000\n","Fold 13 Epoch 1100: Loss=0.001873 | TrainAcc=1.0000\n","Fold 13 Epoch 1200: Loss=0.001431 | TrainAcc=1.0000\n","Fold 13 Epoch 1300: Loss=0.001438 | TrainAcc=1.0000\n","Fold 13 Epoch 1400: Loss=0.001848 | TrainAcc=1.0000\n","Fold 13 Epoch 1500: Loss=0.001469 | TrainAcc=1.0000\n","Fold 13 Epoch 1600: Loss=0.001099 | TrainAcc=1.0000\n","Fold 13 Epoch 1700: Loss=0.001295 | TrainAcc=1.0000\n","Fold 13 Epoch 1800: Loss=0.000733 | TrainAcc=1.0000\n","Fold 13 Epoch 1900: Loss=0.000983 | TrainAcc=1.0000\n","Fold 13 Epoch 2000: Loss=0.001095 | TrainAcc=1.0000\n","Fold 13 → Acc=0.6148 | Prec=0.6494 | Rec=0.6667 | F1=0.6579 | AUC=0.6415 | CE Loss=2.3747\n","\n","=== Fold 14 ===\n","Fold 14 Epoch 1: Loss=0.884190 | TrainAcc=0.3333\n","Fold 14 Epoch 100: Loss=0.269749 | TrainAcc=0.8667\n","Fold 14 Epoch 200: Loss=0.129153 | TrainAcc=1.0000\n","Fold 14 Epoch 300: Loss=0.052835 | TrainAcc=1.0000\n","Fold 14 Epoch 400: Loss=0.026944 | TrainAcc=1.0000\n","Fold 14 Epoch 500: Loss=0.015065 | TrainAcc=1.0000\n","Fold 14 Epoch 600: Loss=0.008646 | TrainAcc=1.0000\n","Fold 14 Epoch 700: Loss=0.006457 | TrainAcc=1.0000\n","Fold 14 Epoch 800: Loss=0.006393 | TrainAcc=1.0000\n","Fold 14 Epoch 900: Loss=0.005095 | TrainAcc=1.0000\n","Fold 14 Epoch 1000: Loss=0.002664 | TrainAcc=1.0000\n","Fold 14 Epoch 1100: Loss=0.003216 | TrainAcc=1.0000\n","Fold 14 Epoch 1200: Loss=0.003135 | TrainAcc=1.0000\n","Fold 14 Epoch 1300: Loss=0.002422 | TrainAcc=1.0000\n","Fold 14 Epoch 1400: Loss=0.002711 | TrainAcc=1.0000\n","Fold 14 Epoch 1500: Loss=0.002208 | TrainAcc=1.0000\n","Fold 14 Epoch 1600: Loss=0.001439 | TrainAcc=1.0000\n","Fold 14 Epoch 1700: Loss=0.001743 | TrainAcc=1.0000\n","Fold 14 Epoch 1800: Loss=0.001231 | TrainAcc=1.0000\n","Fold 14 Epoch 1900: Loss=0.001315 | TrainAcc=1.0000\n","Fold 14 Epoch 2000: Loss=0.001065 | TrainAcc=1.0000\n","Fold 14 → Acc=0.5815 | Prec=0.6312 | Rec=0.5933 | F1=0.6117 | AUC=0.6152 | CE Loss=2.3785\n","\n","=== Fold 15 ===\n","Fold 15 Epoch 1: Loss=0.656043 | TrainAcc=0.6333\n","Fold 15 Epoch 100: Loss=0.155719 | TrainAcc=0.9333\n","Fold 15 Epoch 200: Loss=0.097679 | TrainAcc=1.0000\n","Fold 15 Epoch 300: Loss=0.059024 | TrainAcc=1.0000\n","Fold 15 Epoch 400: Loss=0.057039 | TrainAcc=1.0000\n","Fold 15 Epoch 500: Loss=0.028990 | TrainAcc=1.0000\n","Fold 15 Epoch 600: Loss=0.017898 | TrainAcc=1.0000\n","Fold 15 Epoch 700: Loss=0.018321 | TrainAcc=1.0000\n","Fold 15 Epoch 800: Loss=0.005580 | TrainAcc=1.0000\n","Fold 15 Epoch 900: Loss=0.004171 | TrainAcc=1.0000\n","Fold 15 Epoch 1000: Loss=0.005668 | TrainAcc=1.0000\n","Fold 15 Epoch 1100: Loss=0.003299 | TrainAcc=1.0000\n","Fold 15 Epoch 1200: Loss=0.004205 | TrainAcc=1.0000\n","Fold 15 Epoch 1300: Loss=0.005448 | TrainAcc=1.0000\n","Fold 15 Epoch 1400: Loss=0.002410 | TrainAcc=1.0000\n","Fold 15 Epoch 1500: Loss=0.001878 | TrainAcc=1.0000\n","Fold 15 Epoch 1600: Loss=0.001721 | TrainAcc=1.0000\n","Fold 15 Epoch 1700: Loss=0.002248 | TrainAcc=1.0000\n","Fold 15 Epoch 1800: Loss=0.002216 | TrainAcc=1.0000\n","Fold 15 Epoch 1900: Loss=0.001065 | TrainAcc=1.0000\n","Fold 15 Epoch 2000: Loss=0.001418 | TrainAcc=1.0000\n","Fold 15 → Acc=0.7259 | Prec=0.7346 | Rec=0.7933 | F1=0.7628 | AUC=0.7900 | CE Loss=1.4795\n","\n","=== Fold 16 ===\n","Fold 16 Epoch 1: Loss=0.733301 | TrainAcc=0.4333\n","Fold 16 Epoch 100: Loss=0.197786 | TrainAcc=0.9333\n","Fold 16 Epoch 200: Loss=0.112224 | TrainAcc=0.9667\n","Fold 16 Epoch 300: Loss=0.090724 | TrainAcc=0.9667\n","Fold 16 Epoch 400: Loss=0.052643 | TrainAcc=1.0000\n","Fold 16 Epoch 500: Loss=0.034992 | TrainAcc=1.0000\n","Fold 16 Epoch 600: Loss=0.033718 | TrainAcc=1.0000\n","Fold 16 Epoch 700: Loss=0.014505 | TrainAcc=1.0000\n","Fold 16 Epoch 800: Loss=0.010698 | TrainAcc=1.0000\n","Fold 16 Epoch 900: Loss=0.014107 | TrainAcc=1.0000\n","Fold 16 Epoch 1000: Loss=0.007098 | TrainAcc=1.0000\n","Fold 16 Epoch 1100: Loss=0.003589 | TrainAcc=1.0000\n","Fold 16 Epoch 1200: Loss=0.008428 | TrainAcc=1.0000\n","Fold 16 Epoch 1300: Loss=0.004000 | TrainAcc=1.0000\n","Fold 16 Epoch 1400: Loss=0.003652 | TrainAcc=1.0000\n","Fold 16 Epoch 1500: Loss=0.002465 | TrainAcc=1.0000\n","Fold 16 Epoch 1600: Loss=0.003899 | TrainAcc=1.0000\n","Fold 16 Epoch 1700: Loss=0.001291 | TrainAcc=1.0000\n","Fold 16 Epoch 1800: Loss=0.001241 | TrainAcc=1.0000\n","Fold 16 Epoch 1900: Loss=0.001635 | TrainAcc=1.0000\n","Fold 16 Epoch 2000: Loss=0.002297 | TrainAcc=1.0000\n","Fold 16 → Acc=0.7741 | Prec=0.7572 | Rec=0.8733 | F1=0.8111 | AUC=0.8376 | CE Loss=1.4912\n","\n","=== Fold 17 ===\n","Fold 17 Epoch 1: Loss=0.784439 | TrainAcc=0.4333\n","Fold 17 Epoch 100: Loss=0.222796 | TrainAcc=0.9333\n","Fold 17 Epoch 200: Loss=0.102612 | TrainAcc=0.9667\n","Fold 17 Epoch 300: Loss=0.053469 | TrainAcc=1.0000\n","Fold 17 Epoch 400: Loss=0.033740 | TrainAcc=1.0000\n","Fold 17 Epoch 500: Loss=0.018439 | TrainAcc=1.0000\n","Fold 17 Epoch 600: Loss=0.011616 | TrainAcc=1.0000\n","Fold 17 Epoch 700: Loss=0.010162 | TrainAcc=1.0000\n","Fold 17 Epoch 800: Loss=0.016101 | TrainAcc=1.0000\n","Fold 17 Epoch 900: Loss=0.005811 | TrainAcc=1.0000\n","Fold 17 Epoch 1000: Loss=0.002716 | TrainAcc=1.0000\n","Fold 17 Epoch 1100: Loss=0.004128 | TrainAcc=1.0000\n","Fold 17 Epoch 1200: Loss=0.004013 | TrainAcc=1.0000\n","Fold 17 Epoch 1300: Loss=0.003711 | TrainAcc=1.0000\n","Fold 17 Epoch 1400: Loss=0.006635 | TrainAcc=1.0000\n","Fold 17 Epoch 1500: Loss=0.002008 | TrainAcc=1.0000\n","Fold 17 Epoch 1600: Loss=0.001399 | TrainAcc=1.0000\n","Fold 17 Epoch 1700: Loss=0.001400 | TrainAcc=1.0000\n","Fold 17 Epoch 1800: Loss=0.001898 | TrainAcc=1.0000\n","Fold 17 Epoch 1900: Loss=0.002304 | TrainAcc=1.0000\n","Fold 17 Epoch 2000: Loss=0.000980 | TrainAcc=1.0000\n","Fold 17 → Acc=0.6074 | Prec=0.6719 | Rec=0.5733 | F1=0.6187 | AUC=0.6943 | CE Loss=2.0705\n","\n","=== Fold 18 ===\n","Fold 18 Epoch 1: Loss=0.688956 | TrainAcc=0.5000\n","Fold 18 Epoch 100: Loss=0.212709 | TrainAcc=0.8667\n","Fold 18 Epoch 200: Loss=0.125292 | TrainAcc=0.9667\n","Fold 18 Epoch 300: Loss=0.073708 | TrainAcc=1.0000\n","Fold 18 Epoch 400: Loss=0.045663 | TrainAcc=1.0000\n","Fold 18 Epoch 500: Loss=0.024062 | TrainAcc=1.0000\n","Fold 18 Epoch 600: Loss=0.014757 | TrainAcc=1.0000\n","Fold 18 Epoch 700: Loss=0.013639 | TrainAcc=1.0000\n","Fold 18 Epoch 800: Loss=0.008167 | TrainAcc=1.0000\n","Fold 18 Epoch 900: Loss=0.008047 | TrainAcc=1.0000\n","Fold 18 Epoch 1000: Loss=0.004828 | TrainAcc=1.0000\n","Fold 18 Epoch 1100: Loss=0.003881 | TrainAcc=1.0000\n","Fold 18 Epoch 1200: Loss=0.003399 | TrainAcc=1.0000\n","Fold 18 Epoch 1300: Loss=0.003517 | TrainAcc=1.0000\n","Fold 18 Epoch 1400: Loss=0.003440 | TrainAcc=1.0000\n","Fold 18 Epoch 1500: Loss=0.003139 | TrainAcc=1.0000\n","Fold 18 Epoch 1600: Loss=0.001318 | TrainAcc=1.0000\n","Fold 18 Epoch 1700: Loss=0.001755 | TrainAcc=1.0000\n","Fold 18 Epoch 1800: Loss=0.002693 | TrainAcc=1.0000\n","Fold 18 Epoch 1900: Loss=0.002635 | TrainAcc=1.0000\n","Fold 18 Epoch 2000: Loss=0.002298 | TrainAcc=1.0000\n","Fold 18 → Acc=0.7148 | Prec=0.7483 | Rec=0.7333 | F1=0.7407 | AUC=0.7815 | CE Loss=1.5221\n","\n","=== Fold 19 ===\n","Fold 19 Epoch 1: Loss=0.626866 | TrainAcc=0.6667\n","Fold 19 Epoch 100: Loss=0.250732 | TrainAcc=0.9333\n","Fold 19 Epoch 200: Loss=0.138566 | TrainAcc=0.9667\n","Fold 19 Epoch 300: Loss=0.067171 | TrainAcc=1.0000\n","Fold 19 Epoch 400: Loss=0.037618 | TrainAcc=1.0000\n","Fold 19 Epoch 500: Loss=0.033348 | TrainAcc=1.0000\n","Fold 19 Epoch 600: Loss=0.013941 | TrainAcc=1.0000\n","Fold 19 Epoch 700: Loss=0.008527 | TrainAcc=1.0000\n","Fold 19 Epoch 800: Loss=0.006687 | TrainAcc=1.0000\n","Fold 19 Epoch 900: Loss=0.005030 | TrainAcc=1.0000\n","Fold 19 Epoch 1000: Loss=0.009132 | TrainAcc=1.0000\n","Fold 19 Epoch 1100: Loss=0.003914 | TrainAcc=1.0000\n","Fold 19 Epoch 1200: Loss=0.003401 | TrainAcc=1.0000\n","Fold 19 Epoch 1300: Loss=0.002627 | TrainAcc=1.0000\n","Fold 19 Epoch 1400: Loss=0.002491 | TrainAcc=1.0000\n","Fold 19 Epoch 1500: Loss=0.005740 | TrainAcc=1.0000\n","Fold 19 Epoch 1600: Loss=0.002499 | TrainAcc=1.0000\n","Fold 19 Epoch 1700: Loss=0.001327 | TrainAcc=1.0000\n","Fold 19 Epoch 1800: Loss=0.001084 | TrainAcc=1.0000\n","Fold 19 Epoch 1900: Loss=0.001190 | TrainAcc=1.0000\n","Fold 19 Epoch 2000: Loss=0.001040 | TrainAcc=1.0000\n","Fold 19 → Acc=0.6148 | Prec=0.6474 | Rec=0.6733 | F1=0.6601 | AUC=0.6312 | CE Loss=2.5913\n","\n","=== Fold 20 ===\n","Fold 20 Epoch 1: Loss=0.725006 | TrainAcc=0.4000\n","Fold 20 Epoch 100: Loss=0.156190 | TrainAcc=0.9000\n","Fold 20 Epoch 200: Loss=0.087581 | TrainAcc=1.0000\n","Fold 20 Epoch 300: Loss=0.047514 | TrainAcc=1.0000\n","Fold 20 Epoch 400: Loss=0.022001 | TrainAcc=1.0000\n","Fold 20 Epoch 500: Loss=0.014556 | TrainAcc=1.0000\n","Fold 20 Epoch 600: Loss=0.010454 | TrainAcc=1.0000\n","Fold 20 Epoch 700: Loss=0.007218 | TrainAcc=1.0000\n","Fold 20 Epoch 800: Loss=0.004042 | TrainAcc=1.0000\n","Fold 20 Epoch 900: Loss=0.006967 | TrainAcc=1.0000\n","Fold 20 Epoch 1000: Loss=0.004740 | TrainAcc=1.0000\n","Fold 20 Epoch 1100: Loss=0.002246 | TrainAcc=1.0000\n","Fold 20 Epoch 1200: Loss=0.002628 | TrainAcc=1.0000\n","Fold 20 Epoch 1300: Loss=0.001282 | TrainAcc=1.0000\n","Fold 20 Epoch 1400: Loss=0.002701 | TrainAcc=1.0000\n","Fold 20 Epoch 1500: Loss=0.001497 | TrainAcc=1.0000\n","Fold 20 Epoch 1600: Loss=0.000990 | TrainAcc=1.0000\n","Fold 20 Epoch 1700: Loss=0.001477 | TrainAcc=1.0000\n","Fold 20 Epoch 1800: Loss=0.285853 | TrainAcc=0.9333\n","Fold 20 Epoch 1900: Loss=0.002468 | TrainAcc=1.0000\n","Fold 20 Epoch 2000: Loss=0.001293 | TrainAcc=1.0000\n","Fold 20 → Acc=0.7333 | Prec=0.7053 | Rec=0.8933 | F1=0.7882 | AUC=0.7897 | CE Loss=1.7264\n","\n","=== Average Results Across 20 Folds ===\n","Accuracy:  0.6902 ± 0.0646\n","Precision: 0.7054 ± 0.0492\n","Recall:    0.7570 ± 0.0976\n","F1-score:  0.7285 ± 0.0665\n","CE Loss:   1.9294 ± 0.4464\n","AUC:       0.7455 ± 0.0817\n"]}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP21NcRu4brbJJyDo9opeST"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obRUlNpQD4Pe","executionInfo":{"status":"ok","timestamp":1767890618547,"user_tz":-330,"elapsed":1919,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"ee18bd0d-c168-4032-f17f-a75719242293"},"outputs":[{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","/home/snu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import copy\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnF\n","import torch.optim as optim\n","from torch_geometric.data import Data\n","from torch_geometric.nn import ARMAConv, GATConv\n","\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","from torchvision import models\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_auc_score"]},{"cell_type":"code","source":["SEED = 42\n","np.random.seed(SEED)\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"yEK0cYg9D79M","executionInfo":{"status":"ok","timestamp":1767890618551,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data = np.load('/home/snu/Downloads/pneumoniamnist_224.npz', allow_pickle=True)\n","all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","images = all_images.astype(np.float32) / 255.0\n","images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N,3,224,224)\n","X = torch.tensor(images)\n","y = torch.tensor(all_labels).long()\n","print(\"Images, labels shapes:\", X.shape, y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RP4O8YvrD9pH","executionInfo":{"status":"ok","timestamp":1767890621327,"user_tz":-330,"elapsed":2775,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"ce1250a6-c08f-4346-9e18-cf31e35ecec7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Images, labels shapes: torch.Size([5856, 3, 224, 224]) torch.Size([5856])\n"]}]},{"cell_type":"code","source":["dataset = TensorDataset(X, y)\n","class0_indices = [i for i in range(len(y)) if y[i] == 0]\n","class1_indices = [i for i in range(len(y)) if y[i] == 1]\n","'''  '''\n","random.seed(SEED)\n","sampled_class0 = random.sample(class0_indices, min(2000, len(class0_indices)))\n","sampled_class1 = random.sample(class1_indices, min(2000, len(class1_indices)))\n","\n","combined_indices = sampled_class0 + sampled_class1\n","random.shuffle(combined_indices)\n","\n","final_dataset = Subset(dataset, combined_indices)\n","final_loader = DataLoader(final_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"3Ju_SIibD_SR","executionInfo":{"status":"ok","timestamp":1767890621381,"user_tz":-330,"elapsed":52,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["resnet = models.resnet18(pretrained=True)\n","resnet.fc = nn.Identity()\n","resnet = resnet.to(device)\n","resnet.eval()\n","\n","resnet_feats = []\n","y_list = []\n","with torch.no_grad():\n","    for imgs, labels in final_loader:\n","        imgs = imgs.to(device)\n","        feats = resnet(imgs)\n","        resnet_feats.append(feats.cpu())\n","        y_list.extend(labels.cpu().tolist())\n","\n","features = torch.cat(resnet_feats, dim=0).numpy().astype(np.float32)\n","y_labels = np.array(y_list).astype(np.int64)\n","print(\"Feature shape:\", features.shape, \"Label shape:\", y_labels.shape)\n","\n","num_nodes, feat_dim = features.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqAWJ9BAEBQJ","executionInfo":{"status":"ok","timestamp":1767890623568,"user_tz":-330,"elapsed":2186,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"ba6890ec-837e-4115-bcd4-7764779632d9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Feature shape: (3583, 512) Label shape: (3583,)\n"]}]},{"cell_type":"code","source":["def create_adj(features, cut, alpha=1.0):\n","    F_norm = features / (np.linalg.norm(features, axis=1, keepdims=True) + 1e-12)\n","    W = np.dot(F_norm, F_norm.T)\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        if W.max() > 0:\n","            W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = (W * (W >= alpha)).astype(np.float32)\n","    return W\n","\n","def edge_index_from_dense(W):\n","    rows, cols = np.nonzero(W > 0)\n","    edge_index = np.vstack([rows, cols]).astype(np.int64)\n","    edge_weight = W[rows, cols].astype(np.float32)\n","    return edge_index, edge_weight\n","\n","def build_adj_list(edge_index_np, num_nodes):\n","    adj = [[] for _ in range(num_nodes)]\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    for s, d in zip(src, dst):\n","        adj[s].append(d)\n","    adj = [np.array(neis, dtype=np.int64) if len(neis) > 0 else np.array([], dtype=np.int64) for neis in adj]\n","    return adj\n","\n","def aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=None):\n","    rng = np.random.default_rng(seed)\n","    E = edge_index_np.shape[1]\n","    keep_mask = rng.random(E) >= drop_percent\n","    new_edge_index = edge_index_np[:, keep_mask]\n","    return new_edge_index\n","\n","def load_data_from_edge_index(node_feats_np, edge_index_np, device):\n","    node_feats = torch.from_numpy(node_feats_np).float()\n","    edge_index = torch.from_numpy(edge_index_np.astype(np.int64)).long()\n","    return node_feats, edge_index\n","\n","def sim(h1, h2, tau=0.2):\n","    z1 = nnF.normalize(h1, dim=-1, p=2)\n","    z2 = nnF.normalize(h2, dim=-1, p=2)\n","    return torch.mm(z1, z2.t()) / tau\n","\n","def contrastive_loss_wo_cross_network(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    intra_sim = f(sim(h1, h1))\n","    inter_sim = f(sim(h1, h2))\n","    return -torch.log(inter_sim.diag() /\n","                     (intra_sim.sum(dim=-1) + inter_sim.sum(dim=-1) - intra_sim.diag() + 1e-12))\n","\n","def contrastive_loss_wo_cross_view(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    cross_sim = f(sim(h1, z))\n","    return -torch.log(cross_sim.diag() / (cross_sim.sum(dim=-1) + 1e-12))"],"metadata":{"id":"0WEUuQOvEDQZ","executionInfo":{"status":"ok","timestamp":1767890623614,"user_tz":-330,"elapsed":42,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.PReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"TeZeQCcjEIIJ","executionInfo":{"status":"ok","timestamp":1767890623617,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class GATEncoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ=\"RELU\", heads=1):\n","        super(GATEncoder, self).__init__()\n","        self.device = device\n","\n","        activations = {\n","            \"SELU\": nnF.selu,\n","            \"SiLU\": nnF.silu,\n","            \"GELU\": nnF.gelu,\n","            \"ELU\": nnF.elu,\n","            \"RELU\": nnF.relu\n","        }\n","        self.act = activations.get(activ, nnF.elu)\n","\n","        self.gat = GATConv(\n","            in_channels=input_dim,\n","            out_channels=hidden_dim,\n","            heads=heads,\n","            dropout=0.25,\n","            concat=False   # keeps output dim = hidden_dim\n","        )\n","\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.gat(x, edge_index)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        x = self.batchnorm(x)\n","        logits = self.mlp(x)\n","        return logits"],"metadata":{"id":"_PvNbF-LEJsR","executionInfo":{"status":"ok","timestamp":1767890623620,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class EMA():\n","    def __init__(self, beta):\n","        self.beta = beta\n","    def update_average(self, old, new):\n","        if old is None:\n","            return new\n","        return old * self.beta + (1 - self.beta) * new"],"metadata":{"id":"0h3RgxmYEL2p","executionInfo":{"status":"ok","timestamp":1767890623679,"user_tz":-330,"elapsed":58,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def update_moving_average(ema_updater, ma_model, current_model):\n","    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n","        old_weight, up_weight = ma_params.data, current_params.data\n","        ma_params.data = ema_updater.update_average(old_weight, up_weight)"],"metadata":{"id":"ad7ru2kKENhh","executionInfo":{"status":"ok","timestamp":1767890623686,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class ARMA(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ, moving_average_decay=0.99, cut=True):\n","        super(ARMA, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","        self.cut = cut\n","        # beta for mixing in contrastive combination\n","        self.beta = 0.6\n","\n","        self.online_encoder = GATEncoder(input_dim, hidden_dim, device, activ)\n","        self.target_encoder = copy.deepcopy(self.online_encoder)\n","        # freeze target encoder params\n","        for p in self.target_encoder.parameters():\n","            p.requires_grad = False\n","\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_dim)\n","\n","        self.loss = self.cut_loss if cut else self.modularity_loss\n","        self.target_ema_updater = EMA(moving_average_decay)\n","\n","    def reset_moving_average(self):\n","        del self.target_encoder\n","        self.target_encoder = None\n","\n","    def update_ma(self):\n","        assert self.target_encoder is not None, 'target encoder has not been created yet'\n","        update_moving_average(self.target_ema_updater, self.target_encoder, self.online_encoder)\n","\n","    def forward(self, data1, data2):\n","        # online projections\n","        x1 = self.online_encoder(data1)      # shape: N x hidden\n","        logits1 = self.online_predictor(x1)  # predictor outputs (raw)\n","        S1 = nnF.softmax(logits1, dim=1)\n","\n","        x2 = self.online_encoder(data2)\n","        logits2 = self.online_predictor(x2)\n","        S2 = nnF.softmax(logits2, dim=1)\n","\n","        # target projections (no grads)\n","        with torch.no_grad():\n","            target_proj_one = self.target_encoder(data1).detach()\n","            target_proj_two = self.target_encoder(data2).detach()\n","\n","        # contrastive style losses\n","        l1 = self.beta * contrastive_loss_wo_cross_network(x1, x2, target_proj_two) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x1, x2, target_proj_two)\n","\n","        l2 = self.beta * contrastive_loss_wo_cross_network(x2, x1, target_proj_one) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x2, x1, target_proj_one)\n","\n","        return S1, S2, logits1, logits2, l1, l2\n","\n","    def modularity_loss(self, A, S):\n","        C = nnF.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A)\n","        B = A - torch.ger(d, d) / (2 * m + 1e-12)\n","\n","        k = torch.tensor(self.num_clusters, device=self.device, dtype=torch.float32)\n","        n = S.shape[0]\n","\n","        modularity_term = (-1.0 / (2.0 * m + 1e-12)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1.0\n","\n","        return modularity_term + collapse_reg_term\n","\n","    def cut_loss(self, A, S):\n","        S = nnF.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / (den + 1e-12))\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / (torch.norm(St_S) + 1e-12) - I_S / (torch.norm(I_S) + 1e-12))\n","\n","        return mincut_loss + ortho_loss"],"metadata":{"id":"okys8C1dEPyA","executionInfo":{"status":"ok","timestamp":1767890623690,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["alpha = 0.9\n","hidden_dim = 256\n","K = 2\n","num_epochs = 2000\n","\n","W0 = create_adj(features, cut=0, alpha=alpha)\n","edge_index_np, edge_weight_np = edge_index_from_dense(W0)\n","node_feats_all, edge_index_all = load_data_from_edge_index(features, edge_index_np, device)\n","data_full = Data(x=node_feats_all.to(device), edge_index=edge_index_all.to(device))\n","A1 = torch.from_numpy(W0).float().to(device)"],"metadata":{"id":"mc3t6XkVESwQ","executionInfo":{"status":"ok","timestamp":1767890623927,"user_tz":-330,"elapsed":236,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["accuracies, precisions, recalls, f1_scores, losses, all_auc = [], [], [], [], [], []\n","\n","sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=SEED)\n","for fold, (train_idx_full, test_idx) in enumerate(sss.split(features, y_labels)):\n","    print(f\"\\n=== Fold {fold+1} ===\")\n","\n","    cn_idx = np.where(y_labels == 0)[0]\n","    mci_idx = np.where(y_labels == 1)[0]\n","    sss_class = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=fold)\n","    cn_train_idx, _ = next(sss_class.split(features[cn_idx], y_labels[cn_idx]))\n","    mci_train_idx, _ = next(sss_class.split(features[mci_idx], y_labels[mci_idx]))\n","    cn_train = cn_idx[cn_train_idx]\n","    mci_train = mci_idx[mci_train_idx]\n","    balanced_train_idx = np.concatenate([cn_train, mci_train])\n","    np.random.shuffle(balanced_train_idx)\n","\n","    train_idx_t = torch.from_numpy(balanced_train_idx).long().to(device)\n","    test_idx_t = torch.from_numpy(test_idx).long().to(device)\n","    y_tensor = torch.from_numpy(y_labels).long().to(device)\n","\n","    model = ARMA(feat_dim, hidden_dim, K, device, activ=\"RELU\", cut=False, moving_average_decay=0.99).to(device)\n","    classifier = nn.Linear(hidden_dim, K).to(device)\n","    optimizer = optim.Adam(list(model.parameters()) + list(classifier.parameters()), lr=1e-4, weight_decay=1e-4)\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","    for ep in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","        edge_index_aug1 = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=ep)\n","        edge_index_aug2 = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=ep+999)\n","        rng = np.random.default_rng(ep)\n","        mask = rng.random(features.shape) >= 0.2\n","        features_aug1 = (features * mask.astype(np.float32))\n","        aug_feat2 = features.copy()\n","        drop_feat_num = int(features.shape[0] * features.shape[1] * 0.2)\n","        flat_idx = rng.choice(features.shape[0] * features.shape[1], size=drop_feat_num, replace=False)\n","        rows = (flat_idx // features.shape[1])\n","        cols = (flat_idx % features.shape[1])\n","        aug_feat2[rows, cols] = 0.0\n","        features_aug2 = aug_feat2.astype(np.float32)\n","        node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, edge_index_aug1, device)\n","        data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","        node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, edge_index_aug2, device)\n","        data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","        S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","        cont_loss = ((l1 + l2) / 2.0).mean()\n","        embeddings = model.online_encoder(data_full)\n","        logits_sup = classifier(embeddings[train_idx_t])\n","        sup_loss = ce_loss(logits_sup, y_tensor[train_idx_t])\n","        unsup_loss = model.loss(A1, logits1)\n","        loss = 0.005 * cont_loss + sup_loss + unsup_loss\n","        loss.backward()\n","        optimizer.step()\n","        model.update_ma()\n","\n","        if ep % 500 == 0 or ep == 1:\n","            print(f\"Epoch {ep} | Total: {loss.item():.6f} | Cont: {cont_loss.item():.6f} | CE: {sup_loss.item():.6f} | Unsup: {unsup_loss.item():.6f}\")\n","\n","    # --- Eval ---\n","    model.eval()\n","    classifier.eval()\n","    with torch.no_grad():\n","        embeddings_final = model.online_encoder(data_full)\n","        logits_final = classifier(embeddings_final)\n","        probs = nnF.softmax(logits_final, dim=1).cpu().numpy()\n","        y_pred = np.argmax(probs, axis=1)\n","\n","    y_test = y_labels[test_idx]\n","    y_pred_test = y_pred[test_idx]\n","    y_proba_test = probs[test_idx, 1] if probs.shape[1] > 1 else probs[test_idx, 0]\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","    try:\n","        loss_val = log_loss(y_test, y_proba_test)\n","    except:\n","        loss_val = np.nan\n","    try:\n","        auc_score = roc_auc_score(y_test, y_proba_test)\n","    except:\n","        auc_score = np.nan\n","\n","    print(f\"Fold {fold+1} → Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} F1={f1:.4f} AUC={auc_score:.4f}\")\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    losses.append(loss_val)\n","    all_auc.append(auc_score)\n","\n","print(\"\\n=== Average Results ===\")\n","print(f\"Accuracy: {np.nanmean(accuracies):.4f} ± {np.nanstd(accuracies):.4f}\")\n","print(f\"Precision: {np.nanmean(precisions):.4f} ± {np.nanstd(precisions):.4f}\")\n","print(f\"Recall: {np.nanmean(recalls):.4f} ± {np.nanstd(recalls):.4f}\")\n","print(f\"F1: {np.nanmean(f1_scores):.4f} ± {np.nanstd(f1_scores):.4f}\")\n","print(f\"LogLoss: {np.nanmean(losses):.4f} ± {np.nanstd(losses):.4f}\")\n","print(f\"AUC: {np.nanmean(all_auc):.4f} ± {np.nanstd(all_auc):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W46yr-cAEV0A","outputId":"9e169120-3ff1-4ead-eb70-a2beba7e5c36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Fold 1 ===\n","Epoch 0 | Total: 0.563154 | Cont: 7.533999 | CE: 0.647583 | Unsup: -0.122100\n","Epoch 1 | Total: 0.502232 | Cont: 7.542381 | CE: 0.588202 | Unsup: -0.123682\n","Epoch 500 | Total: -0.221650 | Cont: 7.028267 | CE: 0.050173 | Unsup: -0.306965\n","Epoch 1000 | Total: -0.256581 | Cont: 6.858398 | CE: 0.016852 | Unsup: -0.307725\n","Epoch 1500 | Total: -0.253657 | Cont: 6.754209 | CE: 0.020410 | Unsup: -0.307838\n","Fold 1 → Acc=0.9287 Prec=0.9511 Rec=0.9194 F1=0.9350 AUC=0.9726\n","\n","=== Fold 2 ===\n","Epoch 0 | Total: 0.562930 | Cont: 7.730334 | CE: 0.649475 | Unsup: -0.125196\n","Epoch 1 | Total: 0.502032 | Cont: 7.714677 | CE: 0.589733 | Unsup: -0.126274\n","Epoch 500 | Total: -0.215462 | Cont: 7.472364 | CE: 0.049666 | Unsup: -0.302490\n","Epoch 1000 | Total: -0.244618 | Cont: 7.411885 | CE: 0.023965 | Unsup: -0.305643\n","Epoch 1500 | Total: -0.250227 | Cont: 7.369588 | CE: 0.018986 | Unsup: -0.306061\n","Fold 2 → Acc=0.9219 Prec=0.9383 Rec=0.9206 F1=0.9293 AUC=0.9653\n","\n","=== Fold 3 ===\n","Epoch 0 | Total: 0.576496 | Cont: 7.607827 | CE: 0.658822 | Unsup: -0.120365\n","Epoch 1 | Total: 0.540550 | Cont: 7.616605 | CE: 0.624444 | Unsup: -0.121977\n","Epoch 500 | Total: -0.255992 | Cont: 7.430938 | CE: 0.013095 | Unsup: -0.306242\n","Epoch 1000 | Total: -0.269837 | Cont: 7.237080 | CE: 0.001941 | Unsup: -0.307963\n","Epoch 1500 | Total: -0.272661 | Cont: 7.022822 | CE: 0.000639 | Unsup: -0.308414\n","Fold 3 → Acc=0.9175 Prec=0.9037 Rec=0.9539 F1=0.9281 AUC=0.9668\n","\n","=== Fold 4 ===\n","Epoch 0 | Total: 0.655283 | Cont: 7.593525 | CE: 0.740431 | Unsup: -0.123116\n","Epoch 1 | Total: 0.599800 | Cont: 7.584394 | CE: 0.685567 | Unsup: -0.123689\n","Epoch 500 | Total: -0.266285 | Cont: 7.314199 | CE: 0.003235 | Unsup: -0.306090\n","Epoch 1000 | Total: -0.271595 | Cont: 7.033498 | CE: 0.001118 | Unsup: -0.307880\n","Epoch 1500 | Total: -0.274288 | Cont: 6.673598 | CE: 0.000721 | Unsup: -0.308377\n","Fold 4 → Acc=0.9451 Prec=0.9699 Rec=0.9306 F1=0.9498 AUC=0.9798\n","\n","=== Fold 5 ===\n","Epoch 0 | Total: 0.604843 | Cont: 7.563883 | CE: 0.688408 | Unsup: -0.121384\n","Epoch 1 | Total: 0.564830 | Cont: 7.560522 | CE: 0.649870 | Unsup: -0.122842\n","Epoch 500 | Total: -0.243842 | Cont: 7.111277 | CE: 0.027529 | Unsup: -0.306927\n","Epoch 1000 | Total: -0.268645 | Cont: 6.926872 | CE: 0.004646 | Unsup: -0.307926\n","Epoch 1500 | Total: -0.271441 | Cont: 6.822561 | CE: 0.002865 | Unsup: -0.308419\n","Fold 5 → Acc=0.9274 Prec=0.9552 Rec=0.9128 F1=0.9335 AUC=0.9693\n","\n","=== Fold 6 ===\n","Epoch 0 | Total: 0.668389 | Cont: 7.586643 | CE: 0.754339 | Unsup: -0.123883\n","Epoch 1 | Total: 0.606308 | Cont: 7.601593 | CE: 0.693236 | Unsup: -0.124936\n","Epoch 500 | Total: -0.235670 | Cont: 7.337843 | CE: 0.032837 | Unsup: -0.305196\n","Epoch 1000 | Total: -0.257815 | Cont: 7.229537 | CE: 0.012997 | Unsup: -0.306960\n","Epoch 1500 | Total: -0.268587 | Cont: 7.133127 | CE: 0.003508 | Unsup: -0.307760\n","Fold 6 → Acc=0.9191 Prec=0.9306 Rec=0.9239 F1=0.9272 AUC=0.9673\n","\n","=== Fold 7 ===\n","Epoch 0 | Total: 0.647912 | Cont: 7.639322 | CE: 0.734599 | Unsup: -0.124884\n","Epoch 1 | Total: 0.596890 | Cont: 7.633843 | CE: 0.685793 | Unsup: -0.127072\n","Epoch 500 | Total: -0.266442 | Cont: 7.435598 | CE: 0.002345 | Unsup: -0.305965\n","Epoch 1000 | Total: -0.271928 | Cont: 7.070668 | CE: 0.000677 | Unsup: -0.307959\n","Epoch 1500 | Total: -0.274741 | Cont: 6.674792 | CE: 0.000341 | Unsup: -0.308457\n","Fold 7 → Acc=0.9476 Prec=0.9631 Rec=0.9422 F1=0.9525 AUC=0.9793\n","\n","=== Fold 8 ===\n","Epoch 0 | Total: 0.676861 | Cont: 7.748160 | CE: 0.762154 | Unsup: -0.124034\n","Epoch 1 | Total: 0.600759 | Cont: 7.771649 | CE: 0.686862 | Unsup: -0.124961\n","Epoch 500 | Total: -0.266163 | Cont: 7.473915 | CE: 0.002792 | Unsup: -0.306325\n","Epoch 1000 | Total: -0.270469 | Cont: 7.172638 | CE: 0.001113 | Unsup: -0.307445\n","Epoch 1500 | Total: -0.272654 | Cont: 6.823572 | CE: 0.001444 | Unsup: -0.308215\n","Fold 8 → Acc=0.9333 Prec=0.9610 Rec=0.9178 F1=0.9389 AUC=0.9738\n","\n","=== Fold 9 ===\n","Epoch 0 | Total: 0.595159 | Cont: 7.673528 | CE: 0.660859 | Unsup: -0.104067\n","Epoch 1 | Total: 0.542849 | Cont: 7.660759 | CE: 0.611674 | Unsup: -0.107128\n","Epoch 500 | Total: -0.204089 | Cont: 7.165298 | CE: 0.067136 | Unsup: -0.307052\n","Epoch 1000 | Total: -0.258650 | Cont: 6.986292 | CE: 0.014118 | Unsup: -0.307700\n","Epoch 1500 | Total: -0.256605 | Cont: 6.860495 | CE: 0.016782 | Unsup: -0.307690\n","Fold 9 → Acc=0.9243 Prec=0.9156 Rec=0.9522 F1=0.9336 AUC=0.9630\n","\n","=== Fold 10 ===\n","Epoch 0 | Total: 0.550358 | Cont: 7.630963 | CE: 0.635114 | Unsup: -0.122910\n","Epoch 1 | Total: 0.506724 | Cont: 7.612154 | CE: 0.591686 | Unsup: -0.123022\n","Epoch 500 | Total: -0.247533 | Cont: 7.108999 | CE: 0.024113 | Unsup: -0.307191\n","Epoch 1000 | Total: -0.263141 | Cont: 6.901313 | CE: 0.010122 | Unsup: -0.307769\n","Epoch 1500 | Total: -0.265334 | Cont: 6.780416 | CE: 0.008946 | Unsup: -0.308182\n","Fold 10 → Acc=0.9318 Prec=0.9577 Rec=0.9183 F1=0.9376 AUC=0.9745\n","\n","=== Fold 11 ===\n","Epoch 0 | Total: 0.563637 | Cont: 7.699679 | CE: 0.646672 | Unsup: -0.121534\n","Epoch 1 | Total: 0.536852 | Cont: 7.672367 | CE: 0.620045 | Unsup: -0.121554\n","Epoch 500 | Total: -0.262104 | Cont: 7.402753 | CE: 0.006311 | Unsup: -0.305429\n","Epoch 1000 | Total: -0.270718 | Cont: 7.104000 | CE: 0.001246 | Unsup: -0.307484\n","Epoch 1500 | Total: -0.272988 | Cont: 6.718465 | CE: 0.001406 | Unsup: -0.307986\n","Fold 11 → Acc=0.9423 Prec=0.9524 Rec=0.9439 F1=0.9481 AUC=0.9746\n","\n","=== Fold 12 ===\n","Epoch 0 | Total: 0.559214 | Cont: 7.666836 | CE: 0.647731 | Unsup: -0.126851\n","Epoch 1 | Total: 0.496278 | Cont: 7.651968 | CE: 0.587248 | Unsup: -0.129230\n","Epoch 500 | Total: -0.267232 | Cont: 7.389834 | CE: 0.002175 | Unsup: -0.306357\n","Epoch 1000 | Total: -0.271514 | Cont: 7.083573 | CE: 0.000868 | Unsup: -0.307800\n","Epoch 1500 | Total: -0.272904 | Cont: 6.793233 | CE: 0.001416 | Unsup: -0.308287\n","Fold 12 → Acc=0.9380 Prec=0.9454 Rec=0.9433 F1=0.9444 AUC=0.9792\n","\n","=== Fold 13 ===\n","Epoch 0 | Total: 0.618106 | Cont: 7.635334 | CE: 0.699826 | Unsup: -0.119897\n","Epoch 1 | Total: 0.543060 | Cont: 7.638292 | CE: 0.626728 | Unsup: -0.121859\n","Epoch 500 | Total: -0.265383 | Cont: 7.362810 | CE: 0.003499 | Unsup: -0.305696\n","Epoch 1000 | Total: -0.271461 | Cont: 7.082812 | CE: 0.000828 | Unsup: -0.307703\n","Epoch 1500 | Total: -0.273992 | Cont: 6.697690 | CE: 0.000547 | Unsup: -0.308028\n","Fold 13 → Acc=0.9436 Prec=0.9426 Rec=0.9572 F1=0.9498 AUC=0.9796\n","\n","=== Fold 14 ===\n","Epoch 0 | Total: 0.600319 | Cont: 7.601196 | CE: 0.688709 | Unsup: -0.126396\n","Epoch 1 | Total: 0.537898 | Cont: 7.622421 | CE: 0.628699 | Unsup: -0.128914\n","Epoch 500 | Total: -0.237472 | Cont: 7.413800 | CE: 0.031283 | Unsup: -0.305824\n","Epoch 1000 | Total: -0.266797 | Cont: 7.168458 | CE: 0.004737 | Unsup: -0.307376\n","Epoch 1500 | Total: -0.266337 | Cont: 6.991411 | CE: 0.006437 | Unsup: -0.307731\n","Fold 14 → Acc=0.9312 Prec=0.9566 Rec=0.9183 F1=0.9371 AUC=0.9731\n","\n","=== Fold 15 ===\n","Epoch 0 | Total: 0.583380 | Cont: 7.593760 | CE: 0.674075 | Unsup: -0.128665\n","Epoch 1 | Total: 0.525172 | Cont: 7.584872 | CE: 0.617683 | Unsup: -0.130436\n","Epoch 500 | Total: -0.268492 | Cont: 7.337882 | CE: 0.001099 | Unsup: -0.306280\n","Epoch 1000 | Total: -0.272356 | Cont: 6.970805 | CE: 0.000685 | Unsup: -0.307895\n","Epoch 1500 | Total: -0.274764 | Cont: 6.651047 | CE: 0.000343 | Unsup: -0.308363\n","Fold 15 → Acc=0.9346 Prec=0.9590 Rec=0.9222 F1=0.9402 AUC=0.9684\n","\n","=== Fold 16 ===\n","Epoch 0 | Total: 0.628144 | Cont: 7.769222 | CE: 0.713688 | Unsup: -0.124390\n","Epoch 1 | Total: 0.603153 | Cont: 7.747213 | CE: 0.690127 | Unsup: -0.125710\n","Epoch 500 | Total: -0.237783 | Cont: 7.177407 | CE: 0.033055 | Unsup: -0.306724\n","Epoch 1000 | Total: -0.261641 | Cont: 7.047090 | CE: 0.010853 | Unsup: -0.307729\n","Epoch 1500 | Total: -0.268883 | Cont: 6.917700 | CE: 0.004853 | Unsup: -0.308324\n","Fold 16 → Acc=0.9309 Prec=0.9576 Rec=0.9167 F1=0.9367 AUC=0.9740\n","\n","=== Fold 17 ===\n","Epoch 0 | Total: 0.523141 | Cont: 7.680971 | CE: 0.600409 | Unsup: -0.115673\n","Epoch 1 | Total: 0.489500 | Cont: 7.686408 | CE: 0.568258 | Unsup: -0.117190\n","Epoch 500 | Total: -0.209675 | Cont: 7.064537 | CE: 0.062023 | Unsup: -0.307021\n","Epoch 1000 | Total: -0.261666 | Cont: 7.016289 | CE: 0.010782 | Unsup: -0.307529\n","Epoch 1500 | Total: -0.268486 | Cont: 6.870759 | CE: 0.005341 | Unsup: -0.308181\n","Fold 17 → Acc=0.9352 Prec=0.9437 Rec=0.9400 F1=0.9418 AUC=0.9746\n","\n","=== Fold 18 ===\n","Epoch 0 | Total: 0.670746 | Cont: 7.646511 | CE: 0.761560 | Unsup: -0.129047\n","Epoch 1 | Total: 0.605797 | Cont: 7.639980 | CE: 0.697639 | Unsup: -0.130041\n","Epoch 500 | Total: -0.246404 | Cont: 7.344334 | CE: 0.022279 | Unsup: -0.305405\n"]}]}]}
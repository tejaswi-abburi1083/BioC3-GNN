{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X7AycSYEEXR4","executionInfo":{"status":"ok","timestamp":1767850223185,"user_tz":-330,"elapsed":17350,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"c1f73d2b-4c0b-4f66-9039-f2a7fa1b643c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install numpy scikit-learn\n","!pip install -q torch_geometric\n","!pip install -q class_resolver\n","!pip3 install pymatting\n","!pip install opencv-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tEyOc6DNEU5H","executionInfo":{"status":"ok","timestamp":1767850247592,"user_tz":-330,"elapsed":24404,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"1325ab86-76cf-44fb-89b5-daddfa70d158"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pymatting\n","  Downloading pymatting-1.1.14-py3-none-any.whl.metadata (7.7 kB)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pymatting) (2.0.2)\n","Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from pymatting) (11.3.0)\n","Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.12/dist-packages (from pymatting) (0.60.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from pymatting) (1.16.3)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba!=0.49.0->pymatting) (0.43.0)\n","Downloading pymatting-1.1.14-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pymatting\n","Successfully installed pymatting-1.1.14\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n","Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhoWIduU0285"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","import torch.optim as optim\n","import numpy as np\n","import random\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from torch_geometric.data import Data\n","from torch_geometric.nn import ARMAConv\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score,\n","    f1_score, roc_auc_score, log_loss\n",")\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GATConv\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","from torchvision import models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMcTVrCjjNZc","outputId":"4b95bbaa-4634-461f-e4dc-cd94e2da07bd","executionInfo":{"status":"ok","timestamp":1767850264904,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available: True\n","GPU Name: NVIDIA A100-SXM4-40GB\n"]}],"source":["import torch\n","print(\"CUDA available:\", torch.cuda.is_available())\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cepApjvKiSCo","outputId":"30669dd1-fecb-4d3e-8bb1-0520ffaa7f5b","executionInfo":{"status":"ok","timestamp":1767850283909,"user_tz":-330,"elapsed":19003,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Raw images: torch.Size([5856, 3, 224, 224]), Labels: torch.Size([5856])\n"]}],"source":["data = np.load('/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/Medmnist_data/pneumoniamnist_224.npz', allow_pickle=True)\n","all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","# Convert to 3-channel RGB\n","images = all_images.astype(np.float32) / 255.0\n","images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N, 3, 224, 224)\n","X_torch = torch.tensor(images)\n","y_torch = torch.tensor(all_labels).long()\n","print(f\"Raw images: {X_torch.shape}, Labels: {y_torch.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8SWzeJfy-NHL"},"outputs":[],"source":["class0_idx = [i for i in range(len(y_torch)) if y_torch[i] == 0]\n","class1_idx = [i for i in range(len(y_torch)) if y_torch[i] == 1]\n","\n","random.seed(42)\n","sampled_class0 = random.sample(class0_idx, min(2000, len(class0_idx)))\n","sampled_class1 = random.sample(class1_idx, min(2000, len(class1_idx)))\n","\n","selected_indices = sampled_class0 + sampled_class1\n","random.shuffle(selected_indices)\n","\n","subset_dataset = Subset(TensorDataset(X_torch, y_torch), selected_indices)\n","subset_loader = DataLoader(subset_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LB9Nehldij_q","outputId":"e759d72b-96e3-4b0c-b559-eeb72ae55730","executionInfo":{"status":"ok","timestamp":1767850286914,"user_tz":-330,"elapsed":2907,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 44.7M/44.7M [00:00<00:00, 173MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Feature shape: (3583, 512) Label shape: (3583,)\n"]}],"source":["resnet = models.resnet18(pretrained=True)\n","resnet.fc = nn.Identity()\n","resnet = resnet.to(device)\n","resnet.eval()\n","\n","resnet_feats = []\n","y_list = []\n","with torch.no_grad():\n","    for imgs, labels in subset_loader:\n","        imgs = imgs.to(device)\n","        feats = resnet(imgs)\n","        resnet_feats.append(feats.cpu())\n","        y_list.extend(labels.cpu().tolist())\n","\n","features = torch.cat(resnet_feats, dim=0).numpy().astype(np.float32)  # shape (N, feat_dim)\n","y_labels = np.array(y_list).astype(np.float32)\n","print(\"Feature shape:\", features.shape, \"Label shape:\", y_labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mTPzJR5gQzXf"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","from torch_geometric.nn import GATConv\n","\n","\n","class GAT_SemiSupervised(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, device, heads=2, activ=\"RELU\", dropout=0.25):\n","        super(GAT_SemiSupervised, self).__init__()\n","        self.device = device\n","\n","        # GAT layer\n","        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True, dropout=dropout)\n","        self.bn1 = nn.BatchNorm1d(hidden_dim * heads)  # heads multiply feature dimension if concat=True\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hidden_dim * heads, output_dim)\n","        self.num_clusters = output_dim\n","\n","        # Activation mapping\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu,\n","            \"ELU\": nnFn.elu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","\n","        # GAT layer\n","        x = self.conv1(x, edge_index)\n","        x = self.bn1(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","\n","        logits = self.fc(x)\n","        return logits\n","\n","    def cut_loss(self, A, S):\n","        S = nnFn.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / den)\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / torch.norm(St_S) - I_S / torch.norm(I_S))\n","\n","        return mincut_loss + ortho_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8AUYk2fh0_iR"},"outputs":[],"source":["def create_adj(F, alpha=1):\n","    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","    W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","    W = W / W.max()\n","    return W\n","\n","def load_data(adj, node_feats):\n","    node_feats = torch.from_numpy(node_feats).float()\n","    edge_index = torch.from_numpy(np.array(np.nonzero((adj > 0))))\n","    return Data(x=node_feats, edge_index=edge_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3TfsmjGLumYY"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","alpha = 0.9\n","feats_dim = features.shape[1]\n","hidden_dim = 256\n","num_classes = 2\n","num_epochs = 2000\n","lr = 0.0001\n","weight_decay = 1e-4\n","batch_print_freq = 500\n","lambda_mod = 0.1  #0.2 #0.001  # weight for modularity loss\n","# lambda_sup = 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-mfsholh1Erx","outputId":"f8c15ba1-f0e7-4a0f-9ff5-d13f50ecff64","executionInfo":{"status":"ok","timestamp":1767850287233,"user_tz":-330,"elapsed":285,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Data(x=[3583, 512], edge_index=[2, 1642257])\n"]}],"source":["W = create_adj(features, alpha)\n","data = load_data(W, features).to(device)\n","print(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBy-hReA1Hqa","outputId":"d654a865-114d-4979-b749-8a20cd8f9f84","executionInfo":{"status":"ok","timestamp":1767852040542,"user_tz":-330,"elapsed":1753005,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Fold 1 ===\n","Fold 1 Epoch 1: TotalLoss=0.641762 | Sup=0.668035 | Unsup=-0.262729 | TrainAcc=0.6145\n","Fold 1 Epoch 500: TotalLoss=-0.059331 | Sup=0.024029 | Unsup=-0.833602 | TrainAcc=0.9916\n","Fold 1 Epoch 1000: TotalLoss=-0.079164 | Sup=0.007396 | Unsup=-0.865603 | TrainAcc=1.0000\n","Fold 1 Epoch 1500: TotalLoss=-0.085377 | Sup=0.002337 | Unsup=-0.877147 | TrainAcc=1.0000\n","Fold 1 Epoch 2000: TotalLoss=-0.087412 | Sup=0.001126 | Unsup=-0.885378 | TrainAcc=1.0000\n","Fold 1 → Acc=0.9088 | Prec=0.9778 | Rec=0.8561 | F1=0.9129 | AUC=0.9690 | CE Loss=0.5487\n","\n","=== Fold 2 ===\n","Fold 2 Epoch 1: TotalLoss=1.022133 | Sup=1.049668 | Unsup=-0.275354 | TrainAcc=0.3156\n","Fold 2 Epoch 500: TotalLoss=-0.078856 | Sup=0.004942 | Unsup=-0.837980 | TrainAcc=1.0000\n","Fold 2 Epoch 1000: TotalLoss=-0.087204 | Sup=0.001285 | Unsup=-0.884888 | TrainAcc=1.0000\n","Fold 2 Epoch 1500: TotalLoss=-0.088400 | Sup=0.000518 | Unsup=-0.889183 | TrainAcc=1.0000\n","Fold 2 Epoch 2000: TotalLoss=-0.089007 | Sup=0.000413 | Unsup=-0.894197 | TrainAcc=1.0000\n","Fold 2 → Acc=0.9119 | Prec=0.9779 | Rec=0.8617 | F1=0.9161 | AUC=0.9770 | CE Loss=0.4823\n","\n","=== Fold 3 ===\n","Fold 3 Epoch 1: TotalLoss=0.562656 | Sup=0.590810 | Unsup=-0.281544 | TrainAcc=0.7709\n","Fold 3 Epoch 500: TotalLoss=-0.077298 | Sup=0.008549 | Unsup=-0.858460 | TrainAcc=1.0000\n","Fold 3 Epoch 1000: TotalLoss=-0.087738 | Sup=0.001034 | Unsup=-0.887715 | TrainAcc=1.0000\n","Fold 3 Epoch 1500: TotalLoss=-0.088302 | Sup=0.000906 | Unsup=-0.892080 | TrainAcc=1.0000\n","Fold 3 Epoch 2000: TotalLoss=-0.088254 | Sup=0.001045 | Unsup=-0.892992 | TrainAcc=1.0000\n","Fold 3 → Acc=0.9091 | Prec=0.9766 | Rec=0.8578 | F1=0.9133 | AUC=0.9781 | CE Loss=0.4722\n","\n","=== Fold 4 ===\n","Fold 4 Epoch 1: TotalLoss=0.843208 | Sup=0.870275 | Unsup=-0.270677 | TrainAcc=0.4022\n","Fold 4 Epoch 500: TotalLoss=-0.082696 | Sup=0.004282 | Unsup=-0.869782 | TrainAcc=1.0000\n","Fold 4 Epoch 1000: TotalLoss=-0.087700 | Sup=0.001062 | Unsup=-0.887618 | TrainAcc=1.0000\n","Fold 4 Epoch 1500: TotalLoss=-0.088669 | Sup=0.000572 | Unsup=-0.892415 | TrainAcc=1.0000\n","Fold 4 Epoch 2000: TotalLoss=-0.089117 | Sup=0.000333 | Unsup=-0.894502 | TrainAcc=1.0000\n","Fold 4 → Acc=0.9119 | Prec=0.9791 | Rec=0.8606 | F1=0.9160 | AUC=0.9633 | CE Loss=0.5879\n","\n","=== Fold 5 ===\n","Fold 5 Epoch 1: TotalLoss=0.654362 | Sup=0.681196 | Unsup=-0.268348 | TrainAcc=0.6145\n","Fold 5 Epoch 500: TotalLoss=-0.067255 | Sup=0.017302 | Unsup=-0.845577 | TrainAcc=1.0000\n","Fold 5 Epoch 1000: TotalLoss=-0.085252 | Sup=0.002733 | Unsup=-0.879846 | TrainAcc=1.0000\n","Fold 5 Epoch 1500: TotalLoss=-0.088036 | Sup=0.000787 | Unsup=-0.888231 | TrainAcc=1.0000\n","Fold 5 Epoch 2000: TotalLoss=-0.088469 | Sup=0.000679 | Unsup=-0.891486 | TrainAcc=1.0000\n","Fold 5 → Acc=0.9126 | Prec=0.9750 | Rec=0.8656 | F1=0.9170 | AUC=0.9683 | CE Loss=0.4943\n","\n","=== Fold 6 ===\n","Fold 6 Epoch 1: TotalLoss=1.000225 | Sup=1.032725 | Unsup=-0.324996 | TrainAcc=0.2374\n","Fold 6 Epoch 500: TotalLoss=-0.077426 | Sup=0.008635 | Unsup=-0.860603 | TrainAcc=1.0000\n","Fold 6 Epoch 1000: TotalLoss=-0.086984 | Sup=0.001478 | Unsup=-0.884628 | TrainAcc=1.0000\n","Fold 6 Epoch 1500: TotalLoss=-0.088061 | Sup=0.001021 | Unsup=-0.890825 | TrainAcc=1.0000\n","Fold 6 Epoch 2000: TotalLoss=-0.088870 | Sup=0.000548 | Unsup=-0.894182 | TrainAcc=1.0000\n","Fold 6 → Acc=0.9194 | Prec=0.9837 | Rec=0.8700 | F1=0.9233 | AUC=0.9792 | CE Loss=0.4474\n","\n","=== Fold 7 ===\n","Fold 7 Epoch 1: TotalLoss=0.625601 | Sup=0.652141 | Unsup=-0.265396 | TrainAcc=0.6648\n","Fold 7 Epoch 500: TotalLoss=-0.080631 | Sup=0.005165 | Unsup=-0.857959 | TrainAcc=1.0000\n","Fold 7 Epoch 1000: TotalLoss=-0.087521 | Sup=0.000874 | Unsup=-0.883950 | TrainAcc=1.0000\n","Fold 7 Epoch 1500: TotalLoss=-0.088432 | Sup=0.000609 | Unsup=-0.890413 | TrainAcc=1.0000\n","Fold 7 Epoch 2000: TotalLoss=-0.089309 | Sup=0.000256 | Unsup=-0.895644 | TrainAcc=1.0000\n","Fold 7 → Acc=0.9172 | Prec=0.9788 | Rec=0.8706 | F1=0.9215 | AUC=0.9781 | CE Loss=0.4508\n","\n","=== Fold 8 ===\n","Fold 8 Epoch 1: TotalLoss=0.647025 | Sup=0.673688 | Unsup=-0.266639 | TrainAcc=0.6508\n","Fold 8 Epoch 500: TotalLoss=-0.076465 | Sup=0.006120 | Unsup=-0.825855 | TrainAcc=1.0000\n","Fold 8 Epoch 1000: TotalLoss=-0.086789 | Sup=0.001043 | Unsup=-0.878320 | TrainAcc=1.0000\n","Fold 8 Epoch 1500: TotalLoss=-0.088525 | Sup=0.000492 | Unsup=-0.890165 | TrainAcc=1.0000\n","Fold 8 Epoch 2000: TotalLoss=-0.089224 | Sup=0.000239 | Unsup=-0.894631 | TrainAcc=1.0000\n","Fold 8 → Acc=0.9085 | Prec=0.9760 | Rec=0.8572 | F1=0.9127 | AUC=0.9731 | CE Loss=0.5319\n","\n","=== Fold 9 ===\n","Fold 9 Epoch 1: TotalLoss=0.491196 | Sup=0.521013 | Unsup=-0.298162 | TrainAcc=0.7821\n","Fold 9 Epoch 500: TotalLoss=-0.078968 | Sup=0.006330 | Unsup=-0.852975 | TrainAcc=1.0000\n","Fold 9 Epoch 1000: TotalLoss=-0.088138 | Sup=0.001034 | Unsup=-0.891722 | TrainAcc=1.0000\n","Fold 9 Epoch 1500: TotalLoss=-0.089554 | Sup=0.000405 | Unsup=-0.899586 | TrainAcc=1.0000\n","Fold 9 Epoch 2000: TotalLoss=-0.089832 | Sup=0.000321 | Unsup=-0.901538 | TrainAcc=1.0000\n","Fold 9 → Acc=0.9054 | Prec=0.9752 | Rec=0.8522 | F1=0.9096 | AUC=0.9667 | CE Loss=0.6191\n","\n","=== Fold 10 ===\n","Fold 10 Epoch 1: TotalLoss=0.825564 | Sup=0.854757 | Unsup=-0.291929 | TrainAcc=0.4581\n","Fold 10 Epoch 500: TotalLoss=-0.042689 | Sup=0.035124 | Unsup=-0.778128 | TrainAcc=0.9944\n","Fold 10 Epoch 1000: TotalLoss=-0.080818 | Sup=0.004959 | Unsup=-0.857768 | TrainAcc=1.0000\n","Fold 10 Epoch 1500: TotalLoss=-0.085789 | Sup=0.001545 | Unsup=-0.873338 | TrainAcc=1.0000\n","Fold 10 Epoch 2000: TotalLoss=-0.086531 | Sup=0.001354 | Unsup=-0.878856 | TrainAcc=1.0000\n","Fold 10 → Acc=0.9088 | Prec=0.9695 | Rec=0.8639 | F1=0.9136 | AUC=0.9652 | CE Loss=0.4610\n","\n","=== Fold 11 ===\n","Fold 11 Epoch 1: TotalLoss=0.612222 | Sup=0.638466 | Unsup=-0.262445 | TrainAcc=0.5726\n","Fold 11 Epoch 500: TotalLoss=-0.028457 | Sup=0.051337 | Unsup=-0.797942 | TrainAcc=0.9860\n","Fold 11 Epoch 1000: TotalLoss=-0.077213 | Sup=0.007856 | Unsup=-0.850688 | TrainAcc=1.0000\n","Fold 11 Epoch 1500: TotalLoss=-0.084118 | Sup=0.003540 | Unsup=-0.876575 | TrainAcc=1.0000\n","Fold 11 Epoch 2000: TotalLoss=-0.086637 | Sup=0.001949 | Unsup=-0.885868 | TrainAcc=1.0000\n","Fold 11 → Acc=0.9119 | Prec=0.9804 | Rec=0.8594 | F1=0.9159 | AUC=0.9779 | CE Loss=0.4759\n","\n","=== Fold 12 ===\n","Fold 12 Epoch 1: TotalLoss=0.776207 | Sup=0.802459 | Unsup=-0.262516 | TrainAcc=0.4497\n","Fold 12 Epoch 500: TotalLoss=-0.083676 | Sup=0.004844 | Unsup=-0.885194 | TrainAcc=1.0000\n","Fold 12 Epoch 1000: TotalLoss=-0.088747 | Sup=0.000980 | Unsup=-0.897273 | TrainAcc=1.0000\n","Fold 12 Epoch 1500: TotalLoss=-0.089515 | Sup=0.000636 | Unsup=-0.901516 | TrainAcc=1.0000\n","Fold 12 Epoch 2000: TotalLoss=-0.089908 | Sup=0.000439 | Unsup=-0.903466 | TrainAcc=1.0000\n","Fold 12 → Acc=0.9113 | Prec=0.9791 | Rec=0.8594 | F1=0.9154 | AUC=0.9707 | CE Loss=0.5581\n","\n","=== Fold 13 ===\n","Fold 13 Epoch 1: TotalLoss=0.679866 | Sup=0.705170 | Unsup=-0.253048 | TrainAcc=0.5168\n","Fold 13 Epoch 500: TotalLoss=-0.071582 | Sup=0.013261 | Unsup=-0.848435 | TrainAcc=0.9972\n","Fold 13 Epoch 1000: TotalLoss=-0.087312 | Sup=0.000913 | Unsup=-0.882251 | TrainAcc=1.0000\n","Fold 13 Epoch 1500: TotalLoss=-0.088174 | Sup=0.000709 | Unsup=-0.888828 | TrainAcc=1.0000\n","Fold 13 Epoch 2000: TotalLoss=-0.088942 | Sup=0.000358 | Unsup=-0.893005 | TrainAcc=1.0000\n","Fold 13 → Acc=0.9135 | Prec=0.9774 | Rec=0.8650 | F1=0.9178 | AUC=0.9735 | CE Loss=0.4875\n","\n","=== Fold 14 ===\n","Fold 14 Epoch 1: TotalLoss=0.575566 | Sup=0.602773 | Unsup=-0.272061 | TrainAcc=0.6760\n","Fold 14 Epoch 500: TotalLoss=-0.081884 | Sup=0.006279 | Unsup=-0.881629 | TrainAcc=1.0000\n","Fold 14 Epoch 1000: TotalLoss=-0.088130 | Sup=0.001261 | Unsup=-0.893908 | TrainAcc=1.0000\n","Fold 14 Epoch 1500: TotalLoss=-0.089165 | Sup=0.000634 | Unsup=-0.897985 | TrainAcc=1.0000\n","Fold 14 Epoch 2000: TotalLoss=-0.089629 | Sup=0.000374 | Unsup=-0.900029 | TrainAcc=1.0000\n","Fold 14 → Acc=0.9126 | Prec=0.9774 | Rec=0.8633 | F1=0.9168 | AUC=0.9733 | CE Loss=0.5173\n","\n","=== Fold 15 ===\n","Fold 15 Epoch 1: TotalLoss=0.919872 | Sup=0.949772 | Unsup=-0.298995 | TrainAcc=0.4134\n","Fold 15 Epoch 500: TotalLoss=-0.077030 | Sup=0.007303 | Unsup=-0.843326 | TrainAcc=1.0000\n","Fold 15 Epoch 1000: TotalLoss=-0.085632 | Sup=0.002506 | Unsup=-0.881377 | TrainAcc=1.0000\n","Fold 15 Epoch 1500: TotalLoss=-0.087892 | Sup=0.000936 | Unsup=-0.888279 | TrainAcc=1.0000\n","Fold 15 Epoch 2000: TotalLoss=-0.088642 | Sup=0.000620 | Unsup=-0.892622 | TrainAcc=1.0000\n","Fold 15 → Acc=0.9107 | Prec=0.9749 | Rec=0.8622 | F1=0.9151 | AUC=0.9713 | CE Loss=0.5180\n","\n","=== Fold 16 ===\n","Fold 16 Epoch 1: TotalLoss=0.752323 | Sup=0.777287 | Unsup=-0.249632 | TrainAcc=0.5196\n","Fold 16 Epoch 500: TotalLoss=-0.080286 | Sup=0.006445 | Unsup=-0.867309 | TrainAcc=1.0000\n","Fold 16 Epoch 1000: TotalLoss=-0.087676 | Sup=0.001141 | Unsup=-0.888176 | TrainAcc=1.0000\n","Fold 16 Epoch 1500: TotalLoss=-0.089019 | Sup=0.000450 | Unsup=-0.894689 | TrainAcc=1.0000\n","Fold 16 Epoch 2000: TotalLoss=-0.089456 | Sup=0.000432 | Unsup=-0.898882 | TrainAcc=1.0000\n","Fold 16 → Acc=0.9138 | Prec=0.9786 | Rec=0.8644 | F1=0.9180 | AUC=0.9775 | CE Loss=0.5060\n","\n","=== Fold 17 ===\n","Fold 17 Epoch 1: TotalLoss=0.714947 | Sup=0.741131 | Unsup=-0.261840 | TrainAcc=0.4888\n","Fold 17 Epoch 500: TotalLoss=-0.080487 | Sup=0.006483 | Unsup=-0.869692 | TrainAcc=1.0000\n","Fold 17 Epoch 1000: TotalLoss=-0.088556 | Sup=0.001025 | Unsup=-0.895807 | TrainAcc=1.0000\n","Fold 17 Epoch 1500: TotalLoss=-0.089402 | Sup=0.000565 | Unsup=-0.899668 | TrainAcc=1.0000\n","Fold 17 Epoch 2000: TotalLoss=-0.089838 | Sup=0.000300 | Unsup=-0.901379 | TrainAcc=1.0000\n","Fold 17 → Acc=0.9169 | Prec=0.9806 | Rec=0.8683 | F1=0.9210 | AUC=0.9766 | CE Loss=0.4915\n","\n","=== Fold 18 ===\n","Fold 18 Epoch 1: TotalLoss=0.494873 | Sup=0.526210 | Unsup=-0.313372 | TrainAcc=0.8352\n","Fold 18 Epoch 500: TotalLoss=-0.081636 | Sup=0.004312 | Unsup=-0.859481 | TrainAcc=1.0000\n","Fold 18 Epoch 1000: TotalLoss=-0.086347 | Sup=0.001791 | Unsup=-0.881380 | TrainAcc=1.0000\n","Fold 18 Epoch 1500: TotalLoss=-0.081701 | Sup=0.007108 | Unsup=-0.888093 | TrainAcc=0.9972\n","Fold 18 Epoch 2000: TotalLoss=-0.088698 | Sup=0.000478 | Unsup=-0.891762 | TrainAcc=1.0000\n","Fold 18 → Acc=0.9175 | Prec=0.9812 | Rec=0.8689 | F1=0.9216 | AUC=0.9752 | CE Loss=0.5141\n","\n","=== Fold 19 ===\n","Fold 19 Epoch 1: TotalLoss=0.733052 | Sup=0.759790 | Unsup=-0.267376 | TrainAcc=0.4609\n","Fold 19 Epoch 500: TotalLoss=-0.068098 | Sup=0.018712 | Unsup=-0.868100 | TrainAcc=0.9972\n","Fold 19 Epoch 1000: TotalLoss=-0.079940 | Sup=0.008541 | Unsup=-0.884815 | TrainAcc=0.9972\n","Fold 19 Epoch 1500: TotalLoss=-0.086619 | Sup=0.002352 | Unsup=-0.889708 | TrainAcc=1.0000\n","Fold 19 Epoch 2000: TotalLoss=-0.087836 | Sup=0.001448 | Unsup=-0.892839 | TrainAcc=1.0000\n","Fold 19 → Acc=0.9181 | Prec=0.9848 | Rec=0.8667 | F1=0.9220 | AUC=0.9549 | CE Loss=0.5696\n","\n","=== Fold 20 ===\n","Fold 20 Epoch 1: TotalLoss=0.554092 | Sup=0.581853 | Unsup=-0.277616 | TrainAcc=0.7318\n","Fold 20 Epoch 500: TotalLoss=-0.077111 | Sup=0.007775 | Unsup=-0.848860 | TrainAcc=1.0000\n","Fold 20 Epoch 1000: TotalLoss=-0.086446 | Sup=0.002009 | Unsup=-0.884542 | TrainAcc=1.0000\n","Fold 20 Epoch 1500: TotalLoss=-0.088261 | Sup=0.000722 | Unsup=-0.889829 | TrainAcc=1.0000\n","Fold 20 Epoch 2000: TotalLoss=-0.089008 | Sup=0.000363 | Unsup=-0.893716 | TrainAcc=1.0000\n","Fold 20 → Acc=0.9181 | Prec=0.9824 | Rec=0.8689 | F1=0.9222 | AUC=0.9769 | CE Loss=0.4715\n","\n","=== Average Results Across 20 Folds ===\n","Accuracy:  0.9129 ± 0.0038\n","Precision: 0.9783 ± 0.0034\n","Recall:    0.8631 ± 0.0049\n","F1-score:  0.9171 ± 0.0037\n","AUC:       0.9723 ± 0.0061\n","CE Loss:   0.5102 ± 0.0457\n"]}],"source":["sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=42)\n","\n","accuracies, precisions, recalls, f1_scores, aucs, ce_losses = [], [], [], [], [], []\n","\n","for fold, (train_idx, test_idx) in enumerate(sss.split(features, y_labels.astype(np.int64)), start=1):\n","    print(f\"\\n=== Fold {fold} ===\")\n","\n","    # Convert to tensors\n","    train_idx_t = torch.from_numpy(train_idx).long().to(device)\n","    y_train_tensor = torch.from_numpy(y_labels[train_idx]).long().to(device)\n","    A_tensor = torch.from_numpy(W).float().to(device)\n","\n","    # Initialize model\n","    model = GAT_SemiSupervised(feats_dim, hidden_dim, num_classes, device, activ=\"RELU\").to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","    # Training\n","    for epoch in range(1, num_epochs + 1):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        logits = model(data)\n","        loss_sup = ce_loss(logits[train_idx_t], y_train_tensor)\n","        loss_unsup = model.cut_loss(A_tensor, logits)\n","        total_loss = loss_sup + lambda_mod * loss_unsup\n","\n","        total_loss.backward()\n","        optimizer.step()\n","\n","        if epoch % batch_print_freq == 0 or epoch == 1:\n","            model.eval()\n","            with torch.no_grad():\n","                preds_train = logits[train_idx_t].argmax(dim=1)\n","                acc_train = accuracy_score(y_train_tensor.cpu(), preds_train.cpu())\n","            print(f\"Fold {fold} Epoch {epoch}: \"\n","                  f\"TotalLoss={total_loss.item():.6f} | Sup={loss_sup.item():.6f} | \"\n","                  f\"Unsup={loss_unsup.item():.6f} | TrainAcc={acc_train:.4f}\")\n","\n","    # Evaluation\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data)\n","        preds = out.argmax(dim=1).cpu().numpy()\n","        probs = torch.softmax(out, dim=1)[:, 1].cpu().numpy()  # Probability for class 1\n","\n","    y_test = y_labels[test_idx]\n","    y_pred_test = preds[test_idx]\n","    y_prob_test = probs[test_idx]\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","    auc = roc_auc_score(y_test, y_prob_test)\n","    ce = log_loss(y_test, y_prob_test)\n","\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    aucs.append(auc)\n","    ce_losses.append(ce)\n","\n","    print(f\"Fold {fold} → \"\n","          f\"Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | \"\n","          f\"F1={f1:.4f} | AUC={auc:.4f} | CE Loss={ce:.4f}\")\n","\n","\n","# Final summary\n","print(\"\\n=== Average Results Across 20 Folds ===\")\n","print(f\"Accuracy:  {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n","print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n","print(f\"Recall:    {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n","print(f\"F1-score:  {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n","print(f\"AUC:       {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n","print(f\"CE Loss:   {np.mean(ce_losses):.4f} ± {np.std(ce_losses):.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLP4bu2YEEKF"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
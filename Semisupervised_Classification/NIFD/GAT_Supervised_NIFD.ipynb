{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1ZHdF03k7siR6svJSBy39rb1pvawrD2Ig","timestamp":1761907241564},{"file_id":"1WkJWHHWYOK-bcEvGxrEJqFxPdjv2C3wv","timestamp":1761906479775},{"file_id":"1ML5e4tUYUPTDb8cFPB9hITV2mhsj7L62","timestamp":1761905050212},{"file_id":"1iiS6eRqJmpU4pVTp3AqifEZYWtDotuU0","timestamp":1761833296070},{"file_id":"1BHr1JkPk832kbYKQYDohItySgMEM_b-k","timestamp":1761650173035}],"authorship_tag":"ABX9TyONeXVynciSc5c30jwAS43F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"b1bbc876","executionInfo":{"status":"ok","timestamp":1767670961900,"user_tz":-330,"elapsed":13,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ZhoWIduU0285","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767670963774,"user_tz":-330,"elapsed":1871,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"9d29e4f9-8240-40e1-abc9-60a80beec2a1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","/home/snu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","import torch.optim as optim\n","import numpy as np\n","import random\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GATConv\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score,\n","    f1_score, roc_auc_score, log_loss\n",")"]},{"cell_type":"code","source":["# === Load Patients ===\n","fa_patients_path = \"/home/snu/Downloads/NIFD_Patients_FA_Histogram_Feature.npy\"\n","Patients_FA_array = np.load(fa_patients_path, allow_pickle=True)\n","\n","# === Load Controls ===\n","fa_controls_path = \"/home/snu/Downloads/NIFD_Control_FA_Histogram_Feature.npy\"\n","Controls_FA_array = np.load(fa_controls_path, allow_pickle=True)\n","\n","print(\"Patients Shape:\", Patients_FA_array.shape)\n","print(\"Controls Shape:\", Controls_FA_array.shape)\n","\n","# === Combine features and labels ===\n","X = np.vstack([Controls_FA_array, Patients_FA_array])\n","y = np.hstack([\n","    np.zeros(Controls_FA_array.shape[0], dtype=np.int64),  # 0 = Control\n","    np.ones(Patients_FA_array.shape[0], dtype=np.int64)    # 1 = Patient\n","])\n","\n","# Shuffle\n","np.random.seed(42)\n","perm = np.random.permutation(X.shape[0])\n","X = X[perm]\n","y = y[perm]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgv5wIW403rR","executionInfo":{"status":"ok","timestamp":1767670963821,"user_tz":-330,"elapsed":48,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"f8da752d-b1da-4ab1-f211-d2ec174edcc3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Patients Shape: (98, 180)\n","Controls Shape: (48, 180)\n"]}]},{"cell_type":"code","source":["class GAT_Supervised(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, heads=4, activ=\"RELU\", dropout=0.2):\n","        super(GAT_Supervised, self).__init__()\n","        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True, dropout=dropout)\n","        self.bn1 = nn.BatchNorm1d(hidden_dim * heads)\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hidden_dim * heads, output_dim)\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu,\n","            \"ELU\": nnFn.elu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index)\n","        x = self.bn1(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        logits = self.fc(x)\n","        return logits"],"metadata":{"id":"rfbVT3Yp05dB","executionInfo":{"status":"ok","timestamp":1767670963824,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def create_adj(F, alpha=1):\n","    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","    W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","    W = W / W.max()\n","    return W\n","\n","def load_data(adj, node_feats):\n","    node_feats = torch.from_numpy(node_feats).float()\n","    edge_index = torch.from_numpy(np.array(np.nonzero((adj > 0))))\n","    return Data(x=node_feats, edge_index=edge_index)"],"metadata":{"id":"8AUYk2fh0_iR","executionInfo":{"status":"ok","timestamp":1767670963868,"user_tz":-330,"elapsed":43,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["num_nodes, num_feats = X.shape\n","print(f\"Number of features: {num_feats}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yOsVzLtc4b6","executionInfo":{"status":"ok","timestamp":1767670963874,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"acf95d7f-e375-47d1-abaf-216a9889ed98"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of features: 180\n"]}]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","alpha = 0.5\n","feats_dim = num_feats\n","hidden_dim = 512\n","num_classes = 2\n","num_epochs = 2000\n","lr = 0.0001\n","weight_decay = 1e-4\n","batch_print_freq = 100"],"metadata":{"id":"5xD2P7ic1B65","executionInfo":{"status":"ok","timestamp":1767670963876,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["W = create_adj(X, alpha)\n","data = load_data(W, X).to(device)\n","A_tensor = torch.from_numpy(W).float().to(device)\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-mfsholh1Erx","executionInfo":{"status":"ok","timestamp":1767670964013,"user_tz":-330,"elapsed":136,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"3f466bc5-a4c8-4ecb-84d9-76994414ad74"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Data(x=[146, 180], edge_index=[2, 21256])\n"]}]},{"cell_type":"code","source":["sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=42)\n","\n","accuracies, precisions, recalls, f1_scores, aucs, ce_losses = [], [], [], [], [], []\n","\n","for fold, (train_idx, test_idx) in enumerate(sss.split(X, y), start=1):\n","    print(f\"\\n=== Fold {fold} ===\")\n","\n","    train_idx_t = torch.from_numpy(train_idx).long().to(device)\n","    y_train_tensor = torch.from_numpy(y[train_idx]).long().to(device)\n","\n","    model = GAT_Supervised(feats_dim, hidden_dim, num_classes).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","\n","    for epoch in range(1, num_epochs + 1):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        logits = model(data)\n","        loss = ce_loss(logits[train_idx_t], y_train_tensor)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if epoch % batch_print_freq == 0 or epoch == 1:\n","            model.eval()\n","            with torch.no_grad():\n","                preds_train = logits[train_idx_t].argmax(dim=1)\n","                acc_train = accuracy_score(y_train_tensor.cpu(), preds_train.cpu())\n","            print(f\"Fold {fold} Epoch {epoch}: \"\n","                  f\"Loss={loss.item():.6f} | TrainAcc={acc_train:.4f}\")\n","\n","\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data)\n","        preds = out.argmax(dim=1).cpu().numpy()\n","        probs = torch.softmax(out, dim=1)[:, 1].cpu().numpy()  # Probability for class 1\n","\n","    y_test = y[test_idx]\n","    y_pred_test = preds[test_idx]\n","    y_prob_test = probs[test_idx]\n","\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","    auc = roc_auc_score(y_test, y_prob_test)\n","    ce = log_loss(y_test, y_prob_test)\n","\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    aucs.append(auc)\n","    ce_losses.append(ce)\n","\n","    print(f\"Fold {fold} → \"\n","          f\"Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | \"\n","          f\"F1={f1:.4f} | AUC={auc:.4f} | CE Loss={ce:.4f}\")\n","\n","\n","print(\"\\n=== Average Results Across 20 Folds ===\")\n","print(f\"Accuracy:  {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n","print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n","print(f\"Recall:    {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n","print(f\"F1-score:  {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n","print(f\"CE Loss:   {np.mean(ce_losses):.4f} ± {np.std(ce_losses):.4f}\")\n","print(f\"AUC:       {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBy-hReA1Hqa","outputId":"46e09c64-ff6f-4c35-f0f0-fd7cc4531f0b","executionInfo":{"status":"ok","timestamp":1767671586228,"user_tz":-330,"elapsed":622214,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Fold 1 ===\n","Fold 1 Epoch 1: Loss=0.667380 | TrainAcc=0.5714\n","Fold 1 Epoch 100: Loss=0.643027 | TrainAcc=0.7143\n","Fold 1 Epoch 200: Loss=0.207719 | TrainAcc=1.0000\n","Fold 1 Epoch 300: Loss=0.189805 | TrainAcc=0.9286\n","Fold 1 Epoch 400: Loss=0.008725 | TrainAcc=1.0000\n","Fold 1 Epoch 500: Loss=0.020836 | TrainAcc=1.0000\n","Fold 1 Epoch 600: Loss=0.001107 | TrainAcc=1.0000\n","Fold 1 Epoch 700: Loss=0.005936 | TrainAcc=1.0000\n","Fold 1 Epoch 800: Loss=0.000290 | TrainAcc=1.0000\n","Fold 1 Epoch 900: Loss=0.007744 | TrainAcc=1.0000\n","Fold 1 Epoch 1000: Loss=0.004271 | TrainAcc=1.0000\n","Fold 1 Epoch 1100: Loss=0.000578 | TrainAcc=1.0000\n","Fold 1 Epoch 1200: Loss=0.000334 | TrainAcc=1.0000\n","Fold 1 Epoch 1300: Loss=0.000596 | TrainAcc=1.0000\n","Fold 1 Epoch 1400: Loss=0.000328 | TrainAcc=1.0000\n","Fold 1 Epoch 1500: Loss=0.000126 | TrainAcc=1.0000\n","Fold 1 Epoch 1600: Loss=0.001110 | TrainAcc=1.0000\n","Fold 1 Epoch 1700: Loss=0.000334 | TrainAcc=1.0000\n","Fold 1 Epoch 1800: Loss=0.000491 | TrainAcc=1.0000\n","Fold 1 Epoch 1900: Loss=0.001267 | TrainAcc=1.0000\n","Fold 1 Epoch 2000: Loss=0.000416 | TrainAcc=1.0000\n","Fold 1 → Acc=0.6212 | Prec=0.7671 | Rec=0.6292 | F1=0.6914 | AUC=0.6342 | CE Loss=1.9221\n","\n","=== Fold 2 ===\n","Fold 2 Epoch 1: Loss=0.683816 | TrainAcc=0.6429\n","Fold 2 Epoch 100: Loss=0.509994 | TrainAcc=0.7143\n","Fold 2 Epoch 200: Loss=0.067289 | TrainAcc=1.0000\n","Fold 2 Epoch 300: Loss=0.015074 | TrainAcc=1.0000\n","Fold 2 Epoch 400: Loss=0.007293 | TrainAcc=1.0000\n","Fold 2 Epoch 500: Loss=0.001007 | TrainAcc=1.0000\n","Fold 2 Epoch 600: Loss=0.000945 | TrainAcc=1.0000\n","Fold 2 Epoch 700: Loss=0.002318 | TrainAcc=1.0000\n","Fold 2 Epoch 800: Loss=0.000593 | TrainAcc=1.0000\n","Fold 2 Epoch 900: Loss=0.000936 | TrainAcc=1.0000\n","Fold 2 Epoch 1000: Loss=0.001104 | TrainAcc=1.0000\n","Fold 2 Epoch 1100: Loss=0.000521 | TrainAcc=1.0000\n","Fold 2 Epoch 1200: Loss=0.006272 | TrainAcc=1.0000\n","Fold 2 Epoch 1300: Loss=0.000288 | TrainAcc=1.0000\n","Fold 2 Epoch 1400: Loss=0.000444 | TrainAcc=1.0000\n","Fold 2 Epoch 1500: Loss=0.000866 | TrainAcc=1.0000\n","Fold 2 Epoch 1600: Loss=0.000777 | TrainAcc=1.0000\n","Fold 2 Epoch 1700: Loss=0.000396 | TrainAcc=1.0000\n","Fold 2 Epoch 1800: Loss=0.000192 | TrainAcc=1.0000\n","Fold 2 Epoch 1900: Loss=0.000070 | TrainAcc=1.0000\n","Fold 2 Epoch 2000: Loss=0.000122 | TrainAcc=1.0000\n","Fold 2 → Acc=0.6439 | Prec=0.8387 | Rec=0.5843 | F1=0.6887 | AUC=0.7298 | CE Loss=1.4831\n","\n","=== Fold 3 ===\n","Fold 3 Epoch 1: Loss=0.627153 | TrainAcc=0.6429\n","Fold 3 Epoch 100: Loss=0.577772 | TrainAcc=0.7143\n","Fold 3 Epoch 200: Loss=0.486872 | TrainAcc=0.9286\n","Fold 3 Epoch 300: Loss=0.123228 | TrainAcc=1.0000\n","Fold 3 Epoch 400: Loss=0.012439 | TrainAcc=1.0000\n","Fold 3 Epoch 500: Loss=0.007343 | TrainAcc=1.0000\n","Fold 3 Epoch 600: Loss=0.011422 | TrainAcc=1.0000\n","Fold 3 Epoch 700: Loss=0.003260 | TrainAcc=1.0000\n","Fold 3 Epoch 800: Loss=0.000844 | TrainAcc=1.0000\n","Fold 3 Epoch 900: Loss=0.000858 | TrainAcc=1.0000\n","Fold 3 Epoch 1000: Loss=0.000766 | TrainAcc=1.0000\n","Fold 3 Epoch 1100: Loss=0.001052 | TrainAcc=1.0000\n","Fold 3 Epoch 1200: Loss=0.000747 | TrainAcc=1.0000\n","Fold 3 Epoch 1300: Loss=0.000815 | TrainAcc=1.0000\n","Fold 3 Epoch 1400: Loss=0.000559 | TrainAcc=1.0000\n","Fold 3 Epoch 1500: Loss=0.000564 | TrainAcc=1.0000\n","Fold 3 Epoch 1600: Loss=0.001231 | TrainAcc=1.0000\n","Fold 3 Epoch 1700: Loss=0.000152 | TrainAcc=1.0000\n","Fold 3 Epoch 1800: Loss=0.000624 | TrainAcc=1.0000\n","Fold 3 Epoch 1900: Loss=0.000121 | TrainAcc=1.0000\n","Fold 3 Epoch 2000: Loss=0.000273 | TrainAcc=1.0000\n","Fold 3 → Acc=0.6288 | Prec=0.7564 | Rec=0.6629 | F1=0.7066 | AUC=0.6086 | CE Loss=1.8456\n","\n","=== Fold 4 ===\n","Fold 4 Epoch 1: Loss=0.672211 | TrainAcc=0.5000\n","Fold 4 Epoch 100: Loss=0.496719 | TrainAcc=0.9286\n","Fold 4 Epoch 200: Loss=0.099295 | TrainAcc=1.0000\n","Fold 4 Epoch 300: Loss=0.007667 | TrainAcc=1.0000\n","Fold 4 Epoch 400: Loss=0.003261 | TrainAcc=1.0000\n","Fold 4 Epoch 500: Loss=0.001576 | TrainAcc=1.0000\n","Fold 4 Epoch 600: Loss=0.000860 | TrainAcc=1.0000\n","Fold 4 Epoch 700: Loss=0.002137 | TrainAcc=1.0000\n","Fold 4 Epoch 800: Loss=0.001555 | TrainAcc=1.0000\n","Fold 4 Epoch 900: Loss=0.000742 | TrainAcc=1.0000\n","Fold 4 Epoch 1000: Loss=0.000657 | TrainAcc=1.0000\n","Fold 4 Epoch 1100: Loss=0.000114 | TrainAcc=1.0000\n","Fold 4 Epoch 1200: Loss=0.000496 | TrainAcc=1.0000\n","Fold 4 Epoch 1300: Loss=0.000316 | TrainAcc=1.0000\n","Fold 4 Epoch 1400: Loss=0.000482 | TrainAcc=1.0000\n","Fold 4 Epoch 1500: Loss=0.000132 | TrainAcc=1.0000\n","Fold 4 Epoch 1600: Loss=0.000207 | TrainAcc=1.0000\n","Fold 4 Epoch 1700: Loss=0.000395 | TrainAcc=1.0000\n","Fold 4 Epoch 1800: Loss=0.000342 | TrainAcc=1.0000\n","Fold 4 Epoch 1900: Loss=0.000182 | TrainAcc=1.0000\n","Fold 4 Epoch 2000: Loss=0.000153 | TrainAcc=1.0000\n","Fold 4 → Acc=0.6136 | Prec=0.8167 | Rec=0.5506 | F1=0.6577 | AUC=0.7591 | CE Loss=1.4369\n","\n","=== Fold 5 ===\n","Fold 5 Epoch 1: Loss=0.651680 | TrainAcc=0.6429\n","Fold 5 Epoch 100: Loss=0.613758 | TrainAcc=0.6429\n","Fold 5 Epoch 200: Loss=0.294882 | TrainAcc=0.9286\n","Fold 5 Epoch 300: Loss=0.045616 | TrainAcc=1.0000\n","Fold 5 Epoch 400: Loss=0.019336 | TrainAcc=1.0000\n","Fold 5 Epoch 500: Loss=0.003835 | TrainAcc=1.0000\n","Fold 5 Epoch 600: Loss=0.001471 | TrainAcc=1.0000\n","Fold 5 Epoch 700: Loss=0.003956 | TrainAcc=1.0000\n","Fold 5 Epoch 800: Loss=0.001821 | TrainAcc=1.0000\n","Fold 5 Epoch 900: Loss=0.000304 | TrainAcc=1.0000\n","Fold 5 Epoch 1000: Loss=0.002152 | TrainAcc=1.0000\n","Fold 5 Epoch 1100: Loss=0.000381 | TrainAcc=1.0000\n","Fold 5 Epoch 1200: Loss=0.000539 | TrainAcc=1.0000\n","Fold 5 Epoch 1300: Loss=0.000503 | TrainAcc=1.0000\n","Fold 5 Epoch 1400: Loss=0.000180 | TrainAcc=1.0000\n","Fold 5 Epoch 1500: Loss=0.000234 | TrainAcc=1.0000\n","Fold 5 Epoch 1600: Loss=0.000349 | TrainAcc=1.0000\n","Fold 5 Epoch 1700: Loss=0.000095 | TrainAcc=1.0000\n","Fold 5 Epoch 1800: Loss=0.000622 | TrainAcc=1.0000\n","Fold 5 Epoch 1900: Loss=0.000335 | TrainAcc=1.0000\n","Fold 5 Epoch 2000: Loss=0.000072 | TrainAcc=1.0000\n","Fold 5 → Acc=0.7121 | Prec=0.8923 | Rec=0.6517 | F1=0.7532 | AUC=0.7972 | CE Loss=1.2888\n","\n","=== Fold 6 ===\n","Fold 6 Epoch 1: Loss=0.753959 | TrainAcc=0.2857\n","Fold 6 Epoch 100: Loss=0.528151 | TrainAcc=0.8571\n","Fold 6 Epoch 200: Loss=0.091636 | TrainAcc=1.0000\n","Fold 6 Epoch 300: Loss=0.007029 | TrainAcc=1.0000\n","Fold 6 Epoch 400: Loss=0.023529 | TrainAcc=1.0000\n","Fold 6 Epoch 500: Loss=0.001413 | TrainAcc=1.0000\n","Fold 6 Epoch 600: Loss=0.008897 | TrainAcc=1.0000\n","Fold 6 Epoch 700: Loss=0.000662 | TrainAcc=1.0000\n","Fold 6 Epoch 800: Loss=0.000747 | TrainAcc=1.0000\n","Fold 6 Epoch 900: Loss=0.000896 | TrainAcc=1.0000\n","Fold 6 Epoch 1000: Loss=0.000415 | TrainAcc=1.0000\n","Fold 6 Epoch 1100: Loss=0.000212 | TrainAcc=1.0000\n","Fold 6 Epoch 1200: Loss=0.000066 | TrainAcc=1.0000\n","Fold 6 Epoch 1300: Loss=0.000291 | TrainAcc=1.0000\n","Fold 6 Epoch 1400: Loss=0.000261 | TrainAcc=1.0000\n","Fold 6 Epoch 1500: Loss=0.000996 | TrainAcc=1.0000\n","Fold 6 Epoch 1600: Loss=0.000806 | TrainAcc=1.0000\n","Fold 6 Epoch 1700: Loss=0.000039 | TrainAcc=1.0000\n","Fold 6 Epoch 1800: Loss=0.000825 | TrainAcc=1.0000\n","Fold 6 Epoch 1900: Loss=0.000193 | TrainAcc=1.0000\n","Fold 6 Epoch 2000: Loss=0.000205 | TrainAcc=1.0000\n","Fold 6 → Acc=0.6515 | Prec=0.8116 | Rec=0.6292 | F1=0.7089 | AUC=0.7941 | CE Loss=1.3547\n","\n","=== Fold 7 ===\n","Fold 7 Epoch 1: Loss=0.683329 | TrainAcc=0.5714\n","Fold 7 Epoch 100: Loss=0.637769 | TrainAcc=0.7143\n","Fold 7 Epoch 200: Loss=0.163215 | TrainAcc=0.9286\n","Fold 7 Epoch 300: Loss=0.011271 | TrainAcc=1.0000\n","Fold 7 Epoch 400: Loss=0.005572 | TrainAcc=1.0000\n","Fold 7 Epoch 500: Loss=0.004249 | TrainAcc=1.0000\n","Fold 7 Epoch 600: Loss=0.005528 | TrainAcc=1.0000\n","Fold 7 Epoch 700: Loss=0.001996 | TrainAcc=1.0000\n","Fold 7 Epoch 800: Loss=0.009549 | TrainAcc=1.0000\n","Fold 7 Epoch 900: Loss=0.001748 | TrainAcc=1.0000\n","Fold 7 Epoch 1000: Loss=0.002130 | TrainAcc=1.0000\n","Fold 7 Epoch 1100: Loss=0.001033 | TrainAcc=1.0000\n","Fold 7 Epoch 1200: Loss=0.001980 | TrainAcc=1.0000\n","Fold 7 Epoch 1300: Loss=0.002107 | TrainAcc=1.0000\n","Fold 7 Epoch 1400: Loss=0.000738 | TrainAcc=1.0000\n","Fold 7 Epoch 1500: Loss=0.000102 | TrainAcc=1.0000\n","Fold 7 Epoch 1600: Loss=0.000181 | TrainAcc=1.0000\n","Fold 7 Epoch 1700: Loss=0.001105 | TrainAcc=1.0000\n","Fold 7 Epoch 1800: Loss=0.000246 | TrainAcc=1.0000\n","Fold 7 Epoch 1900: Loss=0.000167 | TrainAcc=1.0000\n","Fold 7 Epoch 2000: Loss=0.000090 | TrainAcc=1.0000\n","Fold 7 → Acc=0.6742 | Prec=0.8108 | Rec=0.6742 | F1=0.7362 | AUC=0.7831 | CE Loss=1.5826\n","\n","=== Fold 8 ===\n","Fold 8 Epoch 1: Loss=0.733513 | TrainAcc=0.4286\n","Fold 8 Epoch 100: Loss=0.473284 | TrainAcc=0.7857\n","Fold 8 Epoch 200: Loss=0.041823 | TrainAcc=1.0000\n","Fold 8 Epoch 300: Loss=0.027566 | TrainAcc=1.0000\n","Fold 8 Epoch 400: Loss=0.002689 | TrainAcc=1.0000\n","Fold 8 Epoch 500: Loss=0.003709 | TrainAcc=1.0000\n","Fold 8 Epoch 600: Loss=0.002511 | TrainAcc=1.0000\n","Fold 8 Epoch 700: Loss=0.001071 | TrainAcc=1.0000\n","Fold 8 Epoch 800: Loss=0.001524 | TrainAcc=1.0000\n","Fold 8 Epoch 900: Loss=0.001898 | TrainAcc=1.0000\n","Fold 8 Epoch 1000: Loss=0.000341 | TrainAcc=1.0000\n","Fold 8 Epoch 1100: Loss=0.000882 | TrainAcc=1.0000\n","Fold 8 Epoch 1200: Loss=0.000169 | TrainAcc=1.0000\n","Fold 8 Epoch 1300: Loss=0.000261 | TrainAcc=1.0000\n","Fold 8 Epoch 1400: Loss=0.000496 | TrainAcc=1.0000\n","Fold 8 Epoch 1500: Loss=0.000476 | TrainAcc=1.0000\n","Fold 8 Epoch 1600: Loss=0.000231 | TrainAcc=1.0000\n","Fold 8 Epoch 1700: Loss=0.000084 | TrainAcc=1.0000\n","Fold 8 Epoch 1800: Loss=0.000180 | TrainAcc=1.0000\n","Fold 8 Epoch 1900: Loss=0.000080 | TrainAcc=1.0000\n","Fold 8 Epoch 2000: Loss=0.000152 | TrainAcc=1.0000\n","Fold 8 → Acc=0.6439 | Prec=0.7561 | Rec=0.6966 | F1=0.7251 | AUC=0.6431 | CE Loss=2.0127\n","\n","=== Fold 9 ===\n","Fold 9 Epoch 1: Loss=0.729989 | TrainAcc=0.3571\n","Fold 9 Epoch 100: Loss=0.609378 | TrainAcc=0.6429\n","Fold 9 Epoch 200: Loss=0.123446 | TrainAcc=1.0000\n","Fold 9 Epoch 300: Loss=0.011609 | TrainAcc=1.0000\n","Fold 9 Epoch 400: Loss=0.022359 | TrainAcc=1.0000\n","Fold 9 Epoch 500: Loss=0.001364 | TrainAcc=1.0000\n","Fold 9 Epoch 600: Loss=0.010156 | TrainAcc=1.0000\n","Fold 9 Epoch 700: Loss=0.001274 | TrainAcc=1.0000\n","Fold 9 Epoch 800: Loss=0.002527 | TrainAcc=1.0000\n","Fold 9 Epoch 900: Loss=0.000723 | TrainAcc=1.0000\n","Fold 9 Epoch 1000: Loss=0.000758 | TrainAcc=1.0000\n","Fold 9 Epoch 1100: Loss=0.001294 | TrainAcc=1.0000\n","Fold 9 Epoch 1200: Loss=0.001256 | TrainAcc=1.0000\n","Fold 9 Epoch 1300: Loss=0.000949 | TrainAcc=1.0000\n","Fold 9 Epoch 1400: Loss=0.000085 | TrainAcc=1.0000\n","Fold 9 Epoch 1500: Loss=0.000117 | TrainAcc=1.0000\n","Fold 9 Epoch 1600: Loss=0.000286 | TrainAcc=1.0000\n","Fold 9 Epoch 1700: Loss=0.000120 | TrainAcc=1.0000\n","Fold 9 Epoch 1800: Loss=0.000160 | TrainAcc=1.0000\n","Fold 9 Epoch 1900: Loss=0.000543 | TrainAcc=1.0000\n","Fold 9 Epoch 2000: Loss=0.000100 | TrainAcc=1.0000\n","Fold 9 → Acc=0.6288 | Prec=0.8125 | Rec=0.5843 | F1=0.6797 | AUC=0.7288 | CE Loss=1.6260\n","\n","=== Fold 10 ===\n","Fold 10 Epoch 1: Loss=0.783601 | TrainAcc=0.1429\n","Fold 10 Epoch 100: Loss=0.588669 | TrainAcc=0.7857\n","Fold 10 Epoch 200: Loss=0.312483 | TrainAcc=0.9286\n","Fold 10 Epoch 300: Loss=0.010679 | TrainAcc=1.0000\n","Fold 10 Epoch 400: Loss=0.012635 | TrainAcc=1.0000\n","Fold 10 Epoch 500: Loss=0.008761 | TrainAcc=1.0000\n","Fold 10 Epoch 600: Loss=0.002547 | TrainAcc=1.0000\n","Fold 10 Epoch 700: Loss=0.001680 | TrainAcc=1.0000\n","Fold 10 Epoch 800: Loss=0.004468 | TrainAcc=1.0000\n","Fold 10 Epoch 900: Loss=0.000936 | TrainAcc=1.0000\n","Fold 10 Epoch 1000: Loss=0.000440 | TrainAcc=1.0000\n","Fold 10 Epoch 1100: Loss=0.000555 | TrainAcc=1.0000\n","Fold 10 Epoch 1200: Loss=0.001813 | TrainAcc=1.0000\n","Fold 10 Epoch 1300: Loss=0.000415 | TrainAcc=1.0000\n","Fold 10 Epoch 1400: Loss=0.000537 | TrainAcc=1.0000\n","Fold 10 Epoch 1500: Loss=0.000318 | TrainAcc=1.0000\n","Fold 10 Epoch 1600: Loss=0.000107 | TrainAcc=1.0000\n","Fold 10 Epoch 1700: Loss=0.000091 | TrainAcc=1.0000\n","Fold 10 Epoch 1800: Loss=0.000522 | TrainAcc=1.0000\n","Fold 10 Epoch 1900: Loss=0.000248 | TrainAcc=1.0000\n","Fold 10 Epoch 2000: Loss=0.000064 | TrainAcc=1.0000\n","Fold 10 → Acc=0.5530 | Prec=0.6875 | Rec=0.6180 | F1=0.6509 | AUC=0.4910 | CE Loss=2.3550\n","\n","=== Fold 11 ===\n","Fold 11 Epoch 1: Loss=0.695114 | TrainAcc=0.5714\n","Fold 11 Epoch 100: Loss=0.720322 | TrainAcc=0.6429\n","Fold 11 Epoch 200: Loss=0.225377 | TrainAcc=1.0000\n","Fold 11 Epoch 300: Loss=0.041087 | TrainAcc=1.0000\n","Fold 11 Epoch 400: Loss=0.005528 | TrainAcc=1.0000\n","Fold 11 Epoch 500: Loss=0.006472 | TrainAcc=1.0000\n","Fold 11 Epoch 600: Loss=0.002982 | TrainAcc=1.0000\n","Fold 11 Epoch 700: Loss=0.002198 | TrainAcc=1.0000\n","Fold 11 Epoch 800: Loss=0.000893 | TrainAcc=1.0000\n","Fold 11 Epoch 900: Loss=0.001089 | TrainAcc=1.0000\n","Fold 11 Epoch 1000: Loss=0.000661 | TrainAcc=1.0000\n","Fold 11 Epoch 1100: Loss=0.000894 | TrainAcc=1.0000\n","Fold 11 Epoch 1200: Loss=0.000680 | TrainAcc=1.0000\n","Fold 11 Epoch 1300: Loss=0.004646 | TrainAcc=1.0000\n","Fold 11 Epoch 1400: Loss=0.000542 | TrainAcc=1.0000\n","Fold 11 Epoch 1500: Loss=0.000382 | TrainAcc=1.0000\n","Fold 11 Epoch 1600: Loss=0.000184 | TrainAcc=1.0000\n","Fold 11 Epoch 1700: Loss=0.000099 | TrainAcc=1.0000\n","Fold 11 Epoch 1800: Loss=0.000616 | TrainAcc=1.0000\n","Fold 11 Epoch 1900: Loss=0.000440 | TrainAcc=1.0000\n","Fold 11 Epoch 2000: Loss=0.000272 | TrainAcc=1.0000\n","Fold 11 → Acc=0.7348 | Prec=0.9219 | Rec=0.6629 | F1=0.7712 | AUC=0.8142 | CE Loss=1.3391\n","\n","=== Fold 12 ===\n","Fold 12 Epoch 1: Loss=0.692752 | TrainAcc=0.4286\n","Fold 12 Epoch 100: Loss=0.620279 | TrainAcc=0.6429\n","Fold 12 Epoch 200: Loss=0.085486 | TrainAcc=1.0000\n","Fold 12 Epoch 300: Loss=0.025508 | TrainAcc=1.0000\n","Fold 12 Epoch 400: Loss=0.002950 | TrainAcc=1.0000\n","Fold 12 Epoch 500: Loss=0.001765 | TrainAcc=1.0000\n","Fold 12 Epoch 600: Loss=0.000384 | TrainAcc=1.0000\n","Fold 12 Epoch 700: Loss=0.001143 | TrainAcc=1.0000\n","Fold 12 Epoch 800: Loss=0.000170 | TrainAcc=1.0000\n","Fold 12 Epoch 900: Loss=0.000258 | TrainAcc=1.0000\n","Fold 12 Epoch 1000: Loss=0.000205 | TrainAcc=1.0000\n","Fold 12 Epoch 1100: Loss=0.000208 | TrainAcc=1.0000\n","Fold 12 Epoch 1200: Loss=0.001135 | TrainAcc=1.0000\n","Fold 12 Epoch 1300: Loss=0.000054 | TrainAcc=1.0000\n","Fold 12 Epoch 1400: Loss=0.000595 | TrainAcc=1.0000\n","Fold 12 Epoch 1500: Loss=0.000265 | TrainAcc=1.0000\n","Fold 12 Epoch 1600: Loss=0.000078 | TrainAcc=1.0000\n","Fold 12 Epoch 1700: Loss=0.000521 | TrainAcc=1.0000\n","Fold 12 Epoch 1800: Loss=0.000085 | TrainAcc=1.0000\n","Fold 12 Epoch 1900: Loss=0.000391 | TrainAcc=1.0000\n","Fold 12 Epoch 2000: Loss=0.000069 | TrainAcc=1.0000\n","Fold 12 → Acc=0.6136 | Prec=0.7794 | Rec=0.5955 | F1=0.6752 | AUC=0.6543 | CE Loss=1.9695\n","\n","=== Fold 13 ===\n","Fold 13 Epoch 1: Loss=0.674027 | TrainAcc=0.5714\n","Fold 13 Epoch 100: Loss=0.431735 | TrainAcc=0.7857\n","Fold 13 Epoch 200: Loss=0.060451 | TrainAcc=1.0000\n","Fold 13 Epoch 300: Loss=0.013040 | TrainAcc=1.0000\n","Fold 13 Epoch 400: Loss=0.036684 | TrainAcc=1.0000\n","Fold 13 Epoch 500: Loss=0.002505 | TrainAcc=1.0000\n","Fold 13 Epoch 600: Loss=0.004542 | TrainAcc=1.0000\n","Fold 13 Epoch 700: Loss=0.001759 | TrainAcc=1.0000\n","Fold 13 Epoch 800: Loss=0.000813 | TrainAcc=1.0000\n","Fold 13 Epoch 900: Loss=0.000306 | TrainAcc=1.0000\n","Fold 13 Epoch 1000: Loss=0.000982 | TrainAcc=1.0000\n","Fold 13 Epoch 1100: Loss=0.001445 | TrainAcc=1.0000\n","Fold 13 Epoch 1200: Loss=0.000573 | TrainAcc=1.0000\n","Fold 13 Epoch 1300: Loss=0.002665 | TrainAcc=1.0000\n","Fold 13 Epoch 1400: Loss=0.000532 | TrainAcc=1.0000\n","Fold 13 Epoch 1500: Loss=0.000057 | TrainAcc=1.0000\n","Fold 13 Epoch 1600: Loss=0.000972 | TrainAcc=1.0000\n","Fold 13 Epoch 1700: Loss=0.000171 | TrainAcc=1.0000\n","Fold 13 Epoch 1800: Loss=0.000263 | TrainAcc=1.0000\n","Fold 13 Epoch 1900: Loss=0.000267 | TrainAcc=1.0000\n","Fold 13 Epoch 2000: Loss=0.000143 | TrainAcc=1.0000\n","Fold 13 → Acc=0.5379 | Prec=0.6628 | Rec=0.6404 | F1=0.6514 | AUC=0.4899 | CE Loss=2.1285\n","\n","=== Fold 14 ===\n","Fold 14 Epoch 1: Loss=0.688539 | TrainAcc=0.5000\n","Fold 14 Epoch 100: Loss=0.603869 | TrainAcc=0.6429\n","Fold 14 Epoch 200: Loss=0.167461 | TrainAcc=1.0000\n","Fold 14 Epoch 300: Loss=0.008102 | TrainAcc=1.0000\n","Fold 14 Epoch 400: Loss=0.002788 | TrainAcc=1.0000\n","Fold 14 Epoch 500: Loss=0.005977 | TrainAcc=1.0000\n","Fold 14 Epoch 600: Loss=0.001792 | TrainAcc=1.0000\n","Fold 14 Epoch 700: Loss=0.005245 | TrainAcc=1.0000\n","Fold 14 Epoch 800: Loss=0.000723 | TrainAcc=1.0000\n","Fold 14 Epoch 900: Loss=0.004672 | TrainAcc=1.0000\n","Fold 14 Epoch 1000: Loss=0.001810 | TrainAcc=1.0000\n","Fold 14 Epoch 1100: Loss=0.000456 | TrainAcc=1.0000\n","Fold 14 Epoch 1200: Loss=0.000101 | TrainAcc=1.0000\n","Fold 14 Epoch 1300: Loss=0.000189 | TrainAcc=1.0000\n","Fold 14 Epoch 1400: Loss=0.000318 | TrainAcc=1.0000\n","Fold 14 Epoch 1500: Loss=0.000062 | TrainAcc=1.0000\n","Fold 14 Epoch 1600: Loss=0.000335 | TrainAcc=1.0000\n","Fold 14 Epoch 1700: Loss=0.000300 | TrainAcc=1.0000\n","Fold 14 Epoch 1800: Loss=0.000149 | TrainAcc=1.0000\n","Fold 14 Epoch 1900: Loss=0.000135 | TrainAcc=1.0000\n","Fold 14 Epoch 2000: Loss=0.000050 | TrainAcc=1.0000\n","Fold 14 → Acc=0.6288 | Prec=0.8226 | Rec=0.5730 | F1=0.6755 | AUC=0.6948 | CE Loss=2.0261\n","\n","=== Fold 15 ===\n","Fold 15 Epoch 1: Loss=0.659364 | TrainAcc=0.6429\n","Fold 15 Epoch 100: Loss=0.614599 | TrainAcc=0.6429\n","Fold 15 Epoch 200: Loss=0.151431 | TrainAcc=1.0000\n","Fold 15 Epoch 300: Loss=0.046612 | TrainAcc=1.0000\n","Fold 15 Epoch 400: Loss=0.003002 | TrainAcc=1.0000\n","Fold 15 Epoch 500: Loss=0.034197 | TrainAcc=1.0000\n","Fold 15 Epoch 600: Loss=0.001876 | TrainAcc=1.0000\n","Fold 15 Epoch 700: Loss=0.000306 | TrainAcc=1.0000\n","Fold 15 Epoch 800: Loss=0.001462 | TrainAcc=1.0000\n","Fold 15 Epoch 900: Loss=0.000441 | TrainAcc=1.0000\n","Fold 15 Epoch 1000: Loss=0.000330 | TrainAcc=1.0000\n","Fold 15 Epoch 1100: Loss=0.001226 | TrainAcc=1.0000\n","Fold 15 Epoch 1200: Loss=0.000466 | TrainAcc=1.0000\n","Fold 15 Epoch 1300: Loss=0.000243 | TrainAcc=1.0000\n","Fold 15 Epoch 1400: Loss=0.000075 | TrainAcc=1.0000\n","Fold 15 Epoch 1500: Loss=0.000401 | TrainAcc=1.0000\n","Fold 15 Epoch 1600: Loss=0.000475 | TrainAcc=1.0000\n","Fold 15 Epoch 1700: Loss=0.000058 | TrainAcc=1.0000\n","Fold 15 Epoch 1800: Loss=0.000240 | TrainAcc=1.0000\n","Fold 15 Epoch 1900: Loss=0.000103 | TrainAcc=1.0000\n","Fold 15 Epoch 2000: Loss=0.000295 | TrainAcc=1.0000\n","Fold 15 → Acc=0.6515 | Prec=0.8644 | Rec=0.5730 | F1=0.6892 | AUC=0.7674 | CE Loss=1.4385\n","\n","=== Fold 16 ===\n","Fold 16 Epoch 1: Loss=0.671900 | TrainAcc=0.5714\n","Fold 16 Epoch 100: Loss=0.640078 | TrainAcc=0.6429\n","Fold 16 Epoch 200: Loss=0.152942 | TrainAcc=1.0000\n","Fold 16 Epoch 300: Loss=0.015523 | TrainAcc=1.0000\n","Fold 16 Epoch 400: Loss=0.011569 | TrainAcc=1.0000\n","Fold 16 Epoch 500: Loss=0.004983 | TrainAcc=1.0000\n","Fold 16 Epoch 600: Loss=0.001394 | TrainAcc=1.0000\n","Fold 16 Epoch 700: Loss=0.001908 | TrainAcc=1.0000\n","Fold 16 Epoch 800: Loss=0.000500 | TrainAcc=1.0000\n","Fold 16 Epoch 900: Loss=0.005726 | TrainAcc=1.0000\n","Fold 16 Epoch 1000: Loss=0.001572 | TrainAcc=1.0000\n","Fold 16 Epoch 1100: Loss=0.000939 | TrainAcc=1.0000\n","Fold 16 Epoch 1200: Loss=0.001167 | TrainAcc=1.0000\n","Fold 16 Epoch 1300: Loss=0.000058 | TrainAcc=1.0000\n","Fold 16 Epoch 1400: Loss=0.000724 | TrainAcc=1.0000\n","Fold 16 Epoch 1500: Loss=0.000242 | TrainAcc=1.0000\n","Fold 16 Epoch 1600: Loss=0.016716 | TrainAcc=1.0000\n","Fold 16 Epoch 1700: Loss=0.000118 | TrainAcc=1.0000\n","Fold 16 Epoch 1800: Loss=0.000165 | TrainAcc=1.0000\n","Fold 16 Epoch 1900: Loss=0.000244 | TrainAcc=1.0000\n","Fold 16 Epoch 2000: Loss=0.000313 | TrainAcc=1.0000\n","Fold 16 → Acc=0.5606 | Prec=0.7123 | Rec=0.5843 | F1=0.6420 | AUC=0.5950 | CE Loss=1.9547\n","\n","=== Fold 17 ===\n","Fold 17 Epoch 1: Loss=0.709703 | TrainAcc=0.5000\n","Fold 17 Epoch 100: Loss=0.677862 | TrainAcc=0.5714\n","Fold 17 Epoch 200: Loss=0.242033 | TrainAcc=1.0000\n","Fold 17 Epoch 300: Loss=0.017677 | TrainAcc=1.0000\n","Fold 17 Epoch 400: Loss=0.007935 | TrainAcc=1.0000\n","Fold 17 Epoch 500: Loss=0.008649 | TrainAcc=1.0000\n","Fold 17 Epoch 600: Loss=0.008273 | TrainAcc=1.0000\n","Fold 17 Epoch 700: Loss=0.005915 | TrainAcc=1.0000\n","Fold 17 Epoch 800: Loss=0.000578 | TrainAcc=1.0000\n","Fold 17 Epoch 900: Loss=0.001451 | TrainAcc=1.0000\n","Fold 17 Epoch 1000: Loss=0.000648 | TrainAcc=1.0000\n","Fold 17 Epoch 1100: Loss=0.000163 | TrainAcc=1.0000\n","Fold 17 Epoch 1200: Loss=0.000557 | TrainAcc=1.0000\n","Fold 17 Epoch 1300: Loss=0.002317 | TrainAcc=1.0000\n","Fold 17 Epoch 1400: Loss=0.000928 | TrainAcc=1.0000\n","Fold 17 Epoch 1500: Loss=0.000232 | TrainAcc=1.0000\n","Fold 17 Epoch 1600: Loss=0.001629 | TrainAcc=1.0000\n","Fold 17 Epoch 1700: Loss=0.000189 | TrainAcc=1.0000\n","Fold 17 Epoch 1800: Loss=0.001714 | TrainAcc=1.0000\n","Fold 17 Epoch 1900: Loss=0.000130 | TrainAcc=1.0000\n","Fold 17 Epoch 2000: Loss=0.000244 | TrainAcc=1.0000\n","Fold 17 → Acc=0.7045 | Prec=0.9032 | Rec=0.6292 | F1=0.7417 | AUC=0.8035 | CE Loss=1.4328\n","\n","=== Fold 18 ===\n","Fold 18 Epoch 1: Loss=0.715610 | TrainAcc=0.3571\n","Fold 18 Epoch 100: Loss=0.520887 | TrainAcc=0.8571\n","Fold 18 Epoch 200: Loss=0.173475 | TrainAcc=0.9286\n","Fold 18 Epoch 300: Loss=0.017536 | TrainAcc=1.0000\n","Fold 18 Epoch 400: Loss=0.003222 | TrainAcc=1.0000\n","Fold 18 Epoch 500: Loss=0.002851 | TrainAcc=1.0000\n","Fold 18 Epoch 600: Loss=0.000836 | TrainAcc=1.0000\n","Fold 18 Epoch 700: Loss=0.004829 | TrainAcc=1.0000\n","Fold 18 Epoch 800: Loss=0.000198 | TrainAcc=1.0000\n","Fold 18 Epoch 900: Loss=0.000733 | TrainAcc=1.0000\n","Fold 18 Epoch 1000: Loss=0.000823 | TrainAcc=1.0000\n","Fold 18 Epoch 1100: Loss=0.001368 | TrainAcc=1.0000\n","Fold 18 Epoch 1200: Loss=0.006278 | TrainAcc=1.0000\n","Fold 18 Epoch 1300: Loss=0.000170 | TrainAcc=1.0000\n","Fold 18 Epoch 1400: Loss=0.000698 | TrainAcc=1.0000\n","Fold 18 Epoch 1500: Loss=0.000221 | TrainAcc=1.0000\n","Fold 18 Epoch 1600: Loss=0.000712 | TrainAcc=1.0000\n","Fold 18 Epoch 1700: Loss=0.000032 | TrainAcc=1.0000\n","Fold 18 Epoch 1800: Loss=0.000074 | TrainAcc=1.0000\n","Fold 18 Epoch 1900: Loss=0.000077 | TrainAcc=1.0000\n","Fold 18 Epoch 2000: Loss=0.001121 | TrainAcc=1.0000\n","Fold 18 → Acc=0.7348 | Prec=0.9355 | Rec=0.6517 | F1=0.7682 | AUC=0.7917 | CE Loss=1.3229\n","\n","=== Fold 19 ===\n","Fold 19 Epoch 1: Loss=0.687337 | TrainAcc=0.6429\n","Fold 19 Epoch 100: Loss=0.541420 | TrainAcc=0.7857\n","Fold 19 Epoch 200: Loss=0.184920 | TrainAcc=0.9286\n","Fold 19 Epoch 300: Loss=0.030592 | TrainAcc=1.0000\n","Fold 19 Epoch 400: Loss=0.057267 | TrainAcc=1.0000\n","Fold 19 Epoch 500: Loss=0.015101 | TrainAcc=1.0000\n","Fold 19 Epoch 600: Loss=0.008961 | TrainAcc=1.0000\n","Fold 19 Epoch 700: Loss=0.003025 | TrainAcc=1.0000\n","Fold 19 Epoch 800: Loss=0.000799 | TrainAcc=1.0000\n","Fold 19 Epoch 900: Loss=0.003310 | TrainAcc=1.0000\n","Fold 19 Epoch 1000: Loss=0.002502 | TrainAcc=1.0000\n","Fold 19 Epoch 1100: Loss=0.001707 | TrainAcc=1.0000\n","Fold 19 Epoch 1200: Loss=0.006405 | TrainAcc=1.0000\n","Fold 19 Epoch 1300: Loss=0.002020 | TrainAcc=1.0000\n","Fold 19 Epoch 1400: Loss=0.000074 | TrainAcc=1.0000\n","Fold 19 Epoch 1500: Loss=0.000225 | TrainAcc=1.0000\n","Fold 19 Epoch 1600: Loss=0.000257 | TrainAcc=1.0000\n","Fold 19 Epoch 1700: Loss=0.000076 | TrainAcc=1.0000\n","Fold 19 Epoch 1800: Loss=0.002195 | TrainAcc=1.0000\n","Fold 19 Epoch 1900: Loss=0.000095 | TrainAcc=1.0000\n","Fold 19 Epoch 2000: Loss=0.000116 | TrainAcc=1.0000\n","Fold 19 → Acc=0.7121 | Prec=0.8696 | Rec=0.6742 | F1=0.7595 | AUC=0.7938 | CE Loss=1.1689\n","\n","=== Fold 20 ===\n","Fold 20 Epoch 1: Loss=0.716734 | TrainAcc=0.4286\n","Fold 20 Epoch 100: Loss=0.569929 | TrainAcc=0.6429\n","Fold 20 Epoch 200: Loss=0.096478 | TrainAcc=1.0000\n","Fold 20 Epoch 300: Loss=0.019406 | TrainAcc=1.0000\n","Fold 20 Epoch 400: Loss=0.017356 | TrainAcc=1.0000\n","Fold 20 Epoch 500: Loss=0.002020 | TrainAcc=1.0000\n","Fold 20 Epoch 600: Loss=0.000428 | TrainAcc=1.0000\n","Fold 20 Epoch 700: Loss=0.002371 | TrainAcc=1.0000\n","Fold 20 Epoch 800: Loss=0.000873 | TrainAcc=1.0000\n","Fold 20 Epoch 900: Loss=0.001788 | TrainAcc=1.0000\n","Fold 20 Epoch 1000: Loss=0.002589 | TrainAcc=1.0000\n","Fold 20 Epoch 1100: Loss=0.000418 | TrainAcc=1.0000\n","Fold 20 Epoch 1200: Loss=0.000249 | TrainAcc=1.0000\n","Fold 20 Epoch 1300: Loss=0.001800 | TrainAcc=1.0000\n","Fold 20 Epoch 1400: Loss=0.000287 | TrainAcc=1.0000\n","Fold 20 Epoch 1500: Loss=0.000122 | TrainAcc=1.0000\n","Fold 20 Epoch 1600: Loss=0.000630 | TrainAcc=1.0000\n","Fold 20 Epoch 1700: Loss=0.000301 | TrainAcc=1.0000\n","Fold 20 Epoch 1800: Loss=0.000028 | TrainAcc=1.0000\n","Fold 20 Epoch 1900: Loss=0.001042 | TrainAcc=1.0000\n","Fold 20 Epoch 2000: Loss=0.000267 | TrainAcc=1.0000\n","Fold 20 → Acc=0.5303 | Prec=0.6901 | Rec=0.5506 | F1=0.6125 | AUC=0.5562 | CE Loss=2.6950\n","\n","=== Average Results Across 20 Folds ===\n","Accuracy:  0.6390 ± 0.0602\n","Precision: 0.8056 ± 0.0775\n","Recall:    0.6208 ± 0.0428\n","F1-score:  0.6992 ± 0.0444\n","CE Loss:   1.7192 ± 0.3953\n","AUC:       0.6965 ± 0.1033\n"]}]},{"cell_type":"code","source":["# sss = StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=42)\n","\n","# accuracies, precisions, recalls, f1_scores, aucs, ce_losses = [], [], [], [], [], []\n","\n","# for fold, (train_idx, test_idx) in enumerate(sss.split(X, y), start=1):\n","#     print(f\"\\n=== Fold {fold} ===\")\n","\n","#     train_idx_t = torch.from_numpy(train_idx).long().to(device)\n","#     y_train_tensor = torch.from_numpy(y[train_idx]).long().to(device)\n","\n","#     model = GAT_Supervised(feats_dim, hidden_dim, num_classes).to(device)\n","#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","#     ce_loss = nn.CrossEntropyLoss()\n","\n","\n","#     for epoch in range(1, num_epochs + 1):\n","#         model.train()\n","#         optimizer.zero_grad()\n","\n","#         logits = model(data)\n","#         loss = ce_loss(logits[train_idx_t], y_train_tensor)\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         if epoch % batch_print_freq == 0 or epoch == 1:\n","#             model.eval()\n","#             with torch.no_grad():\n","#                 preds_train = logits[train_idx_t].argmax(dim=1)\n","#                 acc_train = accuracy_score(y_train_tensor.cpu(), preds_train.cpu())\n","#             print(f\"Fold {fold} Epoch {epoch}: \"\n","#                   f\"Loss={loss.item():.6f} | TrainAcc={acc_train:.4f}\")\n","\n","\n","#     model.eval()\n","#     with torch.no_grad():\n","#         out = model(data)\n","#         preds = out.argmax(dim=1).cpu().numpy()\n","#         probs = torch.softmax(out, dim=1)[:, 1].cpu().numpy()  # Probability for class 1\n","\n","#     y_test = y[test_idx]\n","#     y_pred_test = preds[test_idx]\n","#     y_prob_test = probs[test_idx]\n","\n","\n","#     acc = accuracy_score(y_test, y_pred_test)\n","#     prec = precision_score(y_test, y_pred_test, zero_division=0)\n","#     rec = recall_score(y_test, y_pred_test, zero_division=0)\n","#     f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","#     auc = roc_auc_score(y_test, y_prob_test)\n","#     ce = log_loss(y_test, y_prob_test)\n","\n","#     accuracies.append(acc)\n","#     precisions.append(prec)\n","#     recalls.append(rec)\n","#     f1_scores.append(f1)\n","#     aucs.append(auc)\n","#     ce_losses.append(ce)\n","\n","#     print(f\"Fold {fold} → \"\n","#           f\"Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | \"\n","#           f\"F1={f1:.4f} | AUC={auc:.4f} | CE Loss={ce:.4f}\")\n","\n","\n","# print(\"\\n=== Average Results Across 20 Folds ===\")\n","# print(f\"Accuracy:  {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n","# print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n","# print(f\"Recall:    {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n","# print(f\"F1-score:  {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n","# print(f\"CE Loss:   {np.mean(ce_losses):.4f} ± {np.std(ce_losses):.4f}\")\n","# print(f\"AUC:       {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")"],"metadata":{"id":"Ulq6yjgsoxUG","executionInfo":{"status":"ok","timestamp":1767671586231,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# sss = StratifiedShuffleSplit(n_splits=20, test_size=0.1, random_state=42)\n","\n","# accuracies, precisions, recalls, f1_scores, aucs, ce_losses = [], [], [], [], [], []\n","\n","# for fold, (train_idx, test_idx) in enumerate(sss.split(X, y), start=1):\n","#     print(f\"\\n=== Fold {fold} ===\")\n","\n","#     train_idx_t = torch.from_numpy(train_idx).long().to(device)\n","#     y_train_tensor = torch.from_numpy(y[train_idx]).long().to(device)\n","\n","#     model = GAT_Supervised(feats_dim, hidden_dim, num_classes).to(device)\n","#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","#     ce_loss = nn.CrossEntropyLoss()\n","\n","\n","#     for epoch in range(1, num_epochs + 1):\n","#         model.train()\n","#         optimizer.zero_grad()\n","\n","#         logits = model(data)\n","#         loss = ce_loss(logits[train_idx_t], y_train_tensor)\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         if epoch % batch_print_freq == 0 or epoch == 1:\n","#             model.eval()\n","#             with torch.no_grad():\n","#                 preds_train = logits[train_idx_t].argmax(dim=1)\n","#                 acc_train = accuracy_score(y_train_tensor.cpu(), preds_train.cpu())\n","#             print(f\"Fold {fold} Epoch {epoch}: \"\n","#                   f\"Loss={loss.item():.6f} | TrainAcc={acc_train:.4f}\")\n","\n","\n","#     model.eval()\n","#     with torch.no_grad():\n","#         out = model(data)\n","#         preds = out.argmax(dim=1).cpu().numpy()\n","#         probs = torch.softmax(out, dim=1)[:, 1].cpu().numpy()  # Probability for class 1\n","\n","#     y_test = y[test_idx]\n","#     y_pred_test = preds[test_idx]\n","#     y_prob_test = probs[test_idx]\n","\n","\n","#     acc = accuracy_score(y_test, y_pred_test)\n","#     prec = precision_score(y_test, y_pred_test, zero_division=0)\n","#     rec = recall_score(y_test, y_pred_test, zero_division=0)\n","#     f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","#     auc = roc_auc_score(y_test, y_prob_test)\n","#     ce = log_loss(y_test, y_prob_test)\n","\n","#     accuracies.append(acc)\n","#     precisions.append(prec)\n","#     recalls.append(rec)\n","#     f1_scores.append(f1)\n","#     aucs.append(auc)\n","#     ce_losses.append(ce)\n","\n","#     print(f\"Fold {fold} → \"\n","#           f\"Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | \"\n","#           f\"F1={f1:.4f} | AUC={auc:.4f} | CE Loss={ce:.4f}\")\n","\n","\n","# print(\"\\n=== Average Results Across 20 Folds ===\")\n","# print(f\"Accuracy:  {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n","# print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n","# print(f\"Recall:    {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n","# print(f\"F1-score:  {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n","# print(f\"CE Loss:   {np.mean(ce_losses):.4f} ± {np.std(ce_losses):.4f}\")\n","# print(f\"AUC:       {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")"],"metadata":{"id":"ELwzBrLKpbmx","executionInfo":{"status":"ok","timestamp":1767671586276,"user_tz":-330,"elapsed":44,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":12,"outputs":[]}]}
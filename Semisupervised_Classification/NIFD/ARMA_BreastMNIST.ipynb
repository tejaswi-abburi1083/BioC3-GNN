{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch_geometric\n",
        "!pip install -q class_resolver\n",
        "!pip3 install pymatting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkAZVXPzQhkS",
        "outputId": "3d5f8ebc-3fef-44f6-e6bf-65657c8bdfbb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymatting in ./.local/lib/python3.10/site-packages (1.1.14)\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZhoWIduU0285",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1598b8b-7794-4586-80b7-940fb286d5e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
            "/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(\n",
            "/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
            "/home/snu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as nnFn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import ChebConv\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, log_loss\n",
        ")\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import ARMAConv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/home/snu/Downloads/breastmnist_224.npz', allow_pickle=True)\n",
        "all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n",
        "all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n",
        "\n",
        "# Convert to 3-channel RGB\n",
        "images = all_images.astype(np.float32) / 255.0\n",
        "images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N, 3, 224, 224)\n",
        "X_torch = torch.tensor(images)\n",
        "y_torch = torch.tensor(all_labels).long()\n",
        "print(f\"Raw images: {X_torch.shape}, Labels: {y_torch.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgv5wIW403rR",
        "outputId": "301dac59-8db0-47bf-8374-0bf3ceaa8fb4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw images: torch.Size([780, 3, 224, 224]), Labels: torch.Size([780])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class0_idx = [i for i in range(len(y_torch)) if y_torch[i] == 0]\n",
        "class1_idx = [i for i in range(len(y_torch)) if y_torch[i] == 1]\n",
        "\n",
        "random.seed(42)\n",
        "sampled_class0 = random.sample(class0_idx, min(300, len(class0_idx)))\n",
        "sampled_class1 = random.sample(class1_idx, min(300, len(class1_idx)))\n",
        "\n",
        "selected_indices = sampled_class0 + sampled_class1\n",
        "random.shuffle(selected_indices)\n",
        "\n",
        "subset_dataset = Subset(TensorDataset(X_torch, y_torch), selected_indices)\n",
        "subset_loader = DataLoader(subset_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "RravF_31Ppdw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "vit = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
        "vit.eval().to(device)\n",
        "\n",
        "vit_feats, y_list = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, lbls in subset_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        feats = vit(imgs)\n",
        "        vit_feats.append(feats.cpu())\n",
        "        y_list.extend(lbls.cpu().tolist())\n",
        "\n",
        "F = torch.cat(vit_feats, dim=0).numpy().astype(np.float32)\n",
        "y = np.array(y_list).astype(np.int64)\n",
        "\n",
        "num_nodes, num_feats = F.shape\n",
        "print(f\"Extracted ViT-DINO Features: {F.shape}, Labels: {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhfaxAc3PrBv",
        "outputId": "067314de-6ae8-4986-f0ce-4a6db901ecd6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /home/snu/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted ViT-DINO Features: (510, 768), Labels: (510,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as nnFn\n",
        "from torch_geometric.nn import ARMAConv\n",
        "\n",
        "class ARMA_Supervised(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, device, num_stacks=1, num_layers=1):\n",
        "        super(ARMA_Supervised, self).__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.conv1 = ARMAConv(input_dim, hidden_dim, num_stacks=num_stacks, num_layers=num_layers,\n",
        "                              shared_weights=True, dropout=0.3)\n",
        "        self.conv2 = ARMAConv(hidden_dim, hidden_dim, num_stacks=num_stacks, num_layers=num_layers,\n",
        "                              shared_weights=True, dropout=0.3)\n",
        "        self.conv3 = ARMAConv(hidden_dim, hidden_dim, num_stacks=num_stacks, num_layers=num_layers,\n",
        "                              shared_weights=True, dropout=0.3)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        activations = {\n",
        "            \"SELU\": nnFn.selu,\n",
        "            \"SiLU\": nnFn.silu,\n",
        "            \"GELU\": nnFn.gelu,\n",
        "            \"RELU\": nnFn.relu,\n",
        "            \"ELU\": nnFn.elu,\n",
        "            \"PReLU\": nnFn.prelu,\n",
        "            \"LeakyReLU\": nnFn.leaky_relu\n",
        "        }\n",
        "        self.act = activations.get(\"RELU\", nnFn.relu)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # --- Layer 1 ---\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.act(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # --- Layer 2 ---\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.act(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # --- Layer 3 ---\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.act(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        logits = self.fc(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "bdbHMxznPMMz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_adj(F, alpha=1):\n",
        "    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n",
        "    W = np.dot(F_norm, F_norm.T)\n",
        "    W = np.where(W >= alpha, 1, 0).astype(np.float32)\n",
        "    W = W / W.max()\n",
        "    return W\n",
        "\n",
        "def load_data(adj, node_feats):\n",
        "    node_feats = torch.from_numpy(node_feats).float()\n",
        "    edge_index = torch.from_numpy(np.array(np.nonzero((adj > 0))))\n",
        "    return Data(x=node_feats, edge_index=edge_index)"
      ],
      "metadata": {
        "id": "8AUYk2fh0_iR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "alpha = 0.6\n",
        "feats_dim = num_feats\n",
        "hidden_dim = 256\n",
        "num_classes = 2\n",
        "num_epochs = 2000\n",
        "lr = 0.0001\n",
        "weight_decay = 1e-4\n",
        "batch_print_freq = 100"
      ],
      "metadata": {
        "id": "5xD2P7ic1B65"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = create_adj(F, alpha)\n",
        "data = load_data(W, F).to(device)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mfsholh1Erx",
        "outputId": "04fe4c3e-66c1-4823-8e69-974731a95145"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[510, 768], edge_index=[2, 233892])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=42)\n",
        "\n",
        "accuracies, precisions, recalls, f1_scores, aucs, ce_losses = [], [], [], [], [], []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(sss.split(F, y), start=1):\n",
        "    print(f\"\\n=== Fold {fold} ===\")\n",
        "\n",
        "    train_idx_t = torch.from_numpy(train_idx).long().to(device)\n",
        "    y_train_tensor = torch.from_numpy(y[train_idx]).long().to(device)\n",
        "\n",
        "    model = ARMA_Supervised(feats_dim, hidden_dim, num_classes, device).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(data)\n",
        "        loss = ce_loss(logits[train_idx_t], y_train_tensor)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % batch_print_freq == 0 or epoch == 1:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                preds_train = logits[train_idx_t].argmax(dim=1)\n",
        "                acc_train = accuracy_score(y_train_tensor.cpu(), preds_train.cpu())\n",
        "            print(f\"Fold {fold} Epoch {epoch}: Loss={loss.item():.6f} | TrainAcc={acc_train:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data)\n",
        "        preds = out.argmax(dim=1).cpu().numpy()\n",
        "        probs = torch.softmax(out, dim=1)[:, 1].cpu().numpy()\n",
        "\n",
        "    y_test = y[test_idx]\n",
        "    y_pred_test = preds[test_idx]\n",
        "    y_pred_test = preds[test_idx]\n",
        "    y_prob_test = probs[test_idx]\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred_test)\n",
        "    prec = precision_score(y_test, y_pred_test, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred_test, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n",
        "    auc = roc_auc_score(y_test, y_prob_test)\n",
        "    ce = log_loss(y_test, y_prob_test)\n",
        "\n",
        "    accuracies.append(acc)\n",
        "    precisions.append(prec)\n",
        "    recalls.append(rec)\n",
        "    f1_scores.append(f1)\n",
        "    aucs.append(auc)\n",
        "    ce_losses.append(ce)\n",
        "\n",
        "    print(f\"Fold {fold} → \"\n",
        "          f\"Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | \"\n",
        "          f\"F1={f1:.4f} | AUC={auc:.4f} | CE Loss={ce:.4f}\")\n",
        "\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n=== Average Results Across 20 Folds ===\")\n",
        "print(f\"Accuracy:  {np.mean(accuracies):.4f} \\u00b1 {np.std(accuracies):.4f}\")\n",
        "print(f\"Precision: {np.mean(precisions):.4f} \\u00b1 {np.std(precisions):.4f}\")\n",
        "print(f\"Recall:    {np.mean(recalls):.4f} \\u00b1 {np.std(recalls):.4f}\")\n",
        "print(f\"F1-score:  {np.mean(f1_scores):.4f} \\u00b1 {np.std(f1_scores):.4f}\")\n",
        "print(f\"AUC:       {np.mean(aucs):.4f} \\u00b1 {np.std(aucs):.4f}\")\n",
        "print(f\"CE Loss:   {np.mean(ce_losses):.4f} \\u00b1 {np.std(ce_losses):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBy-hReA1Hqa",
        "outputId": "918da329-ec88-4f4a-806f-7b980e79f927"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1 ===\n",
            "Fold 1 Epoch 1: Loss=4.447953 | TrainAcc=0.4118\n",
            "Fold 1 Epoch 100: Loss=0.607424 | TrainAcc=0.6824\n",
            "Fold 1 Epoch 200: Loss=0.465208 | TrainAcc=0.7804\n",
            "Fold 1 Epoch 300: Loss=0.373145 | TrainAcc=0.8353\n",
            "Fold 1 Epoch 400: Loss=0.288736 | TrainAcc=0.8784\n",
            "Fold 1 Epoch 500: Loss=0.212624 | TrainAcc=0.9176\n",
            "Fold 1 Epoch 600: Loss=0.179572 | TrainAcc=0.9255\n",
            "Fold 1 Epoch 700: Loss=0.150213 | TrainAcc=0.9490\n",
            "Fold 1 Epoch 800: Loss=0.110108 | TrainAcc=0.9686\n",
            "Fold 1 Epoch 900: Loss=0.129609 | TrainAcc=0.9529\n",
            "Fold 1 Epoch 1000: Loss=0.085313 | TrainAcc=0.9725\n",
            "Fold 1 Epoch 1100: Loss=0.050832 | TrainAcc=0.9725\n",
            "Fold 1 Epoch 1200: Loss=0.093977 | TrainAcc=0.9608\n",
            "Fold 1 Epoch 1300: Loss=0.080213 | TrainAcc=0.9686\n",
            "Fold 1 Epoch 1400: Loss=0.066872 | TrainAcc=0.9686\n",
            "Fold 1 Epoch 1500: Loss=0.031269 | TrainAcc=0.9843\n",
            "Fold 1 Epoch 1600: Loss=0.017064 | TrainAcc=0.9961\n",
            "Fold 1 Epoch 1700: Loss=0.028972 | TrainAcc=0.9843\n",
            "Fold 1 Epoch 1800: Loss=0.034267 | TrainAcc=0.9882\n",
            "Fold 1 Epoch 1900: Loss=0.046903 | TrainAcc=0.9882\n",
            "Fold 1 Epoch 2000: Loss=0.043776 | TrainAcc=0.9922\n",
            "Fold 1 → Acc=0.8588 | Prec=0.9014 | Rec=0.8533 | F1=0.8767 | AUC=0.9326 | CE Loss=0.6055\n",
            "\n",
            "=== Fold 2 ===\n",
            "Fold 2 Epoch 1: Loss=1.801098 | TrainAcc=0.4314\n",
            "Fold 2 Epoch 100: Loss=0.592763 | TrainAcc=0.6627\n",
            "Fold 2 Epoch 200: Loss=0.379670 | TrainAcc=0.8353\n",
            "Fold 2 Epoch 300: Loss=0.314810 | TrainAcc=0.8745\n",
            "Fold 2 Epoch 400: Loss=0.273797 | TrainAcc=0.8863\n",
            "Fold 2 Epoch 500: Loss=0.212255 | TrainAcc=0.9216\n",
            "Fold 2 Epoch 600: Loss=0.205215 | TrainAcc=0.8980\n",
            "Fold 2 Epoch 700: Loss=0.158648 | TrainAcc=0.9333\n",
            "Fold 2 Epoch 800: Loss=0.138061 | TrainAcc=0.9451\n",
            "Fold 2 Epoch 900: Loss=0.123929 | TrainAcc=0.9451\n",
            "Fold 2 Epoch 1000: Loss=0.073588 | TrainAcc=0.9804\n",
            "Fold 2 Epoch 1100: Loss=0.105153 | TrainAcc=0.9608\n",
            "Fold 2 Epoch 1200: Loss=0.062586 | TrainAcc=0.9765\n",
            "Fold 2 Epoch 1300: Loss=0.101013 | TrainAcc=0.9647\n",
            "Fold 2 Epoch 1400: Loss=0.053651 | TrainAcc=0.9882\n",
            "Fold 2 Epoch 1500: Loss=0.043014 | TrainAcc=0.9882\n",
            "Fold 2 Epoch 1600: Loss=0.036334 | TrainAcc=0.9843\n",
            "Fold 2 Epoch 1700: Loss=0.054893 | TrainAcc=0.9804\n",
            "Fold 2 Epoch 1800: Loss=0.051126 | TrainAcc=0.9804\n",
            "Fold 2 Epoch 1900: Loss=0.021305 | TrainAcc=0.9961\n",
            "Fold 2 Epoch 2000: Loss=0.044364 | TrainAcc=0.9765\n",
            "Fold 2 → Acc=0.8667 | Prec=0.8867 | Rec=0.8867 | F1=0.8867 | AUC=0.9396 | CE Loss=0.4873\n",
            "\n",
            "=== Fold 3 ===\n",
            "Fold 3 Epoch 1: Loss=1.749263 | TrainAcc=0.4588\n",
            "Fold 3 Epoch 100: Loss=0.540232 | TrainAcc=0.7412\n",
            "Fold 3 Epoch 200: Loss=0.406161 | TrainAcc=0.8235\n",
            "Fold 3 Epoch 300: Loss=0.334421 | TrainAcc=0.8549\n",
            "Fold 3 Epoch 400: Loss=0.238332 | TrainAcc=0.9020\n",
            "Fold 3 Epoch 500: Loss=0.217567 | TrainAcc=0.9255\n",
            "Fold 3 Epoch 600: Loss=0.189765 | TrainAcc=0.9216\n",
            "Fold 3 Epoch 700: Loss=0.105861 | TrainAcc=0.9569\n",
            "Fold 3 Epoch 800: Loss=0.136133 | TrainAcc=0.9412\n",
            "Fold 3 Epoch 900: Loss=0.090772 | TrainAcc=0.9569\n",
            "Fold 3 Epoch 1000: Loss=0.071105 | TrainAcc=0.9725\n",
            "Fold 3 Epoch 1100: Loss=0.029502 | TrainAcc=0.9961\n",
            "Fold 3 Epoch 1200: Loss=0.050068 | TrainAcc=0.9804\n",
            "Fold 3 Epoch 1300: Loss=0.039175 | TrainAcc=0.9765\n",
            "Fold 3 Epoch 1400: Loss=0.069443 | TrainAcc=0.9765\n",
            "Fold 3 Epoch 1500: Loss=0.030024 | TrainAcc=0.9882\n",
            "Fold 3 Epoch 1600: Loss=0.026471 | TrainAcc=0.9922\n",
            "Fold 3 Epoch 1700: Loss=0.029316 | TrainAcc=0.9922\n",
            "Fold 3 Epoch 1800: Loss=0.050550 | TrainAcc=0.9843\n",
            "Fold 3 Epoch 1900: Loss=0.018867 | TrainAcc=0.9922\n",
            "Fold 3 Epoch 2000: Loss=0.025043 | TrainAcc=0.9922\n",
            "Fold 3 → Acc=0.8314 | Prec=0.8639 | Rec=0.8467 | F1=0.8552 | AUC=0.9113 | CE Loss=0.8133\n",
            "\n",
            "=== Fold 4 ===\n",
            "Fold 4 Epoch 1: Loss=1.707943 | TrainAcc=0.5686\n",
            "Fold 4 Epoch 100: Loss=0.548773 | TrainAcc=0.7137\n",
            "Fold 4 Epoch 200: Loss=0.371070 | TrainAcc=0.8549\n",
            "Fold 4 Epoch 300: Loss=0.296413 | TrainAcc=0.8824\n",
            "Fold 4 Epoch 400: Loss=0.225674 | TrainAcc=0.9176\n",
            "Fold 4 Epoch 500: Loss=0.164410 | TrainAcc=0.9333\n",
            "Fold 4 Epoch 600: Loss=0.110328 | TrainAcc=0.9647\n",
            "Fold 4 Epoch 700: Loss=0.161389 | TrainAcc=0.9333\n",
            "Fold 4 Epoch 800: Loss=0.097491 | TrainAcc=0.9529\n",
            "Fold 4 Epoch 900: Loss=0.115642 | TrainAcc=0.9686\n",
            "Fold 4 Epoch 1000: Loss=0.133304 | TrainAcc=0.9490\n",
            "Fold 4 Epoch 1100: Loss=0.073100 | TrainAcc=0.9529\n",
            "Fold 4 Epoch 1200: Loss=0.053012 | TrainAcc=0.9804\n",
            "Fold 4 Epoch 1300: Loss=0.063482 | TrainAcc=0.9765\n",
            "Fold 4 Epoch 1400: Loss=0.024252 | TrainAcc=0.9882\n",
            "Fold 4 Epoch 1500: Loss=0.035078 | TrainAcc=0.9765\n",
            "Fold 4 Epoch 1600: Loss=0.035967 | TrainAcc=0.9843\n",
            "Fold 4 Epoch 1700: Loss=0.015486 | TrainAcc=0.9922\n",
            "Fold 4 Epoch 1800: Loss=0.019042 | TrainAcc=0.9922\n",
            "Fold 4 Epoch 1900: Loss=0.026004 | TrainAcc=0.9882\n",
            "Fold 4 Epoch 2000: Loss=0.017125 | TrainAcc=0.9961\n",
            "Fold 4 → Acc=0.8745 | Prec=0.8831 | Rec=0.9067 | F1=0.8947 | AUC=0.9327 | CE Loss=0.5459\n",
            "\n",
            "=== Fold 5 ===\n",
            "Fold 5 Epoch 1: Loss=1.357660 | TrainAcc=0.5098\n",
            "Fold 5 Epoch 100: Loss=0.530879 | TrainAcc=0.7373\n",
            "Fold 5 Epoch 200: Loss=0.362536 | TrainAcc=0.8314\n",
            "Fold 5 Epoch 300: Loss=0.284775 | TrainAcc=0.8784\n",
            "Fold 5 Epoch 400: Loss=0.230273 | TrainAcc=0.8941\n",
            "Fold 5 Epoch 500: Loss=0.166011 | TrainAcc=0.9333\n",
            "Fold 5 Epoch 600: Loss=0.105027 | TrainAcc=0.9529\n",
            "Fold 5 Epoch 700: Loss=0.112591 | TrainAcc=0.9608\n",
            "Fold 5 Epoch 800: Loss=0.104483 | TrainAcc=0.9569\n",
            "Fold 5 Epoch 900: Loss=0.154241 | TrainAcc=0.9373\n",
            "Fold 5 Epoch 1000: Loss=0.097306 | TrainAcc=0.9608\n",
            "Fold 5 Epoch 1100: Loss=0.089349 | TrainAcc=0.9686\n",
            "Fold 5 Epoch 1200: Loss=0.057136 | TrainAcc=0.9804\n",
            "Fold 5 Epoch 1300: Loss=0.051221 | TrainAcc=0.9804\n",
            "Fold 5 Epoch 1400: Loss=0.047466 | TrainAcc=0.9804\n",
            "Fold 5 Epoch 1500: Loss=0.047052 | TrainAcc=0.9843\n",
            "Fold 5 Epoch 1600: Loss=0.019051 | TrainAcc=0.9961\n",
            "Fold 5 Epoch 1700: Loss=0.018279 | TrainAcc=0.9922\n",
            "Fold 5 Epoch 1800: Loss=0.014679 | TrainAcc=0.9922\n",
            "Fold 5 Epoch 1900: Loss=0.021399 | TrainAcc=0.9922\n",
            "Fold 5 Epoch 2000: Loss=0.021145 | TrainAcc=0.9961\n",
            "Fold 5 → Acc=0.8667 | Prec=0.9028 | Rec=0.8667 | F1=0.8844 | AUC=0.9513 | CE Loss=0.4830\n",
            "\n",
            "=== Fold 6 ===\n",
            "Fold 6 Epoch 1: Loss=1.208742 | TrainAcc=0.5176\n",
            "Fold 6 Epoch 100: Loss=0.588346 | TrainAcc=0.6941\n",
            "Fold 6 Epoch 200: Loss=0.377447 | TrainAcc=0.8431\n",
            "Fold 6 Epoch 300: Loss=0.325645 | TrainAcc=0.8588\n",
            "Fold 6 Epoch 400: Loss=0.240828 | TrainAcc=0.9216\n",
            "Fold 6 Epoch 500: Loss=0.193151 | TrainAcc=0.9059\n",
            "Fold 6 Epoch 600: Loss=0.196419 | TrainAcc=0.9176\n",
            "Fold 6 Epoch 700: Loss=0.149687 | TrainAcc=0.9451\n",
            "Fold 6 Epoch 800: Loss=0.132475 | TrainAcc=0.9373\n",
            "Fold 6 Epoch 900: Loss=0.137373 | TrainAcc=0.9412\n",
            "Fold 6 Epoch 1000: Loss=0.121915 | TrainAcc=0.9569\n",
            "Fold 6 Epoch 1100: Loss=0.094120 | TrainAcc=0.9686\n",
            "Fold 6 Epoch 1200: Loss=0.076937 | TrainAcc=0.9647\n",
            "Fold 6 Epoch 1300: Loss=0.062724 | TrainAcc=0.9725\n",
            "Fold 6 Epoch 1400: Loss=0.039903 | TrainAcc=0.9843\n",
            "Fold 6 Epoch 1500: Loss=0.030246 | TrainAcc=0.9843\n",
            "Fold 6 Epoch 1600: Loss=0.035246 | TrainAcc=0.9843\n",
            "Fold 6 Epoch 1700: Loss=0.040377 | TrainAcc=0.9843\n",
            "Fold 6 Epoch 1800: Loss=0.041653 | TrainAcc=0.9843\n",
            "Fold 6 Epoch 1900: Loss=0.026586 | TrainAcc=0.9922\n",
            "Fold 6 Epoch 2000: Loss=0.055454 | TrainAcc=0.9804\n",
            "Fold 6 → Acc=0.8510 | Prec=0.9118 | Rec=0.8267 | F1=0.8671 | AUC=0.9163 | CE Loss=0.8244\n",
            "\n",
            "=== Fold 7 ===\n",
            "Fold 7 Epoch 1: Loss=1.366349 | TrainAcc=0.4824\n",
            "Fold 7 Epoch 100: Loss=0.503989 | TrainAcc=0.7373\n",
            "Fold 7 Epoch 200: Loss=0.400624 | TrainAcc=0.8157\n",
            "Fold 7 Epoch 300: Loss=0.298268 | TrainAcc=0.8431\n",
            "Fold 7 Epoch 400: Loss=0.268792 | TrainAcc=0.8863\n",
            "Fold 7 Epoch 500: Loss=0.192739 | TrainAcc=0.9216\n",
            "Fold 7 Epoch 600: Loss=0.141349 | TrainAcc=0.9451\n",
            "Fold 7 Epoch 700: Loss=0.118777 | TrainAcc=0.9608\n",
            "Fold 7 Epoch 800: Loss=0.086301 | TrainAcc=0.9569\n",
            "Fold 7 Epoch 900: Loss=0.113444 | TrainAcc=0.9490\n",
            "Fold 7 Epoch 1000: Loss=0.087432 | TrainAcc=0.9725\n",
            "Fold 7 Epoch 1100: Loss=0.073329 | TrainAcc=0.9686\n",
            "Fold 7 Epoch 1200: Loss=0.057318 | TrainAcc=0.9804\n",
            "Fold 7 Epoch 1300: Loss=0.067331 | TrainAcc=0.9725\n",
            "Fold 7 Epoch 1400: Loss=0.055021 | TrainAcc=0.9804\n",
            "Fold 7 Epoch 1500: Loss=0.008977 | TrainAcc=1.0000\n",
            "Fold 7 Epoch 1600: Loss=0.017243 | TrainAcc=0.9922\n",
            "Fold 7 Epoch 1700: Loss=0.034547 | TrainAcc=0.9882\n",
            "Fold 7 Epoch 1800: Loss=0.018978 | TrainAcc=0.9882\n",
            "Fold 7 Epoch 1900: Loss=0.058218 | TrainAcc=0.9804\n",
            "Fold 7 Epoch 2000: Loss=0.027584 | TrainAcc=0.9961\n",
            "Fold 7 → Acc=0.8549 | Prec=0.9065 | Rec=0.8400 | F1=0.8720 | AUC=0.9444 | CE Loss=0.5291\n",
            "\n",
            "=== Fold 8 ===\n",
            "Fold 8 Epoch 1: Loss=1.633031 | TrainAcc=0.4627\n",
            "Fold 8 Epoch 100: Loss=0.541425 | TrainAcc=0.7333\n",
            "Fold 8 Epoch 200: Loss=0.406369 | TrainAcc=0.8314\n",
            "Fold 8 Epoch 300: Loss=0.295199 | TrainAcc=0.8706\n",
            "Fold 8 Epoch 400: Loss=0.224799 | TrainAcc=0.9176\n",
            "Fold 8 Epoch 500: Loss=0.210268 | TrainAcc=0.9137\n",
            "Fold 8 Epoch 600: Loss=0.181099 | TrainAcc=0.9255\n",
            "Fold 8 Epoch 700: Loss=0.149539 | TrainAcc=0.9294\n",
            "Fold 8 Epoch 800: Loss=0.147729 | TrainAcc=0.9569\n",
            "Fold 8 Epoch 900: Loss=0.116879 | TrainAcc=0.9608\n",
            "Fold 8 Epoch 1000: Loss=0.089791 | TrainAcc=0.9686\n",
            "Fold 8 Epoch 1100: Loss=0.064855 | TrainAcc=0.9804\n",
            "Fold 8 Epoch 1200: Loss=0.072551 | TrainAcc=0.9569\n",
            "Fold 8 Epoch 1300: Loss=0.052799 | TrainAcc=0.9882\n",
            "Fold 8 Epoch 1400: Loss=0.049924 | TrainAcc=0.9765\n",
            "Fold 8 Epoch 1500: Loss=0.036759 | TrainAcc=0.9882\n",
            "Fold 8 Epoch 1600: Loss=0.057735 | TrainAcc=0.9765\n",
            "Fold 8 Epoch 1700: Loss=0.040627 | TrainAcc=0.9804\n",
            "Fold 8 Epoch 1800: Loss=0.006437 | TrainAcc=1.0000\n",
            "Fold 8 Epoch 1900: Loss=0.019113 | TrainAcc=0.9922\n",
            "Fold 8 Epoch 2000: Loss=0.015530 | TrainAcc=0.9922\n",
            "Fold 8 → Acc=0.8706 | Prec=0.8679 | Rec=0.9200 | F1=0.8932 | AUC=0.9447 | CE Loss=0.5375\n",
            "\n",
            "=== Fold 9 ===\n",
            "Fold 9 Epoch 1: Loss=2.721257 | TrainAcc=0.4431\n",
            "Fold 9 Epoch 100: Loss=0.596902 | TrainAcc=0.6941\n",
            "Fold 9 Epoch 200: Loss=0.438238 | TrainAcc=0.7882\n",
            "Fold 9 Epoch 300: Loss=0.341120 | TrainAcc=0.8431\n",
            "Fold 9 Epoch 400: Loss=0.226729 | TrainAcc=0.9137\n",
            "Fold 9 Epoch 500: Loss=0.205403 | TrainAcc=0.9098\n",
            "Fold 9 Epoch 600: Loss=0.152822 | TrainAcc=0.9333\n",
            "Fold 9 Epoch 700: Loss=0.159963 | TrainAcc=0.9529\n",
            "Fold 9 Epoch 800: Loss=0.111552 | TrainAcc=0.9569\n",
            "Fold 9 Epoch 900: Loss=0.161016 | TrainAcc=0.9294\n",
            "Fold 9 Epoch 1000: Loss=0.070553 | TrainAcc=0.9765\n",
            "Fold 9 Epoch 1100: Loss=0.055033 | TrainAcc=0.9725\n",
            "Fold 9 Epoch 1200: Loss=0.068313 | TrainAcc=0.9882\n",
            "Fold 9 Epoch 1300: Loss=0.055058 | TrainAcc=0.9765\n",
            "Fold 9 Epoch 1400: Loss=0.048142 | TrainAcc=0.9843\n",
            "Fold 9 Epoch 1500: Loss=0.065243 | TrainAcc=0.9686\n",
            "Fold 9 Epoch 1600: Loss=0.087914 | TrainAcc=0.9608\n",
            "Fold 9 Epoch 1700: Loss=0.061212 | TrainAcc=0.9843\n",
            "Fold 9 Epoch 1800: Loss=0.034865 | TrainAcc=0.9961\n",
            "Fold 9 Epoch 1900: Loss=0.050830 | TrainAcc=0.9804\n",
            "Fold 9 Epoch 2000: Loss=0.019262 | TrainAcc=0.9922\n",
            "Fold 9 → Acc=0.8627 | Prec=0.8859 | Rec=0.8800 | F1=0.8829 | AUC=0.9437 | CE Loss=0.4870\n",
            "\n",
            "=== Fold 10 ===\n",
            "Fold 10 Epoch 1: Loss=2.727309 | TrainAcc=0.3922\n",
            "Fold 10 Epoch 100: Loss=0.565491 | TrainAcc=0.7294\n",
            "Fold 10 Epoch 200: Loss=0.409317 | TrainAcc=0.8039\n",
            "Fold 10 Epoch 300: Loss=0.304069 | TrainAcc=0.8431\n",
            "Fold 10 Epoch 400: Loss=0.283301 | TrainAcc=0.8784\n",
            "Fold 10 Epoch 500: Loss=0.228653 | TrainAcc=0.8902\n",
            "Fold 10 Epoch 600: Loss=0.149849 | TrainAcc=0.9333\n",
            "Fold 10 Epoch 700: Loss=0.133341 | TrainAcc=0.9373\n",
            "Fold 10 Epoch 800: Loss=0.129522 | TrainAcc=0.9490\n",
            "Fold 10 Epoch 900: Loss=0.127509 | TrainAcc=0.9490\n",
            "Fold 10 Epoch 1000: Loss=0.080034 | TrainAcc=0.9608\n",
            "Fold 10 Epoch 1100: Loss=0.080898 | TrainAcc=0.9765\n",
            "Fold 10 Epoch 1200: Loss=0.095619 | TrainAcc=0.9686\n",
            "Fold 10 Epoch 1300: Loss=0.052963 | TrainAcc=0.9804\n",
            "Fold 10 Epoch 1400: Loss=0.046077 | TrainAcc=0.9843\n",
            "Fold 10 Epoch 1500: Loss=0.071627 | TrainAcc=0.9804\n",
            "Fold 10 Epoch 1600: Loss=0.043470 | TrainAcc=0.9765\n",
            "Fold 10 Epoch 1700: Loss=0.031348 | TrainAcc=0.9843\n",
            "Fold 10 Epoch 1800: Loss=0.017447 | TrainAcc=0.9961\n",
            "Fold 10 Epoch 1900: Loss=0.016530 | TrainAcc=0.9922\n",
            "Fold 10 Epoch 2000: Loss=0.076517 | TrainAcc=0.9765\n",
            "Fold 10 → Acc=0.8431 | Prec=0.8526 | Rec=0.8867 | F1=0.8693 | AUC=0.9196 | CE Loss=0.7721\n",
            "\n",
            "=== Fold 11 ===\n",
            "Fold 11 Epoch 1: Loss=1.492758 | TrainAcc=0.4980\n",
            "Fold 11 Epoch 100: Loss=0.489214 | TrainAcc=0.7529\n",
            "Fold 11 Epoch 200: Loss=0.353432 | TrainAcc=0.8275\n",
            "Fold 11 Epoch 300: Loss=0.242984 | TrainAcc=0.9216\n",
            "Fold 11 Epoch 400: Loss=0.226822 | TrainAcc=0.9020\n",
            "Fold 11 Epoch 500: Loss=0.171896 | TrainAcc=0.9412\n",
            "Fold 11 Epoch 600: Loss=0.102829 | TrainAcc=0.9529\n",
            "Fold 11 Epoch 700: Loss=0.108062 | TrainAcc=0.9608\n",
            "Fold 11 Epoch 800: Loss=0.111763 | TrainAcc=0.9529\n",
            "Fold 11 Epoch 900: Loss=0.067727 | TrainAcc=0.9686\n",
            "Fold 11 Epoch 1000: Loss=0.089329 | TrainAcc=0.9647\n",
            "Fold 11 Epoch 1100: Loss=0.055487 | TrainAcc=0.9725\n",
            "Fold 11 Epoch 1200: Loss=0.073673 | TrainAcc=0.9725\n",
            "Fold 11 Epoch 1300: Loss=0.066491 | TrainAcc=0.9647\n",
            "Fold 11 Epoch 1400: Loss=0.046998 | TrainAcc=0.9843\n",
            "Fold 11 Epoch 1500: Loss=0.060469 | TrainAcc=0.9804\n",
            "Fold 11 Epoch 1600: Loss=0.040224 | TrainAcc=0.9922\n",
            "Fold 11 Epoch 1700: Loss=0.048579 | TrainAcc=0.9725\n",
            "Fold 11 Epoch 1800: Loss=0.017896 | TrainAcc=0.9961\n",
            "Fold 11 Epoch 1900: Loss=0.033332 | TrainAcc=0.9804\n",
            "Fold 11 Epoch 2000: Loss=0.070756 | TrainAcc=0.9804\n",
            "Fold 11 → Acc=0.8275 | Prec=0.8581 | Rec=0.8467 | F1=0.8523 | AUC=0.9187 | CE Loss=0.6729\n",
            "\n",
            "=== Fold 12 ===\n",
            "Fold 12 Epoch 1: Loss=1.476194 | TrainAcc=0.4784\n",
            "Fold 12 Epoch 100: Loss=0.560673 | TrainAcc=0.6980\n",
            "Fold 12 Epoch 200: Loss=0.404427 | TrainAcc=0.8000\n",
            "Fold 12 Epoch 300: Loss=0.295876 | TrainAcc=0.8824\n",
            "Fold 12 Epoch 400: Loss=0.244631 | TrainAcc=0.9059\n",
            "Fold 12 Epoch 500: Loss=0.196373 | TrainAcc=0.9255\n",
            "Fold 12 Epoch 600: Loss=0.157074 | TrainAcc=0.9373\n",
            "Fold 12 Epoch 700: Loss=0.155368 | TrainAcc=0.9294\n",
            "Fold 12 Epoch 800: Loss=0.173750 | TrainAcc=0.9373\n",
            "Fold 12 Epoch 900: Loss=0.093093 | TrainAcc=0.9725\n",
            "Fold 12 Epoch 1000: Loss=0.088336 | TrainAcc=0.9608\n",
            "Fold 12 Epoch 1100: Loss=0.093667 | TrainAcc=0.9725\n",
            "Fold 12 Epoch 1200: Loss=0.087722 | TrainAcc=0.9608\n",
            "Fold 12 Epoch 1300: Loss=0.047739 | TrainAcc=0.9882\n",
            "Fold 12 Epoch 1400: Loss=0.065876 | TrainAcc=0.9725\n",
            "Fold 12 Epoch 1500: Loss=0.056620 | TrainAcc=0.9843\n",
            "Fold 12 Epoch 1600: Loss=0.029515 | TrainAcc=0.9882\n",
            "Fold 12 Epoch 1700: Loss=0.069618 | TrainAcc=0.9725\n",
            "Fold 12 Epoch 1800: Loss=0.025628 | TrainAcc=0.9882\n",
            "Fold 12 Epoch 1900: Loss=0.052105 | TrainAcc=0.9765\n",
            "Fold 12 Epoch 2000: Loss=0.018607 | TrainAcc=0.9922\n",
            "Fold 12 → Acc=0.8275 | Prec=0.8955 | Rec=0.8000 | F1=0.8451 | AUC=0.9383 | CE Loss=0.5672\n",
            "\n",
            "=== Fold 13 ===\n",
            "Fold 13 Epoch 1: Loss=1.186419 | TrainAcc=0.4824\n",
            "Fold 13 Epoch 100: Loss=0.508157 | TrainAcc=0.7569\n",
            "Fold 13 Epoch 200: Loss=0.379792 | TrainAcc=0.8118\n",
            "Fold 13 Epoch 300: Loss=0.293744 | TrainAcc=0.8745\n",
            "Fold 13 Epoch 400: Loss=0.247004 | TrainAcc=0.9020\n",
            "Fold 13 Epoch 500: Loss=0.165571 | TrainAcc=0.9294\n",
            "Fold 13 Epoch 600: Loss=0.139161 | TrainAcc=0.9490\n",
            "Fold 13 Epoch 700: Loss=0.144329 | TrainAcc=0.9529\n",
            "Fold 13 Epoch 800: Loss=0.099029 | TrainAcc=0.9529\n",
            "Fold 13 Epoch 900: Loss=0.128218 | TrainAcc=0.9412\n",
            "Fold 13 Epoch 1000: Loss=0.082271 | TrainAcc=0.9490\n",
            "Fold 13 Epoch 1100: Loss=0.060137 | TrainAcc=0.9765\n",
            "Fold 13 Epoch 1200: Loss=0.082221 | TrainAcc=0.9686\n",
            "Fold 13 Epoch 1300: Loss=0.078742 | TrainAcc=0.9725\n",
            "Fold 13 Epoch 1400: Loss=0.061893 | TrainAcc=0.9725\n",
            "Fold 13 Epoch 1500: Loss=0.034198 | TrainAcc=0.9843\n",
            "Fold 13 Epoch 1600: Loss=0.025953 | TrainAcc=0.9882\n",
            "Fold 13 Epoch 1700: Loss=0.056500 | TrainAcc=0.9686\n",
            "Fold 13 Epoch 1800: Loss=0.021889 | TrainAcc=0.9922\n",
            "Fold 13 Epoch 1900: Loss=0.074707 | TrainAcc=0.9843\n",
            "Fold 13 Epoch 2000: Loss=0.026172 | TrainAcc=0.9843\n",
            "Fold 13 → Acc=0.8314 | Prec=0.8639 | Rec=0.8467 | F1=0.8552 | AUC=0.9195 | CE Loss=0.6574\n",
            "\n",
            "=== Fold 14 ===\n",
            "Fold 14 Epoch 1: Loss=2.323446 | TrainAcc=0.4157\n",
            "Fold 14 Epoch 100: Loss=0.582461 | TrainAcc=0.7059\n",
            "Fold 14 Epoch 200: Loss=0.435615 | TrainAcc=0.8078\n",
            "Fold 14 Epoch 300: Loss=0.312677 | TrainAcc=0.8667\n",
            "Fold 14 Epoch 400: Loss=0.261186 | TrainAcc=0.8941\n",
            "Fold 14 Epoch 500: Loss=0.195849 | TrainAcc=0.8980\n",
            "Fold 14 Epoch 600: Loss=0.156952 | TrainAcc=0.9373\n",
            "Fold 14 Epoch 700: Loss=0.134905 | TrainAcc=0.9490\n",
            "Fold 14 Epoch 800: Loss=0.089385 | TrainAcc=0.9765\n",
            "Fold 14 Epoch 900: Loss=0.075701 | TrainAcc=0.9843\n",
            "Fold 14 Epoch 1000: Loss=0.065257 | TrainAcc=0.9725\n",
            "Fold 14 Epoch 1100: Loss=0.074367 | TrainAcc=0.9725\n",
            "Fold 14 Epoch 1200: Loss=0.095881 | TrainAcc=0.9686\n",
            "Fold 14 Epoch 1300: Loss=0.065932 | TrainAcc=0.9686\n",
            "Fold 14 Epoch 1400: Loss=0.045877 | TrainAcc=0.9804\n",
            "Fold 14 Epoch 1500: Loss=0.053412 | TrainAcc=0.9765\n",
            "Fold 14 Epoch 1600: Loss=0.047592 | TrainAcc=0.9882\n",
            "Fold 14 Epoch 1700: Loss=0.037878 | TrainAcc=0.9922\n",
            "Fold 14 Epoch 1800: Loss=0.034728 | TrainAcc=0.9843\n",
            "Fold 14 Epoch 1900: Loss=0.018835 | TrainAcc=0.9961\n",
            "Fold 14 Epoch 2000: Loss=0.030327 | TrainAcc=0.9765\n",
            "Fold 14 → Acc=0.8510 | Prec=0.9000 | Rec=0.8400 | F1=0.8690 | AUC=0.9303 | CE Loss=0.6381\n",
            "\n",
            "=== Fold 15 ===\n",
            "Fold 15 Epoch 1: Loss=1.517357 | TrainAcc=0.5647\n",
            "Fold 15 Epoch 100: Loss=0.586294 | TrainAcc=0.7098\n",
            "Fold 15 Epoch 200: Loss=0.404120 | TrainAcc=0.8392\n",
            "Fold 15 Epoch 300: Loss=0.297238 | TrainAcc=0.8706\n",
            "Fold 15 Epoch 400: Loss=0.305794 | TrainAcc=0.8706\n",
            "Fold 15 Epoch 500: Loss=0.178754 | TrainAcc=0.9373\n",
            "Fold 15 Epoch 600: Loss=0.156538 | TrainAcc=0.9333\n",
            "Fold 15 Epoch 700: Loss=0.126369 | TrainAcc=0.9451\n",
            "Fold 15 Epoch 800: Loss=0.151030 | TrainAcc=0.9451\n",
            "Fold 15 Epoch 900: Loss=0.075689 | TrainAcc=0.9765\n",
            "Fold 15 Epoch 1000: Loss=0.053749 | TrainAcc=0.9804\n",
            "Fold 15 Epoch 1100: Loss=0.072282 | TrainAcc=0.9608\n",
            "Fold 15 Epoch 1200: Loss=0.070331 | TrainAcc=0.9686\n",
            "Fold 15 Epoch 1300: Loss=0.076328 | TrainAcc=0.9647\n",
            "Fold 15 Epoch 1400: Loss=0.045020 | TrainAcc=0.9882\n",
            "Fold 15 Epoch 1500: Loss=0.115238 | TrainAcc=0.9647\n",
            "Fold 15 Epoch 1600: Loss=0.039715 | TrainAcc=0.9843\n",
            "Fold 15 Epoch 1700: Loss=0.055897 | TrainAcc=0.9765\n",
            "Fold 15 Epoch 1800: Loss=0.047990 | TrainAcc=0.9804\n",
            "Fold 15 Epoch 1900: Loss=0.034646 | TrainAcc=0.9882\n",
            "Fold 15 Epoch 2000: Loss=0.024549 | TrainAcc=0.9882\n",
            "Fold 15 → Acc=0.8471 | Prec=0.9051 | Rec=0.8267 | F1=0.8641 | AUC=0.9432 | CE Loss=0.4893\n",
            "\n",
            "=== Fold 16 ===\n",
            "Fold 16 Epoch 1: Loss=1.898961 | TrainAcc=0.4510\n",
            "Fold 16 Epoch 100: Loss=0.551548 | TrainAcc=0.6980\n",
            "Fold 16 Epoch 200: Loss=0.408114 | TrainAcc=0.8078\n",
            "Fold 16 Epoch 300: Loss=0.265930 | TrainAcc=0.8745\n",
            "Fold 16 Epoch 400: Loss=0.227335 | TrainAcc=0.9020\n",
            "Fold 16 Epoch 500: Loss=0.197331 | TrainAcc=0.9098\n",
            "Fold 16 Epoch 600: Loss=0.163114 | TrainAcc=0.9529\n",
            "Fold 16 Epoch 700: Loss=0.114590 | TrainAcc=0.9373\n",
            "Fold 16 Epoch 800: Loss=0.057123 | TrainAcc=0.9765\n",
            "Fold 16 Epoch 900: Loss=0.073476 | TrainAcc=0.9765\n",
            "Fold 16 Epoch 1000: Loss=0.068006 | TrainAcc=0.9647\n",
            "Fold 16 Epoch 1100: Loss=0.036117 | TrainAcc=0.9843\n",
            "Fold 16 Epoch 1200: Loss=0.033476 | TrainAcc=0.9882\n",
            "Fold 16 Epoch 1300: Loss=0.020503 | TrainAcc=0.9922\n",
            "Fold 16 Epoch 1400: Loss=0.035236 | TrainAcc=0.9843\n",
            "Fold 16 Epoch 1500: Loss=0.032531 | TrainAcc=0.9882\n",
            "Fold 16 Epoch 1600: Loss=0.006188 | TrainAcc=1.0000\n",
            "Fold 16 Epoch 1700: Loss=0.040005 | TrainAcc=0.9843\n",
            "Fold 16 Epoch 1800: Loss=0.008793 | TrainAcc=0.9961\n",
            "Fold 16 Epoch 1900: Loss=0.013149 | TrainAcc=0.9961\n",
            "Fold 16 Epoch 2000: Loss=0.016924 | TrainAcc=0.9961\n",
            "Fold 16 → Acc=0.8275 | Prec=0.8897 | Rec=0.8067 | F1=0.8462 | AUC=0.9210 | CE Loss=0.7408\n",
            "\n",
            "=== Fold 17 ===\n",
            "Fold 17 Epoch 1: Loss=1.264225 | TrainAcc=0.4941\n",
            "Fold 17 Epoch 100: Loss=0.589253 | TrainAcc=0.6706\n",
            "Fold 17 Epoch 200: Loss=0.330212 | TrainAcc=0.8510\n",
            "Fold 17 Epoch 300: Loss=0.240602 | TrainAcc=0.8824\n",
            "Fold 17 Epoch 400: Loss=0.216391 | TrainAcc=0.9333\n",
            "Fold 17 Epoch 500: Loss=0.144864 | TrainAcc=0.9373\n",
            "Fold 17 Epoch 600: Loss=0.106261 | TrainAcc=0.9373\n",
            "Fold 17 Epoch 700: Loss=0.123915 | TrainAcc=0.9608\n",
            "Fold 17 Epoch 800: Loss=0.047666 | TrainAcc=0.9882\n",
            "Fold 17 Epoch 900: Loss=0.054759 | TrainAcc=0.9882\n",
            "Fold 17 Epoch 1000: Loss=0.031919 | TrainAcc=0.9922\n",
            "Fold 17 Epoch 1100: Loss=0.025538 | TrainAcc=0.9922\n",
            "Fold 17 Epoch 1200: Loss=0.047390 | TrainAcc=0.9843\n",
            "Fold 17 Epoch 1300: Loss=0.024065 | TrainAcc=0.9882\n",
            "Fold 17 Epoch 1400: Loss=0.046099 | TrainAcc=0.9804\n",
            "Fold 17 Epoch 1500: Loss=0.018258 | TrainAcc=0.9922\n",
            "Fold 17 Epoch 1600: Loss=0.024639 | TrainAcc=0.9843\n",
            "Fold 17 Epoch 1700: Loss=0.018913 | TrainAcc=0.9922\n",
            "Fold 17 Epoch 1800: Loss=0.014330 | TrainAcc=0.9882\n",
            "Fold 17 Epoch 1900: Loss=0.032926 | TrainAcc=0.9843\n",
            "Fold 17 Epoch 2000: Loss=0.010375 | TrainAcc=1.0000\n",
            "Fold 17 → Acc=0.8431 | Prec=0.8716 | Rec=0.8600 | F1=0.8658 | AUC=0.9194 | CE Loss=0.8097\n",
            "\n",
            "=== Fold 18 ===\n",
            "Fold 18 Epoch 1: Loss=1.568980 | TrainAcc=0.5725\n",
            "Fold 18 Epoch 100: Loss=0.535232 | TrainAcc=0.7373\n",
            "Fold 18 Epoch 200: Loss=0.378032 | TrainAcc=0.8275\n",
            "Fold 18 Epoch 300: Loss=0.266047 | TrainAcc=0.9020\n",
            "Fold 18 Epoch 400: Loss=0.235022 | TrainAcc=0.8980\n",
            "Fold 18 Epoch 500: Loss=0.168897 | TrainAcc=0.9216\n",
            "Fold 18 Epoch 600: Loss=0.145134 | TrainAcc=0.9333\n",
            "Fold 18 Epoch 700: Loss=0.115241 | TrainAcc=0.9451\n",
            "Fold 18 Epoch 800: Loss=0.115558 | TrainAcc=0.9451\n",
            "Fold 18 Epoch 900: Loss=0.075546 | TrainAcc=0.9686\n",
            "Fold 18 Epoch 1000: Loss=0.077868 | TrainAcc=0.9647\n",
            "Fold 18 Epoch 1100: Loss=0.054231 | TrainAcc=0.9804\n",
            "Fold 18 Epoch 1200: Loss=0.039934 | TrainAcc=0.9882\n",
            "Fold 18 Epoch 1300: Loss=0.086349 | TrainAcc=0.9647\n",
            "Fold 18 Epoch 1400: Loss=0.059981 | TrainAcc=0.9765\n",
            "Fold 18 Epoch 1500: Loss=0.037289 | TrainAcc=0.9882\n",
            "Fold 18 Epoch 1600: Loss=0.046095 | TrainAcc=0.9804\n",
            "Fold 18 Epoch 1700: Loss=0.012419 | TrainAcc=0.9961\n",
            "Fold 18 Epoch 1800: Loss=0.009897 | TrainAcc=1.0000\n",
            "Fold 18 Epoch 1900: Loss=0.015771 | TrainAcc=0.9961\n",
            "Fold 18 Epoch 2000: Loss=0.051147 | TrainAcc=0.9765\n",
            "Fold 18 → Acc=0.8549 | Prec=0.9185 | Rec=0.8267 | F1=0.8702 | AUC=0.9393 | CE Loss=0.5182\n",
            "\n",
            "=== Fold 19 ===\n",
            "Fold 19 Epoch 1: Loss=2.118859 | TrainAcc=0.4392\n",
            "Fold 19 Epoch 100: Loss=0.610071 | TrainAcc=0.6980\n",
            "Fold 19 Epoch 200: Loss=0.426584 | TrainAcc=0.8118\n",
            "Fold 19 Epoch 300: Loss=0.348606 | TrainAcc=0.8353\n",
            "Fold 19 Epoch 400: Loss=0.245346 | TrainAcc=0.8902\n",
            "Fold 19 Epoch 500: Loss=0.239114 | TrainAcc=0.8980\n",
            "Fold 19 Epoch 600: Loss=0.174488 | TrainAcc=0.9176\n",
            "Fold 19 Epoch 700: Loss=0.173427 | TrainAcc=0.9255\n",
            "Fold 19 Epoch 800: Loss=0.105999 | TrainAcc=0.9451\n",
            "Fold 19 Epoch 900: Loss=0.110481 | TrainAcc=0.9569\n",
            "Fold 19 Epoch 1000: Loss=0.059321 | TrainAcc=0.9765\n",
            "Fold 19 Epoch 1100: Loss=0.088727 | TrainAcc=0.9725\n",
            "Fold 19 Epoch 1200: Loss=0.075756 | TrainAcc=0.9725\n",
            "Fold 19 Epoch 1300: Loss=0.071137 | TrainAcc=0.9765\n",
            "Fold 19 Epoch 1400: Loss=0.100234 | TrainAcc=0.9608\n",
            "Fold 19 Epoch 1500: Loss=0.032954 | TrainAcc=0.9843\n",
            "Fold 19 Epoch 1600: Loss=0.041239 | TrainAcc=0.9843\n",
            "Fold 19 Epoch 1700: Loss=0.021043 | TrainAcc=0.9961\n",
            "Fold 19 Epoch 1800: Loss=0.018446 | TrainAcc=0.9961\n",
            "Fold 19 Epoch 1900: Loss=0.039374 | TrainAcc=0.9882\n",
            "Fold 19 Epoch 2000: Loss=0.038132 | TrainAcc=0.9804\n",
            "Fold 19 → Acc=0.8588 | Prec=0.9071 | Rec=0.8467 | F1=0.8759 | AUC=0.9427 | CE Loss=0.5391\n",
            "\n",
            "=== Fold 20 ===\n",
            "Fold 20 Epoch 1: Loss=1.251183 | TrainAcc=0.5294\n",
            "Fold 20 Epoch 100: Loss=0.494913 | TrainAcc=0.7451\n",
            "Fold 20 Epoch 200: Loss=0.393565 | TrainAcc=0.8235\n",
            "Fold 20 Epoch 300: Loss=0.287066 | TrainAcc=0.8824\n",
            "Fold 20 Epoch 400: Loss=0.170363 | TrainAcc=0.9490\n",
            "Fold 20 Epoch 500: Loss=0.136200 | TrainAcc=0.9412\n",
            "Fold 20 Epoch 600: Loss=0.111299 | TrainAcc=0.9529\n",
            "Fold 20 Epoch 700: Loss=0.125240 | TrainAcc=0.9490\n",
            "Fold 20 Epoch 800: Loss=0.080488 | TrainAcc=0.9608\n",
            "Fold 20 Epoch 900: Loss=0.076155 | TrainAcc=0.9725\n",
            "Fold 20 Epoch 1000: Loss=0.076034 | TrainAcc=0.9725\n",
            "Fold 20 Epoch 1100: Loss=0.048777 | TrainAcc=0.9882\n",
            "Fold 20 Epoch 1200: Loss=0.038460 | TrainAcc=0.9922\n",
            "Fold 20 Epoch 1300: Loss=0.030826 | TrainAcc=0.9961\n",
            "Fold 20 Epoch 1400: Loss=0.046696 | TrainAcc=0.9804\n",
            "Fold 20 Epoch 1500: Loss=0.026694 | TrainAcc=0.9843\n",
            "Fold 20 Epoch 1600: Loss=0.017706 | TrainAcc=0.9922\n",
            "Fold 20 Epoch 1700: Loss=0.016230 | TrainAcc=0.9882\n",
            "Fold 20 Epoch 1800: Loss=0.012845 | TrainAcc=0.9922\n",
            "Fold 20 Epoch 1900: Loss=0.023023 | TrainAcc=0.9922\n",
            "Fold 20 Epoch 2000: Loss=0.003763 | TrainAcc=1.0000\n",
            "Fold 20 → Acc=0.8549 | Prec=0.8553 | Rec=0.9067 | F1=0.8803 | AUC=0.9304 | CE Loss=0.6475\n",
            "\n",
            "=== Average Results Across 20 Folds ===\n",
            "Accuracy:  0.8502 ± 0.0147\n",
            "Precision: 0.8864 ± 0.0201\n",
            "Recall:    0.8560 ± 0.0323\n",
            "F1-score:  0.8703 ± 0.0141\n",
            "AUC:       0.9319 ± 0.0115\n",
            "CE Loss:   0.6183 ± 0.1161\n"
          ]
        }
      ]
    }
  ]
}
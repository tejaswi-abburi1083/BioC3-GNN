{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LP54bJff1GAJ","executionInfo":{"status":"ok","timestamp":1766240652120,"user_tz":-330,"elapsed":472399,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"5ba57d27-cc1f-4448-a8d5-85ee20fc1f9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Patients Shape: (98, 180)\n","Controls Shape: (48, 180)\n","W0: (146, 146)\n","Number of edges: 21256\n","Using device: cuda\n","\n","=== Fold 1 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.6504 | DGI=0.7147 | Reg=-0.2333 | Total=1.3648 | TrainAcc=0.6923\n","Epoch 500: Sup=0.0116 | DGI=0.7026 | Reg=-0.2757 | Total=0.7140 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0650 | DGI=0.6933 | Reg=-0.2654 | Total=0.7581 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0003 | DGI=0.6932 | Reg=-0.2664 | Total=0.6932 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0024 | DGI=0.6932 | Reg=-0.2422 | Total=0.6954 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6617 ± 0.0000\n","Precision: 0.6746 ± 0.0000\n","Recall: 0.9551 ± 0.0000\n","F1: 0.7907 ± 0.0000\n","LogLoss: 2.0032 ± 0.0000\n","AUC: 0.5790 ± 0.0000\n","\n","=== Fold 2 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.6542 | DGI=0.7093 | Reg=-0.2337 | Total=1.3632 | TrainAcc=0.6923\n","Epoch 500: Sup=0.0513 | DGI=0.6937 | Reg=-0.3025 | Total=0.7447 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0753 | DGI=0.6936 | Reg=-0.2439 | Total=0.7687 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0135 | DGI=0.6931 | Reg=-0.2221 | Total=0.7064 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0243 | DGI=0.6933 | Reg=-0.2268 | Total=0.7174 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6729 ± 0.0113\n","Precision: 0.7136 ± 0.0390\n","Recall: 0.8708 ± 0.0843\n","F1: 0.7800 ± 0.0107\n","LogLoss: 1.3959 ± 0.6073\n","AUC: 0.6578 ± 0.0787\n","\n","=== Fold 3 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.8735 | DGI=0.7082 | Reg=-0.2336 | Total=1.5815 | TrainAcc=0.3077\n","Epoch 500: Sup=0.1822 | DGI=0.6943 | Reg=-0.3531 | Total=0.8762 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0007 | DGI=0.6937 | Reg=-0.3039 | Total=0.6942 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0033 | DGI=0.6932 | Reg=-0.2766 | Total=0.6962 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0002 | DGI=0.6932 | Reg=-0.2536 | Total=0.6932 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6967 ± 0.0349\n","Precision: 0.7265 ± 0.0367\n","Recall: 0.8876 ± 0.0728\n","F1: 0.7961 ± 0.0244\n","LogLoss: 1.2872 ± 0.5191\n","AUC: 0.6975 ± 0.0854\n","\n","=== Fold 4 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.7686 | DGI=0.7099 | Reg=-0.2334 | Total=1.4782 | TrainAcc=0.6154\n","Epoch 500: Sup=0.0185 | DGI=0.6955 | Reg=-0.3549 | Total=0.7136 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0114 | DGI=0.6952 | Reg=-0.3447 | Total=0.7063 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0031 | DGI=0.6932 | Reg=-0.3117 | Total=0.6960 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.3772 | DGI=0.6935 | Reg=-0.3270 | Total=1.0704 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6974 ± 0.0303\n","Precision: 0.7474 ± 0.0482\n","Recall: 0.8455 ± 0.0965\n","F1: 0.7875 ± 0.0258\n","LogLoss: 1.2730 ± 0.4503\n","AUC: 0.7099 ± 0.0770\n","\n","=== Fold 5 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.6573 | DGI=0.7082 | Reg=-0.2332 | Total=1.3652 | TrainAcc=0.6923\n","Epoch 500: Sup=0.0180 | DGI=0.6938 | Reg=-0.4207 | Total=0.7114 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0006 | DGI=0.6932 | Reg=-0.4306 | Total=0.6933 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0002 | DGI=0.6933 | Reg=-0.4314 | Total=0.6931 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0001 | DGI=0.6931 | Reg=-0.4503 | Total=0.6928 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6962 ± 0.0272\n","Precision: 0.7807 ± 0.0793\n","Recall: 0.7955 ± 0.1321\n","F1: 0.7742 ± 0.0352\n","LogLoss: 1.2577 ± 0.4039\n","AUC: 0.7291 ± 0.0789\n","\n","=== Fold 6 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.6414 | DGI=0.7117 | Reg=-0.2333 | Total=1.3528 | TrainAcc=0.6154\n","Epoch 500: Sup=0.0474 | DGI=0.6932 | Reg=-0.2705 | Total=0.7403 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0836 | DGI=0.6939 | Reg=-0.2865 | Total=0.7772 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0113 | DGI=0.6933 | Reg=-0.2837 | Total=0.7044 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0010 | DGI=0.6932 | Reg=-0.2818 | Total=0.6939 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6855 ± 0.0346\n","Precision: 0.7746 ± 0.0737\n","Recall: 0.7772 ± 0.1274\n","F1: 0.7641 ± 0.0393\n","LogLoss: 1.2272 ± 0.3750\n","AUC: 0.7170 ± 0.0769\n","\n","=== Fold 7 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.8274 | DGI=0.7135 | Reg=-0.2334 | Total=1.5406 | TrainAcc=0.3077\n","Epoch 500: Sup=0.0552 | DGI=0.6989 | Reg=-0.2868 | Total=0.7538 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0161 | DGI=0.7043 | Reg=-0.3103 | Total=0.7201 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0134 | DGI=0.6932 | Reg=-0.2909 | Total=0.7062 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0006 | DGI=0.6932 | Reg=-0.2741 | Total=0.6934 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6831 ± 0.0325\n","Precision: 0.7692 ± 0.0695\n","Recall: 0.7785 ± 0.1180\n","F1: 0.7636 ± 0.0364\n","LogLoss: 1.1900 ± 0.3589\n","AUC: 0.7166 ± 0.0712\n","\n","=== Fold 8 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.6808 | DGI=0.7103 | Reg=-0.2333 | Total=1.3909 | TrainAcc=0.6923\n","Epoch 500: Sup=0.1072 | DGI=0.6997 | Reg=-0.3696 | Total=0.8065 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0003 | DGI=0.6933 | Reg=-0.3094 | Total=0.6933 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0013 | DGI=0.7003 | Reg=-0.3147 | Total=0.7013 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0007 | DGI=0.6932 | Reg=-0.3144 | Total=0.6936 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6823 ± 0.0305\n","Precision: 0.7930 ± 0.0906\n","Recall: 0.7486 ± 0.1358\n","F1: 0.7545 ± 0.0418\n","LogLoss: 1.1976 ± 0.3363\n","AUC: 0.7339 ± 0.0808\n","\n","=== Fold 9 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.8366 | DGI=0.7143 | Reg=-0.2332 | Total=1.5507 | TrainAcc=0.3077\n","Epoch 500: Sup=0.0314 | DGI=0.7048 | Reg=-0.3140 | Total=0.7360 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0037 | DGI=0.6941 | Reg=-0.2552 | Total=0.6975 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0023 | DGI=0.6939 | Reg=-0.2578 | Total=0.6960 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0006 | DGI=0.6931 | Reg=-0.2510 | Total=0.6935 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6834 ± 0.0289\n","Precision: 0.7915 ± 0.0855\n","Recall: 0.7491 ± 0.1280\n","F1: 0.7558 ± 0.0395\n","LogLoss: 1.2103 ± 0.3191\n","AUC: 0.7312 ± 0.0766\n","\n","=== Fold 10 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.7507 | DGI=0.7065 | Reg=-0.2334 | Total=1.4570 | TrainAcc=0.6923\n","Epoch 500: Sup=0.0120 | DGI=0.6935 | Reg=-0.2764 | Total=0.7052 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0035 | DGI=0.6940 | Reg=-0.2904 | Total=0.6972 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0002 | DGI=0.6936 | Reg=-0.2816 | Total=0.6936 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0012 | DGI=0.6932 | Reg=-0.2678 | Total=0.6941 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6805 ± 0.0288\n","Precision: 0.7807 ± 0.0873\n","Recall: 0.7640 ± 0.1295\n","F1: 0.7579 ± 0.0380\n","LogLoss: 1.2474 ± 0.3226\n","AUC: 0.7137 ± 0.0896\n","\n","=== Fold 11 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.8045 | DGI=0.7146 | Reg=-0.2337 | Total=1.5189 | TrainAcc=0.4615\n","Epoch 500: Sup=0.0109 | DGI=0.6960 | Reg=-0.3318 | Total=0.7066 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.1453 | DGI=0.6937 | Reg=-0.3064 | Total=0.8386 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0046 | DGI=0.6942 | Reg=-0.2661 | Total=0.6985 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0032 | DGI=0.6933 | Reg=-0.2819 | Total=0.6962 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6712 ± 0.0401\n","Precision: 0.7783 ± 0.0836\n","Recall: 0.7446 ± 0.1379\n","F1: 0.7468 ± 0.0503\n","LogLoss: 1.2322 ± 0.3113\n","AUC: 0.7109 ± 0.0859\n","\n","=== Fold 12 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.6580 | DGI=0.7068 | Reg=-0.2333 | Total=1.3646 | TrainAcc=0.3077\n","Epoch 500: Sup=0.2664 | DGI=0.6934 | Reg=-0.3564 | Total=0.9595 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0223 | DGI=0.6951 | Reg=-0.3726 | Total=0.7171 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0109 | DGI=0.7061 | Reg=-0.3577 | Total=0.7165 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0285 | DGI=0.6953 | Reg=-0.3622 | Total=0.7234 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6698 ± 0.0386\n","Precision: 0.7826 ± 0.0814\n","Recall: 0.7331 ± 0.1374\n","F1: 0.7430 ± 0.0498\n","LogLoss: 1.2521 ± 0.3053\n","AUC: 0.7120 ± 0.0823\n","\n","=== Fold 13 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.6136 | DGI=0.7058 | Reg=-0.2335 | Total=1.3191 | TrainAcc=0.3077\n","Epoch 500: Sup=0.1138 | DGI=0.6944 | Reg=-0.2808 | Total=0.8079 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0050 | DGI=0.6967 | Reg=-0.3075 | Total=0.7014 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0017 | DGI=0.6944 | Reg=-0.2680 | Total=0.6958 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0001 | DGI=0.6933 | Reg=-0.2734 | Total=0.6932 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6755 ± 0.0421\n","Precision: 0.7832 ± 0.0782\n","Recall: 0.7416 ± 0.1352\n","F1: 0.7486 ± 0.0516\n","LogLoss: 1.2279 ± 0.3050\n","AUC: 0.7173 ± 0.0812\n","\n","=== Fold 14 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.7240 | DGI=0.7087 | Reg=-0.2335 | Total=1.4325 | TrainAcc=0.3077\n","Epoch 500: Sup=0.0066 | DGI=0.6935 | Reg=-0.3053 | Total=0.6998 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0076 | DGI=0.6950 | Reg=-0.2775 | Total=0.7024 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.6104 | DGI=0.6958 | Reg=-0.2578 | Total=1.3059 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0001 | DGI=0.6943 | Reg=-0.2820 | Total=0.6941 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6788 ± 0.0423\n","Precision: 0.7795 ± 0.0765\n","Recall: 0.7544 ± 0.1383\n","F1: 0.7534 ± 0.0526\n","LogLoss: 1.2238 ± 0.2943\n","AUC: 0.7185 ± 0.0783\n","\n","=== Fold 15 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.7891 | DGI=0.7136 | Reg=-0.2336 | Total=1.5025 | TrainAcc=0.6923\n","Epoch 500: Sup=0.0085 | DGI=0.6935 | Reg=-0.2936 | Total=0.7017 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0202 | DGI=0.6964 | Reg=-0.2496 | Total=0.7164 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0001 | DGI=0.6948 | Reg=-0.2136 | Total=0.6947 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0397 | DGI=0.6931 | Reg=-0.2071 | Total=0.7326 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6837 ± 0.0447\n","Precision: 0.7788 ± 0.0739\n","Recall: 0.7640 ± 0.1383\n","F1: 0.7584 ± 0.0542\n","LogLoss: 1.1863 ± 0.3171\n","AUC: 0.7257 ± 0.0804\n","\n","=== Fold 16 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.7645 | DGI=0.7123 | Reg=-0.2333 | Total=1.4766 | TrainAcc=0.3077\n","Epoch 500: Sup=0.0096 | DGI=0.6932 | Reg=-0.3513 | Total=0.7024 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0109 | DGI=0.6933 | Reg=-0.3070 | Total=0.7039 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0014 | DGI=0.6937 | Reg=-0.3222 | Total=0.6947 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0008 | DGI=0.6933 | Reg=-0.3023 | Total=0.6938 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6814 ± 0.0442\n","Precision: 0.7791 ± 0.0716\n","Recall: 0.7570 ± 0.1367\n","F1: 0.7555 ± 0.0537\n","LogLoss: 1.2075 ± 0.3177\n","AUC: 0.7262 ± 0.0779\n","\n","=== Fold 17 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.7282 | DGI=0.7114 | Reg=-0.2333 | Total=1.4393 | TrainAcc=0.3846\n","Epoch 500: Sup=0.0322 | DGI=0.6935 | Reg=-0.3187 | Total=0.7253 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0522 | DGI=0.7022 | Reg=-0.2870 | Total=0.7542 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0001 | DGI=0.6969 | Reg=-0.2790 | Total=0.6967 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0000 | DGI=0.6959 | Reg=-0.2876 | Total=0.6956 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6833 ± 0.0436\n","Precision: 0.7782 ± 0.0696\n","Recall: 0.7614 ± 0.1338\n","F1: 0.7579 ± 0.0530\n","LogLoss: 1.2018 ± 0.3091\n","AUC: 0.7301 ± 0.0772\n","\n","=== Fold 18 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.7072 | DGI=0.7123 | Reg=-0.2332 | Total=1.4193 | TrainAcc=0.3077\n","Epoch 500: Sup=0.0212 | DGI=0.6962 | Reg=-0.3027 | Total=0.7171 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0677 | DGI=0.6932 | Reg=-0.3258 | Total=0.7605 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0007 | DGI=0.6950 | Reg=-0.2984 | Total=0.6954 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0065 | DGI=0.6935 | Reg=-0.2723 | Total=0.6998 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6708 ± 0.0667\n","Precision: 0.7780 ± 0.0676\n","Recall: 0.7341 ± 0.1720\n","F1: 0.7380 ± 0.0968\n","LogLoss: 1.2245 ± 0.3146\n","AUC: 0.7236 ± 0.0797\n","\n","=== Fold 19 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.7447 | DGI=0.7102 | Reg=-0.2333 | Total=1.4547 | TrainAcc=0.3077\n","Epoch 500: Sup=0.0079 | DGI=0.6937 | Reg=-0.3126 | Total=0.7013 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0009 | DGI=0.6936 | Reg=-0.2619 | Total=0.6942 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0006 | DGI=0.6932 | Reg=-0.2181 | Total=0.6935 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0002 | DGI=0.6979 | Reg=-0.2449 | Total=0.6978 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6727 ± 0.0654\n","Precision: 0.7741 ± 0.0678\n","Recall: 0.7463 ± 0.1753\n","F1: 0.7420 ± 0.0958\n","LogLoss: 1.2462 ± 0.3197\n","AUC: 0.7218 ± 0.0779\n","\n","=== Fold 20 (Controls vs Patients) ===\n","Train Controls: 4, Train Patients: 9\n","Test Controls: 44, Test Patients: 89\n","Epoch 1: Sup=0.6531 | DGI=0.7095 | Reg=-0.2333 | Total=1.3624 | TrainAcc=0.3077\n","Epoch 500: Sup=0.0408 | DGI=0.6934 | Reg=-0.2838 | Total=0.7339 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.0019 | DGI=0.6932 | Reg=-0.2301 | Total=0.6949 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.0006 | DGI=0.6940 | Reg=-0.2427 | Total=0.6944 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0029 | DGI=0.6934 | Reg=-0.2292 | Total=0.6961 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6726 ± 0.0637\n","Precision: 0.7699 ± 0.0686\n","Recall: 0.7551 ± 0.1750\n","F1: 0.7444 ± 0.0939\n","LogLoss: 1.2495 ± 0.3120\n","AUC: 0.7225 ± 0.0760\n"]}],"source":["import os\n","import sys\n","import numpy as np\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.data import Data\n","from torch_geometric.nn import ARMAConv\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score,\n","    f1_score, log_loss, roc_auc_score\n",")\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","SEED = 42\n","np.random.seed(SEED)\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","torch.set_num_threads(4)\n","\n","# === Load Patients ===\n","fa_patients_path = \"/home/snu/Downloads/NIFD_Patients_FA_Histogram_Feature.npy\"\n","Patients_FA_array = np.load(fa_patients_path, allow_pickle=True)\n","\n","# === Load Controls ===\n","fa_controls_path = \"/home/snu/Downloads/NIFD_Control_FA_Histogram_Feature.npy\"\n","Controls_FA_array = np.load(fa_controls_path, allow_pickle=True)\n","\n","print(\"Patients Shape:\", Patients_FA_array.shape)\n","print(\"Controls Shape:\", Controls_FA_array.shape)\n","\n","# === Combine features and labels ===\n","X = np.vstack([Controls_FA_array, Patients_FA_array])\n","y = np.hstack([\n","    np.zeros(Controls_FA_array.shape[0], dtype=np.int64),  # 0 = Control\n","    np.ones(Patients_FA_array.shape[0], dtype=np.int64)    # 1 = Patient\n","])\n","\n","# Shuffle\n","np.random.seed(42)\n","perm = np.random.permutation(X.shape[0])\n","X = X[perm]\n","y = y[perm]\n","\n","# ------------------------\n","# Adjacency building\n","# ------------------------\n","def create_adj(F, alpha=1.0):\n","    norms = np.linalg.norm(F, axis=1, keepdims=True)\n","    norms[norms == 0] = 1.0\n","    F_norm = F / norms\n","    W = np.dot(F_norm, F_norm.T)\n","    W = (W >= alpha).astype(np.float32)\n","    return W\n","\n","W0 = create_adj(X, alpha=0.5)\n","print(f\"W0: {W0.shape}\")\n","\n","def load_graph_torch(adj, node_feats):\n","    node_feats_t = torch.from_numpy(node_feats).float()\n","    edge_idx = np.array(np.nonzero(adj))\n","    edge_index = torch.from_numpy(edge_idx).long()\n","    return node_feats_t, edge_index\n","\n","node_feats_all, edge_index_all = load_graph_torch(W0, X)\n","print(f\"Number of edges: {edge_index_all.size(1)}\")\n","\n","# ------------------------\n","# Model components\n","# ------------------------\n","class ARMAEncoder(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_stacks=1, num_layers=1, activ=\"RELU\"):\n","        super(ARMAEncoder, self).__init__()\n","        activations = {\n","            \"SELU\": F.selu,\n","            \"SiLU\": F.silu,\n","            \"GELU\": F.gelu,\n","            \"ELU\": F.elu,\n","            \"RELU\": F.relu\n","        }\n","        self.act = activations.get(activ, F.elu)\n","        self.arma = ARMAConv(\n","            input_dim, hidden_dim,\n","            num_stacks=num_stacks,\n","            num_layers=num_layers,\n","            shared_weights=True,\n","            dropout=0.3\n","        )\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.arma(x, edge_index)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        x = self.batchnorm(x)\n","        logits = self.mlp(x)\n","        return logits\n","\n","class AvgReadout(nn.Module):\n","    def forward(self, seq, msk=None):\n","        if msk is None:\n","            return torch.mean(seq, 0)\n","        else:\n","            msk = torch.unsqueeze(msk, -1)\n","            return torch.sum(seq * msk, 0) / torch.sum(msk)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, n_h):\n","        super().__init__()\n","        self.f_k = nn.Bilinear(n_h, n_h, 1)\n","        nn.init.xavier_uniform_(self.f_k.weight.data)\n","        if self.f_k.bias is not None:\n","            self.f_k.bias.data.fill_(0.0)\n","\n","    def forward(self, c, h_pl, h_mi):\n","        c_x = torch.unsqueeze(c, 0).expand_as(h_pl)\n","        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 1)\n","        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 1)\n","        return torch.cat((sc_1, sc_2), 0)\n","\n","class DGI(nn.Module):\n","    def __init__(self, n_in, n_h, num_stacks=2, num_layers=1):\n","        super().__init__()\n","        self.gcn1 = ARMAEncoder(n_in, n_h, num_stacks=num_stacks, num_layers=num_layers)\n","        self.read = AvgReadout()\n","        self.sigm = nn.Sigmoid()\n","        self.disc = Discriminator(n_h)\n","\n","    def forward(self, seq1, seq2, edge_index):\n","        data1 = Data(x=seq1, edge_index=edge_index)\n","        data2 = Data(x=seq2, edge_index=edge_index)\n","        h_1 = self.gcn1(data1)\n","        c = self.read(h_1)\n","        c = self.sigm(c)\n","        h_2 = self.gcn1(data2)\n","        logits = self.disc(c, h_1, h_2)\n","        return logits, h_1\n","\n","class DGI_with_classifier(DGI):\n","    def __init__(self, n_in, n_h, n_classes=2, cut=0, device='cpu', num_stacks=1, num_layers=1):\n","        super().__init__(n_in, n_h, num_stacks=num_stacks, num_layers=num_layers)\n","        self.classifier = nn.Linear(n_h, n_classes)\n","        self.cut = cut\n","        self.device = device\n","        self.n_clusters = n_classes\n","\n","    def get_embeddings(self, node_feats, edge_index):\n","        _, embeddings = self.forward(node_feats, node_feats, edge_index)\n","        return embeddings\n","\n","    def cut_loss(self, A, S):\n","        C = F.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, C).t(), C)\n","        num = torch.trace(A_pool)\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, C).t(), C)\n","        den = torch.trace(D_pooled) + 1e-9\n","        mincut_loss = -(num / den)\n","        St_S = torch.matmul(C.t(), C)\n","        I_S = torch.eye(C.shape[1], device=A.device)\n","        ortho_loss = torch.norm(St_S / (torch.norm(St_S) + 1e-9) - I_S / (torch.norm(I_S) + 1e-9))\n","        return mincut_loss + ortho_loss\n","\n","    def modularity_loss(self, A, S):\n","        C = F.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A) + 1e-9\n","        B = A - torch.outer(d, d) / (2 * m)\n","        I_S = torch.eye(C.shape[1], device=A.device)\n","        k = torch.norm(I_S)\n","        n = S.shape[0]\n","        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n","        return modularity_term + collapse_reg_term\n","\n","    def Reg_loss(self, A, embeddings):\n","        logits = self.classifier(embeddings)\n","        if self.cut == 1:\n","            return self.cut_loss(A, logits)\n","        else:\n","            return self.modularity_loss(A, logits)\n","\n","# ------------------------\n","# Prepare cross-validation\n","# ------------------------\n","sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=SEED)\n","accuracies, precisions, recalls, f1_scores, losses, all_auc = [], [], [], [], [], []\n","\n","def get_device():\n","    try:\n","        if torch.cuda.is_available():\n","            dev = torch.device(\"cuda\")\n","            torch.tensor([1.0], device=dev) + 1.0\n","            return dev\n","    except Exception as e:\n","        print(\"CUDA not usable, falling back to CPU:\", e)\n","        try:\n","            torch.cuda.empty_cache()\n","        except:\n","            pass\n","    return torch.device(\"cpu\")\n","\n","device = get_device()\n","print(\"Using device:\", device)\n","\n","A_tensor = torch.from_numpy(W0).float().to(device)\n","hidden_dim = 512\n","cut = 1\n","num_epochs = 2000\n","lr = 1e-4\n","weight_decay = 1e-4\n","reg_weight = 0.001\n","num_stacks = 1\n","num_layers = 1\n","\n","node_feats = node_feats_all.to(device)\n","edge_index = edge_index_all.to(device)\n","\n","N = node_feats.size(0)\n","lbl = torch.cat([torch.ones(N, device=device), torch.zeros(N, device=device)]).float()\n","\n","# Define num_feats\n","num_feats = X.shape[1]\n","\n","for fold, (train_idx, test_idx) in enumerate(sss.split(X, y), start=1):\n","    print(f\"\\n=== Fold {fold} (Controls vs Patients) ===\")\n","\n","    cn_idx = np.where(y == 0)[0]\n","    ad_idx = np.where(y == 1)[0]\n","\n","    sss_class = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=fold)\n","    cn_train_idx, cn_test_idx = next(sss_class.split(X[cn_idx], y[cn_idx]))\n","    ad_train_idx, ad_test_idx = next(sss_class.split(X[ad_idx], y[ad_idx]))\n","\n","    cn_train = cn_idx[cn_train_idx]\n","    ad_train = ad_idx[ad_train_idx]\n","    cn_test = cn_idx[cn_test_idx]\n","    ad_test = ad_idx[ad_test_idx]\n","\n","    balanced_train_idx = np.concatenate([cn_train, ad_train])\n","    test_idx_final = np.concatenate([cn_test, ad_test])\n","    np.random.shuffle(balanced_train_idx)\n","    np.random.shuffle(test_idx_final)\n","\n","    print(f\"Train Controls: {len(cn_train)}, Train Patients: {len(ad_train)}\")\n","    print(f\"Test Controls: {len(cn_test)}, Test Patients: {len(ad_test)}\")\n","\n","    y_tensor = torch.from_numpy(y).long().to(device)\n","    train_idx_t = torch.from_numpy(balanced_train_idx).long().to(device)\n","    test_idx_t = torch.from_numpy(test_idx_final).long().to(device)\n","\n","    model = DGI_with_classifier(num_feats, hidden_dim, n_classes=2, cut=cut,\n","                                device=device, num_stacks=num_stacks, num_layers=num_layers).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    bce_loss = nn.BCEWithLogitsLoss()\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","    for epoch in range(1, num_epochs + 1):\n","        model.train()\n","        optimizer.zero_grad()\n","        perm = torch.randperm(N, device=device)\n","        corrupt = node_feats[perm]\n","        logits_dgi, embeddings = model(node_feats, corrupt, edge_index)\n","        dgi_loss = bce_loss(logits_dgi.squeeze(), lbl)\n","        logits_cls = model.classifier(embeddings)\n","        train_logits = logits_cls[train_idx_t]\n","        train_labels = y_tensor[train_idx_t]\n","        supervised_loss = ce_loss(train_logits, train_labels)\n","        reg_loss_val = model.Reg_loss(A_tensor, embeddings)\n","        total_loss = supervised_loss + dgi_loss + reg_weight * reg_loss_val\n","        total_loss.backward()\n","        optimizer.step()\n","\n","        if epoch % 500 == 0 or epoch == 1:\n","            model.eval()\n","            with torch.no_grad():\n","                logits_eval = model.classifier(model.get_embeddings(node_feats, edge_index))\n","                preds_train = torch.argmax(logits_eval[train_idx_t], dim=1).cpu().numpy()\n","                acc = accuracy_score(train_labels.cpu().numpy(), preds_train)\n","            print(f\"Epoch {epoch}: Sup={supervised_loss.item():.4f} | DGI={dgi_loss.item():.4f} | \"\n","                  f\"Reg={reg_loss_val.item():.4f} | Total={total_loss.item():.4f} | TrainAcc={acc:.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        emb_final = model.get_embeddings(node_feats, edge_index)\n","        logits_final = model.classifier(emb_final)\n","        probs = F.softmax(logits_final, dim=1).cpu().numpy()\n","        y_pred = np.argmax(probs, axis=1)\n","\n","    y_test = y[test_idx_final]\n","    y_pred_test = y_pred[test_idx_final]\n","    y_proba_test = probs[test_idx_final, 1]\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","    loss_val = log_loss(y_test, y_proba_test)\n","    auc_score = roc_auc_score(y_test, y_proba_test)\n","\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    losses.append(loss_val)\n","    all_auc.append(auc_score)\n","\n","    print(\"\\n=== Average Results (Controls vs Patients) ===\")\n","    print(f\"Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n","    print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n","    print(f\"Recall: {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n","    print(f\"F1: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n","    print(f\"LogLoss: {np.mean(losses):.4f} ± {np.std(losses):.4f}\")\n","    print(f\"AUC: {np.mean(all_auc):.4f} ± {np.std(all_auc):.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EaFRNj1X1GAM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762350989265,"user_tz":-330,"elapsed":288171,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"3fa8a33a-2c23-445f-f1af-c07f9a3a7070"},"outputs":[{"output_type":"stream","name":"stdout","text":["Patients Shape: (98, 180)\n","Controls Shape: (48, 180)\n","W0: (146, 146)\n","Number of edges: 13046\n","Using device: cuda\n","\n","=== Fold 1 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7137 | DGI=0.7151 | Reg=-0.2374 | Total=1.4264 | TrainAcc=0.6641\n","Epoch 500: Sup=0.3139 | DGI=0.6946 | Reg=-0.2925 | Total=1.0056 | TrainAcc=0.9313\n","Epoch 1000: Sup=0.2526 | DGI=0.6935 | Reg=-0.3039 | Total=0.9431 | TrainAcc=0.9771\n","Epoch 1500: Sup=0.0992 | DGI=0.6940 | Reg=-0.2747 | Total=0.7904 | TrainAcc=0.9924\n","Epoch 2000: Sup=0.0849 | DGI=0.6960 | Reg=-0.2864 | Total=0.7780 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.5333 ± 0.0000\n","Precision: 1.0000 ± 0.0000\n","Recall: 0.3000 ± 0.0000\n","F1: 0.4615 ± 0.0000\n","LogLoss: 1.0476 ± 0.0000\n","AUC: 0.8000 ± 0.0000\n","\n","=== Fold 2 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7008 | DGI=0.7091 | Reg=-0.2371 | Total=1.4075 | TrainAcc=0.6718\n","Epoch 500: Sup=0.2447 | DGI=0.6936 | Reg=-0.2921 | Total=0.9354 | TrainAcc=0.9542\n","Epoch 1000: Sup=0.0971 | DGI=0.6985 | Reg=-0.2616 | Total=0.7930 | TrainAcc=0.9847\n","Epoch 1500: Sup=0.1916 | DGI=0.6948 | Reg=-0.2697 | Total=0.8837 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0855 | DGI=0.6932 | Reg=-0.2611 | Total=0.7761 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.5667 ± 0.0333\n","Precision: 0.8750 ± 0.1250\n","Recall: 0.4500 ± 0.1500\n","F1: 0.5641 ± 0.1026\n","LogLoss: 0.9316 ± 0.1160\n","AUC: 0.7800 ± 0.0200\n","\n","=== Fold 3 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7363 | DGI=0.7087 | Reg=-0.2438 | Total=1.4426 | TrainAcc=0.3282\n","Epoch 500: Sup=0.2688 | DGI=0.6937 | Reg=-0.2893 | Total=0.9595 | TrainAcc=0.9771\n","Epoch 1000: Sup=0.2169 | DGI=0.6973 | Reg=-0.2942 | Total=0.9113 | TrainAcc=0.9924\n","Epoch 1500: Sup=0.1658 | DGI=0.6935 | Reg=-0.2705 | Total=0.8566 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.1083 | DGI=0.7008 | Reg=-0.2629 | Total=0.8065 | TrainAcc=0.9924\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.5556 ± 0.0314\n","Precision: 0.8056 ± 0.1416\n","Recall: 0.5000 ± 0.1414\n","F1: 0.5866 ± 0.0896\n","LogLoss: 0.8621 ± 0.1365\n","AUC: 0.7067 ± 0.1050\n","\n","=== Fold 4 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7463 | DGI=0.7101 | Reg=-0.2388 | Total=1.4540 | TrainAcc=0.4962\n","Epoch 500: Sup=0.2041 | DGI=0.6983 | Reg=-0.2886 | Total=0.8995 | TrainAcc=0.9618\n","Epoch 1000: Sup=0.1568 | DGI=0.6935 | Reg=-0.2947 | Total=0.8474 | TrainAcc=0.9771\n","Epoch 1500: Sup=0.0746 | DGI=0.6932 | Reg=-0.2889 | Total=0.7648 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0899 | DGI=0.6978 | Reg=-0.3096 | Total=0.7846 | TrainAcc=0.9771\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.5500 ± 0.0289\n","Precision: 0.8042 ± 0.1227\n","Recall: 0.4750 ± 0.1299\n","F1: 0.5733 ± 0.0809\n","LogLoss: 1.1298 ± 0.4786\n","AUC: 0.6750 ± 0.1062\n","\n","=== Fold 5 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.6788 | DGI=0.7085 | Reg=-0.2360 | Total=1.3849 | TrainAcc=0.6718\n","Epoch 500: Sup=0.2175 | DGI=0.6946 | Reg=-0.3009 | Total=0.9091 | TrainAcc=0.9771\n","Epoch 1000: Sup=0.2296 | DGI=0.6932 | Reg=-0.2817 | Total=0.9199 | TrainAcc=0.9924\n","Epoch 1500: Sup=0.1725 | DGI=0.6951 | Reg=-0.2789 | Total=0.8648 | TrainAcc=0.9924\n","Epoch 2000: Sup=0.1230 | DGI=0.6932 | Reg=-0.2825 | Total=0.8133 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.5733 ± 0.0533\n","Precision: 0.8148 ± 0.1118\n","Recall: 0.5000 ± 0.1265\n","F1: 0.5998 ± 0.0897\n","LogLoss: 1.0746 ± 0.4421\n","AUC: 0.6880 ± 0.0985\n","\n","=== Fold 6 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7232 | DGI=0.7133 | Reg=-0.2368 | Total=1.4341 | TrainAcc=0.6718\n","Epoch 500: Sup=0.2497 | DGI=0.6934 | Reg=-0.2881 | Total=0.9402 | TrainAcc=0.9847\n","Epoch 1000: Sup=0.2053 | DGI=0.6972 | Reg=-0.2562 | Total=0.8999 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.2299 | DGI=0.6960 | Reg=-0.2737 | Total=0.9232 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.1057 | DGI=0.6932 | Reg=-0.2560 | Total=0.7963 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.5889 ± 0.0598\n","Precision: 0.8002 ± 0.1071\n","Recall: 0.5500 ± 0.1607\n","F1: 0.6268 ± 0.1018\n","LogLoss: 0.9679 ± 0.4688\n","AUC: 0.7133 ± 0.1062\n","\n","=== Fold 7 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7502 | DGI=0.7126 | Reg=-0.2369 | Total=1.4604 | TrainAcc=0.3282\n","Epoch 500: Sup=0.2531 | DGI=0.6957 | Reg=-0.2963 | Total=0.9458 | TrainAcc=0.9695\n","Epoch 1000: Sup=0.2642 | DGI=0.6934 | Reg=-0.2895 | Total=0.9547 | TrainAcc=0.9771\n","Epoch 1500: Sup=0.1052 | DGI=0.6949 | Reg=-0.2736 | Total=0.7973 | TrainAcc=0.9924\n","Epoch 2000: Sup=0.1042 | DGI=0.6939 | Reg=-0.2621 | Total=0.7955 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6095 ± 0.0750\n","Precision: 0.8287 ± 0.1213\n","Recall: 0.5571 ± 0.1498\n","F1: 0.6444 ± 0.1036\n","LogLoss: 0.9002 ± 0.4646\n","AUC: 0.7343 ± 0.1110\n","\n","=== Fold 8 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.6843 | DGI=0.7105 | Reg=-0.2374 | Total=1.3924 | TrainAcc=0.6718\n","Epoch 500: Sup=0.2985 | DGI=0.6938 | Reg=-0.2934 | Total=0.9893 | TrainAcc=1.0000\n","Epoch 1000: Sup=0.1524 | DGI=0.6982 | Reg=-0.2970 | Total=0.8476 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.1578 | DGI=0.6953 | Reg=-0.2781 | Total=0.8504 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0875 | DGI=0.6932 | Reg=-0.2799 | Total=0.7779 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6333 ± 0.0943\n","Precision: 0.8362 ± 0.1152\n","Recall: 0.5875 ± 0.1615\n","F1: 0.6691 ± 0.1169\n","LogLoss: 0.8679 ± 0.4429\n","AUC: 0.7450 ± 0.1076\n","\n","=== Fold 9 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7639 | DGI=0.7135 | Reg=-0.2362 | Total=1.4750 | TrainAcc=0.3282\n","Epoch 500: Sup=0.2833 | DGI=0.6941 | Reg=-0.2872 | Total=0.9745 | TrainAcc=0.9695\n","Epoch 1000: Sup=0.1975 | DGI=0.6953 | Reg=-0.2520 | Total=0.8903 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.1376 | DGI=0.6939 | Reg=-0.2510 | Total=0.8290 | TrainAcc=0.9924\n","Epoch 2000: Sup=0.1331 | DGI=0.6964 | Reg=-0.2621 | Total=0.8269 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6370 ± 0.0895\n","Precision: 0.8297 ± 0.1102\n","Recall: 0.6000 ± 0.1563\n","F1: 0.6767 ± 0.1123\n","LogLoss: 0.8262 ± 0.4339\n","AUC: 0.7511 ± 0.1029\n","\n","=== Fold 10 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7069 | DGI=0.7074 | Reg=-0.2363 | Total=1.4119 | TrainAcc=0.6718\n","Epoch 500: Sup=0.2472 | DGI=0.6946 | Reg=-0.2620 | Total=0.9392 | TrainAcc=0.9084\n","Epoch 1000: Sup=0.1689 | DGI=0.6943 | Reg=-0.2778 | Total=0.8605 | TrainAcc=0.9695\n","Epoch 1500: Sup=0.1997 | DGI=0.7184 | Reg=-0.2502 | Total=0.9156 | TrainAcc=0.9771\n","Epoch 2000: Sup=0.0865 | DGI=0.6932 | Reg=-0.2553 | Total=0.7771 | TrainAcc=0.9771\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6333 ± 0.0856\n","Precision: 0.8218 ± 0.1072\n","Recall: 0.6000 ± 0.1483\n","F1: 0.6757 ± 0.1066\n","LogLoss: 0.8408 ± 0.4140\n","AUC: 0.7400 ± 0.1032\n","\n","=== Fold 11 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7187 | DGI=0.7143 | Reg=-0.2400 | Total=1.4306 | TrainAcc=0.5954\n","Epoch 500: Sup=0.2121 | DGI=0.6934 | Reg=-0.3014 | Total=0.9024 | TrainAcc=0.9695\n","Epoch 1000: Sup=0.2075 | DGI=0.7010 | Reg=-0.2700 | Total=0.9058 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.1693 | DGI=0.6933 | Reg=-0.2944 | Total=0.8596 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0941 | DGI=0.6932 | Reg=-0.3115 | Total=0.7841 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6303 ± 0.0822\n","Precision: 0.8152 ± 0.1043\n","Recall: 0.6000 ± 0.1414\n","F1: 0.6748 ± 0.1016\n","LogLoss: 0.8349 ± 0.3952\n","AUC: 0.7418 ± 0.0985\n","\n","=== Fold 12 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7204 | DGI=0.7069 | Reg=-0.2346 | Total=1.4250 | TrainAcc=0.3817\n","Epoch 500: Sup=0.2891 | DGI=0.6962 | Reg=-0.2697 | Total=0.9826 | TrainAcc=0.9466\n","Epoch 1000: Sup=0.1838 | DGI=0.6935 | Reg=-0.2845 | Total=0.8745 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.1768 | DGI=0.6932 | Reg=-0.2868 | Total=0.8670 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.1086 | DGI=0.7069 | Reg=-0.2925 | Total=0.8126 | TrainAcc=0.9847\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6278 ± 0.0792\n","Precision: 0.8056 ± 0.1048\n","Recall: 0.6083 ± 0.1382\n","F1: 0.6769 ± 0.0975\n","LogLoss: 0.8254 ± 0.3797\n","AUC: 0.7450 ± 0.0949\n","\n","=== Fold 13 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7207 | DGI=0.7067 | Reg=-0.2383 | Total=1.4251 | TrainAcc=0.3282\n","Epoch 500: Sup=0.1873 | DGI=0.6947 | Reg=-0.2911 | Total=0.8791 | TrainAcc=0.9237\n","Epoch 1000: Sup=0.2621 | DGI=0.6933 | Reg=-0.3087 | Total=0.9523 | TrainAcc=0.9924\n","Epoch 1500: Sup=0.1120 | DGI=0.6933 | Reg=-0.2975 | Total=0.8024 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.1201 | DGI=0.6946 | Reg=-0.3173 | Total=0.8115 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6205 ± 0.0801\n","Precision: 0.8206 ± 0.1132\n","Recall: 0.5846 ± 0.1561\n","F1: 0.6604 ± 0.1099\n","LogLoss: 0.8259 ± 0.3648\n","AUC: 0.7554 ± 0.0980\n","\n","=== Fold 14 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7160 | DGI=0.7093 | Reg=-0.2391 | Total=1.4229 | TrainAcc=0.3359\n","Epoch 500: Sup=0.2653 | DGI=0.6945 | Reg=-0.2668 | Total=0.9571 | TrainAcc=0.9847\n","Epoch 1000: Sup=0.1788 | DGI=0.6948 | Reg=-0.2880 | Total=0.8708 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.1546 | DGI=0.6956 | Reg=-0.2458 | Total=0.8477 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0797 | DGI=0.6935 | Reg=-0.2826 | Total=0.7704 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6238 ± 0.0781\n","Precision: 0.8139 ± 0.1117\n","Recall: 0.6000 ± 0.1604\n","F1: 0.6676 ± 0.1091\n","LogLoss: 0.8130 ± 0.3546\n","AUC: 0.7543 ± 0.0945\n","\n","=== Fold 15 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7216 | DGI=0.7137 | Reg=-0.2421 | Total=1.4329 | TrainAcc=0.6718\n","Epoch 500: Sup=0.2234 | DGI=0.6942 | Reg=-0.3032 | Total=0.9146 | TrainAcc=0.9466\n","Epoch 1000: Sup=0.1749 | DGI=0.6957 | Reg=-0.3153 | Total=0.8674 | TrainAcc=0.9466\n","Epoch 1500: Sup=0.1268 | DGI=0.6932 | Reg=-0.2775 | Total=0.8172 | TrainAcc=0.9695\n","Epoch 2000: Sup=0.1093 | DGI=0.6938 | Reg=-0.3055 | Total=0.8000 | TrainAcc=0.9924\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6222 ± 0.0757\n","Precision: 0.8152 ± 0.1081\n","Recall: 0.5933 ± 0.1569\n","F1: 0.6648 ± 0.1059\n","LogLoss: 0.8328 ± 0.3505\n","AUC: 0.7573 ± 0.0920\n","\n","=== Fold 16 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7347 | DGI=0.7123 | Reg=-0.2364 | Total=1.4446 | TrainAcc=0.2977\n","Epoch 500: Sup=0.3160 | DGI=0.6943 | Reg=-0.2974 | Total=1.0073 | TrainAcc=0.9618\n","Epoch 1000: Sup=0.1302 | DGI=0.6933 | Reg=-0.2745 | Total=0.8207 | TrainAcc=0.9542\n","Epoch 1500: Sup=0.1475 | DGI=0.6932 | Reg=-0.2772 | Total=0.8379 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.1632 | DGI=0.6932 | Reg=-0.3001 | Total=0.8534 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6208 ± 0.0735\n","Precision: 0.8268 ± 0.1138\n","Recall: 0.5813 ± 0.1590\n","F1: 0.6589 ± 0.1050\n","LogLoss: 0.8202 ± 0.3428\n","AUC: 0.7650 ± 0.0939\n","\n","=== Fold 17 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7122 | DGI=0.7110 | Reg=-0.2365 | Total=1.4208 | TrainAcc=0.3969\n","Epoch 500: Sup=0.2316 | DGI=0.6949 | Reg=-0.2743 | Total=0.9237 | TrainAcc=0.9771\n","Epoch 1000: Sup=0.1653 | DGI=0.6943 | Reg=-0.2802 | Total=0.8568 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.1426 | DGI=0.6932 | Reg=-0.2621 | Total=0.8332 | TrainAcc=0.9924\n","Epoch 2000: Sup=0.0805 | DGI=0.6938 | Reg=-0.2503 | Total=0.7718 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6275 ± 0.0760\n","Precision: 0.8252 ± 0.1106\n","Recall: 0.5941 ± 0.1626\n","F1: 0.6672 ± 0.1072\n","LogLoss: 0.7983 ± 0.3439\n","AUC: 0.7682 ± 0.0921\n","\n","=== Fold 18 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7109 | DGI=0.7121 | Reg=-0.2357 | Total=1.4206 | TrainAcc=0.3359\n","Epoch 500: Sup=0.2143 | DGI=0.6935 | Reg=-0.2823 | Total=0.9050 | TrainAcc=0.9618\n","Epoch 1000: Sup=0.1887 | DGI=0.6960 | Reg=-0.2889 | Total=0.8819 | TrainAcc=1.0000\n","Epoch 1500: Sup=0.1725 | DGI=0.6944 | Reg=-0.2451 | Total=0.8645 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.1623 | DGI=0.6932 | Reg=-0.2714 | Total=0.8527 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6333 ± 0.0778\n","Precision: 0.8238 ± 0.1076\n","Recall: 0.6056 ± 0.1649\n","F1: 0.6746 ± 0.1085\n","LogLoss: 0.7814 ± 0.3414\n","AUC: 0.7700 ± 0.0898\n","\n","=== Fold 19 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7826 | DGI=0.7100 | Reg=-0.2374 | Total=1.4903 | TrainAcc=0.3282\n","Epoch 500: Sup=0.2372 | DGI=0.6944 | Reg=-0.2736 | Total=0.9288 | TrainAcc=0.9542\n","Epoch 1000: Sup=0.2040 | DGI=0.7043 | Reg=-0.2842 | Total=0.9055 | TrainAcc=0.9924\n","Epoch 1500: Sup=0.1614 | DGI=0.6940 | Reg=-0.2577 | Total=0.8528 | TrainAcc=0.9771\n","Epoch 2000: Sup=0.1213 | DGI=0.6934 | Reg=-0.2439 | Total=0.8123 | TrainAcc=1.0000\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6456 ± 0.0919\n","Precision: 0.8331 ± 0.1119\n","Recall: 0.6158 ± 0.1663\n","F1: 0.6859 ± 0.1159\n","LogLoss: 0.7551 ± 0.3506\n","AUC: 0.7811 ± 0.0991\n","\n","=== Fold 20 (Controls vs Patients) ===\n","Train Controls: 43, Train Patients: 88\n","Test Controls: 5, Test Patients: 10\n","Epoch 1: Sup=0.7471 | DGI=0.7099 | Reg=-0.2350 | Total=1.4547 | TrainAcc=0.3282\n","Epoch 500: Sup=0.2608 | DGI=0.6939 | Reg=-0.2966 | Total=0.9517 | TrainAcc=0.9695\n","Epoch 1000: Sup=0.1877 | DGI=0.6944 | Reg=-0.2671 | Total=0.8794 | TrainAcc=0.9924\n","Epoch 1500: Sup=0.1290 | DGI=0.7039 | Reg=-0.2683 | Total=0.8303 | TrainAcc=1.0000\n","Epoch 2000: Sup=0.0680 | DGI=0.6933 | Reg=-0.2629 | Total=0.7587 | TrainAcc=0.9924\n","\n","=== Average Results (Controls vs Patients) ===\n","Accuracy: 0.6533 ± 0.0957\n","Precision: 0.8414 ± 0.1150\n","Recall: 0.6200 ± 0.1631\n","F1: 0.6928 ± 0.1169\n","LogLoss: 0.7524 ± 0.3419\n","AUC: 0.7820 ± 0.0967\n"]}],"source":["import os\n","import sys\n","import numpy as np\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.data import Data\n","from torch_geometric.nn import ARMAConv\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score,\n","    f1_score, log_loss, roc_auc_score\n",")\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","SEED = 42\n","np.random.seed(SEED)\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","torch.set_num_threads(4)\n","\n","# === Load Patients ===\n","fa_patients_path = \"/home/snu/Downloads/NIFD_Patients_FA_Histogram_Feature.npy\"\n","Patients_FA_array = np.load(fa_patients_path, allow_pickle=True)\n","\n","# === Load Controls ===\n","fa_controls_path = \"/home/snu/Downloads/NIFD_Control_FA_Histogram_Feature.npy\"\n","Controls_FA_array = np.load(fa_controls_path, allow_pickle=True)\n","\n","print(\"Patients Shape:\", Patients_FA_array.shape)\n","print(\"Controls Shape:\", Controls_FA_array.shape)\n","\n","# === Combine features and labels ===\n","X = np.vstack([Controls_FA_array, Patients_FA_array])\n","y = np.hstack([\n","    np.zeros(Controls_FA_array.shape[0], dtype=np.int64),  # 0 = Control\n","    np.ones(Patients_FA_array.shape[0], dtype=np.int64)    # 1 = Patient\n","])\n","\n","# Shuffle\n","np.random.seed(42)\n","perm = np.random.permutation(X.shape[0])\n","X = X[perm]\n","y = y[perm]\n","\n","# ------------------------\n","# Adjacency building\n","# ------------------------\n","def create_adj(F, alpha=1.0):\n","    norms = np.linalg.norm(F, axis=1, keepdims=True)\n","    norms[norms == 0] = 1.0\n","    F_norm = F / norms\n","    W = np.dot(F_norm, F_norm.T)\n","    W = (W >= alpha).astype(np.float32)\n","    return W\n","\n","W0 = create_adj(X, alpha=0.8)\n","print(f\"W0: {W0.shape}\")\n","\n","def load_graph_torch(adj, node_feats):\n","    node_feats_t = torch.from_numpy(node_feats).float()\n","    edge_idx = np.array(np.nonzero(adj))\n","    edge_index = torch.from_numpy(edge_idx).long()\n","    return node_feats_t, edge_index\n","\n","node_feats_all, edge_index_all = load_graph_torch(W0, X)\n","print(f\"Number of edges: {edge_index_all.size(1)}\")\n","\n","# ------------------------\n","# Model components\n","# ------------------------\n","class ARMAEncoder(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_stacks=1, num_layers=1, activ=\"RELU\"):\n","        super(ARMAEncoder, self).__init__()\n","        activations = {\n","            \"SELU\": F.selu,\n","            \"SiLU\": F.silu,\n","            \"GELU\": F.gelu,\n","            \"ELU\": F.elu,\n","            \"RELU\": F.relu\n","        }\n","        self.act = activations.get(activ, F.elu)\n","        self.arma = ARMAConv(\n","            input_dim, hidden_dim,\n","            num_stacks=num_stacks,\n","            num_layers=num_layers,\n","            shared_weights=True,\n","            dropout=0.3\n","        )\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.arma(x, edge_index)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        x = self.batchnorm(x)\n","        logits = self.mlp(x)\n","        return logits\n","\n","class AvgReadout(nn.Module):\n","    def forward(self, seq, msk=None):\n","        if msk is None:\n","            return torch.mean(seq, 0)\n","        else:\n","            msk = torch.unsqueeze(msk, -1)\n","            return torch.sum(seq * msk, 0) / torch.sum(msk)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, n_h):\n","        super().__init__()\n","        self.f_k = nn.Bilinear(n_h, n_h, 1)\n","        nn.init.xavier_uniform_(self.f_k.weight.data)\n","        if self.f_k.bias is not None:\n","            self.f_k.bias.data.fill_(0.0)\n","\n","    def forward(self, c, h_pl, h_mi):\n","        c_x = torch.unsqueeze(c, 0).expand_as(h_pl)\n","        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 1)\n","        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 1)\n","        return torch.cat((sc_1, sc_2), 0)\n","\n","class DGI(nn.Module):\n","    def __init__(self, n_in, n_h, num_stacks=2, num_layers=1):\n","        super().__init__()\n","        self.gcn1 = ARMAEncoder(n_in, n_h, num_stacks=num_stacks, num_layers=num_layers)\n","        self.read = AvgReadout()\n","        self.sigm = nn.Sigmoid()\n","        self.disc = Discriminator(n_h)\n","\n","    def forward(self, seq1, seq2, edge_index):\n","        data1 = Data(x=seq1, edge_index=edge_index)\n","        data2 = Data(x=seq2, edge_index=edge_index)\n","        h_1 = self.gcn1(data1)\n","        c = self.read(h_1)\n","        c = self.sigm(c)\n","        h_2 = self.gcn1(data2)\n","        logits = self.disc(c, h_1, h_2)\n","        return logits, h_1\n","\n","class DGI_with_classifier(DGI):\n","    def __init__(self, n_in, n_h, n_classes=2, cut=0, device='cpu', num_stacks=1, num_layers=1):\n","        super().__init__(n_in, n_h, num_stacks=num_stacks, num_layers=num_layers)\n","        self.classifier = nn.Linear(n_h, n_classes)\n","        self.cut = cut\n","        self.device = device\n","        self.n_clusters = n_classes\n","\n","    def get_embeddings(self, node_feats, edge_index):\n","        _, embeddings = self.forward(node_feats, node_feats, edge_index)\n","        return embeddings\n","\n","    def cut_loss(self, A, S):\n","        C = F.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, C).t(), C)\n","        num = torch.trace(A_pool)\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, C).t(), C)\n","        den = torch.trace(D_pooled) + 1e-9\n","        mincut_loss = -(num / den)\n","        St_S = torch.matmul(C.t(), C)\n","        I_S = torch.eye(C.shape[1], device=A.device)\n","        ortho_loss = torch.norm(St_S / (torch.norm(St_S) + 1e-9) - I_S / (torch.norm(I_S) + 1e-9))\n","        return mincut_loss + ortho_loss\n","\n","    def modularity_loss(self, A, S):\n","        C = F.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A) + 1e-9\n","        B = A - torch.outer(d, d) / (2 * m)\n","        I_S = torch.eye(C.shape[1], device=A.device)\n","        k = torch.norm(I_S)\n","        n = S.shape[0]\n","        modularity_term = (-1 / (2 * m)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1\n","        return modularity_term + collapse_reg_term\n","\n","    def Reg_loss(self, A, embeddings):\n","        logits = self.classifier(embeddings)\n","        if self.cut == 1:\n","            return self.cut_loss(A, logits)\n","        else:\n","            return self.modularity_loss(A, logits)\n","\n","# ------------------------\n","# Prepare cross-validation\n","# ------------------------\n","sss = StratifiedShuffleSplit(n_splits=20, test_size=0.5, random_state=SEED)\n","accuracies, precisions, recalls, f1_scores, losses, all_auc = [], [], [], [], [], []\n","\n","def get_device():\n","    try:\n","        if torch.cuda.is_available():\n","            dev = torch.device(\"cuda\")\n","            torch.tensor([1.0], device=dev) + 1.0\n","            return dev\n","    except Exception as e:\n","        print(\"CUDA not usable, falling back to CPU:\", e)\n","        try:\n","            torch.cuda.empty_cache()\n","        except:\n","            pass\n","    return torch.device(\"cpu\")\n","\n","device = get_device()\n","print(\"Using device:\", device)\n","\n","A_tensor = torch.from_numpy(W0).float().to(device)\n","hidden_dim = 512\n","cut = 1\n","num_epochs = 2000\n","lr = 1e-4\n","weight_decay = 1e-4\n","reg_weight = 0.01\n","num_stacks = 1\n","num_layers = 1\n","\n","node_feats = node_feats_all.to(device)\n","edge_index = edge_index_all.to(device)\n","\n","N = node_feats.size(0)\n","lbl = torch.cat([torch.ones(N, device=device), torch.zeros(N, device=device)]).float()\n","\n","# Define num_feats\n","num_feats = X.shape[1]\n","\n","for fold, (train_idx, test_idx) in enumerate(sss.split(X, y), start=1):\n","    print(f\"\\n=== Fold {fold} (Controls vs Patients) ===\")\n","\n","    cn_idx = np.where(y == 0)[0]\n","    ad_idx = np.where(y == 1)[0]\n","\n","    sss_class = StratifiedShuffleSplit(n_splits=20, test_size=0.1, random_state=fold)\n","    cn_train_idx, cn_test_idx = next(sss_class.split(X[cn_idx], y[cn_idx]))\n","    ad_train_idx, ad_test_idx = next(sss_class.split(X[ad_idx], y[ad_idx]))\n","\n","    cn_train = cn_idx[cn_train_idx]\n","    ad_train = ad_idx[ad_train_idx]\n","    cn_test = cn_idx[cn_test_idx]\n","    ad_test = ad_idx[ad_test_idx]\n","\n","    balanced_train_idx = np.concatenate([cn_train, ad_train])\n","    test_idx_final = np.concatenate([cn_test, ad_test])\n","    np.random.shuffle(balanced_train_idx)\n","    np.random.shuffle(test_idx_final)\n","\n","    print(f\"Train Controls: {len(cn_train)}, Train Patients: {len(ad_train)}\")\n","    print(f\"Test Controls: {len(cn_test)}, Test Patients: {len(ad_test)}\")\n","\n","    y_tensor = torch.from_numpy(y).long().to(device)\n","    train_idx_t = torch.from_numpy(balanced_train_idx).long().to(device)\n","    test_idx_t = torch.from_numpy(test_idx_final).long().to(device)\n","\n","    model = DGI_with_classifier(num_feats, hidden_dim, n_classes=2, cut=cut,\n","                                device=device, num_stacks=num_stacks, num_layers=num_layers).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    bce_loss = nn.BCEWithLogitsLoss()\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","    for epoch in range(1, num_epochs + 1):\n","        model.train()\n","        optimizer.zero_grad()\n","        perm = torch.randperm(N, device=device)\n","        corrupt = node_feats[perm]\n","        logits_dgi, embeddings = model(node_feats, corrupt, edge_index)\n","        dgi_loss = bce_loss(logits_dgi.squeeze(), lbl)\n","        logits_cls = model.classifier(embeddings)\n","        train_logits = logits_cls[train_idx_t]\n","        train_labels = y_tensor[train_idx_t]\n","        supervised_loss = ce_loss(train_logits, train_labels)\n","        reg_loss_val = model.Reg_loss(A_tensor, embeddings)\n","        total_loss = supervised_loss + dgi_loss + reg_weight * reg_loss_val\n","        total_loss.backward()\n","        optimizer.step()\n","\n","        if epoch % 500 == 0 or epoch == 1:\n","            model.eval()\n","            with torch.no_grad():\n","                logits_eval = model.classifier(model.get_embeddings(node_feats, edge_index))\n","                preds_train = torch.argmax(logits_eval[train_idx_t], dim=1).cpu().numpy()\n","                acc = accuracy_score(train_labels.cpu().numpy(), preds_train)\n","            print(f\"Epoch {epoch}: Sup={supervised_loss.item():.4f} | DGI={dgi_loss.item():.4f} | \"\n","                  f\"Reg={reg_loss_val.item():.4f} | Total={total_loss.item():.4f} | TrainAcc={acc:.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        emb_final = model.get_embeddings(node_feats, edge_index)\n","        logits_final = model.classifier(emb_final)\n","        probs = F.softmax(logits_final, dim=1).cpu().numpy()\n","        y_pred = np.argmax(probs, axis=1)\n","\n","    y_test = y[test_idx_final]\n","    y_pred_test = y_pred[test_idx_final]\n","    y_proba_test = probs[test_idx_final, 1]\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","    loss_val = log_loss(y_test, y_proba_test)\n","    auc_score = roc_auc_score(y_test, y_proba_test)\n","\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    losses.append(loss_val)\n","    all_auc.append(auc_score)\n","\n","    print(\"\\n=== Average Results (Controls vs Patients) ===\")\n","    print(f\"Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n","    print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n","    print(f\"Recall: {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n","    print(f\"F1: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n","    print(f\"LogLoss: {np.mean(losses):.4f} ± {np.std(losses):.4f}\")\n","    print(f\"AUC: {np.mean(all_auc):.4f} ± {np.std(all_auc):.4f}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"}},"nbformat":4,"nbformat_minor":0}
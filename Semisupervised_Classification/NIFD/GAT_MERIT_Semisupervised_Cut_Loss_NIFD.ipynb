{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeY1CwLnzALWjsDNFSLvNj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"mmlxX_9O-r-G","executionInfo":{"status":"ok","timestamp":1767673428571,"user_tz":-330,"elapsed":8,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","import copy\n","import random\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnF\n","import torch.optim as optim\n","from torch_geometric.data import Data\n","from torch_geometric.nn import ARMAConv\n","\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_auc_score"],"metadata":{"id":"cPaEtrmyio-7","executionInfo":{"status":"ok","timestamp":1767673430377,"user_tz":-330,"elapsed":1804,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f25a95a5-e82e-4615-e3f4-e0c53479bcef"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(\n","/home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/snu/anaconda3/envs/torch_env/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n","  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n","/home/snu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}]},{"cell_type":"code","source":["SEED = 42\n","np.random.seed(SEED)\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)"],"metadata":{"id":"bubKVZjNil9a","executionInfo":{"status":"ok","timestamp":1767673430422,"user_tz":-330,"elapsed":42,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(\"Device:\", device)\n","\n","# === Load Patients ===\n","fa_patients_path = \"/home/snu/Downloads/NIFD_Patients_FA_Histogram_Feature.npy\"\n","Patients_FA_array = np.load(fa_patients_path, allow_pickle=True)\n","\n","# === Load Controls ===\n","fa_controls_path = \"/home/snu/Downloads/NIFD_Control_FA_Histogram_Feature.npy\"\n","Controls_FA_array = np.load(fa_controls_path, allow_pickle=True)\n","\n","print(\"Patients Shape:\", Patients_FA_array.shape)\n","print(\"Controls Shape:\", Controls_FA_array.shape)\n","\n","# === Combine features and labels ===\n","X = np.vstack([Controls_FA_array, Patients_FA_array])\n","y = np.hstack([\n","    np.zeros(Controls_FA_array.shape[0], dtype=np.int64),  # 0 = Control\n","    np.ones(Patients_FA_array.shape[0], dtype=np.int64)    # 1 = Patient\n","])\n","\n","# Shuffle\n","np.random.seed(42)\n","perm = np.random.permutation(X.shape[0])\n","X = X[perm]\n","y = y[perm]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t1jWZXCGm2SV","executionInfo":{"status":"ok","timestamp":1767673430442,"user_tz":-330,"elapsed":18,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"51df9a48-8338-4ebd-b238-a8e6457c13c5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","Patients Shape: (98, 180)\n","Controls Shape: (48, 180)\n"]}]},{"cell_type":"code","source":["def sim(h1, h2, tau=0.2):\n","    z1 = nnF.normalize(h1, dim=-1, p=2)\n","    z2 = nnF.normalize(h2, dim=-1, p=2)\n","    return torch.mm(z1, z2.t()) / tau\n","\n","def contrastive_loss_wo_cross_network(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    intra_sim = f(sim(h1, h1))\n","    inter_sim = f(sim(h1, h2))\n","    # diagonal numerator; denominator excludes intra diag\n","    return -torch.log(inter_sim.diag() /\n","                     (intra_sim.sum(dim=-1) + inter_sim.sum(dim=-1) - intra_sim.diag() + 1e-12))\n","\n","def contrastive_loss_wo_cross_view(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    cross_sim = f(sim(h1, z))\n","    return -torch.log(cross_sim.diag() / (cross_sim.sum(dim=-1) + 1e-12))"],"metadata":{"id":"1kw3ljHanRov","executionInfo":{"status":"ok","timestamp":1767673430449,"user_tz":-330,"elapsed":6,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.PReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"uDcrA3XQnWYP","executionInfo":{"status":"ok","timestamp":1767673430497,"user_tz":-330,"elapsed":47,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnF\n","from torch_geometric.nn import GATConv\n","\n","class GATEncoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ=\"RELU\", heads=2):\n","        super(GATEncoder, self).__init__()\n","        self.device = device\n","\n","        activations = {\n","            \"SELU\": nnF.selu,\n","            \"SiLU\": nnF.silu,\n","            \"GELU\": nnF.gelu,\n","            \"ELU\": nnF.elu,\n","            \"RELU\": nnF.relu\n","        }\n","        self.act = activations.get(activ, nnF.elu)\n","\n","        self.gat = GATConv(\n","            in_channels=input_dim,\n","            out_channels=hidden_dim,\n","            heads=heads,\n","            dropout=0.25,\n","            concat=False   # keeps output dim = hidden_dim\n","        )\n","\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.gat(x, edge_index)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        x = self.batchnorm(x)\n","        logits = self.mlp(x)\n","        return logits"],"metadata":{"id":"JHJO_XZFnXEF","executionInfo":{"status":"ok","timestamp":1767673430499,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class EMA():\n","    def __init__(self, beta):\n","        self.beta = beta\n","\n","    def update_average(self, old, new):\n","        if old is None:\n","            return new\n","        return old * self.beta + (1 - self.beta) * new\n","\n","def update_moving_average(ema_updater, ma_model, current_model):\n","    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n","        old_weight, up_weight = ma_params.data, current_params.data\n","        ma_params.data = ema_updater.update_average(old_weight, up_weight)"],"metadata":{"id":"YJHpeOzfneJX","executionInfo":{"status":"ok","timestamp":1767673430502,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class GAT(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ, moving_average_decay=0.99, cut=True):\n","        super(GAT, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","        self.cut = cut\n","        # beta for mixing in contrastive combination\n","        self.beta = 0.6\n","\n","        self.online_encoder = GATEncoder(input_dim, hidden_dim, device, activ)\n","        self.target_encoder = copy.deepcopy(self.online_encoder)\n","        # freeze target encoder params\n","        for p in self.target_encoder.parameters():\n","            p.requires_grad = False\n","\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_dim)\n","\n","        self.loss = self.cut_loss if cut else self.modularity_loss\n","        self.target_ema_updater = EMA(moving_average_decay)\n","\n","    def reset_moving_average(self):\n","        del self.target_encoder\n","        self.target_encoder = None\n","\n","    def update_ma(self):\n","        assert self.target_encoder is not None, 'target encoder has not been created yet'\n","        update_moving_average(self.target_ema_updater, self.target_encoder, self.online_encoder)\n","\n","    def forward(self, data1, data2):\n","        # online projections\n","        x1 = self.online_encoder(data1)      # shape: N x hidden\n","        logits1 = self.online_predictor(x1)  # predictor outputs (raw)\n","        S1 = nnF.softmax(logits1, dim=1)\n","\n","        x2 = self.online_encoder(data2)\n","        logits2 = self.online_predictor(x2)\n","        S2 = nnF.softmax(logits2, dim=1)\n","\n","        # target projections (no grads)\n","        with torch.no_grad():\n","            target_proj_one = self.target_encoder(data1).detach()\n","            target_proj_two = self.target_encoder(data2).detach()\n","\n","        # contrastive style losses\n","        l1 = self.beta * contrastive_loss_wo_cross_network(x1, x2, target_proj_two) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x1, x2, target_proj_two)\n","\n","        l2 = self.beta * contrastive_loss_wo_cross_network(x2, x1, target_proj_one) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x2, x1, target_proj_one)\n","\n","        return S1, S2, logits1, logits2, l1, l2\n","\n","    def modularity_loss(self, A, S):\n","        C = nnF.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A)\n","        B = A - torch.ger(d, d) / (2 * m + 1e-12)\n","\n","        k = torch.tensor(self.num_clusters, device=self.device, dtype=torch.float32)\n","        n = S.shape[0]\n","\n","        modularity_term = (-1.0 / (2.0 * m + 1e-12)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1.0\n","\n","        return modularity_term + collapse_reg_term\n","\n","    def cut_loss(self, A, S):\n","        S = nnF.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / (den + 1e-12))\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / (torch.norm(St_S) + 1e-12) - I_S / (torch.norm(I_S) + 1e-12))\n","\n","        return mincut_loss + ortho_loss"],"metadata":{"id":"Kwsbu0iPni1L","executionInfo":{"status":"ok","timestamp":1767673430555,"user_tz":-330,"elapsed":52,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def create_adj(features, cut, alpha=1.0):\n","    F_norm = features / (np.linalg.norm(features, axis=1, keepdims=True) + 1e-12)\n","    W = np.dot(F_norm, F_norm.T)\n","\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        if W.max() > 0:\n","            W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = (W * (W >= alpha)).astype(np.float32)\n","    return W\n","\n","def edge_index_from_dense(W):\n","    rows, cols = np.nonzero(W > 0)\n","    edge_index = np.vstack([rows, cols]).astype(np.int64)\n","    edge_weight = W[rows, cols].astype(np.float32)\n","    return edge_index, edge_weight\n","\n","def build_adj_list(edge_index_np, num_nodes):\n","    adj = [[] for _ in range(num_nodes)]\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    for s, d in zip(src, dst):\n","        adj[s].append(d)\n","    adj = [np.array(neis, dtype=np.int64) if len(neis) > 0 else np.array([], dtype=np.int64) for neis in adj]\n","    return adj\n","\n","def aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=None):\n","    rng = np.random.default_rng(seed)\n","    E = edge_index_np.shape[1]\n","    keep_mask = rng.random(E) >= drop_percent\n","    new_edge_index = edge_index_np[:, keep_mask]\n","    return new_edge_index\n","\n","def aug_subgraph_edge_index(features_np, edge_index_np, adj_list, drop_percent=0.2, seed=None):\n","    rng = np.random.default_rng(seed)\n","    num_nodes = features_np.shape[0]\n","    s_node_num = int(num_nodes * (1 - drop_percent))\n","    s_node_num = max(1, s_node_num)\n","\n","    center_node = int(rng.integers(0, num_nodes))\n","    sub_nodes = [center_node]\n","    front_idx = 0\n","\n","    while len(sub_nodes) < s_node_num and front_idx < len(sub_nodes):\n","        cur = sub_nodes[front_idx]\n","        neighbors = adj_list[cur]\n","        if neighbors.size > 0:\n","            nbrs_shuffled = neighbors.copy()\n","            rng.shuffle(nbrs_shuffled)\n","            for nb in nbrs_shuffled:\n","                if nb not in sub_nodes:\n","                    sub_nodes.append(int(nb))\n","                    if len(sub_nodes) >= s_node_num:\n","                        break\n","        front_idx += 1\n","        if front_idx >= len(sub_nodes) and len(sub_nodes) < s_node_num:\n","            remaining = [n for n in range(num_nodes) if n not in sub_nodes]\n","            if not remaining:\n","                break\n","            add = int(rng.choice(remaining))\n","            sub_nodes.append(add)\n","\n","    sub_nodes = sorted(set(sub_nodes))\n","    node_map = {old: new for new, old in enumerate(sub_nodes)}\n","\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    mask_src_in = np.isin(src, sub_nodes)\n","    mask_dst_in = np.isin(dst, sub_nodes)\n","    mask = mask_src_in & mask_dst_in\n","    sel_src = src[mask]\n","    sel_dst = dst[mask]\n","    remapped_src = np.array([node_map[int(s)] for s in sel_src], dtype=np.int64)\n","    remapped_dst = np.array([node_map[int(d)] for d in sel_dst], dtype=np.int64)\n","    new_edge_index = np.vstack([remapped_src, remapped_dst])\n","    sub_features = features_np[sub_nodes, :].astype(np.float32)\n","    return sub_features, new_edge_index\n","\n","def load_data_from_edge_index(node_feats_np, edge_index_np, device):\n","    node_feats = torch.from_numpy(node_feats_np).float()\n","    edge_index = torch.from_numpy(edge_index_np.astype(np.int64)).long()\n","    return node_feats, edge_index"],"metadata":{"id":"hr9Mo6a5nqqH","executionInfo":{"status":"ok","timestamp":1767673430559,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","hidden_dim = 256\n","K = 2\n","num_epochs = 2000\n","alpha = 0.5\n","features = X.astype(np.float32)\n","num_nodes = features.shape[0]\n","feat_dim = features.shape[1]\n","W0 = create_adj(features, cut=0, alpha=alpha)\n","edge_index_np, edge_weight_np = edge_index_from_dense(W0)\n","adj_list = build_adj_list(edge_index_np, num_nodes)\n","node_feats_all, edge_index_all = load_data_from_edge_index(features, edge_index_np, device)\n","data_full = Data(x=node_feats_all.to(device), edge_index=edge_index_all.to(device))\n","print(f\"Data: {data_full}\")\n","\n","A1 = torch.from_numpy(W0).float().to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvDNO88wnwUR","executionInfo":{"status":"ok","timestamp":1767673430793,"user_tz":-330,"elapsed":233,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"f1171c79-a978-4c9e-a9c6-6ff3e25cb1d0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Data: Data(x=[146, 180], edge_index=[2, 21256])\n"]}]},{"cell_type":"code","source":["accuracies, precisions, recalls, f1_scores, losses, all_auc = [], [], [], [], [], []\n","\n","sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=SEED)\n","for fold, (train_idx_full, test_idx) in enumerate(sss.split(X, y)):\n","    print(f\"\\n=== Fold {fold+1} ===\")\n","\n","    # Build a tiny balanced \"train\" set within the fold for supervised head\n","    cn_idx = np.where(y == 0)[0]\n","    mci_idx = np.where(y == 1)[0]\n","    sss_class = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=fold)\n","    cn_train_idx, _ = next(sss_class.split(X[cn_idx], y[cn_idx]))\n","    mci_train_idx, _ = next(sss_class.split(X[mci_idx], y[mci_idx]))\n","    cn_train = cn_idx[cn_train_idx]\n","    mci_train = mci_idx[mci_train_idx]\n","    balanced_train_idx = np.concatenate([cn_train, mci_train])\n","    np.random.shuffle(balanced_train_idx)\n","\n","    train_idx_t = torch.from_numpy(balanced_train_idx).long().to(device)\n","    test_idx_t = torch.from_numpy(test_idx).long().to(device)\n","    y_tensor = torch.from_numpy(y).long().to(device)\n","\n","    model = GAT(feat_dim, hidden_dim, K, device, activ=\"RELU\", cut=False, moving_average_decay=0.99).to(device)\n","    classifier = nn.Linear(hidden_dim, K).to(device)\n","    optimizer = optim.Adam(list(model.parameters()) + list(classifier.parameters()), lr=1e-4, weight_decay=1e-4)\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","    for ep in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        # Aug 1: random edge drop\n","        edge_index_aug1 = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=ep)\n","        # Aug 2: independent random edge drop\n","        edge_index_aug2 = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=ep+999)\n","\n","        rng = np.random.default_rng(ep)\n","        mask = rng.random(features.shape) >= 0.2\n","        features_aug1 = (features * mask.astype(np.float32))\n","\n","        aug_feat2 = features.copy()\n","        drop_feat_num = int(features.shape[0] * features.shape[1] * 0.2)\n","        flat_idx = rng.choice(features.shape[0] * features.shape[1], size=drop_feat_num, replace=False)\n","        rows = (flat_idx // features.shape[1])\n","        cols = (flat_idx % features.shape[1])\n","        aug_feat2[rows, cols] = 0.0\n","        features_aug2 = aug_feat2.astype(np.float32)\n","\n","        node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, edge_index_aug1, device)\n","        data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","        node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, edge_index_aug2, device)\n","        data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","\n","        S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","        cont_loss = ((l1 + l2) / 2.0).mean()\n","\n","        embeddings = model.online_encoder(data_full)\n","        logits_sup = classifier(embeddings[train_idx_t])\n","        sup_loss = ce_loss(logits_sup, y_tensor[train_idx_t])\n","\n","        unsup_loss = model.loss(A1, logits1)\n","\n","        loss = 0.0001 * cont_loss + sup_loss + unsup_loss\n","\n","        loss.backward()\n","        optimizer.step()\n","        model.update_ma()\n","\n","        if ep % 500 == 0 or ep == 1:\n","            print(f\"Epoch {ep} | Total: {loss.item():.6f} | Cont: {cont_loss.item():.6f} | CE: {sup_loss.item():.6f} | Unsup: {unsup_loss.item():.6f}\")\n","\n","    # --- Eval for this fold ---\n","    model.eval()\n","    classifier.eval()\n","    with torch.no_grad():\n","        embeddings_final = model.online_encoder(data_full)\n","        logits_final = classifier(embeddings_final)\n","        probs = nnF.softmax(logits_final, dim=1).cpu().numpy()\n","        y_pred = np.argmax(probs, axis=1)\n","\n","    y_test = y[test_idx]\n","    y_pred_test = y_pred[test_idx]\n","    # ensure probability vector for class 1 exists\n","    y_proba_test = probs[test_idx, 1] if probs.shape[1] > 1 else probs[test_idx, 0]\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","\n","    # log_loss expects shape (n_samples,) probabilities for binary, or (n_samples, n_classes)\n","    try:\n","        loss_val = log_loss(y_test, y_proba_test)\n","    except Exception:\n","        loss_val = np.nan\n","\n","    try:\n","        auc_score = roc_auc_score(y_test, y_proba_test)\n","    except Exception:\n","        auc_score = np.nan\n","\n","    print(f\"Fold {fold+1} → Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} F1={f1:.4f} AUC={auc_score:.4f}\")\n","\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    losses.append(loss_val)\n","    all_auc.append(auc_score)\n","\n","print(\"\\n=== Average Results ===\")\n","print(f\"Accuracy: {np.nanmean(accuracies):.4f} \\u00B1 {np.nanstd(accuracies):.4f}\")\n","print(f\"Precision: {np.nanmean(precisions):.4f} \\u00B1 {np.nanstd(precisions):.4f}\")\n","print(f\"Recall: {np.nanmean(recalls):.4f} \\u00B1 {np.nanstd(recalls):.4f}\")\n","print(f\"F1: {np.nanmean(f1_scores):.4f} \\u00B1 {np.nanstd(f1_scores):.4f}\")\n","print(f\"LogLoss: {np.nanmean(losses):.4f} \\u00B1 {np.nanstd(losses):.4f}\")\n","print(f\"AUC: {np.nanmean(all_auc):.4f} \\u00B1 {np.nanstd(all_auc):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"unLiGhaXn39r","outputId":"8f849a2b-df79-43ee-bcc3-828ec4631171","executionInfo":{"status":"ok","timestamp":1767674644128,"user_tz":-330,"elapsed":1213333,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Fold 1 ===\n","Epoch 0 | Total: 0.480732 | Cont: 5.514585 | CE: 0.605175 | Unsup: -0.124994\n","Epoch 1 | Total: 0.550768 | Cont: 5.544402 | CE: 0.675187 | Unsup: -0.124973\n","Epoch 500 | Total: -0.116449 | Cont: 5.638959 | CE: 0.007513 | Unsup: -0.124526\n","Epoch 1000 | Total: -0.121685 | Cont: 5.960539 | CE: 0.002851 | Unsup: -0.125132\n","Epoch 1500 | Total: -0.124301 | Cont: 5.954204 | CE: 0.000276 | Unsup: -0.125173\n","Fold 1 → Acc=0.6061 Prec=0.7681 Rec=0.5955 F1=0.6709 AUC=0.7037\n","\n","=== Fold 2 ===\n","Epoch 0 | Total: 0.600324 | Cont: 5.537526 | CE: 0.722499 | Unsup: -0.122728\n","Epoch 1 | Total: 0.551989 | Cont: 5.526889 | CE: 0.675428 | Unsup: -0.123992\n","Epoch 500 | Total: -0.108004 | Cont: 5.669553 | CE: 0.016702 | Unsup: -0.125273\n","Epoch 1000 | Total: -0.107141 | Cont: 5.856269 | CE: 0.017515 | Unsup: -0.125241\n","Epoch 1500 | Total: -0.124118 | Cont: 6.084128 | CE: 0.000274 | Unsup: -0.125001\n","Fold 2 → Acc=0.6667 Prec=0.7273 Rec=0.8090 F1=0.7660 AUC=0.6625\n","\n","=== Fold 3 ===\n","Epoch 0 | Total: 0.529137 | Cont: 5.517751 | CE: 0.653578 | Unsup: -0.124993\n","Epoch 1 | Total: 0.574751 | Cont: 5.517717 | CE: 0.699167 | Unsup: -0.124968\n","Epoch 500 | Total: -0.106040 | Cont: 5.480986 | CE: 0.018690 | Unsup: -0.125278\n","Epoch 1000 | Total: -0.114827 | Cont: 6.014562 | CE: 0.009349 | Unsup: -0.124778\n","Epoch 1500 | Total: -0.124461 | Cont: 5.918409 | CE: 0.000210 | Unsup: -0.125263\n","Fold 3 → Acc=0.7197 Prec=0.7766 Rec=0.8202 F1=0.7978 AUC=0.7923\n","\n","=== Fold 4 ===\n","Epoch 0 | Total: 0.523599 | Cont: 5.555185 | CE: 0.647358 | Unsup: -0.124315\n","Epoch 1 | Total: 0.575418 | Cont: 5.537912 | CE: 0.699412 | Unsup: -0.124548\n","Epoch 500 | Total: -0.117870 | Cont: 5.346709 | CE: 0.006418 | Unsup: -0.124823\n","Epoch 1000 | Total: -0.121631 | Cont: 5.450368 | CE: 0.003110 | Unsup: -0.125286\n","Epoch 1500 | Total: -0.124453 | Cont: 5.735448 | CE: 0.000241 | Unsup: -0.125268\n","Fold 4 → Acc=0.7424 Prec=0.8571 Rec=0.7416 F1=0.7952 AUC=0.8038\n","\n","=== Fold 5 ===\n","Epoch 0 | Total: 0.576154 | Cont: 5.573041 | CE: 0.699367 | Unsup: -0.123770\n","Epoch 1 | Total: 0.629510 | Cont: 5.522966 | CE: 0.753676 | Unsup: -0.124719\n","Epoch 500 | Total: -0.102177 | Cont: 5.658464 | CE: 0.022269 | Unsup: -0.125012\n","Epoch 1000 | Total: -0.123166 | Cont: 5.783889 | CE: 0.001210 | Unsup: -0.124954\n","Epoch 1500 | Total: -0.124237 | Cont: 5.930482 | CE: 0.000164 | Unsup: -0.124994\n","Fold 5 → Acc=0.6970 Prec=0.7952 Rec=0.7416 F1=0.7674 AUC=0.7367\n","\n","=== Fold 6 ===\n","Epoch 0 | Total: 0.602636 | Cont: 5.552810 | CE: 0.721739 | Unsup: -0.119658\n","Epoch 1 | Total: 0.531933 | Cont: 5.549414 | CE: 0.651137 | Unsup: -0.119759\n","Epoch 500 | Total: -0.123347 | Cont: 5.904329 | CE: 0.001375 | Unsup: -0.125312\n","Epoch 1000 | Total: -0.124280 | Cont: 6.151143 | CE: 0.000374 | Unsup: -0.125270\n","Epoch 1500 | Total: -0.124229 | Cont: 6.223834 | CE: 0.000351 | Unsup: -0.125203\n","Fold 6 → Acc=0.7121 Prec=0.8592 Rec=0.6854 F1=0.7625 AUC=0.8226\n","\n","=== Fold 7 ===\n","Epoch 0 | Total: 0.600140 | Cont: 5.506267 | CE: 0.724170 | Unsup: -0.124580\n","Epoch 1 | Total: 0.587149 | Cont: 5.531531 | CE: 0.710671 | Unsup: -0.124075\n","Epoch 500 | Total: -0.110879 | Cont: 5.792621 | CE: 0.013504 | Unsup: -0.124962\n","Epoch 1000 | Total: -0.122702 | Cont: 5.867643 | CE: 0.001911 | Unsup: -0.125200\n","Epoch 1500 | Total: -0.119583 | Cont: 5.717767 | CE: 0.005041 | Unsup: -0.125196\n","Fold 7 → Acc=0.6667 Prec=0.7528 Rec=0.7528 F1=0.7528 AUC=0.7303\n","\n","=== Fold 8 ===\n","Epoch 0 | Total: 0.568344 | Cont: 5.514416 | CE: 0.692271 | Unsup: -0.124479\n","Epoch 1 | Total: 0.538033 | Cont: 5.495897 | CE: 0.662474 | Unsup: -0.124991\n","Epoch 500 | Total: -0.114504 | Cont: 5.653344 | CE: 0.010070 | Unsup: -0.125139\n","Epoch 1000 | Total: -0.104356 | Cont: 6.068311 | CE: 0.020226 | Unsup: -0.125189\n","Epoch 1500 | Total: -0.124270 | Cont: 6.070939 | CE: 0.000324 | Unsup: -0.125200\n","Fold 8 → Acc=0.7045 Prec=0.8049 Rec=0.7416 F1=0.7719 AUC=0.7667\n","\n","=== Fold 9 ===\n","Epoch 0 | Total: 0.563109 | Cont: 5.526776 | CE: 0.678507 | Unsup: -0.115951\n","Epoch 1 | Total: 0.592553 | Cont: 5.520617 | CE: 0.708883 | Unsup: -0.116882\n","Epoch 500 | Total: -0.095019 | Cont: 5.716302 | CE: 0.029739 | Unsup: -0.125329\n","Epoch 1000 | Total: -0.111293 | Cont: 6.128929 | CE: 0.013206 | Unsup: -0.125112\n","Epoch 1500 | Total: -0.123205 | Cont: 6.094960 | CE: 0.001343 | Unsup: -0.125158\n","Fold 9 → Acc=0.7803 Prec=0.9286 Rec=0.7303 F1=0.8176 AUC=0.8832\n","\n","=== Fold 10 ===\n","Epoch 0 | Total: 0.558071 | Cont: 5.610124 | CE: 0.682004 | Unsup: -0.124494\n","Epoch 1 | Total: 0.649398 | Cont: 5.547459 | CE: 0.773195 | Unsup: -0.124351\n","Epoch 500 | Total: -0.123183 | Cont: 5.623776 | CE: 0.001400 | Unsup: -0.125146\n","Epoch 1000 | Total: -0.123202 | Cont: 5.707002 | CE: 0.001285 | Unsup: -0.125058\n","Epoch 1500 | Total: -0.124459 | Cont: 5.917595 | CE: 0.000085 | Unsup: -0.125136\n","Fold 10 → Acc=0.6970 Prec=0.7753 Rec=0.7753 F1=0.7753 AUC=0.7330\n","\n","=== Fold 11 ===\n","Epoch 0 | Total: 0.607880 | Cont: 5.507288 | CE: 0.727101 | Unsup: -0.119772\n","Epoch 1 | Total: 0.540792 | Cont: 5.523994 | CE: 0.659265 | Unsup: -0.119025\n","Epoch 500 | Total: -0.101023 | Cont: 5.607645 | CE: 0.023390 | Unsup: -0.124974\n","Epoch 1000 | Total: -0.122894 | Cont: 5.933531 | CE: 0.001407 | Unsup: -0.124894\n","Epoch 1500 | Total: -0.119092 | Cont: 5.906215 | CE: 0.005275 | Unsup: -0.124958\n","Fold 11 → Acc=0.6212 Prec=0.6970 Rec=0.7753 F1=0.7340 AUC=0.5594\n","\n","=== Fold 12 ===\n","Epoch 0 | Total: 0.681656 | Cont: 5.533033 | CE: 0.805945 | Unsup: -0.124842\n","Epoch 1 | Total: 0.621591 | Cont: 5.545336 | CE: 0.745864 | Unsup: -0.124828\n","Epoch 500 | Total: -0.114735 | Cont: 5.753088 | CE: 0.009915 | Unsup: -0.125226\n","Epoch 1000 | Total: -0.121207 | Cont: 6.081025 | CE: 0.003187 | Unsup: -0.125003\n","Epoch 1500 | Total: -0.122007 | Cont: 5.937670 | CE: 0.002637 | Unsup: -0.125238\n","Fold 12 → Acc=0.6818 Prec=0.8310 Rec=0.6629 F1=0.7375 AUC=0.7865\n","\n","=== Fold 13 ===\n","Epoch 0 | Total: 0.588804 | Cont: 5.499753 | CE: 0.685606 | Unsup: -0.097351\n","Epoch 1 | Total: 0.653345 | Cont: 5.543106 | CE: 0.752993 | Unsup: -0.100202\n","Epoch 500 | Total: -0.119536 | Cont: 5.600369 | CE: 0.004922 | Unsup: -0.125018\n","Epoch 1000 | Total: -0.123229 | Cont: 5.614414 | CE: 0.001373 | Unsup: -0.125164\n","Epoch 1500 | Total: -0.123819 | Cont: 5.813847 | CE: 0.000330 | Unsup: -0.124731\n","Fold 13 → Acc=0.6894 Prec=0.8158 Rec=0.6966 F1=0.7515 AUC=0.7285\n","\n","=== Fold 14 ===\n","Epoch 0 | Total: 0.697601 | Cont: 5.511602 | CE: 0.809917 | Unsup: -0.112867\n","Epoch 1 | Total: 0.573919 | Cont: 5.529068 | CE: 0.686500 | Unsup: -0.113134\n","Epoch 500 | Total: 0.528956 | Cont: 5.547554 | CE: 0.653296 | Unsup: -0.124894\n","Epoch 1000 | Total: 0.476142 | Cont: 5.573360 | CE: 0.600532 | Unsup: -0.124947\n","Epoch 1500 | Total: -0.121805 | Cont: 5.892325 | CE: 0.002600 | Unsup: -0.124995\n","Fold 14 → Acc=0.7803 Prec=0.8409 Rec=0.8315 F1=0.8362 AUC=0.7775\n","\n","=== Fold 15 ===\n","Epoch 0 | Total: 0.524767 | Cont: 5.562084 | CE: 0.648927 | Unsup: -0.124716\n","Epoch 1 | Total: 0.657358 | Cont: 5.526062 | CE: 0.781771 | Unsup: -0.124966\n","Epoch 500 | Total: -0.117992 | Cont: 5.692885 | CE: 0.006338 | Unsup: -0.124899\n","Epoch 1000 | Total: -0.121185 | Cont: 5.788203 | CE: 0.003333 | Unsup: -0.125097\n","Epoch 1500 | Total: -0.124025 | Cont: 6.067001 | CE: 0.000363 | Unsup: -0.124994\n","Fold 15 → Acc=0.6894 Prec=0.7857 Rec=0.7416 F1=0.7630 AUC=0.7600\n","\n","=== Fold 16 ===\n","Epoch 0 | Total: 0.578893 | Cont: 5.587870 | CE: 0.701311 | Unsup: -0.122977\n","Epoch 1 | Total: 0.584389 | Cont: 5.552413 | CE: 0.707994 | Unsup: -0.124160\n","Epoch 500 | Total: -0.115603 | Cont: 5.562084 | CE: 0.008907 | Unsup: -0.125066\n","Epoch 1000 | Total: -0.122609 | Cont: 5.807600 | CE: 0.002079 | Unsup: -0.125269\n","Epoch 1500 | Total: -0.123863 | Cont: 5.939613 | CE: 0.000733 | Unsup: -0.125189\n","Fold 16 → Acc=0.7424 Prec=0.8022 Rec=0.8202 F1=0.8111 AUC=0.8249\n","\n","=== Fold 17 ===\n","Epoch 0 | Total: 0.673792 | Cont: 5.515837 | CE: 0.788994 | Unsup: -0.115754\n","Epoch 1 | Total: 0.560796 | Cont: 5.523305 | CE: 0.675781 | Unsup: -0.115537\n","Epoch 500 | Total: -0.110737 | Cont: 6.030972 | CE: 0.013979 | Unsup: -0.125319\n","Epoch 1000 | Total: -0.122929 | Cont: 5.794808 | CE: 0.001839 | Unsup: -0.125347\n","Epoch 1500 | Total: -0.117541 | Cont: 6.075305 | CE: 0.006748 | Unsup: -0.124897\n","Fold 17 → Acc=0.6818 Prec=0.7831 Rec=0.7303 F1=0.7558 AUC=0.7591\n","\n","=== Fold 18 ===\n","Epoch 0 | Total: 0.584175 | Cont: 5.544443 | CE: 0.705704 | Unsup: -0.122084\n","Epoch 1 | Total: 0.553039 | Cont: 5.605058 | CE: 0.675175 | Unsup: -0.122697\n","Epoch 500 | Total: -0.119271 | Cont: 5.596168 | CE: 0.005419 | Unsup: -0.125250\n","Epoch 1000 | Total: -0.123700 | Cont: 5.463447 | CE: 0.001053 | Unsup: -0.125300\n","Epoch 1500 | Total: -0.123955 | Cont: 5.528819 | CE: 0.000690 | Unsup: -0.125198\n","Fold 18 → Acc=0.7348 Prec=0.8553 Rec=0.7303 F1=0.7879 AUC=0.8343\n","\n","=== Fold 19 ===\n","Epoch 0 | Total: 0.636727 | Cont: 5.557961 | CE: 0.758881 | Unsup: -0.122710\n","Epoch 1 | Total: 0.518315 | Cont: 5.534588 | CE: 0.639227 | Unsup: -0.121465\n","Epoch 500 | Total: -0.080756 | Cont: 6.009585 | CE: 0.043570 | Unsup: -0.124927\n","Epoch 1000 | Total: -0.121309 | Cont: 6.382246 | CE: 0.003098 | Unsup: -0.125045\n","Epoch 1500 | Total: -0.121614 | Cont: 6.515519 | CE: 0.002711 | Unsup: -0.124977\n","Fold 19 → Acc=0.6742 Prec=0.7212 Rec=0.8427 F1=0.7772 AUC=0.7366\n","\n","=== Fold 20 ===\n","Epoch 0 | Total: 0.679566 | Cont: 5.541986 | CE: 0.798059 | Unsup: -0.119047\n","Epoch 1 | Total: 0.599024 | Cont: 5.488851 | CE: 0.720108 | Unsup: -0.121633\n","Epoch 500 | Total: -0.106910 | Cont: 5.636985 | CE: 0.017509 | Unsup: -0.124982\n","Epoch 1000 | Total: -0.124382 | Cont: 5.986263 | CE: 0.000073 | Unsup: -0.125053\n","Epoch 1500 | Total: -0.123936 | Cont: 5.957633 | CE: 0.000280 | Unsup: -0.124812\n","Fold 20 → Acc=0.7727 Prec=0.8315 Rec=0.8315 F1=0.8315 AUC=0.7975\n","\n","=== Average Results ===\n","Accuracy: 0.7030 ± 0.0459\n","Precision: 0.8004 ± 0.0535\n","Recall: 0.7528 ± 0.0617\n","F1: 0.7732 ± 0.0366\n","LogLoss: 1.5295 ± 0.4165\n","AUC: 0.7600 ± 0.0674\n"]}]},{"cell_type":"markdown","source":["=== Average Results ===\n","Accuracy: 0.7969 ± 0.0182\n","Precision: 0.8193 ± 0.0429\n","Recall: 0.8207 ± 0.0527\n","F1: 0.8175 ± 0.0164\n","LogLoss: 1.0717 ± 0.1945\n","AUC: 0.8543 ± 0.0279"],"metadata":{"id":"o_g8ZPRVBFUf"}},{"cell_type":"markdown","source":["=== Average Results ===\n","Accuracy: 0.7854 ± 0.0362\n","Precision: 0.8127 ± 0.0410\n","Recall: 0.8007 ± 0.0568\n","F1: 0.8051 ± 0.0353\n","LogLoss: 1.2815 ± 0.2870\n","AUC: 0.8497 ± 0.0335 wth 512 hid dim"],"metadata":{"id":"v8y6nAEz4jAi"}},{"cell_type":"code","source":["# import os\n","# import nibabel as nib\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","\n","# paths = [\n","#     \"/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/ISBI_ADNI_CN_dataset/Ordered_4d_all_CN/all_55_diff_4d_img_ordered_CN/4d_img_DTI_016_S_6381_M_73_CN.nii.gz\",\n","#     \"/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/ISBI_ADNI_MCI_dataset/Ordered_4d_all_MCI/all_55_diff_4d_img_ordered_MCI/4d_img_DTI_016_S_6926_F_81_MCI.nii.gz\",\n","#     \"/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/ISBI_ADNI_AD_dataset/Ordered_4d_all_AD/all_55_diff_4d_img_ordered_AD/4d_img_DTI_003_S_6264_M_55_AD.nii.gz\"\n","# ]\n","\n","# labels = [\"CN\", \"MCI\", \"AD\"]\n","\n","# # Output directory to save images\n","# output_dir = \"/content/drive/MyDrive/TejaswiAbburi_va797/Dataset/nifti_images\"\n","# os.makedirs(output_dir, exist_ok=True)\n","\n","# plt.figure(figsize=(12, 4))\n","\n","# for i, (path, label) in enumerate(zip(paths, labels)):\n","\n","#     if not os.path.exists(path):\n","#         print(f\"File not found, skipping: {path}\")\n","#         continue\n","\n","#     # Load NIfTI file\n","#     img = nib.load(path)\n","#     data = img.get_fdata()\n","\n","#     # If 4D DTI, take the first volume\n","#     if data.ndim == 4:\n","#         data = data[..., 0]\n","\n","#     # Take middle axial slice\n","#     mid_slice = data.shape[2] // 2\n","#     slice_img = data[:, :, mid_slice].T\n","\n","#     # Plot\n","#     plt.subplot(1, 3, i + 1)\n","#     plt.imshow(slice_img, cmap=\"gray\", origin=\"lower\")\n","#     plt.title(label)\n","#     plt.axis(\"off\")\n","\n","#     # Save image\n","#     save_path = os.path.join(output_dir, f\"{label}_mid_slice.png\")\n","#     plt.imsave(save_path, slice_img, cmap=\"gray\")\n","#     print(f\"Saved: {save_path}\")\n","\n","# plt.tight_layout()\n","# plt.show()\n"],"metadata":{"id":"GDwvc4Fu5o-G","executionInfo":{"status":"ok","timestamp":1767674644130,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["ls /home/snu/Downloads/4d_img_DTI_016_S_6839_F_70_AD_nii.gz\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D68smNOB799U","executionInfo":{"status":"ok","timestamp":1767674644287,"user_tz":-330,"elapsed":156,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"e05c5455-d041-47b9-baa7-55d6a7ab05d0"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access '/home/snu/Downloads/4d_img_DTI_016_S_6839_F_70_AD_nii.gz': No such file or directory\r\n"]}]}]}
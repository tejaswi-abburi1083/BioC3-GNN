{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPZvzxJHwGesxMChOKLU1Gy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":25,"metadata":{"id":"XtuvijZud-Ro","executionInfo":{"status":"ok","timestamp":1767763803203,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import os\n","import copy\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnF\n","import torch.optim as optim\n","from torch_geometric.data import Data\n","from torch_geometric.nn import ARMAConv\n","\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","from torchvision import models\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_auc_score"]},{"cell_type":"code","source":["SEED = 42\n","np.random.seed(SEED)\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"uUGD1KcheGP7","executionInfo":{"status":"ok","timestamp":1767763803253,"user_tz":-330,"elapsed":48,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["data = np.load('/home/snu/Downloads/breastmnist_224.npz', allow_pickle=True)\n","all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","images = all_images.astype(np.float32) / 255.0\n","images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N,3,224,224)\n","X = torch.tensor(images)\n","y = torch.tensor(all_labels).long()\n","print(\"Images, labels shapes:\", X.shape, y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSK5w7fOeIB6","executionInfo":{"status":"ok","timestamp":1767763803625,"user_tz":-330,"elapsed":371,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"78378a72-9f45-42ff-f602-f1328ad7f02c"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Images, labels shapes: torch.Size([780, 3, 224, 224]) torch.Size([780])\n"]}]},{"cell_type":"code","source":["dataset = TensorDataset(X, y)\n","class0_indices = [i for i in range(len(y)) if y[i] == 0]\n","class1_indices = [i for i in range(len(y)) if y[i] == 1]\n","\n","random.seed(SEED)\n","sampled_class0 = random.sample(class0_indices, min(1000, len(class0_indices)))\n","sampled_class1 = random.sample(class1_indices, min(1000, len(class1_indices)))\n","\n","combined_indices = sampled_class0 + sampled_class1\n","random.shuffle(combined_indices)\n","\n","final_dataset = Subset(dataset, combined_indices)\n","final_loader = DataLoader(final_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"Ij_DjWvJeKDr","executionInfo":{"status":"ok","timestamp":1767763803628,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","vit = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n","vit.eval().to(device)\n","\n","vit_feats, y_list = [], []\n","\n","with torch.no_grad():\n","    for imgs, lbls in final_loader:\n","        imgs = imgs.to(device)\n","        feats = vit(imgs)\n","        vit_feats.append(feats.cpu())\n","        y_list.extend(lbls.cpu().tolist())\n","\n","F = torch.cat(vit_feats, dim=0).numpy().astype(np.float32)\n","y = np.array(y_list).astype(np.int64)\n","\n","num_nodes, num_feats = F.shape\n","print(f\"Extracted ViT-DINO Features: {F.shape}, Labels: {y.shape}\")\n","features = F\n","y_labels = y\n","feat_dim = features.shape[1]      # = 768 for ViT-DINO\n","K = len(np.unique(y_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75f7P_w6eOsD","executionInfo":{"status":"ok","timestamp":1767763820099,"user_tz":-330,"elapsed":16470,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"07822166-6992-44b1-d1de-f737f54139cf"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /home/snu/.cache/torch/hub/facebookresearch_dino_main\n"]},{"output_type":"stream","name":"stdout","text":["Extracted ViT-DINO Features: (780, 768), Labels: (780,)\n"]}]},{"cell_type":"code","source":["def create_adj(features, cut, alpha=1.0):\n","    F_norm = features / (np.linalg.norm(features, axis=1, keepdims=True) + 1e-12)\n","    W = np.dot(F_norm, F_norm.T)\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        if W.max() > 0:\n","            W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = (W * (W >= alpha)).astype(np.float32)\n","    return W\n","\n","def edge_index_from_dense(W):\n","    rows, cols = np.nonzero(W > 0)\n","    edge_index = np.vstack([rows, cols]).astype(np.int64)\n","    edge_weight = W[rows, cols].astype(np.float32)\n","    return edge_index, edge_weight\n","\n","def build_adj_list(edge_index_np, num_nodes):\n","    adj = [[] for _ in range(num_nodes)]\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    for s, d in zip(src, dst):\n","        adj[s].append(d)\n","    adj = [np.array(neis, dtype=np.int64) if len(neis) > 0 else np.array([], dtype=np.int64) for neis in adj]\n","    return adj\n","\n","def aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=None):\n","    rng = np.random.default_rng(seed)\n","    E = edge_index_np.shape[1]\n","    keep_mask = rng.random(E) >= drop_percent\n","    new_edge_index = edge_index_np[:, keep_mask]\n","    return new_edge_index\n","\n","def load_data_from_edge_index(node_feats_np, edge_index_np, device):\n","    node_feats = torch.from_numpy(node_feats_np).float()\n","    edge_index = torch.from_numpy(edge_index_np.astype(np.int64)).long()\n","    return node_feats, edge_index"],"metadata":{"id":"_O2R6X3WeSlr","executionInfo":{"status":"ok","timestamp":1767763820102,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def sim(h1, h2, tau=0.2):\n","    z1 = nnF.normalize(h1, dim=-1, p=2)\n","    z2 = nnF.normalize(h2, dim=-1, p=2)\n","    return torch.mm(z1, z2.t()) / tau\n","\n","def contrastive_loss_wo_cross_network(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    intra_sim = f(sim(h1, h1))\n","    inter_sim = f(sim(h1, h2))\n","    return -torch.log(inter_sim.diag() /\n","                     (intra_sim.sum(dim=-1) + inter_sim.sum(dim=-1) - intra_sim.diag() + 1e-12))\n","\n","def contrastive_loss_wo_cross_view(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    cross_sim = f(sim(h1, z))\n","    return -torch.log(cross_sim.diag() / (cross_sim.sum(dim=-1) + 1e-12))"],"metadata":{"id":"dNgFCCgbeWFD","executionInfo":{"status":"ok","timestamp":1767763820169,"user_tz":-330,"elapsed":66,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.PReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class ARMAEncoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device,\n","                 activ=\"RELU\", num_stacks=1, num_layers=1):\n","        super().__init__()\n","\n","        activations = {\n","            \"SELU\": nnF.selu,\n","            \"SiLU\": nnF.silu,\n","            \"GELU\": nnF.gelu,\n","            \"ELU\": nnF.elu,\n","            \"RELU\": nnF.relu\n","        }\n","        self.act = activations.get(activ, nnF.elu)\n","\n","        self.arma = ARMAConv(\n","            in_channels=input_dim,\n","            out_channels=hidden_dim,\n","            num_stacks=num_stacks,\n","            num_layers=num_layers,\n","            act=self.act,\n","            shared_weights=True,\n","            dropout=0.3\n","        )\n","\n","        self.dropout = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x = self.arma(data.x, data.edge_index)\n","        x = self.dropout(x)\n","        return self.mlp(x)\n"],"metadata":{"id":"X3rsj_azeX4D","executionInfo":{"status":"ok","timestamp":1767763820173,"user_tz":-330,"elapsed":2,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["class EMA():\n","    def __init__(self, beta):\n","        self.beta = beta\n","    def update_average(self, old, new):\n","        if old is None:\n","            return new\n","        return old * self.beta + (1 - self.beta) * new\n","\n","def update_moving_average(ema_updater, ma_model, current_model):\n","    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n","        old_weight, up_weight = ma_params.data, current_params.data\n","        ma_params.data = ema_updater.update_average(old_weight, up_weight)"],"metadata":{"id":"9Ob2AJVjeaTb","executionInfo":{"status":"ok","timestamp":1767763820175,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["class ARMA(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ, moving_average_decay=0.99, cut=True):\n","        super(ARMA, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","        self.cut = cut\n","        self.beta = 0.6\n","\n","        self.online_encoder = ARMAEncoder(input_dim, hidden_dim, device, activ)\n","        self.target_encoder = copy.deepcopy(self.online_encoder)\n","        for p in self.target_encoder.parameters():\n","            p.requires_grad = False\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_dim)\n","        self.loss = self.cut_loss if cut else self.modularity_loss\n","        self.target_ema_updater = EMA(moving_average_decay)\n","\n","    def reset_moving_average(self):\n","        del self.target_encoder\n","        self.target_encoder = None\n","\n","    def update_ma(self):\n","        assert self.target_encoder is not None, 'target encoder has not been created yet'\n","        update_moving_average(self.target_ema_updater, self.target_encoder, self.online_encoder)\n","\n","    def forward(self, data1, data2):\n","        x1 = self.online_encoder(data1)\n","        logits1 = self.online_predictor(x1)\n","        S1 = nnF.softmax(logits1, dim=1)\n","        x2 = self.online_encoder(data2)\n","        logits2 = self.online_predictor(x2)\n","        S2 = nnF.softmax(logits2, dim=1)\n","        with torch.no_grad():\n","            target_proj_one = self.target_encoder(data1).detach()\n","            target_proj_two = self.target_encoder(data2).detach()\n","        l1 = self.beta * contrastive_loss_wo_cross_network(x1, x2, target_proj_two) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x1, x2, target_proj_two)\n","        l2 = self.beta * contrastive_loss_wo_cross_network(x2, x1, target_proj_one) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x2, x1, target_proj_one)\n","        return S1, S2, logits1, logits2, l1, l2\n","\n","    def modularity_loss(self, A, S):\n","        C = nnF.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A)\n","        B = A - torch.ger(d, d) / (2 * m + 1e-12)\n","        k = torch.tensor(self.num_clusters, device=self.device, dtype=torch.float32)\n","        n = S.shape[0]\n","        modularity_term = (-1.0 / (2.0 * m + 1e-12)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1.0\n","        return modularity_term + collapse_reg_term\n","\n","    def cut_loss(self, A, S):\n","        S = nnF.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / (den + 1e-12))\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / (torch.norm(St_S) + 1e-12) - I_S / (torch.norm(I_S) + 1e-12))\n","        return mincut_loss + ortho_loss"],"metadata":{"id":"bcmcF_CcedKT","executionInfo":{"status":"ok","timestamp":1767763820229,"user_tz":-330,"elapsed":53,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["alpha = 0.73\n","hidden_dim = 256\n","K = 2\n","num_epochs = 2000\n","\n","W0 = create_adj(features, cut=1, alpha=alpha)\n","edge_index_np, edge_weight_np = edge_index_from_dense(W0)\n","node_feats_all, edge_index_all = load_data_from_edge_index(features, edge_index_np, device)\n","data_full = Data(x=node_feats_all.to(device), edge_index=edge_index_all.to(device))\n","A1 = torch.from_numpy(W0).float().to(device)"],"metadata":{"id":"r80v3qj2efX8","executionInfo":{"status":"ok","timestamp":1767763820232,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["accuracies, precisions, recalls, f1_scores, losses, all_auc = [], [], [], [], [], []\n","\n","sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=SEED)\n","for fold, (train_idx_full, test_idx) in enumerate(sss.split(features, y_labels)):\n","    print(f\"\\n=== Fold {fold+1} ===\")\n","\n","    cn_idx = np.where(y_labels == 0)[0]\n","    mci_idx = np.where(y_labels == 1)[0]\n","    sss_class = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=fold)\n","    cn_train_idx, _ = next(sss_class.split(features[cn_idx], y_labels[cn_idx]))\n","    mci_train_idx, _ = next(sss_class.split(features[mci_idx], y_labels[mci_idx]))\n","    cn_train = cn_idx[cn_train_idx]\n","    mci_train = mci_idx[mci_train_idx]\n","    balanced_train_idx = np.concatenate([cn_train, mci_train])\n","    np.random.shuffle(balanced_train_idx)\n","\n","    train_idx_t = torch.from_numpy(balanced_train_idx).long().to(device)\n","    test_idx_t = torch.from_numpy(test_idx).long().to(device)\n","    y_tensor = torch.from_numpy(y_labels).long().to(device)\n","\n","    model = ARMA(feat_dim, hidden_dim, K, device, activ=\"RELU\", cut=False, moving_average_decay=0.99).to(device)\n","    classifier = nn.Linear(hidden_dim, K).to(device)\n","    optimizer = optim.Adam(list(model.parameters()) + list(classifier.parameters()), lr=1e-4, weight_decay=1e-4)\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","    for ep in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","        edge_index_aug1 = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=ep)\n","        edge_index_aug2 = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=ep+999)\n","        rng = np.random.default_rng(ep)\n","        mask = rng.random(features.shape) >= 0.2\n","        features_aug1 = (features * mask.astype(np.float32))\n","        aug_feat2 = features.copy()\n","        drop_feat_num = int(features.shape[0] * features.shape[1] * 0.2)\n","        flat_idx = rng.choice(features.shape[0] * features.shape[1], size=drop_feat_num, replace=False)\n","        rows = (flat_idx // features.shape[1])\n","        cols = (flat_idx % features.shape[1])\n","        aug_feat2[rows, cols] = 0.0\n","        features_aug2 = aug_feat2.astype(np.float32)\n","        node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, edge_index_aug1, device)\n","        data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","        node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, edge_index_aug2, device)\n","        data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","        S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","        cont_loss = ((l1 + l2) / 2.0).mean()\n","        embeddings = model.online_encoder(data_full)\n","        logits_sup = classifier(embeddings[train_idx_t])\n","        sup_loss = ce_loss(logits_sup, y_tensor[train_idx_t])\n","        unsup_loss = model.loss(A1, logits1)\n","        loss = 0.0001 * cont_loss + sup_loss + unsup_loss\n","        loss.backward()\n","        optimizer.step()\n","        model.update_ma()\n","\n","        if ep % 500 == 0 or ep == 1:\n","            print(f\"Epoch {ep} | Total: {loss.item():.6f} | Cont: {cont_loss.item():.6f} | CE: {sup_loss.item():.6f} | Unsup: {unsup_loss.item():.6f}\")\n","\n","    # --- Eval ---\n","    model.eval()\n","    classifier.eval()\n","    with torch.no_grad():\n","        embeddings_final = model.online_encoder(data_full)\n","        logits_final = classifier(embeddings_final)\n","        probs = nnF.softmax(logits_final, dim=1).cpu().numpy()\n","        y_pred = np.argmax(probs, axis=1)\n","\n","    y_test = y_labels[test_idx]\n","    y_pred_test = y_pred[test_idx]\n","    y_proba_test = probs[test_idx, 1] if probs.shape[1] > 1 else probs[test_idx, 0]\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","    try:\n","        loss_val = log_loss(y_test, y_proba_test)\n","    except:\n","        loss_val = np.nan\n","    try:\n","        auc_score = roc_auc_score(y_test, y_proba_test)\n","    except:\n","        auc_score = np.nan\n","\n","    print(f\"Fold {fold+1} → Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} F1={f1:.4f} AUC={auc_score:.4f}\")\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    losses.append(loss_val)\n","    all_auc.append(auc_score)\n","\n","print(\"\\n=== Average Results ===\")\n","print(f\"Accuracy: {np.nanmean(accuracies):.4f} ± {np.nanstd(accuracies):.4f}\")\n","print(f\"Precision: {np.nanmean(precisions):.4f} ± {np.nanstd(precisions):.4f}\")\n","print(f\"Recall: {np.nanmean(recalls):.4f} ± {np.nanstd(recalls):.4f}\")\n","print(f\"F1: {np.nanmean(f1_scores):.4f} ± {np.nanstd(f1_scores):.4f}\")\n","print(f\"LogLoss: {np.nanmean(losses):.4f} ± {np.nanstd(losses):.4f}\")\n","print(f\"AUC: {np.nanmean(all_auc):.4f} ± {np.nanstd(all_auc):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59D1R49oehVd","executionInfo":{"status":"ok","timestamp":1767769368199,"user_tz":-330,"elapsed":5547965,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"758007b4-c9ee-4b83-e836-e11e1b9abe9f"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Fold 1 ===\n","Epoch 0 | Total: 0.653618 | Cont: 6.797913 | CE: 0.776840 | Unsup: -0.123902\n","Epoch 1 | Total: 0.663202 | Cont: 6.799214 | CE: 0.786730 | Unsup: -0.124208\n","Epoch 500 | Total: -0.140272 | Cont: 6.309523 | CE: 0.035215 | Unsup: -0.176118\n","Epoch 1000 | Total: -0.161757 | Cont: 6.192934 | CE: 0.016130 | Unsup: -0.178506\n","Epoch 1500 | Total: -0.163096 | Cont: 6.161389 | CE: 0.015847 | Unsup: -0.179559\n","Fold 1 → Acc=0.8561 Prec=0.8902 Rec=0.9162 F1=0.9030 AUC=0.8880\n","\n","=== Fold 2 ===\n","Epoch 0 | Total: 1.142727 | Cont: 6.834289 | CE: 1.267231 | Unsup: -0.125187\n","Epoch 1 | Total: 0.795409 | Cont: 6.826859 | CE: 0.920210 | Unsup: -0.125484\n","Epoch 500 | Total: -0.167587 | Cont: 6.374746 | CE: 0.007771 | Unsup: -0.175996\n","Epoch 1000 | Total: -0.177545 | Cont: 6.225940 | CE: 0.000779 | Unsup: -0.178946\n","Epoch 1500 | Total: -0.178514 | Cont: 6.145736 | CE: 0.000542 | Unsup: -0.179670\n","Fold 2 → Acc=0.8419 Prec=0.8880 Rec=0.8967 F1=0.8923 AUC=0.8402\n","\n","=== Fold 3 ===\n","Epoch 0 | Total: 0.535297 | Cont: 6.797527 | CE: 0.659127 | Unsup: -0.124509\n","Epoch 1 | Total: 0.462402 | Cont: 6.794439 | CE: 0.586476 | Unsup: -0.124754\n","Epoch 500 | Total: -0.166376 | Cont: 6.282639 | CE: 0.007045 | Unsup: -0.174050\n","Epoch 1000 | Total: -0.176151 | Cont: 6.177284 | CE: 0.000194 | Unsup: -0.176963\n","Epoch 1500 | Total: -0.176710 | Cont: 6.090560 | CE: 0.000737 | Unsup: -0.178055\n","Fold 3 → Acc=0.8689 Prec=0.8766 Rec=0.9552 F1=0.9142 AUC=0.9126\n","\n","=== Fold 4 ===\n","Epoch 0 | Total: 0.663330 | Cont: 6.821498 | CE: 0.784413 | Unsup: -0.121765\n","Epoch 1 | Total: 0.567031 | Cont: 6.806022 | CE: 0.687789 | Unsup: -0.121438\n","Epoch 500 | Total: -0.172028 | Cont: 6.334858 | CE: 0.002597 | Unsup: -0.175258\n","Epoch 1000 | Total: -0.172234 | Cont: 6.186074 | CE: 0.005017 | Unsup: -0.177870\n","Epoch 1500 | Total: -0.172594 | Cont: 6.154709 | CE: 0.006402 | Unsup: -0.179611\n","Fold 4 → Acc=0.8333 Prec=0.8680 Rec=0.9103 F1=0.8887 AUC=0.8602\n","\n","=== Fold 5 ===\n","Epoch 0 | Total: 0.753774 | Cont: 6.791738 | CE: 0.878189 | Unsup: -0.125094\n","Epoch 1 | Total: 0.655748 | Cont: 6.807748 | CE: 0.780196 | Unsup: -0.125129\n","Epoch 500 | Total: -0.172229 | Cont: 6.374131 | CE: 0.003124 | Unsup: -0.175990\n","Epoch 1000 | Total: -0.161912 | Cont: 6.222323 | CE: 0.015748 | Unsup: -0.178282\n","Epoch 1500 | Total: -0.172087 | Cont: 6.136244 | CE: 0.006256 | Unsup: -0.178957\n","Fold 5 → Acc=0.8519 Prec=0.8645 Rec=0.9454 F1=0.9032 AUC=0.9220\n","\n","=== Fold 6 ===\n","Epoch 0 | Total: 1.077247 | Cont: 6.815105 | CE: 1.195575 | Unsup: -0.119009\n","Epoch 1 | Total: 0.619123 | Cont: 6.816786 | CE: 0.737785 | Unsup: -0.119343\n","Epoch 500 | Total: -0.150785 | Cont: 6.355734 | CE: 0.022660 | Unsup: -0.174080\n","Epoch 1000 | Total: -0.176203 | Cont: 6.221723 | CE: 0.001000 | Unsup: -0.177825\n","Epoch 1500 | Total: -0.177643 | Cont: 6.093420 | CE: 0.000509 | Unsup: -0.178761\n","Fold 6 → Acc=0.8590 Prec=0.8966 Rec=0.9123 F1=0.9043 AUC=0.8821\n","\n","=== Fold 7 ===\n","Epoch 0 | Total: 0.836039 | Cont: 6.795343 | CE: 0.959683 | Unsup: -0.124323\n","Epoch 1 | Total: 0.663293 | Cont: 6.797803 | CE: 0.786637 | Unsup: -0.124024\n","Epoch 500 | Total: -0.173928 | Cont: 6.250696 | CE: 0.001509 | Unsup: -0.176063\n","Epoch 1000 | Total: -0.177672 | Cont: 6.132611 | CE: 0.000836 | Unsup: -0.179122\n","Epoch 1500 | Total: -0.179487 | Cont: 6.042950 | CE: 0.000239 | Unsup: -0.180331\n","Fold 7 → Acc=0.8675 Prec=0.9150 Rec=0.9025 F1=0.9087 AUC=0.9157\n","\n","=== Fold 8 ===\n","Epoch 0 | Total: 0.699771 | Cont: 6.804547 | CE: 0.822248 | Unsup: -0.123158\n","Epoch 1 | Total: 0.602781 | Cont: 6.807535 | CE: 0.725328 | Unsup: -0.123228\n","Epoch 500 | Total: -0.158831 | Cont: 6.296388 | CE: 0.014833 | Unsup: -0.174293\n","Epoch 1000 | Total: -0.174663 | Cont: 6.200957 | CE: 0.000772 | Unsup: -0.176055\n","Epoch 1500 | Total: -0.173313 | Cont: 6.131601 | CE: 0.002857 | Unsup: -0.176783\n","Fold 8 → Acc=0.8661 Prec=0.8990 Rec=0.9201 F1=0.9094 AUC=0.9102\n","\n","=== Fold 9 ===\n","Epoch 0 | Total: 0.679327 | Cont: 6.805427 | CE: 0.803384 | Unsup: -0.124738\n","Epoch 1 | Total: 0.770406 | Cont: 6.802920 | CE: 0.894714 | Unsup: -0.124988\n","Epoch 500 | Total: -0.173776 | Cont: 6.250283 | CE: 0.001782 | Unsup: -0.176183\n","Epoch 1000 | Total: -0.177425 | Cont: 6.113343 | CE: 0.000673 | Unsup: -0.178709\n","Epoch 1500 | Total: -0.178878 | Cont: 6.037807 | CE: 0.000400 | Unsup: -0.179881\n","Fold 9 → Acc=0.8348 Prec=0.9179 Rec=0.8499 F1=0.8826 AUC=0.8940\n","\n","=== Fold 10 ===\n","Epoch 0 | Total: 0.711913 | Cont: 6.827199 | CE: 0.805285 | Unsup: -0.094054\n","Epoch 1 | Total: 0.546482 | Cont: 6.830465 | CE: 0.642810 | Unsup: -0.097012\n","Epoch 500 | Total: -0.171261 | Cont: 6.292409 | CE: 0.000757 | Unsup: -0.172647\n","Epoch 1000 | Total: -0.175971 | Cont: 6.119120 | CE: 0.000114 | Unsup: -0.176697\n","Epoch 1500 | Total: -0.171674 | Cont: 6.033673 | CE: 0.005572 | Unsup: -0.177849\n","Fold 10 → Acc=0.8618 Prec=0.9047 Rec=0.9064 F1=0.9056 AUC=0.9009\n","\n","=== Fold 11 ===\n","Epoch 0 | Total: 0.515315 | Cont: 6.813720 | CE: 0.638630 | Unsup: -0.123997\n","Epoch 1 | Total: 0.506823 | Cont: 6.821298 | CE: 0.630607 | Unsup: -0.124466\n","Epoch 500 | Total: -0.167143 | Cont: 6.301255 | CE: 0.005562 | Unsup: -0.173335\n","Epoch 1000 | Total: -0.173254 | Cont: 6.127789 | CE: 0.002430 | Unsup: -0.176297\n","Epoch 1500 | Total: -0.176434 | Cont: 6.072587 | CE: 0.000123 | Unsup: -0.177164\n","Fold 11 → Acc=0.8533 Prec=0.8927 Rec=0.9084 F1=0.9005 AUC=0.8992\n","\n","=== Fold 12 ===\n","Epoch 0 | Total: 0.649613 | Cont: 6.835864 | CE: 0.772409 | Unsup: -0.123479\n","Epoch 1 | Total: 0.612620 | Cont: 6.853677 | CE: 0.735913 | Unsup: -0.123978\n","Epoch 500 | Total: -0.155202 | Cont: 6.302762 | CE: 0.020186 | Unsup: -0.176018\n","Epoch 1000 | Total: -0.166467 | Cont: 6.142560 | CE: 0.011333 | Unsup: -0.178415\n","Epoch 1500 | Total: -0.177029 | Cont: 6.062343 | CE: 0.001971 | Unsup: -0.179606\n","Fold 12 → Acc=0.8234 Prec=0.9027 Rec=0.8499 F1=0.8755 AUC=0.8783\n","\n","=== Fold 13 ===\n","Epoch 0 | Total: 0.744111 | Cont: 6.796682 | CE: 0.861271 | Unsup: -0.117840\n","Epoch 1 | Total: 0.411376 | Cont: 6.808293 | CE: 0.528188 | Unsup: -0.117493\n","Epoch 500 | Total: -0.127581 | Cont: 6.345265 | CE: 0.045755 | Unsup: -0.173970\n","Epoch 1000 | Total: -0.156972 | Cont: 6.181408 | CE: 0.019771 | Unsup: -0.177362\n","Epoch 1500 | Total: -0.151820 | Cont: 6.126801 | CE: 0.026322 | Unsup: -0.178754\n","Fold 13 → Acc=0.8590 Prec=0.8750 Rec=0.9415 F1=0.9070 AUC=0.9050\n","\n","=== Fold 14 ===\n","Epoch 0 | Total: 0.595224 | Cont: 6.790024 | CE: 0.719714 | Unsup: -0.125168\n","Epoch 1 | Total: 0.481903 | Cont: 6.810467 | CE: 0.606604 | Unsup: -0.125382\n","Epoch 500 | Total: -0.168922 | Cont: 6.352788 | CE: 0.005652 | Unsup: -0.175210\n","Epoch 1000 | Total: -0.175499 | Cont: 6.207004 | CE: 0.002166 | Unsup: -0.178286\n","Epoch 1500 | Total: -0.177805 | Cont: 6.143677 | CE: 0.000936 | Unsup: -0.179355\n","Fold 14 → Acc=0.8561 Prec=0.8931 Rec=0.9123 F1=0.9026 AUC=0.9117\n","\n","=== Fold 15 ===\n","Epoch 0 | Total: 0.754755 | Cont: 6.800292 | CE: 0.875792 | Unsup: -0.121717\n","Epoch 1 | Total: 0.632001 | Cont: 6.810151 | CE: 0.754131 | Unsup: -0.122812\n","Epoch 500 | Total: -0.170827 | Cont: 6.361256 | CE: 0.003876 | Unsup: -0.175339\n","Epoch 1000 | Total: -0.176616 | Cont: 6.228381 | CE: 0.000317 | Unsup: -0.177556\n","Epoch 1500 | Total: -0.177637 | Cont: 6.168942 | CE: 0.000351 | Unsup: -0.178605\n","Fold 15 → Acc=0.8704 Prec=0.8893 Rec=0.9396 F1=0.9137 AUC=0.8889\n","\n","=== Fold 16 ===\n","Epoch 0 | Total: 0.588320 | Cont: 6.817274 | CE: 0.705019 | Unsup: -0.117381\n","Epoch 1 | Total: 0.605934 | Cont: 6.810430 | CE: 0.723996 | Unsup: -0.118744\n","Epoch 500 | Total: -0.165086 | Cont: 6.248672 | CE: 0.007568 | Unsup: -0.173279\n","Epoch 1000 | Total: -0.173772 | Cont: 6.156287 | CE: 0.001685 | Unsup: -0.176072\n","Epoch 1500 | Total: -0.176351 | Cont: 6.030491 | CE: 0.000144 | Unsup: -0.177098\n","Fold 16 → Acc=0.8718 Prec=0.9013 Rec=0.9259 F1=0.9135 AUC=0.8851\n","\n","=== Fold 17 ===\n","Epoch 0 | Total: 0.662446 | Cont: 6.819027 | CE: 0.771574 | Unsup: -0.109810\n","Epoch 1 | Total: 0.505243 | Cont: 6.819108 | CE: 0.615249 | Unsup: -0.110688\n","Epoch 500 | Total: -0.163465 | Cont: 6.361930 | CE: 0.010328 | Unsup: -0.174430\n","Epoch 1000 | Total: -0.174666 | Cont: 6.184714 | CE: 0.000743 | Unsup: -0.176027\n","Epoch 1500 | Total: -0.176946 | Cont: 6.189710 | CE: 0.000318 | Unsup: -0.177882\n","Fold 17 → Acc=0.8362 Prec=0.8579 Rec=0.9298 F1=0.8924 AUC=0.8710\n","\n","=== Fold 18 ===\n","Epoch 0 | Total: 0.633020 | Cont: 6.830111 | CE: 0.753500 | Unsup: -0.121163\n","Epoch 1 | Total: 0.727619 | Cont: 6.839018 | CE: 0.849183 | Unsup: -0.122248\n","Epoch 500 | Total: -0.171970 | Cont: 6.287751 | CE: 0.002323 | Unsup: -0.174922\n","Epoch 1000 | Total: -0.174940 | Cont: 6.159767 | CE: 0.002403 | Unsup: -0.177959\n","Epoch 1500 | Total: -0.178348 | Cont: 6.093680 | CE: 0.000147 | Unsup: -0.179104\n","Fold 18 → Acc=0.8575 Prec=0.8918 Rec=0.9162 F1=0.9038 AUC=0.8878\n","\n","=== Fold 19 ===\n","Epoch 0 | Total: 1.060745 | Cont: 6.772168 | CE: 1.177095 | Unsup: -0.117028\n","Epoch 1 | Total: 0.655778 | Cont: 6.790833 | CE: 0.772402 | Unsup: -0.117304\n","Epoch 500 | Total: -0.148773 | Cont: 6.342963 | CE: 0.024193 | Unsup: -0.173600\n","Epoch 1000 | Total: -0.173517 | Cont: 6.189645 | CE: 0.002369 | Unsup: -0.176505\n","Epoch 1500 | Total: -0.175509 | Cont: 6.148563 | CE: 0.001165 | Unsup: -0.177288\n","Fold 19 → Acc=0.8775 Prec=0.9146 Rec=0.9181 F1=0.9163 AUC=0.9229\n","\n","=== Fold 20 ===\n","Epoch 0 | Total: 1.106812 | Cont: 6.790688 | CE: 1.231149 | Unsup: -0.125016\n","Epoch 1 | Total: 0.684387 | Cont: 6.791119 | CE: 0.808923 | Unsup: -0.125215\n","Epoch 500 | Total: -0.168461 | Cont: 6.298408 | CE: 0.006004 | Unsup: -0.175095\n","Epoch 1000 | Total: -0.177239 | Cont: 6.130729 | CE: 0.001096 | Unsup: -0.178949\n","Epoch 1500 | Total: -0.178299 | Cont: 6.083660 | CE: 0.001046 | Unsup: -0.179954\n","Fold 20 → Acc=0.8903 Prec=0.9007 Rec=0.9552 F1=0.9272 AUC=0.9031\n","\n","=== Average Results ===\n","Accuracy: 0.8568 ± 0.0161\n","Precision: 0.8920 ± 0.0162\n","Recall: 0.9156 ± 0.0273\n","F1: 0.9032 ± 0.0119\n","LogLoss: 0.9151 ± 0.1608\n","AUC: 0.8939 ± 0.0205\n"]}]}]}
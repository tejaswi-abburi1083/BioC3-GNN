{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QWTM7sVHQGBucEggx5FV0wOvu9VSaDA0","timestamp":1761729169561}],"gpuType":"T4","authorship_tag":"ABX9TyMB7YxOzKttHCnefahk9+Nq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# !pip install -q torch_geometric\n","# !pip install -q class_resolver\n","# !pip3 install pymatting"],"metadata":{"id":"tkAZVXPzQhkS","executionInfo":{"status":"ok","timestamp":1767721089028,"user_tz":-330,"elapsed":10,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"Sy2LhdAWj_l8","executionInfo":{"status":"ok","timestamp":1767721089038,"user_tz":-330,"elapsed":8,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["!pip install -q torch_geometric\n","!pip install -q class_resolver\n","!pip3 install pymatting"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I41ztqsOkVN9","executionInfo":{"status":"ok","timestamp":1767721090353,"user_tz":-330,"elapsed":1314,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"165f7db8-7c21-4000-ccbe-e648aebdf12d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pymatting in ./.local/lib/python3.10/site-packages (1.1.14)\r\n"]}]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ZhoWIduU0285","executionInfo":{"status":"ok","timestamp":1767721090401,"user_tz":-330,"elapsed":38,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnFn\n","import torch.optim as optim\n","import numpy as np\n","import random\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from torch_geometric.data import Data\n","from torch_geometric.nn import ChebConv\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score,\n","    f1_score, roc_auc_score, log_loss\n",")\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","from torch_geometric.data import Data\n","from torch_geometric.nn import ARMAConv"]},{"cell_type":"code","source":["data = np.load('/home/snu/Downloads/breastmnist_224.npz', allow_pickle=True)\n","all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","# Convert to 3-channel RGB\n","images = all_images.astype(np.float32) / 255.0\n","images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N, 3, 224, 224)\n","X_torch = torch.tensor(images)\n","y_torch = torch.tensor(all_labels).long()\n","print(f\"Raw images: {X_torch.shape}, Labels: {y_torch.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgv5wIW403rR","executionInfo":{"status":"ok","timestamp":1767721090801,"user_tz":-330,"elapsed":398,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"113aa4bc-55bf-4881-a452-d6c854e44b5b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Raw images: torch.Size([780, 3, 224, 224]), Labels: torch.Size([780])\n"]}]},{"cell_type":"code","source":["class0_idx = [i for i in range(len(y_torch)) if y_torch[i] == 0]\n","class1_idx = [i for i in range(len(y_torch)) if y_torch[i] == 1]\n","\n","random.seed(42)\n","sampled_class0 = random.sample(class0_idx, min(1000, len(class0_idx)))\n","sampled_class1 = random.sample(class1_idx, min(1000, len(class1_idx)))\n","\n","selected_indices = sampled_class0 + sampled_class1\n","random.shuffle(selected_indices)\n","\n","subset_dataset = Subset(TensorDataset(X_torch, y_torch), selected_indices)\n","subset_loader = DataLoader(subset_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"RravF_31Ppdw","executionInfo":{"status":"ok","timestamp":1767721090803,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","vit = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n","vit.eval().to(device)\n","\n","vit_feats, y_list = [], []\n","\n","with torch.no_grad():\n","    for imgs, lbls in subset_loader:\n","        imgs = imgs.to(device)\n","        feats = vit(imgs)\n","        vit_feats.append(feats.cpu())\n","        y_list.extend(lbls.cpu().tolist())\n","\n","F = torch.cat(vit_feats, dim=0).numpy().astype(np.float32)\n","y = np.array(y_list).astype(np.int64)\n","\n","num_nodes, num_feats = F.shape\n","print(f\"Extracted ViT-DINO Features: {F.shape}, Labels: {y.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zhfaxAc3PrBv","executionInfo":{"status":"ok","timestamp":1767721095475,"user_tz":-330,"elapsed":4670,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"81a559c9-c74a-4f3e-ee03-0bf33d9d87b0"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /home/snu/.cache/torch/hub/facebookresearch_dino_main\n"]},{"output_type":"stream","name":"stdout","text":["Extracted ViT-DINO Features: (780, 768), Labels: (780,)\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as nnFn\n","from torch_geometric.nn import GATConv\n","\n","class GAT_Supervised(nn.Module):\n","    def __init__(\n","        self,\n","        input_dim,\n","        hidden_dim,\n","        output_dim,\n","        heads=2,\n","        activ=\"RELU\",\n","        dropout=0.2\n","    ):\n","        super(GAT_Supervised, self).__init__()\n","\n","        # -------- GAT layers --------\n","        self.gat1 = GATConv(\n","            input_dim, hidden_dim, heads=heads, concat=True, dropout=dropout\n","        )\n","        self.bn1 = nn.BatchNorm1d(hidden_dim * heads)\n","\n","        self.gat2 = GATConv(\n","            hidden_dim * heads, hidden_dim, heads=heads, concat=True, dropout=dropout\n","        )\n","        self.bn2 = nn.BatchNorm1d(hidden_dim * heads)\n","\n","        self.gat3 = GATConv(\n","            hidden_dim * heads, hidden_dim, heads=1, concat=False, dropout=dropout\n","        )\n","        self.bn3 = nn.BatchNorm1d(hidden_dim)\n","\n","        # -------- Classifier --------\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","        activations = {\n","            \"SELU\": nnFn.selu,\n","            \"SiLU\": nnFn.silu,\n","            \"GELU\": nnFn.gelu,\n","            \"RELU\": nnFn.relu,\n","            \"ELU\": nnFn.elu\n","        }\n","        self.act = activations.get(activ, nnFn.elu)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","\n","        x = self.gat1(x, edge_index)\n","        x = self.bn1(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","\n","        x = self.gat2(x, edge_index)\n","        x = self.bn2(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","\n","        x = self.gat3(x, edge_index)\n","        x = self.bn3(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","\n","        logits = self.fc(x)\n","        return logits\n"],"metadata":{"id":"bdbHMxznPMMz","executionInfo":{"status":"ok","timestamp":1767721095483,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def create_adj(F, alpha=1):\n","    F_norm = F / np.linalg.norm(F, axis=1, keepdims=True)\n","    W = np.dot(F_norm, F_norm.T)\n","    W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","    W = W / W.max()\n","    return W\n","\n","def load_data(adj, node_feats):\n","    node_feats = torch.from_numpy(node_feats).float()\n","    edge_index = torch.from_numpy(np.array(np.nonzero((adj > 0))))\n","    return Data(x=node_feats, edge_index=edge_index)"],"metadata":{"id":"8AUYk2fh0_iR","executionInfo":{"status":"ok","timestamp":1767721095549,"user_tz":-330,"elapsed":64,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","alpha = 0.73\n","feats_dim = num_feats\n","hidden_dim = 256\n","num_classes = 2\n","num_epochs = 2000\n","lr = 0.0001\n","weight_decay = 1e-4\n","batch_print_freq = 100"],"metadata":{"id":"5xD2P7ic1B65","executionInfo":{"status":"ok","timestamp":1767721095554,"user_tz":-330,"elapsed":3,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["W = create_adj(F, alpha)\n","data = load_data(W, F).to(device)\n","print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-mfsholh1Erx","executionInfo":{"status":"ok","timestamp":1767721095610,"user_tz":-330,"elapsed":53,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"cc4e3d72-012e-4493-deb0-5ca91be9661e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Data(x=[780, 768], edge_index=[2, 266936])\n"]}]},{"cell_type":"code","source":["sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=42)\n","\n","accuracies, precisions, recalls, f1_scores, aucs, ce_losses = [], [], [], [], [], []\n","\n","for fold, (train_idx, test_idx) in enumerate(sss.split(F, y), start=1):\n","    print(f\"\\n=== Fold {fold} ===\")\n","\n","    train_idx_t = torch.from_numpy(train_idx).long().to(device)\n","    y_train_tensor = torch.from_numpy(y[train_idx]).long().to(device)\n","\n","\n","    model = GAT_Supervised(feats_dim, hidden_dim, num_classes).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","    for epoch in range(1, num_epochs + 1):\n","        model.train()\n","        optimizer.zero_grad()\n","\n","        logits = model(data)\n","        loss = ce_loss(logits[train_idx_t], y_train_tensor)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        if epoch % batch_print_freq == 0 or epoch == 1:\n","            model.eval()\n","            with torch.no_grad():\n","                preds_train = logits[train_idx_t].argmax(dim=1)\n","                acc_train = accuracy_score(y_train_tensor.cpu(), preds_train.cpu())\n","            print(f\"Fold {fold} Epoch {epoch}: Loss={loss.item():.6f} | TrainAcc={acc_train:.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        out = model(data)\n","        preds = out.argmax(dim=1).cpu().numpy()\n","        probs = torch.softmax(out, dim=1)[:, 1].cpu().numpy()\n","\n","    y_test = y[test_idx]\n","    y_pred_test = preds[test_idx]\n","    y_pred_test = preds[test_idx]\n","    y_prob_test = probs[test_idx]\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","    auc = roc_auc_score(y_test, y_prob_test)\n","    ce = log_loss(y_test, y_prob_test)\n","\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    aucs.append(auc)\n","    ce_losses.append(ce)\n","\n","    print(f\"Fold {fold} → \"\n","          f\"Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | \"\n","          f\"F1={f1:.4f} | AUC={auc:.4f} | CE Loss={ce:.4f}\")\n","\n","\n","# Final summary\n","print(\"\\n=== Average Results Across 20 Folds ===\")\n","print(f\"Accuracy:  {np.mean(accuracies):.4f} \\u00b1 {np.std(accuracies):.4f}\")\n","print(f\"Precision: {np.mean(precisions):.4f} \\u00b1 {np.std(precisions):.4f}\")\n","print(f\"Recall:    {np.mean(recalls):.4f} \\u00b1 {np.std(recalls):.4f}\")\n","print(f\"F1-score:  {np.mean(f1_scores):.4f} \\u00b1 {np.std(f1_scores):.4f}\")\n","print(f\"AUC:       {np.mean(aucs):.4f} \\u00b1 {np.std(aucs):.4f}\")\n","print(f\"CE Loss:   {np.mean(ce_losses):.4f} \\u00b1 {np.std(ce_losses):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6IoqsZcNK3qI","executionInfo":{"status":"ok","timestamp":1767727980968,"user_tz":-330,"elapsed":6885357,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"9f1ee679-d5f5-48cf-a06b-09aa8b79c344"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Fold 1 ===\n","Fold 1 Epoch 1: Loss=0.626082 | TrainAcc=0.7692\n","Fold 1 Epoch 100: Loss=0.167052 | TrainAcc=0.9487\n","Fold 1 Epoch 200: Loss=0.062563 | TrainAcc=0.9872\n","Fold 1 Epoch 300: Loss=0.016779 | TrainAcc=1.0000\n","Fold 1 Epoch 400: Loss=0.042161 | TrainAcc=0.9744\n","Fold 1 Epoch 500: Loss=0.071083 | TrainAcc=0.9872\n","Fold 1 Epoch 600: Loss=0.004109 | TrainAcc=1.0000\n","Fold 1 Epoch 700: Loss=0.010926 | TrainAcc=1.0000\n","Fold 1 Epoch 800: Loss=0.058513 | TrainAcc=0.9872\n","Fold 1 Epoch 900: Loss=0.002918 | TrainAcc=1.0000\n","Fold 1 Epoch 1000: Loss=0.003132 | TrainAcc=1.0000\n","Fold 1 Epoch 1100: Loss=0.013536 | TrainAcc=0.9872\n","Fold 1 Epoch 1200: Loss=0.030433 | TrainAcc=0.9872\n","Fold 1 Epoch 1300: Loss=0.002206 | TrainAcc=1.0000\n","Fold 1 Epoch 1400: Loss=0.011803 | TrainAcc=0.9872\n","Fold 1 Epoch 1500: Loss=0.001421 | TrainAcc=1.0000\n","Fold 1 Epoch 1600: Loss=0.004438 | TrainAcc=1.0000\n","Fold 1 Epoch 1700: Loss=0.000712 | TrainAcc=1.0000\n","Fold 1 Epoch 1800: Loss=0.003468 | TrainAcc=1.0000\n","Fold 1 Epoch 1900: Loss=0.037473 | TrainAcc=0.9872\n","Fold 1 Epoch 2000: Loss=0.010828 | TrainAcc=1.0000\n","Fold 1 → Acc=0.7821 | Prec=0.8093 | Rec=0.9181 | F1=0.8603 | AUC=0.7556 | CE Loss=1.5845\n","\n","=== Fold 2 ===\n","Fold 2 Epoch 1: Loss=0.657696 | TrainAcc=0.7051\n","Fold 2 Epoch 100: Loss=0.117571 | TrainAcc=0.9615\n","Fold 2 Epoch 200: Loss=0.025336 | TrainAcc=1.0000\n","Fold 2 Epoch 300: Loss=0.015433 | TrainAcc=1.0000\n","Fold 2 Epoch 400: Loss=0.034726 | TrainAcc=0.9872\n","Fold 2 Epoch 500: Loss=0.009808 | TrainAcc=1.0000\n","Fold 2 Epoch 600: Loss=0.006912 | TrainAcc=1.0000\n","Fold 2 Epoch 700: Loss=0.002901 | TrainAcc=1.0000\n","Fold 2 Epoch 800: Loss=0.003737 | TrainAcc=1.0000\n","Fold 2 Epoch 900: Loss=0.004078 | TrainAcc=1.0000\n","Fold 2 Epoch 1000: Loss=0.001545 | TrainAcc=1.0000\n","Fold 2 Epoch 1100: Loss=0.008555 | TrainAcc=1.0000\n","Fold 2 Epoch 1200: Loss=0.002511 | TrainAcc=1.0000\n","Fold 2 Epoch 1300: Loss=0.002778 | TrainAcc=1.0000\n","Fold 2 Epoch 1400: Loss=0.001940 | TrainAcc=1.0000\n","Fold 2 Epoch 1500: Loss=0.004212 | TrainAcc=1.0000\n","Fold 2 Epoch 1600: Loss=0.004463 | TrainAcc=1.0000\n","Fold 2 Epoch 1700: Loss=0.004226 | TrainAcc=1.0000\n","Fold 2 Epoch 1800: Loss=0.002144 | TrainAcc=1.0000\n","Fold 2 Epoch 1900: Loss=0.002833 | TrainAcc=1.0000\n","Fold 2 Epoch 2000: Loss=0.000717 | TrainAcc=1.0000\n","Fold 2 → Acc=0.8020 | Prec=0.8596 | Rec=0.8713 | F1=0.8654 | AUC=0.8282 | CE Loss=1.0664\n","\n","=== Fold 3 ===\n","Fold 3 Epoch 1: Loss=0.691717 | TrainAcc=0.6410\n","Fold 3 Epoch 100: Loss=0.224675 | TrainAcc=0.9103\n","Fold 3 Epoch 200: Loss=0.169995 | TrainAcc=0.9744\n","Fold 3 Epoch 300: Loss=0.164121 | TrainAcc=0.9359\n","Fold 3 Epoch 400: Loss=0.100072 | TrainAcc=0.9872\n","Fold 3 Epoch 500: Loss=0.105321 | TrainAcc=0.9615\n","Fold 3 Epoch 600: Loss=0.055680 | TrainAcc=0.9872\n","Fold 3 Epoch 700: Loss=0.035234 | TrainAcc=0.9872\n","Fold 3 Epoch 800: Loss=0.027796 | TrainAcc=1.0000\n","Fold 3 Epoch 900: Loss=0.031389 | TrainAcc=0.9872\n","Fold 3 Epoch 1000: Loss=0.015218 | TrainAcc=1.0000\n","Fold 3 Epoch 1100: Loss=0.014495 | TrainAcc=1.0000\n","Fold 3 Epoch 1200: Loss=0.015861 | TrainAcc=0.9872\n","Fold 3 Epoch 1300: Loss=0.016607 | TrainAcc=1.0000\n","Fold 3 Epoch 1400: Loss=0.006919 | TrainAcc=1.0000\n","Fold 3 Epoch 1500: Loss=0.006919 | TrainAcc=1.0000\n","Fold 3 Epoch 1600: Loss=0.013711 | TrainAcc=1.0000\n","Fold 3 Epoch 1700: Loss=0.002517 | TrainAcc=1.0000\n","Fold 3 Epoch 1800: Loss=0.016844 | TrainAcc=0.9872\n","Fold 3 Epoch 1900: Loss=0.009786 | TrainAcc=1.0000\n","Fold 3 Epoch 2000: Loss=0.003468 | TrainAcc=1.0000\n","Fold 3 → Acc=0.6396 | Prec=0.8963 | Rec=0.5731 | F1=0.6992 | AUC=0.7712 | CE Loss=2.1887\n","\n","=== Fold 4 ===\n","Fold 4 Epoch 1: Loss=0.889707 | TrainAcc=0.4103\n","Fold 4 Epoch 100: Loss=0.399416 | TrainAcc=0.8333\n","Fold 4 Epoch 200: Loss=0.145737 | TrainAcc=0.9615\n","Fold 4 Epoch 300: Loss=0.087740 | TrainAcc=0.9744\n","Fold 4 Epoch 400: Loss=0.017132 | TrainAcc=1.0000\n","Fold 4 Epoch 500: Loss=0.025753 | TrainAcc=0.9872\n","Fold 4 Epoch 600: Loss=0.052690 | TrainAcc=0.9872\n","Fold 4 Epoch 700: Loss=0.015763 | TrainAcc=1.0000\n","Fold 4 Epoch 800: Loss=0.004840 | TrainAcc=1.0000\n","Fold 4 Epoch 900: Loss=0.012338 | TrainAcc=1.0000\n","Fold 4 Epoch 1000: Loss=0.004075 | TrainAcc=1.0000\n","Fold 4 Epoch 1100: Loss=0.003352 | TrainAcc=1.0000\n","Fold 4 Epoch 1200: Loss=0.002428 | TrainAcc=1.0000\n","Fold 4 Epoch 1300: Loss=0.008204 | TrainAcc=1.0000\n","Fold 4 Epoch 1400: Loss=0.007672 | TrainAcc=1.0000\n","Fold 4 Epoch 1500: Loss=0.044893 | TrainAcc=0.9872\n","Fold 4 Epoch 1600: Loss=0.001320 | TrainAcc=1.0000\n","Fold 4 Epoch 1700: Loss=0.045867 | TrainAcc=0.9744\n","Fold 4 Epoch 1800: Loss=0.002629 | TrainAcc=1.0000\n","Fold 4 Epoch 1900: Loss=0.027387 | TrainAcc=0.9872\n","Fold 4 Epoch 2000: Loss=0.002931 | TrainAcc=1.0000\n","Fold 4 → Acc=0.7080 | Prec=0.8775 | Rec=0.6979 | F1=0.7774 | AUC=0.8019 | CE Loss=1.3660\n","\n","=== Fold 5 ===\n","Fold 5 Epoch 1: Loss=0.721647 | TrainAcc=0.5897\n","Fold 5 Epoch 100: Loss=0.144059 | TrainAcc=0.9744\n","Fold 5 Epoch 200: Loss=0.070508 | TrainAcc=0.9872\n","Fold 5 Epoch 300: Loss=0.049398 | TrainAcc=0.9872\n","Fold 5 Epoch 400: Loss=0.038506 | TrainAcc=0.9872\n","Fold 5 Epoch 500: Loss=0.014066 | TrainAcc=1.0000\n","Fold 5 Epoch 600: Loss=0.028693 | TrainAcc=1.0000\n","Fold 5 Epoch 700: Loss=0.008927 | TrainAcc=1.0000\n","Fold 5 Epoch 800: Loss=0.005844 | TrainAcc=1.0000\n","Fold 5 Epoch 900: Loss=0.005861 | TrainAcc=1.0000\n","Fold 5 Epoch 1000: Loss=0.007518 | TrainAcc=1.0000\n","Fold 5 Epoch 1100: Loss=0.001846 | TrainAcc=1.0000\n","Fold 5 Epoch 1200: Loss=0.001202 | TrainAcc=1.0000\n","Fold 5 Epoch 1300: Loss=0.004890 | TrainAcc=1.0000\n","Fold 5 Epoch 1400: Loss=0.009148 | TrainAcc=1.0000\n","Fold 5 Epoch 1500: Loss=0.013197 | TrainAcc=1.0000\n","Fold 5 Epoch 1600: Loss=0.062734 | TrainAcc=0.9872\n","Fold 5 Epoch 1700: Loss=0.012493 | TrainAcc=1.0000\n","Fold 5 Epoch 1800: Loss=0.005837 | TrainAcc=1.0000\n","Fold 5 Epoch 1900: Loss=0.003709 | TrainAcc=1.0000\n","Fold 5 Epoch 2000: Loss=0.002902 | TrainAcc=1.0000\n","Fold 5 → Acc=0.7792 | Prec=0.8303 | Rec=0.8772 | F1=0.8531 | AUC=0.7790 | CE Loss=1.3832\n","\n","=== Fold 6 ===\n","Fold 6 Epoch 1: Loss=0.785128 | TrainAcc=0.3205\n","Fold 6 Epoch 100: Loss=0.242666 | TrainAcc=0.8974\n","Fold 6 Epoch 200: Loss=0.148710 | TrainAcc=0.9487\n","Fold 6 Epoch 300: Loss=0.081462 | TrainAcc=0.9872\n","Fold 6 Epoch 400: Loss=0.065233 | TrainAcc=0.9872\n","Fold 6 Epoch 500: Loss=0.052067 | TrainAcc=0.9872\n","Fold 6 Epoch 600: Loss=0.053597 | TrainAcc=0.9744\n","Fold 6 Epoch 700: Loss=0.057667 | TrainAcc=0.9744\n","Fold 6 Epoch 800: Loss=0.039101 | TrainAcc=0.9872\n","Fold 6 Epoch 900: Loss=0.026273 | TrainAcc=0.9872\n","Fold 6 Epoch 1000: Loss=0.022789 | TrainAcc=0.9872\n","Fold 6 Epoch 1100: Loss=0.020922 | TrainAcc=1.0000\n","Fold 6 Epoch 1200: Loss=0.008824 | TrainAcc=1.0000\n","Fold 6 Epoch 1300: Loss=0.015372 | TrainAcc=0.9872\n","Fold 6 Epoch 1400: Loss=0.007788 | TrainAcc=1.0000\n","Fold 6 Epoch 1500: Loss=0.005541 | TrainAcc=1.0000\n","Fold 6 Epoch 1600: Loss=0.006691 | TrainAcc=1.0000\n","Fold 6 Epoch 1700: Loss=0.004853 | TrainAcc=1.0000\n","Fold 6 Epoch 1800: Loss=0.001934 | TrainAcc=1.0000\n","Fold 6 Epoch 1900: Loss=0.002117 | TrainAcc=1.0000\n","Fold 6 Epoch 2000: Loss=0.000982 | TrainAcc=1.0000\n","Fold 6 → Acc=0.7507 | Prec=0.8492 | Rec=0.8012 | F1=0.8245 | AUC=0.8096 | CE Loss=1.4301\n","\n","=== Fold 7 ===\n","Fold 7 Epoch 1: Loss=0.641248 | TrainAcc=0.6795\n","Fold 7 Epoch 100: Loss=0.329206 | TrainAcc=0.8590\n","Fold 7 Epoch 200: Loss=0.142982 | TrainAcc=0.9487\n","Fold 7 Epoch 300: Loss=0.055443 | TrainAcc=0.9872\n","Fold 7 Epoch 400: Loss=0.008823 | TrainAcc=1.0000\n","Fold 7 Epoch 500: Loss=0.005708 | TrainAcc=1.0000\n","Fold 7 Epoch 600: Loss=0.007742 | TrainAcc=1.0000\n","Fold 7 Epoch 700: Loss=0.005032 | TrainAcc=1.0000\n","Fold 7 Epoch 800: Loss=0.004112 | TrainAcc=1.0000\n","Fold 7 Epoch 900: Loss=0.002760 | TrainAcc=1.0000\n","Fold 7 Epoch 1000: Loss=0.002610 | TrainAcc=1.0000\n","Fold 7 Epoch 1100: Loss=0.015965 | TrainAcc=1.0000\n","Fold 7 Epoch 1200: Loss=0.006411 | TrainAcc=1.0000\n","Fold 7 Epoch 1300: Loss=0.073749 | TrainAcc=0.9872\n","Fold 7 Epoch 1400: Loss=0.002322 | TrainAcc=1.0000\n","Fold 7 Epoch 1500: Loss=0.002976 | TrainAcc=1.0000\n","Fold 7 Epoch 1600: Loss=0.000735 | TrainAcc=1.0000\n","Fold 7 Epoch 1700: Loss=0.000676 | TrainAcc=1.0000\n","Fold 7 Epoch 1800: Loss=0.001071 | TrainAcc=1.0000\n","Fold 7 Epoch 1900: Loss=0.001841 | TrainAcc=1.0000\n","Fold 7 Epoch 2000: Loss=0.001725 | TrainAcc=1.0000\n","Fold 7 → Acc=0.6553 | Prec=0.8974 | Rec=0.5965 | F1=0.7166 | AUC=0.7945 | CE Loss=1.9874\n","\n","=== Fold 8 ===\n","Fold 8 Epoch 1: Loss=0.685134 | TrainAcc=0.6410\n","Fold 8 Epoch 100: Loss=0.314104 | TrainAcc=0.8333\n","Fold 8 Epoch 200: Loss=0.187471 | TrainAcc=0.9231\n","Fold 8 Epoch 300: Loss=0.136126 | TrainAcc=0.9487\n","Fold 8 Epoch 400: Loss=0.102417 | TrainAcc=0.9744\n","Fold 8 Epoch 500: Loss=0.090151 | TrainAcc=0.9615\n","Fold 8 Epoch 600: Loss=0.045324 | TrainAcc=1.0000\n","Fold 8 Epoch 700: Loss=0.041155 | TrainAcc=1.0000\n","Fold 8 Epoch 800: Loss=0.030558 | TrainAcc=1.0000\n","Fold 8 Epoch 900: Loss=0.041076 | TrainAcc=0.9872\n","Fold 8 Epoch 1000: Loss=0.018370 | TrainAcc=1.0000\n","Fold 8 Epoch 1100: Loss=0.016241 | TrainAcc=1.0000\n","Fold 8 Epoch 1200: Loss=0.014928 | TrainAcc=1.0000\n","Fold 8 Epoch 1300: Loss=0.013259 | TrainAcc=1.0000\n","Fold 8 Epoch 1400: Loss=0.005148 | TrainAcc=1.0000\n","Fold 8 Epoch 1500: Loss=0.007232 | TrainAcc=1.0000\n","Fold 8 Epoch 1600: Loss=0.007060 | TrainAcc=1.0000\n","Fold 8 Epoch 1700: Loss=0.004662 | TrainAcc=1.0000\n","Fold 8 Epoch 1800: Loss=0.001592 | TrainAcc=1.0000\n","Fold 8 Epoch 1900: Loss=0.003288 | TrainAcc=1.0000\n","Fold 8 Epoch 2000: Loss=0.003322 | TrainAcc=1.0000\n","Fold 8 → Acc=0.7949 | Prec=0.8653 | Rec=0.8519 | F1=0.8585 | AUC=0.8412 | CE Loss=0.7317\n","\n","=== Fold 9 ===\n","Fold 9 Epoch 1: Loss=0.647978 | TrainAcc=0.7051\n","Fold 9 Epoch 100: Loss=0.227768 | TrainAcc=0.8974\n","Fold 9 Epoch 200: Loss=0.130849 | TrainAcc=0.9744\n","Fold 9 Epoch 300: Loss=0.079417 | TrainAcc=0.9744\n","Fold 9 Epoch 400: Loss=0.053062 | TrainAcc=0.9744\n","Fold 9 Epoch 500: Loss=0.017062 | TrainAcc=1.0000\n","Fold 9 Epoch 600: Loss=0.026481 | TrainAcc=1.0000\n","Fold 9 Epoch 700: Loss=0.028876 | TrainAcc=0.9872\n","Fold 9 Epoch 800: Loss=0.007793 | TrainAcc=1.0000\n","Fold 9 Epoch 900: Loss=0.021947 | TrainAcc=0.9872\n","Fold 9 Epoch 1000: Loss=0.002048 | TrainAcc=1.0000\n","Fold 9 Epoch 1100: Loss=0.004585 | TrainAcc=1.0000\n","Fold 9 Epoch 1200: Loss=0.015275 | TrainAcc=1.0000\n","Fold 9 Epoch 1300: Loss=0.010613 | TrainAcc=1.0000\n","Fold 9 Epoch 1400: Loss=0.015891 | TrainAcc=0.9872\n","Fold 9 Epoch 1500: Loss=0.004735 | TrainAcc=1.0000\n","Fold 9 Epoch 1600: Loss=0.002313 | TrainAcc=1.0000\n","Fold 9 Epoch 1700: Loss=0.000897 | TrainAcc=1.0000\n","Fold 9 Epoch 1800: Loss=0.002694 | TrainAcc=1.0000\n","Fold 9 Epoch 1900: Loss=0.001620 | TrainAcc=1.0000\n","Fold 9 Epoch 2000: Loss=0.003624 | TrainAcc=1.0000\n","Fold 9 → Acc=0.7920 | Prec=0.8404 | Rec=0.8830 | F1=0.8612 | AUC=0.7948 | CE Loss=1.0464\n","\n","=== Fold 10 ===\n","Fold 10 Epoch 1: Loss=0.860083 | TrainAcc=0.6154\n","Fold 10 Epoch 100: Loss=0.409801 | TrainAcc=0.7692\n","Fold 10 Epoch 200: Loss=0.197144 | TrainAcc=0.8974\n","Fold 10 Epoch 300: Loss=0.107899 | TrainAcc=0.9744\n","Fold 10 Epoch 400: Loss=0.095648 | TrainAcc=0.9744\n","Fold 10 Epoch 500: Loss=0.040327 | TrainAcc=0.9872\n","Fold 10 Epoch 600: Loss=0.027076 | TrainAcc=0.9872\n","Fold 10 Epoch 700: Loss=0.007086 | TrainAcc=1.0000\n","Fold 10 Epoch 800: Loss=0.012566 | TrainAcc=1.0000\n","Fold 10 Epoch 900: Loss=0.010461 | TrainAcc=1.0000\n","Fold 10 Epoch 1000: Loss=0.006069 | TrainAcc=1.0000\n","Fold 10 Epoch 1100: Loss=0.005958 | TrainAcc=1.0000\n","Fold 10 Epoch 1200: Loss=0.003108 | TrainAcc=1.0000\n","Fold 10 Epoch 1300: Loss=0.005233 | TrainAcc=1.0000\n","Fold 10 Epoch 1400: Loss=0.059847 | TrainAcc=0.9872\n","Fold 10 Epoch 1500: Loss=0.072643 | TrainAcc=0.9744\n","Fold 10 Epoch 1600: Loss=0.056247 | TrainAcc=0.9872\n","Fold 10 Epoch 1700: Loss=0.023466 | TrainAcc=1.0000\n","Fold 10 Epoch 1800: Loss=0.038289 | TrainAcc=0.9872\n","Fold 10 Epoch 1900: Loss=0.036545 | TrainAcc=0.9872\n","Fold 10 Epoch 2000: Loss=0.010368 | TrainAcc=1.0000\n","Fold 10 → Acc=0.6738 | Prec=0.8989 | Rec=0.6238 | F1=0.7365 | AUC=0.8124 | CE Loss=1.4182\n","\n","=== Fold 11 ===\n","Fold 11 Epoch 1: Loss=0.693803 | TrainAcc=0.5000\n","Fold 11 Epoch 100: Loss=0.111102 | TrainAcc=0.9744\n","Fold 11 Epoch 200: Loss=0.059919 | TrainAcc=0.9744\n","Fold 11 Epoch 300: Loss=0.028267 | TrainAcc=1.0000\n","Fold 11 Epoch 400: Loss=0.056818 | TrainAcc=0.9744\n","Fold 11 Epoch 500: Loss=0.023381 | TrainAcc=1.0000\n","Fold 11 Epoch 600: Loss=0.020709 | TrainAcc=1.0000\n","Fold 11 Epoch 700: Loss=0.011740 | TrainAcc=1.0000\n","Fold 11 Epoch 800: Loss=0.015999 | TrainAcc=1.0000\n","Fold 11 Epoch 900: Loss=0.017526 | TrainAcc=1.0000\n","Fold 11 Epoch 1000: Loss=0.008757 | TrainAcc=1.0000\n","Fold 11 Epoch 1100: Loss=0.016644 | TrainAcc=0.9872\n","Fold 11 Epoch 1200: Loss=0.004754 | TrainAcc=1.0000\n","Fold 11 Epoch 1300: Loss=0.058642 | TrainAcc=0.9872\n","Fold 11 Epoch 1400: Loss=0.085366 | TrainAcc=0.9744\n","Fold 11 Epoch 1500: Loss=0.008087 | TrainAcc=1.0000\n","Fold 11 Epoch 1600: Loss=0.002980 | TrainAcc=1.0000\n","Fold 11 Epoch 1700: Loss=0.005254 | TrainAcc=1.0000\n","Fold 11 Epoch 1800: Loss=0.002275 | TrainAcc=1.0000\n","Fold 11 Epoch 1900: Loss=0.008554 | TrainAcc=1.0000\n","Fold 11 Epoch 2000: Loss=0.003572 | TrainAcc=1.0000\n","Fold 11 → Acc=0.7607 | Prec=0.8363 | Rec=0.8363 | F1=0.8363 | AUC=0.7480 | CE Loss=1.3036\n","\n","=== Fold 12 ===\n","Fold 12 Epoch 1: Loss=0.723733 | TrainAcc=0.3333\n","Fold 12 Epoch 100: Loss=0.224441 | TrainAcc=0.9615\n","Fold 12 Epoch 200: Loss=0.186220 | TrainAcc=0.9103\n","Fold 12 Epoch 300: Loss=0.163776 | TrainAcc=0.9487\n","Fold 12 Epoch 400: Loss=0.074232 | TrainAcc=0.9615\n","Fold 12 Epoch 500: Loss=0.056720 | TrainAcc=0.9872\n","Fold 12 Epoch 600: Loss=0.091457 | TrainAcc=0.9615\n","Fold 12 Epoch 700: Loss=0.053269 | TrainAcc=0.9872\n","Fold 12 Epoch 800: Loss=0.042760 | TrainAcc=0.9872\n","Fold 12 Epoch 900: Loss=0.023241 | TrainAcc=0.9872\n","Fold 12 Epoch 1000: Loss=0.005691 | TrainAcc=1.0000\n","Fold 12 Epoch 1100: Loss=0.008190 | TrainAcc=1.0000\n","Fold 12 Epoch 1200: Loss=0.009307 | TrainAcc=1.0000\n","Fold 12 Epoch 1300: Loss=0.030345 | TrainAcc=0.9872\n","Fold 12 Epoch 1400: Loss=0.060725 | TrainAcc=0.9872\n","Fold 12 Epoch 1500: Loss=0.016908 | TrainAcc=0.9872\n","Fold 12 Epoch 1600: Loss=0.004300 | TrainAcc=1.0000\n","Fold 12 Epoch 1700: Loss=0.001743 | TrainAcc=1.0000\n","Fold 12 Epoch 1800: Loss=0.002152 | TrainAcc=1.0000\n","Fold 12 Epoch 1900: Loss=0.004513 | TrainAcc=1.0000\n","Fold 12 Epoch 2000: Loss=0.016569 | TrainAcc=0.9872\n","Fold 12 → Acc=0.7422 | Prec=0.8578 | Rec=0.7758 | F1=0.8147 | AUC=0.8036 | CE Loss=1.4579\n","\n","=== Fold 13 ===\n","Fold 13 Epoch 1: Loss=0.740795 | TrainAcc=0.5000\n","Fold 13 Epoch 100: Loss=0.329427 | TrainAcc=0.8462\n","Fold 13 Epoch 200: Loss=0.140344 | TrainAcc=0.9615\n","Fold 13 Epoch 300: Loss=0.108155 | TrainAcc=0.9487\n","Fold 13 Epoch 400: Loss=0.107412 | TrainAcc=0.9615\n","Fold 13 Epoch 500: Loss=0.067399 | TrainAcc=0.9744\n","Fold 13 Epoch 600: Loss=0.032324 | TrainAcc=0.9872\n","Fold 13 Epoch 700: Loss=0.018227 | TrainAcc=1.0000\n","Fold 13 Epoch 800: Loss=0.017302 | TrainAcc=1.0000\n","Fold 13 Epoch 900: Loss=0.012527 | TrainAcc=1.0000\n","Fold 13 Epoch 1000: Loss=0.009647 | TrainAcc=1.0000\n","Fold 13 Epoch 1100: Loss=0.017229 | TrainAcc=1.0000\n","Fold 13 Epoch 1200: Loss=0.015707 | TrainAcc=1.0000\n","Fold 13 Epoch 1300: Loss=0.017546 | TrainAcc=0.9872\n","Fold 13 Epoch 1400: Loss=0.005014 | TrainAcc=1.0000\n","Fold 13 Epoch 1500: Loss=0.006613 | TrainAcc=1.0000\n","Fold 13 Epoch 1600: Loss=0.004632 | TrainAcc=1.0000\n","Fold 13 Epoch 1700: Loss=0.003871 | TrainAcc=1.0000\n","Fold 13 Epoch 1800: Loss=0.006707 | TrainAcc=1.0000\n","Fold 13 Epoch 1900: Loss=0.066592 | TrainAcc=0.9872\n","Fold 13 Epoch 2000: Loss=0.001972 | TrainAcc=1.0000\n","Fold 13 → Acc=0.7322 | Prec=0.8480 | Rec=0.7719 | F1=0.8082 | AUC=0.7582 | CE Loss=1.7480\n","\n","=== Fold 14 ===\n","Fold 14 Epoch 1: Loss=0.722388 | TrainAcc=0.5385\n","Fold 14 Epoch 100: Loss=0.277837 | TrainAcc=0.8974\n","Fold 14 Epoch 200: Loss=0.223238 | TrainAcc=0.8974\n","Fold 14 Epoch 300: Loss=0.027015 | TrainAcc=1.0000\n","Fold 14 Epoch 400: Loss=0.041197 | TrainAcc=0.9872\n","Fold 14 Epoch 500: Loss=0.063994 | TrainAcc=0.9744\n","Fold 14 Epoch 600: Loss=0.019154 | TrainAcc=0.9872\n","Fold 14 Epoch 700: Loss=0.007102 | TrainAcc=1.0000\n","Fold 14 Epoch 800: Loss=0.033796 | TrainAcc=0.9872\n","Fold 14 Epoch 900: Loss=0.003318 | TrainAcc=1.0000\n","Fold 14 Epoch 1000: Loss=0.003287 | TrainAcc=1.0000\n","Fold 14 Epoch 1100: Loss=0.003426 | TrainAcc=1.0000\n","Fold 14 Epoch 1200: Loss=0.003967 | TrainAcc=1.0000\n","Fold 14 Epoch 1300: Loss=0.001939 | TrainAcc=1.0000\n","Fold 14 Epoch 1400: Loss=0.002137 | TrainAcc=1.0000\n","Fold 14 Epoch 1500: Loss=0.003834 | TrainAcc=1.0000\n","Fold 14 Epoch 1600: Loss=0.001177 | TrainAcc=1.0000\n","Fold 14 Epoch 1700: Loss=0.001008 | TrainAcc=1.0000\n","Fold 14 Epoch 1800: Loss=0.002150 | TrainAcc=1.0000\n","Fold 14 Epoch 1900: Loss=0.001092 | TrainAcc=1.0000\n","Fold 14 Epoch 2000: Loss=0.001293 | TrainAcc=1.0000\n","Fold 14 → Acc=0.7721 | Prec=0.8250 | Rec=0.8733 | F1=0.8485 | AUC=0.7759 | CE Loss=1.2518\n","\n","=== Fold 15 ===\n","Fold 15 Epoch 1: Loss=0.688465 | TrainAcc=0.6282\n","Fold 15 Epoch 100: Loss=0.226309 | TrainAcc=0.9359\n","Fold 15 Epoch 200: Loss=0.117081 | TrainAcc=0.9615\n","Fold 15 Epoch 300: Loss=0.054290 | TrainAcc=0.9744\n","Fold 15 Epoch 400: Loss=0.062420 | TrainAcc=0.9744\n","Fold 15 Epoch 500: Loss=0.098033 | TrainAcc=0.9872\n","Fold 15 Epoch 600: Loss=0.114291 | TrainAcc=0.9615\n","Fold 15 Epoch 700: Loss=0.062998 | TrainAcc=0.9872\n","Fold 15 Epoch 800: Loss=0.010165 | TrainAcc=1.0000\n","Fold 15 Epoch 900: Loss=0.021994 | TrainAcc=1.0000\n","Fold 15 Epoch 1000: Loss=0.062096 | TrainAcc=0.9872\n","Fold 15 Epoch 1100: Loss=0.021149 | TrainAcc=0.9872\n","Fold 15 Epoch 1200: Loss=0.037968 | TrainAcc=0.9872\n","Fold 15 Epoch 1300: Loss=0.005241 | TrainAcc=1.0000\n","Fold 15 Epoch 1400: Loss=0.038246 | TrainAcc=0.9872\n","Fold 15 Epoch 1500: Loss=0.002924 | TrainAcc=1.0000\n","Fold 15 Epoch 1600: Loss=0.005919 | TrainAcc=1.0000\n","Fold 15 Epoch 1700: Loss=0.001388 | TrainAcc=1.0000\n","Fold 15 Epoch 1800: Loss=0.001524 | TrainAcc=1.0000\n","Fold 15 Epoch 1900: Loss=0.000777 | TrainAcc=1.0000\n","Fold 15 Epoch 2000: Loss=0.063020 | TrainAcc=0.9872\n","Fold 15 → Acc=0.6254 | Prec=0.9032 | Rec=0.5458 | F1=0.6804 | AUC=0.8099 | CE Loss=2.9147\n","\n","=== Fold 16 ===\n","Fold 16 Epoch 1: Loss=0.697047 | TrainAcc=0.6923\n","Fold 16 Epoch 100: Loss=0.168310 | TrainAcc=0.8974\n","Fold 16 Epoch 200: Loss=0.090445 | TrainAcc=0.9872\n","Fold 16 Epoch 300: Loss=0.021015 | TrainAcc=1.0000\n","Fold 16 Epoch 400: Loss=0.015951 | TrainAcc=1.0000\n","Fold 16 Epoch 500: Loss=0.006133 | TrainAcc=1.0000\n","Fold 16 Epoch 600: Loss=0.009612 | TrainAcc=1.0000\n","Fold 16 Epoch 700: Loss=0.010801 | TrainAcc=1.0000\n","Fold 16 Epoch 800: Loss=0.005691 | TrainAcc=1.0000\n","Fold 16 Epoch 900: Loss=0.008274 | TrainAcc=1.0000\n","Fold 16 Epoch 1000: Loss=0.004391 | TrainAcc=1.0000\n","Fold 16 Epoch 1100: Loss=0.004381 | TrainAcc=1.0000\n","Fold 16 Epoch 1200: Loss=0.003606 | TrainAcc=1.0000\n","Fold 16 Epoch 1300: Loss=0.001380 | TrainAcc=1.0000\n","Fold 16 Epoch 1400: Loss=0.000819 | TrainAcc=1.0000\n","Fold 16 Epoch 1500: Loss=0.008453 | TrainAcc=1.0000\n","Fold 16 Epoch 1600: Loss=0.000853 | TrainAcc=1.0000\n","Fold 16 Epoch 1700: Loss=0.000569 | TrainAcc=1.0000\n","Fold 16 Epoch 1800: Loss=0.004603 | TrainAcc=1.0000\n","Fold 16 Epoch 1900: Loss=0.004712 | TrainAcc=1.0000\n","Fold 16 Epoch 2000: Loss=0.003469 | TrainAcc=1.0000\n","Fold 16 → Acc=0.7778 | Prec=0.8083 | Rec=0.9123 | F1=0.8571 | AUC=0.7670 | CE Loss=1.0544\n","\n","=== Fold 17 ===\n","Fold 17 Epoch 1: Loss=0.680376 | TrainAcc=0.4231\n","Fold 17 Epoch 100: Loss=0.090548 | TrainAcc=0.9872\n","Fold 17 Epoch 200: Loss=0.022328 | TrainAcc=1.0000\n","Fold 17 Epoch 300: Loss=0.015214 | TrainAcc=1.0000\n","Fold 17 Epoch 400: Loss=0.004052 | TrainAcc=1.0000\n","Fold 17 Epoch 500: Loss=0.013284 | TrainAcc=1.0000\n","Fold 17 Epoch 600: Loss=0.002509 | TrainAcc=1.0000\n","Fold 17 Epoch 700: Loss=0.002345 | TrainAcc=1.0000\n","Fold 17 Epoch 800: Loss=0.003471 | TrainAcc=1.0000\n","Fold 17 Epoch 900: Loss=0.002074 | TrainAcc=1.0000\n","Fold 17 Epoch 1000: Loss=0.001335 | TrainAcc=1.0000\n","Fold 17 Epoch 1100: Loss=0.035876 | TrainAcc=0.9872\n","Fold 17 Epoch 1200: Loss=0.002243 | TrainAcc=1.0000\n","Fold 17 Epoch 1300: Loss=0.001353 | TrainAcc=1.0000\n","Fold 17 Epoch 1400: Loss=0.151762 | TrainAcc=0.9487\n","Fold 17 Epoch 1500: Loss=0.042300 | TrainAcc=0.9872\n","Fold 17 Epoch 1600: Loss=0.012447 | TrainAcc=1.0000\n","Fold 17 Epoch 1700: Loss=0.106269 | TrainAcc=0.9615\n","Fold 17 Epoch 1800: Loss=0.003623 | TrainAcc=1.0000\n","Fold 17 Epoch 1900: Loss=0.003207 | TrainAcc=1.0000\n","Fold 17 Epoch 2000: Loss=0.002300 | TrainAcc=1.0000\n","Fold 17 → Acc=0.7949 | Prec=0.8528 | Rec=0.8694 | F1=0.8610 | AUC=0.8014 | CE Loss=1.1729\n","\n","=== Fold 18 ===\n","Fold 18 Epoch 1: Loss=0.766261 | TrainAcc=0.6410\n","Fold 18 Epoch 100: Loss=0.175631 | TrainAcc=0.9231\n","Fold 18 Epoch 200: Loss=0.081145 | TrainAcc=0.9744\n","Fold 18 Epoch 300: Loss=0.065727 | TrainAcc=0.9872\n","Fold 18 Epoch 400: Loss=0.013182 | TrainAcc=1.0000\n","Fold 18 Epoch 500: Loss=0.031952 | TrainAcc=0.9872\n","Fold 18 Epoch 600: Loss=0.008550 | TrainAcc=1.0000\n","Fold 18 Epoch 700: Loss=0.025483 | TrainAcc=0.9872\n","Fold 18 Epoch 800: Loss=0.009396 | TrainAcc=1.0000\n","Fold 18 Epoch 900: Loss=0.011120 | TrainAcc=1.0000\n","Fold 18 Epoch 1000: Loss=0.007144 | TrainAcc=1.0000\n","Fold 18 Epoch 1100: Loss=0.003919 | TrainAcc=1.0000\n","Fold 18 Epoch 1200: Loss=0.002276 | TrainAcc=1.0000\n","Fold 18 Epoch 1300: Loss=0.002339 | TrainAcc=1.0000\n","Fold 18 Epoch 1400: Loss=0.016892 | TrainAcc=0.9872\n","Fold 18 Epoch 1500: Loss=0.003229 | TrainAcc=1.0000\n","Fold 18 Epoch 1600: Loss=0.016005 | TrainAcc=1.0000\n","Fold 18 Epoch 1700: Loss=0.007416 | TrainAcc=1.0000\n","Fold 18 Epoch 1800: Loss=0.001476 | TrainAcc=1.0000\n","Fold 18 Epoch 1900: Loss=0.002207 | TrainAcc=1.0000\n","Fold 18 Epoch 2000: Loss=0.003735 | TrainAcc=1.0000\n","Fold 18 → Acc=0.7664 | Prec=0.8554 | Rec=0.8187 | F1=0.8367 | AUC=0.7552 | CE Loss=1.3999\n","\n","=== Fold 19 ===\n","Fold 19 Epoch 1: Loss=0.786130 | TrainAcc=0.2564\n","Fold 19 Epoch 100: Loss=0.410705 | TrainAcc=0.8205\n","Fold 19 Epoch 200: Loss=0.207033 | TrainAcc=0.9231\n","Fold 19 Epoch 300: Loss=0.146352 | TrainAcc=0.9487\n","Fold 19 Epoch 400: Loss=0.066644 | TrainAcc=0.9872\n","Fold 19 Epoch 500: Loss=0.046681 | TrainAcc=0.9872\n","Fold 19 Epoch 600: Loss=0.077378 | TrainAcc=0.9744\n","Fold 19 Epoch 700: Loss=0.064924 | TrainAcc=0.9872\n","Fold 19 Epoch 800: Loss=0.014763 | TrainAcc=1.0000\n","Fold 19 Epoch 900: Loss=0.006591 | TrainAcc=1.0000\n","Fold 19 Epoch 1000: Loss=0.008230 | TrainAcc=1.0000\n","Fold 19 Epoch 1100: Loss=0.007380 | TrainAcc=1.0000\n","Fold 19 Epoch 1200: Loss=0.088637 | TrainAcc=0.9615\n","Fold 19 Epoch 1300: Loss=0.038578 | TrainAcc=0.9872\n","Fold 19 Epoch 1400: Loss=0.009896 | TrainAcc=1.0000\n","Fold 19 Epoch 1500: Loss=0.005751 | TrainAcc=1.0000\n","Fold 19 Epoch 1600: Loss=0.046744 | TrainAcc=0.9744\n","Fold 19 Epoch 1700: Loss=0.003072 | TrainAcc=1.0000\n","Fold 19 Epoch 1800: Loss=0.078398 | TrainAcc=0.9744\n","Fold 19 Epoch 1900: Loss=0.007992 | TrainAcc=1.0000\n","Fold 19 Epoch 2000: Loss=0.005630 | TrainAcc=1.0000\n","Fold 19 → Acc=0.6838 | Prec=0.8799 | Rec=0.6569 | F1=0.7522 | AUC=0.7911 | CE Loss=1.3499\n","\n","=== Fold 20 ===\n","Fold 20 Epoch 1: Loss=0.940907 | TrainAcc=0.2692\n","Fold 20 Epoch 100: Loss=0.320254 | TrainAcc=0.8718\n","Fold 20 Epoch 200: Loss=0.168391 | TrainAcc=0.9231\n","Fold 20 Epoch 300: Loss=0.107255 | TrainAcc=0.9615\n","Fold 20 Epoch 400: Loss=0.102506 | TrainAcc=0.9615\n","Fold 20 Epoch 500: Loss=0.108301 | TrainAcc=0.9487\n","Fold 20 Epoch 600: Loss=0.062369 | TrainAcc=0.9615\n","Fold 20 Epoch 700: Loss=0.033203 | TrainAcc=0.9872\n","Fold 20 Epoch 800: Loss=0.022656 | TrainAcc=1.0000\n","Fold 20 Epoch 900: Loss=0.025782 | TrainAcc=0.9872\n","Fold 20 Epoch 1000: Loss=0.011009 | TrainAcc=1.0000\n","Fold 20 Epoch 1100: Loss=0.018823 | TrainAcc=0.9872\n","Fold 20 Epoch 1200: Loss=0.015860 | TrainAcc=1.0000\n","Fold 20 Epoch 1300: Loss=0.009980 | TrainAcc=1.0000\n","Fold 20 Epoch 1400: Loss=0.012491 | TrainAcc=1.0000\n","Fold 20 Epoch 1500: Loss=0.010816 | TrainAcc=1.0000\n","Fold 20 Epoch 1600: Loss=0.010628 | TrainAcc=1.0000\n","Fold 20 Epoch 1700: Loss=0.006880 | TrainAcc=1.0000\n","Fold 20 Epoch 1800: Loss=0.003506 | TrainAcc=1.0000\n","Fold 20 Epoch 1900: Loss=0.021794 | TrainAcc=0.9872\n","Fold 20 Epoch 2000: Loss=0.002285 | TrainAcc=1.0000\n","Fold 20 → Acc=0.7578 | Prec=0.8769 | Rec=0.7778 | F1=0.8244 | AUC=0.8077 | CE Loss=1.3083\n","\n","=== Average Results Across 20 Folds ===\n","Accuracy:  0.7395 ± 0.0543\n","Precision: 0.8584 ± 0.0280\n","Recall:    0.7766 ± 0.1161\n","F1-score:  0.8086 ± 0.0584\n","AUC:       0.7903 ± 0.0251\n","CE Loss:   1.4582 ± 0.4610\n"]}]}]}
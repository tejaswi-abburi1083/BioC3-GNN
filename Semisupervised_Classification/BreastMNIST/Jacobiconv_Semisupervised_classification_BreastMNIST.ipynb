{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"12BSY21jv9N-jYL-IJ8oGGRTeC9p4roGT","timestamp":1761724462367},{"file_id":"1OZL0M_Zh_cHw-H5utOpn6sc6NtsdViEf","timestamp":1747279993555},{"file_id":"1UDJaQxcixFBoLdBH8KoBHMxo19SRI1My","timestamp":1747238356883},{"file_id":"1y40jw9ksHpmIeKlcMcBmqpvK5gnOF8vb","timestamp":1746704120540},{"file_id":"1vLY-ZFYfdexWlCV5nMBy_s8I-TdUUtXi","timestamp":1746702771944},{"file_id":"1O03CrIGAL9R-y4SCrFZLyak5k2mxsJxe","timestamp":1741177807100}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"Mi6DYiF-SVHo","executionInfo":{"status":"ok","timestamp":1767796977060,"user_tz":-330,"elapsed":6,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","from torch_geometric.nn import MessagePassing\n","from torch_geometric.utils import add_self_loops, degree\n","from torch_geometric.nn.inits import glorot, zeros\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_auc_score, roc_curve, auc\n","import math\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"tv7boNsbNGuX","executionInfo":{"status":"ok","timestamp":1767796977062,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["data = np.load('/home/snu/Downloads/breastmnist_224.npz', allow_pickle=True)\n","all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","# Convert to 3-channel RGB\n","images = all_images.astype(np.float32) / 255.0\n","images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N, 3, 224, 224)\n","X_torch = torch.tensor(images)\n","y_torch = torch.tensor(all_labels).long()\n","\n","print(f\"Raw images: {X_torch.shape}, Labels: {y_torch.shape}\")"],"metadata":{"id":"lY70a67PO5fK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767796977443,"user_tz":-330,"elapsed":380,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"91a32f09-dc83-4203-c0f2-b4601c804e91"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Raw images: torch.Size([780, 3, 224, 224]), Labels: torch.Size([780])\n"]}]},{"cell_type":"code","source":["import random\n","from torch.utils.data import Subset, TensorDataset, DataLoader\n","\n","class0_idx = [i for i in range(len(y_torch)) if y_torch[i] == 0]\n","class1_idx = [i for i in range(len(y_torch)) if y_torch[i] == 1]\n","\n","random.seed(42)\n","sampled_class0 = random.sample(class0_idx, min(1000, len(class0_idx)))\n","sampled_class1 = random.sample(class1_idx, min(1000, len(class1_idx)))\n","\n","selected_indices = sampled_class0 + sampled_class1\n","random.shuffle(selected_indices)\n","\n","subset_dataset = Subset(TensorDataset(X_torch, y_torch), selected_indices)\n","subset_loader = DataLoader(subset_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"U36GtUurSabo","executionInfo":{"status":"ok","timestamp":1767796977494,"user_tz":-330,"elapsed":48,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","vit = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n","vit.eval().to(device)\n","\n","vit_feats, y_list = [], []\n","\n","with torch.no_grad():\n","    for imgs, lbls in subset_loader:\n","        imgs = imgs.to(device)\n","        feats = vit(imgs)\n","        vit_feats.append(feats.cpu())\n","        y_list.extend(lbls.cpu().tolist())\n","\n","features_numpy = torch.cat(vit_feats, dim=0).numpy().astype(np.float32)\n","y = np.array(y_list).astype(np.int64)\n","\n","num_nodes, num_feats = features_numpy.shape\n","print(f\"Extracted ViT-DINO Features: {features_numpy.shape}, Labels: {y.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iBADkGCB9uhf","executionInfo":{"status":"ok","timestamp":1767796986185,"user_tz":-330,"elapsed":8689,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"9249a376-1547-414c-93f2-199455664ef6"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /home/snu/.cache/torch/hub/facebookresearch_dino_main\n"]},{"output_type":"stream","name":"stdout","text":["Extracted ViT-DINO Features: (780, 768), Labels: (780,)\n"]}]},{"cell_type":"code","source":["X_tensor = torch.tensor(features_numpy).to(device)\n","y_tensor = torch.tensor(y).to(device)\n","\n","alpha = 0.7\n","X_norm = torch.nn.functional.normalize(X_tensor, p=2, dim=1)\n","sim_matrix = torch.mm(X_norm, X_norm.T)\n","src, dst = torch.where(sim_matrix > alpha)\n","mask = src != dst\n","src, dst = src[mask], dst[mask]\n","\n","edge_index = torch.stack([src, dst], dim=0).to(device)\n","\n","\n","print(f\"Graph Nodes: {num_nodes}, Edges: {edge_index.size(1)}, Device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b32bLKoFtKak","executionInfo":{"status":"ok","timestamp":1767796986193,"user_tz":-330,"elapsed":6,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"5d625c2c-64fe-4587-b4f4-14936d856369"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Graph Nodes: 780, Edges: 350698, Device: cuda\n"]}]},{"cell_type":"code","source":["# edge_index = torch.combinations(torch.arange(num_nodes), r=2).T\n","# src, dst = edge_index\n","# graph = dgl.graph((src, dst))\n","# graph = dgl.to_bidirected(graph)\n","# graph = dgl.add_self_loop(graph)\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# graph = graph.to(device)\n","# X_tensor = X_tensor.to(device)\n","# y_tensor = y_tensor.to(device)\n","\n","# print(f\"Graph Nodes: {graph.num_nodes()}, Edges: {graph.num_edges()}, Device: {device}\")"],"metadata":{"id":"RnHF5jgNSbFj","executionInfo":{"status":"ok","timestamp":1767796986241,"user_tz":-330,"elapsed":46,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["class JacobiConv(MessagePassing):\n","    def __init__(self, in_channels, out_channels, K=3, alpha=1.0, beta=1.0,\n","                 normalization='sym', bias=True, **kwargs):\n","        kwargs.setdefault('aggr', 'add')\n","        super(JacobiConv, self).__init__(**kwargs)\n","\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.K = K\n","        self.alpha = alpha\n","        self.beta = beta\n","        self.normalization = normalization\n","\n","        self.weight = nn.Parameter(torch.Tensor(K + 1, in_channels, out_channels))\n","\n","        if bias:\n","            self.bias = nn.Parameter(torch.Tensor(out_channels))\n","        else:\n","            self.register_parameter('bias', None)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.weight)\n","        zeros(self.bias)\n","\n","    def __norm__(self, edge_index, num_nodes, edge_weight=None, improved=False,\n","                 dtype=None):\n","        if edge_weight is None:\n","            edge_weight = torch.ones((edge_index.size(1),), dtype=dtype,\n","                                     device=edge_index.device)\n","\n","        fill_value = 2. if improved else 1.\n","        edge_index, edge_weight = add_self_loops(\n","            edge_index, edge_weight, fill_value, num_nodes)\n","\n","        row, col = edge_index\n","        deg = degree(col, num_nodes, dtype=edge_weight.dtype)\n","\n","        if self.normalization == 'sym':\n","            deg_inv_sqrt = deg.pow(-0.5)\n","            deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n","            return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n","        elif self.normalization == 'rw':\n","            deg_inv = deg.pow(-1.0)\n","            deg_inv[deg_inv == float('inf')] = 0\n","            return edge_index, deg_inv[row] * edge_weight\n","        else:\n","            return edge_index, edge_weight\n","\n","    def compute_jacobi_coeffs(self, k):\n","        if k == 0:\n","            return 1.0, 0.0, 0.0\n","        elif k == 1:\n","            theta_k = (self.alpha + self.beta + 2) / 2\n","            theta_k_prime = (self.alpha - self.beta) / 2\n","            return theta_k, theta_k_prime, 0.0\n","        else:\n","            theta_k = (2 * k + self.alpha + self.beta) * (2 * k + self.alpha + self.beta - 1) / (2 * k * (k + self.alpha + self.beta))\n","            theta_k_prime = (2 * k + self.alpha + self.beta - 1) * (self.alpha ** 2 - self.beta ** 2) / (2 * k * (k + self.alpha + self.beta) * (2 * k + self.alpha + self.beta - 2))\n","            theta_k_double = (k + self.alpha - 1) * (k + self.beta - 1) * (2 * k + self.alpha + self.beta) / (k * (k + self.alpha + self.beta) * (2 * k + self.alpha + self.beta - 2))\n","            return theta_k, theta_k_prime, theta_k_double\n","\n","    def forward(self, x, edge_index, edge_weight=None):\n","        edge_index, norm = self.__norm__(edge_index, x.size(0), edge_weight,\n","                                         dtype=x.dtype)\n","\n","        Tx_0 = x\n","        #out = torch.einsum('ijk,jk->ik', self.weight[0:1], Tx_0.unsqueeze(0))\n","        out = Tx_0 @ self.weight[0]\n","\n","\n","        if self.K > 0:\n","            Tx_1 = (self.alpha - self.beta) / 2 * x + (self.alpha + self.beta + 2) / 2 * self.propagate(edge_index, x=x, norm=norm)\n","            #out += torch.einsum('ijk,jk->ik', self.weight[1:2], Tx_1.unsqueeze(0))\n","            out += Tx_1 @ self.weight[1]\n","\n","        for k in range(2, self.K + 1):\n","            theta_k, theta_k_prime, theta_k_double = self.compute_jacobi_coeffs(k)\n","            Tx_2 = theta_k * self.propagate(edge_index, x=Tx_1, norm=norm) + theta_k_prime * Tx_1 - theta_k_double * Tx_0\n","            #out += torch.einsum('ijk,jk->ik', self.weight[k:k+1], Tx_2.unsqueeze(0))\n","            out += Tx_2 @ self.weight[k]\n","            Tx_0, Tx_1 = Tx_1, Tx_2\n","\n","        if self.bias is not None:\n","            out += self.bias\n","\n","        return out\n","\n","    def message(self, x_j, norm):\n","        return norm.view(-1, 1) * x_j\n","\n","    def __repr__(self):\n","        return f'{self.__class__.__name__}({self.in_channels}, {self.out_channels}, K={self.K}, alpha={self.alpha}, beta={self.beta})'"],"metadata":{"id":"mmSxhDyuSbIb","executionInfo":{"status":"ok","timestamp":1767796986352,"user_tz":-330,"elapsed":109,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["class JacobiNet(nn.Module):\n","    \"\"\"\n","    Multi-layer JacobiConv network for node classification\n","\n","    Args:\n","        in_channels (int): Size of input features\n","        hidden_channels (int): Size of hidden representations\n","        out_channels (int): Number of output classes\n","        num_layers (int): Number of JacobiConv layers (default: 2)\n","        K (int): Polynomial order for each layer (default: 3)\n","        alpha (float): Jacobi polynomial parameter alpha (default: 1.0)\n","        beta (float): Jacobi polynomial parameter beta (default: 1.0)\n","        dropout (float): Dropout probability (default: 0.5)\n","    \"\"\"\n","\n","    def __init__(self, in_channels, hidden_channels, out_channels,\n","                 num_layers=2, K=3, alpha=1.0, beta=1.0, dropout=0.2):\n","        super(JacobiNet, self).__init__()\n","\n","        self.num_layers = num_layers\n","        self.dropout = dropout\n","\n","        self.convs = nn.ModuleList()\n","\n","        # First layer\n","        if num_layers == 1:\n","            self.convs.append(JacobiConv(in_channels, out_channels, K, alpha, beta))\n","        else:\n","            self.convs.append(JacobiConv(in_channels, hidden_channels, K, alpha, beta))\n","\n","            # Hidden layers\n","            for _ in range(num_layers - 2):\n","                self.convs.append(JacobiConv(hidden_channels, hidden_channels, K, alpha, beta))\n","\n","            # Output layer\n","            self.convs.append(JacobiConv(hidden_channels, out_channels, K, alpha, beta))\n","\n","    def forward(self, x, edge_index, edge_weight=None):\n","        for i, conv in enumerate(self.convs):\n","            x = conv(x, edge_index, edge_weight)\n","            if i < self.num_layers - 1:\n","                x = F.relu(x)\n","                x = F.dropout(x, p=self.dropout, training=self.training)\n","        return x"],"metadata":{"id":"6qhdCCRSShu7","executionInfo":{"status":"ok","timestamp":1767796986361,"user_tz":-330,"elapsed":1,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=42)\n","num_epochs = 2000\n","\n","accuracies, precisions, recalls, f1_scores, losses, all_auc = [], [], [], [], [], []\n","all_fpr, all_tpr, all_y_true, all_y_proba = [], [], [], []\n","\n","for fold, (train_idx, test_idx) in enumerate(sss.split(features_numpy, y)):\n","    print(f\"\\nTraining fold {fold + 1}\")\n","\n","    train_mask = torch.tensor(train_idx, dtype=torch.long).to(device)\n","    test_mask = torch.tensor(test_idx, dtype=torch.long).to(device)\n","\n","    model = JacobiNet(in_channels=features_numpy.shape[1], hidden_channels=512, out_channels=2, num_layers=2, K=5, alpha=1.0, beta=1.0, dropout=0.2).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=5e-4)\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","        out = model(X_tensor, edge_index)\n","        loss = loss_fn(out[train_mask], y_tensor[train_mask])\n","        if torch.isnan(loss) or torch.isinf(loss):\n","            print(f\"NaN/Inf loss at epoch {epoch}\")\n","            break\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Evaluation\n","    model.eval()\n","    with torch.no_grad():\n","        logits = model(X_tensor, edge_index)\n","        y_pred = torch.argmax(logits, dim=1).cpu().numpy()\n","        y_pred_proba = F.softmax(logits, dim=1).cpu().numpy()\n","\n","    y_true_test = y_tensor[test_mask].cpu().numpy()\n","    y_pred_test = y_pred[test_mask.cpu().numpy()]\n","    y_proba_test = y_pred_proba[test_mask.cpu().numpy()][:, 1]\n","\n","    acc = accuracy_score(y_true_test, y_pred_test)\n","    prec = precision_score(y_true_test, y_pred_test)\n","    rec = recall_score(y_true_test, y_pred_test)\n","    f1 = f1_score(y_true_test, y_pred_test)\n","    loss_val = log_loss(y_true_test, y_pred_proba[test_mask.cpu().numpy()])\n","\n","    fpr, tpr, _ = roc_curve(y_true_test, y_proba_test)\n","    fold_auc_score = auc(fpr, tpr)\n","\n","\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    losses.append(loss_val)\n","    all_auc.append(fold_auc_score)\n","    all_fpr.append(fpr)\n","    all_tpr.append(tpr)\n","    all_y_true.extend(y_true_test)\n","    all_y_proba.extend(y_proba_test)\n","\n","    print(f\"Fold {fold+1} | Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f} | Loss: {loss_val:.4f} | AUC: {fold_auc_score:.4f}\")\n","\n","print(\"\\nAverage Results across 20 folds:\")\n","print(f\"Accuracy: {np.mean(accuracies):.4f} \\u00b1 {np.std(accuracies):.4f}\")\n","print(f\"Precision: {np.mean(precisions):.4f} \\u00b1 {np.std(precisions):.4f}\")\n","print(f\"Recall: {np.mean(recalls):.4f} \\u00b1 {np.std(recalls):.4f}\")\n","print(f\"F1 Score: {np.mean(f1_scores):.4f} \\u00b1 {np.std(f1_scores):.4f}\")\n","print(f\"Cross-Entropy Loss: {np.mean(losses):.4f} \\u00b1 {np.std(losses):.4f}\")\n","print(f\"Average AUC: {np.mean(all_auc):.4f} \\u00b1 {np.std(all_auc):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R63Lt6i_Shxb","outputId":"be7906ea-7a6c-41b7-c629-1093d0291708"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training fold 1\n","Fold 1 | Acc: 0.7821 | Prec: 0.8557 | Rec: 0.8441 | F1: 0.8499 | Loss: 2.6614 | AUC: 0.7912\n","\n","Training fold 2\n","Fold 2 | Acc: 0.8362 | Prec: 0.8769 | Rec: 0.9025 | F1: 0.8895 | Loss: 2.1027 | AUC: 0.8253\n","\n","Training fold 3\n","Fold 3 | Acc: 0.8091 | Prec: 0.8694 | Rec: 0.8694 | F1: 0.8694 | Loss: 2.1888 | AUC: 0.8190\n","\n","Training fold 4\n","Fold 4 | Acc: 0.8162 | Prec: 0.8200 | Rec: 0.9591 | F1: 0.8841 | Loss: 2.4107 | AUC: 0.7467\n","\n","Training fold 5\n","Fold 5 | Acc: 0.8234 | Prec: 0.8663 | Rec: 0.8967 | F1: 0.8812 | Loss: 2.2473 | AUC: 0.8126\n","\n","Training fold 6\n","Fold 6 | Acc: 0.8447 | Prec: 0.8556 | Rec: 0.9474 | F1: 0.8992 | Loss: 1.8849 | AUC: 0.8411\n","\n","Training fold 7\n","Fold 7 | Acc: 0.7593 | Prec: 0.7567 | Rec: 0.9883 | F1: 0.8571 | Loss: 3.6940 | AUC: 0.5919\n","\n","Training fold 8\n","Fold 8 | Acc: 0.8148 | Prec: 0.9342 | Rec: 0.8031 | F1: 0.8637 | Loss: 2.0785 | AUC: 0.8978\n","\n","Training fold 9\n","Fold 9 | Acc: 0.8419 | Prec: 0.8792 | Rec: 0.9084 | F1: 0.8936 | Loss: 1.6330 | AUC: 0.8675\n","\n","Training fold 10\n","Fold 10 | Acc: 0.8447 | Prec: 0.8495 | Rec: 0.9571 | F1: 0.9001 | Loss: 2.0290 | AUC: 0.7982\n","\n","Training fold 11\n","Fold 11 | Acc: 0.8276 | Prec: 0.8755 | Rec: 0.8908 | F1: 0.8831 | Loss: 2.0741 | AUC: 0.8404\n","\n","Training fold 12\n","Fold 12 | Acc: 0.8462 | Prec: 0.8485 | Rec: 0.9610 | F1: 0.9013 | Loss: 1.8497 | AUC: 0.8325\n","\n","Training fold 13\n","Fold 13 | Acc: 0.8148 | Prec: 0.8229 | Rec: 0.9513 | F1: 0.8825 | Loss: 2.3994 | AUC: 0.7724\n","\n","Training fold 14\n","Fold 14 | Acc: 0.8604 | Prec: 0.8922 | Rec: 0.9201 | F1: 0.9060 | Loss: 1.5110 | AUC: 0.8690\n","\n","Training fold 15\n","Fold 15 | Acc: 0.7279 | Prec: 0.9522 | Rec: 0.6608 | F1: 0.7802 | Loss: 3.3832 | AUC: 0.8954\n","\n","Training fold 16\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plot ROC curves for each fold\n","plt.figure(figsize=(8, 6))\n","\n","for i in range(len(all_fpr)):\n","    plt.plot(all_fpr[i], all_tpr[i], alpha=0.3, label=f\"Fold {i+1} AUC = {all_auc[i]:.2f}\")\n","\n","fpr_avg, tpr_avg, _ = roc_curve(all_y_true, all_y_proba)\n","auc_avg = roc_auc_score(all_y_true, all_y_proba)\n","plt.plot(fpr_avg, tpr_avg, color='blue', lw=2, label=f\"Mean ROC (AUC = {auc_avg:.2f})\")\n","\n","plt.plot([0, 1], [0, 1], 'k--', label=\"Chance\")\n","\n","plt.xlabel(\"False Positive Rate\", fontsize=14)\n","plt.ylabel(\"True Positive Rate\", fontsize=14)\n","plt.title(\"ROC Curve Across 20 Folds (JACOBI CONV)\", fontsize=16)\n","plt.xticks(fontsize=12)\n","plt.yticks(fontsize=12)\n","plt.legend(loc=\"lower right\", fontsize=9)\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"HCJwy49MUy5d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.manifold import TSNE\n","import matplotlib.pyplot as plt\n","\n","X_input = X_tensor.cpu().numpy()\n","tsne_input = TSNE(n_components=2, init='pca', random_state=42)\n","input_2d = tsne_input.fit_transform(X_input)\n","\n","model.eval()\n","with torch.no_grad():\n","    # Get final APPNP embeddings (after propagation)\n","    Z = model(X_tensor, edge_index).cpu().numpy()\n","\n","tsne_embed = TSNE(n_components=2, init='pca', random_state=42)\n","embed_2d = tsne_embed.fit_transform(Z)\n","\n","labels = y_tensor.cpu().numpy()\n","\n","colors = ['blue', 'red']\n","markers = ['o', 's']\n","class_names = ['CN', 'MCI']\n","font_size = 8\n","\n","fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n","\n","# Plot raw input t-SNE\n","for cls, color, marker in zip([0, 1], colors, markers):\n","    idx = labels == cls\n","    axes[0].scatter(input_2d[idx, 0], input_2d[idx, 1],\n","                    c=color, marker=marker, label=class_names[cls], alpha=0.7, s=10)\n","axes[0].set_title(\"Raw Input Features (APPNP CN vs MCI)\", fontsize=font_size)\n","axes[0].set_xlabel(\"t-SNE 1\", fontsize=font_size)\n","axes[0].set_ylabel(\"t-SNE 2\", fontsize=font_size)\n","axes[0].tick_params(labelsize=font_size)\n","\n","# Plot APPNP embeddings t-SNE\n","for cls, color, marker in zip([0, 1], colors, markers):\n","    idx = labels == cls\n","    axes[1].scatter(embed_2d[idx, 0], embed_2d[idx, 1],\n","                    c=color, marker=marker, label=class_names[cls], alpha=0.7, s=10)\n","axes[1].set_title(\"APPNP Embeddings (CN vs MCI)\", fontsize=font_size)\n","axes[1].set_xlabel(\"t-SNE 1\", fontsize=font_size)\n","axes[1].set_ylabel(\"t-SNE 2\", fontsize=font_size)\n","axes[1].tick_params(labelsize=font_size)\n","axes[1].legend(fontsize=font_size, loc='best')\n","\n","plt.tight_layout()\n","plt.savefig(\"tsne_appnp_comparison.png\", dpi=300, bbox_inches='tight')\n","plt.show()"],"metadata":{"id":"8ZyfHS_QU4Dx"},"execution_count":null,"outputs":[]}]}
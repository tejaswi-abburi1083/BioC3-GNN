{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMk3eGZXcouk94tK93O8gZo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XtuvijZud-Ro"},"outputs":[],"source":["import os\n","import copy\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as nnF\n","import torch.optim as optim\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GATConv\n","\n","from torch.utils.data import TensorDataset, DataLoader, Subset\n","from torchvision import models\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_auc_score"]},{"cell_type":"code","source":["SEED = 42\n","np.random.seed(SEED)\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"uUGD1KcheGP7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = np.load('/home/snu/Downloads/breastmnist_224.npz', allow_pickle=True)\n","all_images = np.concatenate([data['train_images'], data['val_images'], data['test_images']], axis=0)\n","all_labels = np.concatenate([data['train_labels'], data['val_labels'], data['test_labels']], axis=0).squeeze()\n","\n","images = all_images.astype(np.float32) / 255.0\n","images = np.repeat(images[:, None, :, :], 3, axis=1)  # (N,3,224,224)\n","X = torch.tensor(images)\n","y = torch.tensor(all_labels).long()\n","print(\"Images, labels shapes:\", X.shape, y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSK5w7fOeIB6","executionInfo":{"status":"ok","timestamp":1767772842013,"user_tz":-330,"elapsed":390,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"006b483f-cd36-45ce-b1d4-4f8fb8b44bc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Images, labels shapes: torch.Size([780, 3, 224, 224]) torch.Size([780])\n"]}]},{"cell_type":"code","source":["dataset = TensorDataset(X, y)\n","class0_indices = [i for i in range(len(y)) if y[i] == 0]\n","class1_indices = [i for i in range(len(y)) if y[i] == 1]\n","\n","random.seed(SEED)\n","sampled_class0 = random.sample(class0_indices, min(1000, len(class0_indices)))\n","sampled_class1 = random.sample(class1_indices, min(1000, len(class1_indices)))\n","\n","combined_indices = sampled_class0 + sampled_class1\n","random.shuffle(combined_indices)\n","\n","final_dataset = Subset(dataset, combined_indices)\n","final_loader = DataLoader(final_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"Ij_DjWvJeKDr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","vit = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n","vit.eval().to(device)\n","\n","vit_feats, y_list = [], []\n","\n","with torch.no_grad():\n","    for imgs, lbls in final_loader:\n","        imgs = imgs.to(device)\n","        feats = vit(imgs)\n","        vit_feats.append(feats.cpu())\n","        y_list.extend(lbls.cpu().tolist())\n","\n","F = torch.cat(vit_feats, dim=0).numpy().astype(np.float32)\n","y = np.array(y_list).astype(np.int64)\n","\n","num_nodes, num_feats = F.shape\n","print(f\"Extracted ViT-DINO Features: {F.shape}, Labels: {y.shape}\")\n","features = F\n","y_labels = y\n","feat_dim = features.shape[1]      # = 768 for ViT-DINO\n","K = len(np.unique(y_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75f7P_w6eOsD","executionInfo":{"status":"ok","timestamp":1767772851091,"user_tz":-330,"elapsed":9074,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"59ceeaad-4a3b-41a3-8dd0-30e79dca1b98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /home/snu/.cache/torch/hub/facebookresearch_dino_main\n"]},{"output_type":"stream","name":"stdout","text":["Extracted ViT-DINO Features: (780, 768), Labels: (780,)\n"]}]},{"cell_type":"code","source":["def create_adj(features, cut, alpha=1.0):\n","    F_norm = features / (np.linalg.norm(features, axis=1, keepdims=True) + 1e-12)\n","    W = np.dot(F_norm, F_norm.T)\n","    if cut == 0:\n","        W = np.where(W >= alpha, 1, 0).astype(np.float32)\n","        if W.max() > 0:\n","            W = (W / W.max()).astype(np.float32)\n","    else:\n","        W = (W * (W >= alpha)).astype(np.float32)\n","    return W\n","\n","def edge_index_from_dense(W):\n","    rows, cols = np.nonzero(W > 0)\n","    edge_index = np.vstack([rows, cols]).astype(np.int64)\n","    edge_weight = W[rows, cols].astype(np.float32)\n","    return edge_index, edge_weight\n","\n","def build_adj_list(edge_index_np, num_nodes):\n","    adj = [[] for _ in range(num_nodes)]\n","    src = edge_index_np[0]\n","    dst = edge_index_np[1]\n","    for s, d in zip(src, dst):\n","        adj[s].append(d)\n","    adj = [np.array(neis, dtype=np.int64) if len(neis) > 0 else np.array([], dtype=np.int64) for neis in adj]\n","    return adj\n","\n","def aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=None):\n","    rng = np.random.default_rng(seed)\n","    E = edge_index_np.shape[1]\n","    keep_mask = rng.random(E) >= drop_percent\n","    new_edge_index = edge_index_np[:, keep_mask]\n","    return new_edge_index\n","\n","def load_data_from_edge_index(node_feats_np, edge_index_np, device):\n","    node_feats = torch.from_numpy(node_feats_np).float()\n","    edge_index = torch.from_numpy(edge_index_np.astype(np.int64)).long()\n","    return node_feats, edge_index"],"metadata":{"id":"_O2R6X3WeSlr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sim(h1, h2, tau=0.2):\n","    z1 = nnF.normalize(h1, dim=-1, p=2)\n","    z2 = nnF.normalize(h2, dim=-1, p=2)\n","    return torch.mm(z1, z2.t()) / tau\n","\n","def contrastive_loss_wo_cross_network(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    intra_sim = f(sim(h1, h1))\n","    inter_sim = f(sim(h1, h2))\n","    return -torch.log(inter_sim.diag() /\n","                     (intra_sim.sum(dim=-1) + inter_sim.sum(dim=-1) - intra_sim.diag() + 1e-12))\n","\n","def contrastive_loss_wo_cross_view(h1, h2, z):\n","    f = lambda x: torch.exp(x)\n","    cross_sim = f(sim(h1, z))\n","    return -torch.log(cross_sim.diag() / (cross_sim.sum(dim=-1) + 1e-12))"],"metadata":{"id":"dNgFCCgbeWFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MLP(nn.Module):\n","    def __init__(self, inp_size, outp_size, hidden_size):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(inp_size, hidden_size),\n","            nn.BatchNorm1d(hidden_size),\n","            nn.PReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_size, outp_size)\n","        )\n","    def forward(self, x):\n","        return self.net(x)\n","\n","\n","class GATEncoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, device, activ=\"RELU\", heads=2):\n","        super(GATEncoder, self).__init__()\n","        self.device = device\n","\n","        activations = {\n","            \"SELU\": nnF.selu,\n","            \"SiLU\": nnF.silu,\n","            \"GELU\": nnF.gelu,\n","            \"ELU\": nnF.elu,\n","            \"RELU\": nnF.relu\n","        }\n","        self.act = activations.get(activ, nnF.elu)\n","\n","        self.gat = GATConv(\n","            in_channels=input_dim,\n","            out_channels=hidden_dim,\n","            heads=heads,\n","            dropout=0.25,\n","            concat=False   # keeps output dim = hidden_dim\n","        )\n","\n","        self.batchnorm = nn.BatchNorm1d(hidden_dim)\n","        self.dropout = nn.Dropout(0.3)\n","        self.mlp = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.gat(x, edge_index)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        x = self.batchnorm(x)\n","        logits = self.mlp(x)\n","        return logits"],"metadata":{"id":"X3rsj_azeX4D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EMA():\n","    def __init__(self, beta):\n","        self.beta = beta\n","    def update_average(self, old, new):\n","        if old is None:\n","            return new\n","        return old * self.beta + (1 - self.beta) * new\n","\n","def update_moving_average(ema_updater, ma_model, current_model):\n","    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n","        old_weight, up_weight = ma_params.data, current_params.data\n","        ma_params.data = ema_updater.update_average(old_weight, up_weight)"],"metadata":{"id":"9Ob2AJVjeaTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ARMA(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_clusters, device, activ, moving_average_decay=0.99, cut=True):\n","        super(ARMA, self).__init__()\n","        self.device = device\n","        self.num_clusters = num_clusters\n","        self.cut = cut\n","        # beta for mixing in contrastive combination\n","        self.beta = 0.6\n","\n","        self.online_encoder = GATEncoder(input_dim, hidden_dim, device, activ)\n","        self.target_encoder = copy.deepcopy(self.online_encoder)\n","        # freeze target encoder params\n","        for p in self.target_encoder.parameters():\n","            p.requires_grad = False\n","\n","        self.online_predictor = MLP(hidden_dim, num_clusters, hidden_dim)\n","\n","        self.loss = self.cut_loss if cut else self.modularity_loss\n","        self.target_ema_updater = EMA(moving_average_decay)\n","\n","    def reset_moving_average(self):\n","        del self.target_encoder\n","        self.target_encoder = None\n","\n","    def update_ma(self):\n","        assert self.target_encoder is not None, 'target encoder has not been created yet'\n","        update_moving_average(self.target_ema_updater, self.target_encoder, self.online_encoder)\n","\n","    def forward(self, data1, data2):\n","        # online projections\n","        x1 = self.online_encoder(data1)      # shape: N x hidden\n","        logits1 = self.online_predictor(x1)  # predictor outputs (raw)\n","        S1 = nnF.softmax(logits1, dim=1)\n","\n","        x2 = self.online_encoder(data2)\n","        logits2 = self.online_predictor(x2)\n","        S2 = nnF.softmax(logits2, dim=1)\n","\n","        # target projections (no grads)\n","        with torch.no_grad():\n","            target_proj_one = self.target_encoder(data1).detach()\n","            target_proj_two = self.target_encoder(data2).detach()\n","\n","        # contrastive style losses\n","        l1 = self.beta * contrastive_loss_wo_cross_network(x1, x2, target_proj_two) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x1, x2, target_proj_two)\n","\n","        l2 = self.beta * contrastive_loss_wo_cross_network(x2, x1, target_proj_one) + \\\n","             (1.0 - self.beta) * contrastive_loss_wo_cross_view(x2, x1, target_proj_one)\n","\n","        return S1, S2, logits1, logits2, l1, l2\n","\n","    def modularity_loss(self, A, S):\n","        C = nnF.softmax(S, dim=1)\n","        d = torch.sum(A, dim=1)\n","        m = torch.sum(A)\n","        B = A - torch.ger(d, d) / (2 * m + 1e-12)\n","\n","        k = torch.tensor(self.num_clusters, device=self.device, dtype=torch.float32)\n","        n = S.shape[0]\n","\n","        modularity_term = (-1.0 / (2.0 * m + 1e-12)) * torch.trace(torch.mm(torch.mm(C.t(), B), C))\n","        collapse_reg_term = (torch.sqrt(k) / n) * torch.norm(torch.sum(C, dim=0), p='fro') - 1.0\n","\n","        return modularity_term + collapse_reg_term\n","\n","    def cut_loss(self, A, S):\n","        S = nnF.softmax(S, dim=1)\n","        A_pool = torch.matmul(torch.matmul(A, S).t(), S)\n","        num = torch.trace(A_pool)\n","\n","        D = torch.diag(torch.sum(A, dim=-1))\n","        D_pooled = torch.matmul(torch.matmul(D, S).t(), S)\n","        den = torch.trace(D_pooled)\n","        mincut_loss = -(num / (den + 1e-12))\n","\n","        St_S = torch.matmul(S.t(), S)\n","        I_S = torch.eye(self.num_clusters, device=self.device)\n","        ortho_loss = torch.norm(St_S / (torch.norm(St_S) + 1e-12) - I_S / (torch.norm(I_S) + 1e-12))\n","\n","        return mincut_loss + ortho_loss"],"metadata":{"id":"bcmcF_CcedKT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alpha = 0.73\n","hidden_dim = 256\n","K = 2\n","num_epochs = 2000\n","\n","W0 = create_adj(features, cut=0, alpha=alpha)\n","edge_index_np, edge_weight_np = edge_index_from_dense(W0)\n","node_feats_all, edge_index_all = load_data_from_edge_index(features, edge_index_np, device)\n","data_full = Data(x=node_feats_all.to(device), edge_index=edge_index_all.to(device))\n","A1 = torch.from_numpy(W0).float().to(device)"],"metadata":{"id":"r80v3qj2efX8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracies, precisions, recalls, f1_scores, losses, all_auc = [], [], [], [], [], []\n","\n","sss = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=SEED)\n","for fold, (train_idx_full, test_idx) in enumerate(sss.split(features, y_labels)):\n","    print(f\"\\n=== Fold {fold+1} ===\")\n","\n","    cn_idx = np.where(y_labels == 0)[0]\n","    mci_idx = np.where(y_labels == 1)[0]\n","    sss_class = StratifiedShuffleSplit(n_splits=20, test_size=0.9, random_state=fold)\n","    cn_train_idx, _ = next(sss_class.split(features[cn_idx], y_labels[cn_idx]))\n","    mci_train_idx, _ = next(sss_class.split(features[mci_idx], y_labels[mci_idx]))\n","    cn_train = cn_idx[cn_train_idx]\n","    mci_train = mci_idx[mci_train_idx]\n","    balanced_train_idx = np.concatenate([cn_train, mci_train])\n","    np.random.shuffle(balanced_train_idx)\n","\n","    train_idx_t = torch.from_numpy(balanced_train_idx).long().to(device)\n","    test_idx_t = torch.from_numpy(test_idx).long().to(device)\n","    y_tensor = torch.from_numpy(y_labels).long().to(device)\n","\n","    model = ARMA(feat_dim, hidden_dim, K, device, activ=\"RELU\", cut=False, moving_average_decay=0.99).to(device)\n","    classifier = nn.Linear(hidden_dim, K).to(device)\n","    optimizer = optim.Adam(list(model.parameters()) + list(classifier.parameters()), lr=1e-4, weight_decay=1e-4)\n","    ce_loss = nn.CrossEntropyLoss()\n","\n","    for ep in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","        edge_index_aug1 = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=ep)\n","        edge_index_aug2 = aug_random_edge_edge_index(edge_index_np, drop_percent=0.2, seed=ep+999)\n","        rng = np.random.default_rng(ep)\n","        mask = rng.random(features.shape) >= 0.2\n","        features_aug1 = (features * mask.astype(np.float32))\n","        aug_feat2 = features.copy()\n","        drop_feat_num = int(features.shape[0] * features.shape[1] * 0.2)\n","        flat_idx = rng.choice(features.shape[0] * features.shape[1], size=drop_feat_num, replace=False)\n","        rows = (flat_idx // features.shape[1])\n","        cols = (flat_idx % features.shape[1])\n","        aug_feat2[rows, cols] = 0.0\n","        features_aug2 = aug_feat2.astype(np.float32)\n","        node_feats1, edge_index1 = load_data_from_edge_index(features_aug1, edge_index_aug1, device)\n","        data1 = Data(x=node_feats1.to(device), edge_index=edge_index1.to(device))\n","        node_feats2, edge_index2 = load_data_from_edge_index(features_aug2, edge_index_aug2, device)\n","        data2 = Data(x=node_feats2.to(device), edge_index=edge_index2.to(device))\n","        S1, S2, logits1, logits2, l1, l2 = model(data1, data2)\n","        cont_loss = ((l1 + l2) / 2.0).mean()\n","        embeddings = model.online_encoder(data_full)\n","        logits_sup = classifier(embeddings[train_idx_t])\n","        sup_loss = ce_loss(logits_sup, y_tensor[train_idx_t])\n","        unsup_loss = model.loss(A1, logits1)\n","        loss = 0.0001 * cont_loss + sup_loss + unsup_loss\n","        loss.backward()\n","        optimizer.step()\n","        model.update_ma()\n","\n","        if ep % 500 == 0 or ep == 1:\n","            print(f\"Epoch {ep} | Total: {loss.item():.6f} | Cont: {cont_loss.item():.6f} | CE: {sup_loss.item():.6f} | Unsup: {unsup_loss.item():.6f}\")\n","\n","    # --- Eval ---\n","    model.eval()\n","    classifier.eval()\n","    with torch.no_grad():\n","        embeddings_final = model.online_encoder(data_full)\n","        logits_final = classifier(embeddings_final)\n","        probs = nnF.softmax(logits_final, dim=1).cpu().numpy()\n","        y_pred = np.argmax(probs, axis=1)\n","\n","    y_test = y_labels[test_idx]\n","    y_pred_test = y_pred[test_idx]\n","    y_proba_test = probs[test_idx, 1] if probs.shape[1] > 1 else probs[test_idx, 0]\n","\n","    acc = accuracy_score(y_test, y_pred_test)\n","    prec = precision_score(y_test, y_pred_test, zero_division=0)\n","    rec = recall_score(y_test, y_pred_test, zero_division=0)\n","    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n","    try:\n","        loss_val = log_loss(y_test, y_proba_test)\n","    except:\n","        loss_val = np.nan\n","    try:\n","        auc_score = roc_auc_score(y_test, y_proba_test)\n","    except:\n","        auc_score = np.nan\n","\n","    print(f\"Fold {fold+1} → Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} F1={f1:.4f} AUC={auc_score:.4f}\")\n","    accuracies.append(acc)\n","    precisions.append(prec)\n","    recalls.append(rec)\n","    f1_scores.append(f1)\n","    losses.append(loss_val)\n","    all_auc.append(auc_score)\n","\n","print(\"\\n=== Average Results ===\")\n","print(f\"Accuracy: {np.nanmean(accuracies):.4f} ± {np.nanstd(accuracies):.4f}\")\n","print(f\"Precision: {np.nanmean(precisions):.4f} ± {np.nanstd(precisions):.4f}\")\n","print(f\"Recall: {np.nanmean(recalls):.4f} ± {np.nanstd(recalls):.4f}\")\n","print(f\"F1: {np.nanmean(f1_scores):.4f} ± {np.nanstd(f1_scores):.4f}\")\n","print(f\"LogLoss: {np.nanmean(losses):.4f} ± {np.nanstd(losses):.4f}\")\n","print(f\"AUC: {np.nanmean(all_auc):.4f} ± {np.nanstd(all_auc):.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59D1R49oehVd","executionInfo":{"status":"ok","timestamp":1767777355767,"user_tz":-330,"elapsed":4504496,"user":{"displayName":"Saurabh Shigwan","userId":"13392925412739105503"}},"outputId":"e0bbbd6d-631f-4269-d982-6d5bb5a89a4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Fold 1 ===\n","Epoch 0 | Total: 0.582294 | Cont: 6.796734 | CE: 0.704321 | Unsup: -0.122707\n","Epoch 1 | Total: 0.570999 | Cont: 6.814794 | CE: 0.693055 | Unsup: -0.122738\n","Epoch 500 | Total: -0.148498 | Cont: 6.435452 | CE: 0.022205 | Unsup: -0.171347\n","Epoch 1000 | Total: -0.151933 | Cont: 6.526250 | CE: 0.019112 | Unsup: -0.171698\n","Epoch 1500 | Total: -0.159678 | Cont: 6.334260 | CE: 0.014736 | Unsup: -0.175047\n","Fold 1 → Acc=0.6481 Prec=0.9006 Rec=0.5828 F1=0.7077 AUC=0.7780\n","\n","=== Fold 2 ===\n","Epoch 0 | Total: 0.603603 | Cont: 6.709299 | CE: 0.706066 | Unsup: -0.103134\n","Epoch 1 | Total: 0.615411 | Cont: 6.703167 | CE: 0.719847 | Unsup: -0.105106\n","Epoch 500 | Total: -0.174171 | Cont: 6.265163 | CE: 0.000677 | Unsup: -0.175475\n","Epoch 1000 | Total: -0.176779 | Cont: 6.210797 | CE: 0.000298 | Unsup: -0.177698\n","Epoch 1500 | Total: -0.176843 | Cont: 6.220294 | CE: 0.000159 | Unsup: -0.177625\n","Fold 2 → Acc=0.7934 Prec=0.8725 Rec=0.8402 F1=0.8560 AUC=0.8046\n","\n","=== Fold 3 ===\n","Epoch 0 | Total: 0.567700 | Cont: 6.807171 | CE: 0.691994 | Unsup: -0.124974\n","Epoch 1 | Total: 0.544103 | Cont: 6.789695 | CE: 0.668499 | Unsup: -0.125075\n","Epoch 500 | Total: -0.166842 | Cont: 6.361284 | CE: 0.001236 | Unsup: -0.168714\n","Epoch 1000 | Total: -0.175497 | Cont: 6.308799 | CE: 0.000481 | Unsup: -0.176609\n","Epoch 1500 | Total: -0.177725 | Cont: 6.069454 | CE: 0.000139 | Unsup: -0.178471\n","Fold 3 → Acc=0.7564 Prec=0.9500 Rec=0.7037 F1=0.8085 AUC=0.8788\n","\n","=== Fold 4 ===\n","Epoch 0 | Total: 0.602854 | Cont: 6.658339 | CE: 0.712747 | Unsup: -0.110558\n","Epoch 1 | Total: 0.580084 | Cont: 6.652805 | CE: 0.693978 | Unsup: -0.114558\n","Epoch 500 | Total: -0.175022 | Cont: 6.113106 | CE: 0.000458 | Unsup: -0.176091\n","Epoch 1000 | Total: -0.177507 | Cont: 6.011189 | CE: 0.000092 | Unsup: -0.178200\n","Epoch 1500 | Total: -0.178212 | Cont: 5.976250 | CE: 0.000060 | Unsup: -0.178869\n","Fold 4 → Acc=0.7066 Prec=0.9160 Rec=0.6589 F1=0.7664 AUC=0.8307\n","\n","=== Fold 5 ===\n","Epoch 0 | Total: 0.566257 | Cont: 6.741472 | CE: 0.689967 | Unsup: -0.124384\n","Epoch 1 | Total: 0.541734 | Cont: 6.719374 | CE: 0.665429 | Unsup: -0.124368\n","Epoch 500 | Total: -0.173476 | Cont: 6.188026 | CE: 0.001079 | Unsup: -0.175173\n","Epoch 1000 | Total: -0.172467 | Cont: 6.305659 | CE: 0.000883 | Unsup: -0.173981\n","Epoch 1500 | Total: -0.176380 | Cont: 6.180734 | CE: 0.000346 | Unsup: -0.177344\n","Fold 5 → Acc=0.7365 Prec=0.8942 Rec=0.7251 F1=0.8009 AUC=0.8274\n","\n","=== Fold 6 ===\n","Epoch 0 | Total: 0.557648 | Cont: 6.687399 | CE: 0.682131 | Unsup: -0.125152\n","Epoch 1 | Total: 0.505041 | Cont: 6.661576 | CE: 0.629747 | Unsup: -0.125372\n","Epoch 500 | Total: -0.174142 | Cont: 6.227852 | CE: 0.000898 | Unsup: -0.175663\n","Epoch 1000 | Total: -0.175804 | Cont: 6.090032 | CE: 0.001026 | Unsup: -0.177439\n","Epoch 1500 | Total: -0.177897 | Cont: 6.116256 | CE: 0.000115 | Unsup: -0.178623\n","Fold 6 → Acc=0.8134 Prec=0.8775 Rec=0.8655 F1=0.8714 AUC=0.8408\n","\n","=== Fold 7 ===\n","Epoch 0 | Total: 0.602131 | Cont: 6.702299 | CE: 0.726699 | Unsup: -0.125239\n","Epoch 1 | Total: 0.592755 | Cont: 6.752367 | CE: 0.717251 | Unsup: -0.125172\n","Epoch 500 | Total: -0.171060 | Cont: 6.482118 | CE: 0.003295 | Unsup: -0.175004\n","Epoch 1000 | Total: -0.174662 | Cont: 6.163332 | CE: 0.001683 | Unsup: -0.176961\n","Epoch 1500 | Total: -0.175917 | Cont: 6.281270 | CE: 0.000816 | Unsup: -0.177361\n","Fold 7 → Acc=0.7635 Prec=0.9102 Rec=0.7505 F1=0.8226 AUC=0.8604\n","\n","=== Fold 8 ===\n","Epoch 0 | Total: 0.625495 | Cont: 6.784929 | CE: 0.739329 | Unsup: -0.114513\n","Epoch 1 | Total: 0.590464 | Cont: 6.839174 | CE: 0.704551 | Unsup: -0.114771\n","Epoch 500 | Total: -0.159420 | Cont: 6.466362 | CE: 0.006966 | Unsup: -0.167033\n","Epoch 1000 | Total: -0.171498 | Cont: 6.813603 | CE: 0.000667 | Unsup: -0.172846\n","Epoch 1500 | Total: -0.168728 | Cont: 6.656559 | CE: 0.004030 | Unsup: -0.173424\n","Fold 8 → Acc=0.8490 Prec=0.8832 Rec=0.9142 F1=0.8985 AUC=0.8755\n","\n","=== Fold 9 ===\n","Epoch 0 | Total: 0.563681 | Cont: 6.739316 | CE: 0.688379 | Unsup: -0.125372\n","Epoch 1 | Total: 0.531641 | Cont: 6.697723 | CE: 0.656196 | Unsup: -0.125225\n","Epoch 500 | Total: -0.175874 | Cont: 6.330470 | CE: 0.000416 | Unsup: -0.176923\n","Epoch 1000 | Total: -0.177506 | Cont: 6.225848 | CE: 0.000336 | Unsup: -0.178465\n","Epoch 1500 | Total: -0.178335 | Cont: 6.244266 | CE: 0.000169 | Unsup: -0.179128\n","Fold 9 → Acc=0.6823 Prec=0.9096 Rec=0.6277 F1=0.7428 AUC=0.8155\n","\n","=== Fold 10 ===\n","Epoch 0 | Total: 0.611997 | Cont: 6.856931 | CE: 0.723533 | Unsup: -0.112222\n","Epoch 1 | Total: 0.548430 | Cont: 6.801005 | CE: 0.659993 | Unsup: -0.112243\n","Epoch 500 | Total: -0.173790 | Cont: 6.298835 | CE: 0.000813 | Unsup: -0.175232\n","Epoch 1000 | Total: -0.176541 | Cont: 6.253923 | CE: 0.000170 | Unsup: -0.177336\n","Epoch 1500 | Total: -0.176526 | Cont: 6.267458 | CE: 0.000219 | Unsup: -0.177372\n","Fold 10 → Acc=0.7493 Prec=0.8804 Rec=0.7602 F1=0.8159 AUC=0.7953\n","\n","=== Fold 11 ===\n","Epoch 0 | Total: 0.593191 | Cont: 6.742613 | CE: 0.712825 | Unsup: -0.120308\n","Epoch 1 | Total: 0.570545 | Cont: 6.765368 | CE: 0.690957 | Unsup: -0.121088\n","Epoch 500 | Total: -0.175987 | Cont: 6.301040 | CE: 0.000610 | Unsup: -0.177227\n","Epoch 1000 | Total: -0.178772 | Cont: 6.357333 | CE: 0.000104 | Unsup: -0.179513\n","Epoch 1500 | Total: -0.178929 | Cont: 6.331593 | CE: 0.000167 | Unsup: -0.179729\n","Fold 11 → Acc=0.6624 Prec=0.9157 Rec=0.5926 F1=0.7195 AUC=0.8198\n","\n","=== Fold 12 ===\n","Epoch 0 | Total: 0.576963 | Cont: 6.690923 | CE: 0.694314 | Unsup: -0.118020\n","Epoch 1 | Total: 0.578473 | Cont: 6.647288 | CE: 0.696647 | Unsup: -0.118839\n","Epoch 500 | Total: -0.176087 | Cont: 6.219899 | CE: 0.000664 | Unsup: -0.177373\n","Epoch 1000 | Total: -0.177004 | Cont: 6.152172 | CE: 0.000675 | Unsup: -0.178295\n","Epoch 1500 | Total: -0.045895 | Cont: 5.973803 | CE: 0.129558 | Unsup: -0.176050\n","Fold 12 → Acc=0.7479 Prec=0.9179 Rec=0.7193 F1=0.8066 AUC=0.8110\n","\n","=== Fold 13 ===\n","Epoch 0 | Total: 0.608203 | Cont: 6.746856 | CE: 0.731054 | Unsup: -0.123525\n","Epoch 1 | Total: 0.579182 | Cont: 6.746970 | CE: 0.702257 | Unsup: -0.123750\n","Epoch 500 | Total: -0.173836 | Cont: 6.740579 | CE: 0.001472 | Unsup: -0.175982\n","Epoch 1000 | Total: -0.133363 | Cont: 6.517148 | CE: 0.039929 | Unsup: -0.173944\n","Epoch 1500 | Total: -0.175360 | Cont: 6.556256 | CE: 0.001323 | Unsup: -0.177339\n","Fold 13 → Acc=0.7094 Prec=0.8796 Rec=0.6979 F1=0.7783 AUC=0.7814\n","\n","=== Fold 14 ===\n","Epoch 0 | Total: 0.581166 | Cont: 6.780188 | CE: 0.705664 | Unsup: -0.125176\n","Epoch 1 | Total: 0.538474 | Cont: 6.781114 | CE: 0.663231 | Unsup: -0.125435\n","Epoch 500 | Total: -0.163896 | Cont: 6.353878 | CE: 0.008261 | Unsup: -0.172792\n","Epoch 1000 | Total: -0.163085 | Cont: 6.441205 | CE: 0.010419 | Unsup: -0.174148\n","Epoch 1500 | Total: -0.172809 | Cont: 6.451456 | CE: 0.001279 | Unsup: -0.174733\n","Fold 14 → Acc=0.7906 Prec=0.8735 Rec=0.8343 F1=0.8534 AUC=0.7950\n","\n","=== Fold 15 ===\n","Epoch 0 | Total: 0.606425 | Cont: 6.781299 | CE: 0.729438 | Unsup: -0.123691\n","Epoch 1 | Total: 0.580578 | Cont: 6.838750 | CE: 0.703523 | Unsup: -0.123629\n","Epoch 500 | Total: -0.173314 | Cont: 6.390622 | CE: 0.001168 | Unsup: -0.175121\n","Epoch 1000 | Total: -0.176558 | Cont: 6.533551 | CE: 0.000197 | Unsup: -0.177408\n","Epoch 1500 | Total: -0.177991 | Cont: 6.510325 | CE: 0.000171 | Unsup: -0.178814\n","Fold 15 → Acc=0.7721 Prec=0.8624 Rec=0.8187 F1=0.8400 AUC=0.8026\n","\n","=== Fold 16 ===\n","Epoch 0 | Total: 0.585704 | Cont: 6.708061 | CE: 0.709155 | Unsup: -0.124122\n","Epoch 1 | Total: 0.544312 | Cont: 6.681410 | CE: 0.668155 | Unsup: -0.124512\n","Epoch 500 | Total: -0.173594 | Cont: 6.458581 | CE: 0.000652 | Unsup: -0.174892\n","Epoch 1000 | Total: -0.176776 | Cont: 6.454279 | CE: 0.000169 | Unsup: -0.177591\n","Epoch 1500 | Total: -0.177282 | Cont: 6.304677 | CE: 0.000082 | Unsup: -0.177995\n","Fold 16 → Acc=0.7593 Prec=0.9236 Rec=0.7310 F1=0.8161 AUC=0.8470\n","\n","=== Fold 17 ===\n","Epoch 0 | Total: 0.595906 | Cont: 6.744680 | CE: 0.716586 | Unsup: -0.121354\n","Epoch 1 | Total: 0.575305 | Cont: 6.785834 | CE: 0.696829 | Unsup: -0.122203\n","Epoch 500 | Total: -0.161125 | Cont: 6.362468 | CE: 0.011637 | Unsup: -0.173399\n","Epoch 1000 | Total: -0.174808 | Cont: 6.321707 | CE: 0.000583 | Unsup: -0.176023\n","Epoch 1500 | Total: -0.175041 | Cont: 6.268673 | CE: 0.000303 | Unsup: -0.175971\n","Fold 17 → Acc=0.7037 Prec=0.9088 Rec=0.6608 F1=0.7652 AUC=0.7937\n","\n","=== Fold 18 ===\n","Epoch 0 | Total: 0.595334 | Cont: 6.724817 | CE: 0.719706 | Unsup: -0.125045\n","Epoch 1 | Total: 0.592146 | Cont: 6.751373 | CE: 0.716383 | Unsup: -0.124912\n","Epoch 500 | Total: -0.174401 | Cont: 6.335437 | CE: 0.000670 | Unsup: -0.175705\n","Epoch 1000 | Total: -0.175678 | Cont: 6.337240 | CE: 0.000142 | Unsup: -0.176454\n","Epoch 1500 | Total: -0.177446 | Cont: 6.296754 | CE: 0.000087 | Unsup: -0.178163\n","Fold 18 → Acc=0.7293 Prec=0.9027 Rec=0.7057 F1=0.7921 AUC=0.8596\n","\n","=== Fold 19 ===\n","Epoch 0 | Total: 0.579633 | Cont: 6.828346 | CE: 0.700074 | Unsup: -0.121124\n","Epoch 1 | Total: 0.571152 | Cont: 6.801325 | CE: 0.692939 | Unsup: -0.122467\n","Epoch 500 | Total: -0.167179 | Cont: 6.528359 | CE: 0.002678 | Unsup: -0.170510\n","Epoch 1000 | Total: -0.176050 | Cont: 6.225195 | CE: 0.000867 | Unsup: -0.177540\n","Epoch 1500 | Total: -0.175846 | Cont: 6.218986 | CE: 0.000344 | Unsup: -0.176811\n","Fold 19 → Acc=0.8148 Prec=0.9049 Rec=0.8343 F1=0.8682 AUC=0.8735\n","\n","=== Fold 20 ===\n","Epoch 0 | Total: 0.570604 | Cont: 6.881217 | CE: 0.682741 | Unsup: -0.112825\n","Epoch 1 | Total: 0.595336 | Cont: 6.789508 | CE: 0.709955 | Unsup: -0.115298\n","Epoch 500 | Total: -0.166321 | Cont: 6.561547 | CE: 0.000879 | Unsup: -0.167855\n","Epoch 1000 | Total: -0.169822 | Cont: 6.360899 | CE: 0.001638 | Unsup: -0.172096\n","Epoch 1500 | Total: -0.174649 | Cont: 6.404194 | CE: 0.000127 | Unsup: -0.175417\n","Fold 20 → Acc=0.8234 Prec=0.8994 Rec=0.8538 F1=0.8760 AUC=0.8611\n","\n","=== Average Results ===\n","Accuracy: 0.7506 ± 0.0532\n","Precision: 0.8991 ± 0.0208\n","Recall: 0.7439 ± 0.0922\n","F1: 0.8103 ± 0.0515\n","LogLoss: 2.0179 ± 0.4000\n","AUC: 0.8276 ± 0.0319\n"]}]}]}